{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tools import compute_metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning)"
      ],
      "metadata": {
        "id": "9y2o1YaKxYEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка данных"
      ],
      "metadata": {
        "id": "BLsBGB0pxUIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных"
      ],
      "metadata": {
        "id": "bXlNY2IKyx9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://storage.yandexcloud.net/itmo-recsys-public-data/kion_train.zip\"\n",
        "\n",
        "req = requests.get(url, stream=True)\n",
        "\n",
        "with open('kion_train.zip', \"wb\") as fd:\n",
        "    total_size_in_bytes = int(req.headers.get('Content-Length', 0))\n",
        "    progress_bar = tqdm(desc='kion dataset download', total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
        "    for chunk in req.iter_content(chunk_size=2 ** 20):\n",
        "        progress_bar.update(len(chunk))\n",
        "        fd.write(chunk)"
      ],
      "metadata": {
        "id": "j_k3Of0LxT1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49eee0e8-125b-4059-ce62-1b42aef39440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "kion dataset download:  98%|█████████▊| 77.6M/78.8M [00:04<00:00, 20.8MiB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip kion_train.zip"
      ],
      "metadata": {
        "id": "IuSCfTX2x22B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977cf70f-434a-4bc1-c5ea-a9e3bbe05f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  kion_train.zip\n",
            "   creating: kion_train/\n",
            "  inflating: kion_train/interactions.csv  \n",
            "  inflating: __MACOSX/kion_train/._interactions.csv  \n",
            "  inflating: kion_train/users.csv    \n",
            "  inflating: __MACOSX/kion_train/._users.csv  \n",
            "  inflating: kion_train/items.csv    \n",
            "  inflating: __MACOSX/kion_train/._items.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interactions = pd.read_csv('kion_train/interactions.csv')\n",
        "interactions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tJVHc7WXxTgx",
        "outputId": "6a778dfd-e9aa-46f4-ec86-550cbe73d360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
              "0   176549     9506    2021-05-11       4250         72.0\n",
              "1   699317     1659    2021-05-29       8317        100.0\n",
              "2   656683     7107    2021-05-09         10          0.0\n",
              "3   864613     7638    2021-07-05      14483        100.0\n",
              "4   964868     9506    2021-04-30       6725        100.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4426e64-d9ae-4b3b-90a3-29f2fa61b4a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>last_watch_dt</th>\n",
              "      <th>total_dur</th>\n",
              "      <th>watched_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>176549</td>\n",
              "      <td>9506</td>\n",
              "      <td>2021-05-11</td>\n",
              "      <td>4250</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>699317</td>\n",
              "      <td>1659</td>\n",
              "      <td>2021-05-29</td>\n",
              "      <td>8317</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>656683</td>\n",
              "      <td>7107</td>\n",
              "      <td>2021-05-09</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>864613</td>\n",
              "      <td>7638</td>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>14483</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>964868</td>\n",
              "      <td>9506</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>6725</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4426e64-d9ae-4b3b-90a3-29f2fa61b4a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4426e64-d9ae-4b3b-90a3-29f2fa61b4a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4426e64-d9ae-4b3b-90a3-29f2fa61b4a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interactions.drop(interactions[interactions['last_watch_dt'].str.len() != 10].index, inplace=True)\n",
        "interactions['last_watch_dt'] = pd.to_datetime(interactions['last_watch_dt'], format='%Y-%m-%d')\n",
        "max_date = interactions['last_watch_dt'].max()\n",
        "interactions.drop(interactions.query(\"total_dur < 300\").index, inplace=True)\n",
        "interactions['watched_pct'] = np.where(interactions['watched_pct'] > 10, 3, 1)"
      ],
      "metadata": {
        "id": "8CszXTB3xTc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions.user_id.nunique(), interactions.item_id.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVnmXgW9Gr8e",
        "outputId": "5eff180e-5b6b-44fb-e459-38c41db4cada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(809577, 14163)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Преобразование формата данных под BERT4Rec и SasRec"
      ],
      "metadata": {
        "id": "gGvd89ei6Gbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = interactions[interactions['last_watch_dt'] < max_date - pd.Timedelta(days=7)].copy()\n",
        "test = interactions[interactions['last_watch_dt'] >= max_date - pd.Timedelta(days=7)].copy()"
      ],
      "metadata": {
        "id": "Rvn-CQeZxTYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Избавимся от пользователей с историей просмотров < 10\n",
        "train_count = train.groupby('user_id')['item_id'].count()\n",
        "valid_users = train_count[train_count > 20].index\n",
        "\n",
        "train_count = train.groupby('item_id')['user_id'].count()\n",
        "valid_items = train_count[train_count > 10].index\n",
        "\n",
        "train = train[train['user_id'].isin(valid_users)] \n",
        "train = train[train['item_id'].isin(valid_items)] "
      ],
      "metadata": {
        "id": "uN9Yy9kXA5Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cold_users = set(test['user_id']) - set(train['user_id'])\n",
        "\n",
        "# Отбрасываем холодных пользователей\n",
        "test.drop(test[test['user_id'].isin(cold_users)].index, inplace=True)"
      ],
      "metadata": {
        "id": "XG4CAWxNF1Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_idx_map_inv = {idx+1:user_id for idx, user_id in enumerate(np.sort(train.user_id.unique()))}\n",
        "item_idx_map = {item_id:idx+1 for idx, item_id in enumerate(np.sort(train.item_id.unique()))}\n",
        "\n",
        "train.sort_values(by='last_watch_dt', inplace=True)\n",
        "train['item_id'] = train['item_id'].map(lambda x: item_idx_map[x])\n",
        "train_users_items = train.groupby('user_id')['item_id'].apply(list)\n",
        "\n",
        "users_history = pd.DataFrame({\n",
        "    'user_id': np.arange(1, train['user_id'].nunique())\n",
        "})\n",
        "\n",
        "users_history['item_id'] = users_history['user_id'].map(lambda x: train_users_items[user_idx_map_inv[x]])\n",
        "users_history = users_history.explode('item_id')\n",
        "\n",
        "users_history.to_csv('/content/train.txt', sep=' ', index=False, header=False)"
      ],
      "metadata": {
        "id": "6kS5HcJCxTTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT4Rec"
      ],
      "metadata": {
        "id": "Ns0tQdJ9yuwF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er9Bf4LAH4uS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f018aa5f-21e4-4bb8-cd9e-ec4b3ef2ebfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BERT4rec_py3_tf2'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 184 (delta 18), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (184/184), 71.58 MiB | 2.06 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "/content/BERT4rec_py3_tf2/BERT4rec\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Tagirov0/BERT4rec_py3_tf2.git\n",
        "%cd /content/BERT4rec_py3_tf2/BERT4rec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_ml-1m.sh"
      ],
      "metadata": {
        "id": "Dy9OsORDE_g-",
        "outputId": "be56c198-a1c9-40a8-814c-c795791558f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "I0509 15:58:02.642991 140437868455744 basic_session_run_hooks.py:263] loss = 7.177764, step = 295300 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.279\n",
            "I0509 15:58:03.592465 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.279\n",
            "INFO:tensorflow:loss = 5.222242, step = 295400 (0.950 sec)\n",
            "I0509 15:58:03.592834 140437868455744 basic_session_run_hooks.py:263] loss = 5.222242, step = 295400 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.078\n",
            "I0509 15:58:04.562634 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.078\n",
            "INFO:tensorflow:loss = 5.0558815, step = 295500 (0.970 sec)\n",
            "I0509 15:58:04.563043 140437868455744 basic_session_run_hooks.py:263] loss = 5.0558815, step = 295500 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.637\n",
            "I0509 15:58:05.518297 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.637\n",
            "INFO:tensorflow:loss = 8.00245, step = 295600 (0.956 sec)\n",
            "I0509 15:58:05.518658 140437868455744 basic_session_run_hooks.py:263] loss = 8.00245, step = 295600 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.533\n",
            "I0509 15:58:06.512990 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.533\n",
            "INFO:tensorflow:loss = 7.041621, step = 295700 (0.995 sec)\n",
            "I0509 15:58:06.513383 140437868455744 basic_session_run_hooks.py:263] loss = 7.041621, step = 295700 (0.995 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.185\n",
            "I0509 15:58:07.463704 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.185\n",
            "INFO:tensorflow:loss = 7.1220646, step = 295800 (0.951 sec)\n",
            "I0509 15:58:07.464110 140437868455744 basic_session_run_hooks.py:263] loss = 7.1220646, step = 295800 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.021\n",
            "I0509 15:58:08.425049 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.021\n",
            "INFO:tensorflow:loss = 6.6830616, step = 295900 (0.961 sec)\n",
            "I0509 15:58:08.425436 140437868455744 basic_session_run_hooks.py:263] loss = 6.6830616, step = 295900 (0.961 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 296000...\n",
            "I0509 15:58:09.380810 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 296000...\n",
            "INFO:tensorflow:Saving checkpoints for 296000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:58:09.381022 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 296000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 296000...\n",
            "I0509 15:58:09.605411 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 296000...\n",
            "INFO:tensorflow:global_step/sec: 83.8177\n",
            "I0509 15:58:09.618130 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.8177\n",
            "INFO:tensorflow:loss = 6.2546782, step = 296000 (1.193 sec)\n",
            "I0509 15:58:09.618412 140437868455744 basic_session_run_hooks.py:263] loss = 6.2546782, step = 296000 (1.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.061\n",
            "I0509 15:58:10.579102 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.061\n",
            "INFO:tensorflow:loss = 7.3615294, step = 296100 (0.961 sec)\n",
            "I0509 15:58:10.579478 140437868455744 basic_session_run_hooks.py:263] loss = 7.3615294, step = 296100 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 95.0161\n",
            "I0509 15:58:11.631554 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 95.0161\n",
            "INFO:tensorflow:loss = 7.801518, step = 296200 (1.052 sec)\n",
            "I0509 15:58:11.631911 140437868455744 basic_session_run_hooks.py:263] loss = 7.801518, step = 296200 (1.052 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.9296\n",
            "I0509 15:58:13.061572 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 69.9296\n",
            "INFO:tensorflow:loss = 7.63501, step = 296300 (1.430 sec)\n",
            "I0509 15:58:13.061968 140437868455744 basic_session_run_hooks.py:263] loss = 7.63501, step = 296300 (1.430 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.438\n",
            "I0509 15:58:14.019079 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.438\n",
            "INFO:tensorflow:loss = 5.8022695, step = 296400 (0.957 sec)\n",
            "I0509 15:58:14.019351 140437868455744 basic_session_run_hooks.py:263] loss = 5.8022695, step = 296400 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.31\n",
            "I0509 15:58:14.977738 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.31\n",
            "INFO:tensorflow:loss = 7.0496683, step = 296500 (0.959 sec)\n",
            "I0509 15:58:14.978122 140437868455744 basic_session_run_hooks.py:263] loss = 7.0496683, step = 296500 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.086\n",
            "I0509 15:58:15.929352 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.086\n",
            "INFO:tensorflow:loss = 5.8997946, step = 296600 (0.952 sec)\n",
            "I0509 15:58:15.929751 140437868455744 basic_session_run_hooks.py:263] loss = 5.8997946, step = 296600 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.167\n",
            "I0509 15:58:16.898644 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.167\n",
            "INFO:tensorflow:loss = 5.9798636, step = 296700 (0.969 sec)\n",
            "I0509 15:58:16.899021 140437868455744 basic_session_run_hooks.py:263] loss = 5.9798636, step = 296700 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.504\n",
            "I0509 15:58:17.874251 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.504\n",
            "INFO:tensorflow:loss = 6.6980042, step = 296800 (0.976 sec)\n",
            "I0509 15:58:17.874646 140437868455744 basic_session_run_hooks.py:263] loss = 6.6980042, step = 296800 (0.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.916\n",
            "I0509 15:58:18.836533 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.916\n",
            "INFO:tensorflow:loss = 6.6768026, step = 296900 (0.962 sec)\n",
            "I0509 15:58:18.836909 140437868455744 basic_session_run_hooks.py:263] loss = 6.6768026, step = 296900 (0.962 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 297000...\n",
            "I0509 15:58:19.784755 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 297000...\n",
            "INFO:tensorflow:Saving checkpoints for 297000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:58:19.784975 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 297000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 297000...\n",
            "I0509 15:58:20.007255 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 297000...\n",
            "INFO:tensorflow:global_step/sec: 84.4488\n",
            "I0509 15:58:20.020665 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.4488\n",
            "INFO:tensorflow:loss = 6.07319, step = 297000 (1.184 sec)\n",
            "I0509 15:58:20.021046 140437868455744 basic_session_run_hooks.py:263] loss = 6.07319, step = 297000 (1.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.537\n",
            "I0509 15:58:21.005546 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.537\n",
            "INFO:tensorflow:loss = 5.7132564, step = 297100 (0.985 sec)\n",
            "I0509 15:58:21.005924 140437868455744 basic_session_run_hooks.py:263] loss = 5.7132564, step = 297100 (0.985 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.457\n",
            "I0509 15:58:21.972154 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.457\n",
            "INFO:tensorflow:loss = 6.3251557, step = 297200 (0.967 sec)\n",
            "I0509 15:58:21.972425 140437868455744 basic_session_run_hooks.py:263] loss = 6.3251557, step = 297200 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.808\n",
            "I0509 15:58:22.935441 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.808\n",
            "INFO:tensorflow:loss = 6.714627, step = 297300 (0.963 sec)\n",
            "I0509 15:58:22.935798 140437868455744 basic_session_run_hooks.py:263] loss = 6.714627, step = 297300 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.9102\n",
            "I0509 15:58:24.307010 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 72.9102\n",
            "INFO:tensorflow:loss = 7.6553483, step = 297400 (1.372 sec)\n",
            "I0509 15:58:24.307348 140437868455744 basic_session_run_hooks.py:263] loss = 7.6553483, step = 297400 (1.372 sec)\n",
            "INFO:tensorflow:global_step/sec: 92.6948\n",
            "I0509 15:58:25.385802 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 92.6948\n",
            "INFO:tensorflow:loss = 6.6555243, step = 297500 (1.079 sec)\n",
            "I0509 15:58:25.386190 140437868455744 basic_session_run_hooks.py:263] loss = 6.6555243, step = 297500 (1.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.542\n",
            "I0509 15:58:26.342355 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.542\n",
            "INFO:tensorflow:loss = 5.9451776, step = 297600 (0.957 sec)\n",
            "I0509 15:58:26.342718 140437868455744 basic_session_run_hooks.py:263] loss = 5.9451776, step = 297600 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.317\n",
            "I0509 15:58:27.300968 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.317\n",
            "INFO:tensorflow:loss = 7.235748, step = 297700 (0.959 sec)\n",
            "I0509 15:58:27.301353 140437868455744 basic_session_run_hooks.py:263] loss = 7.235748, step = 297700 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.964\n",
            "I0509 15:58:28.262844 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.964\n",
            "INFO:tensorflow:loss = 7.37486, step = 297800 (0.962 sec)\n",
            "I0509 15:58:28.263241 140437868455744 basic_session_run_hooks.py:263] loss = 7.37486, step = 297800 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.152\n",
            "I0509 15:58:29.222978 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.152\n",
            "INFO:tensorflow:loss = 6.0304313, step = 297900 (0.960 sec)\n",
            "I0509 15:58:29.223349 140437868455744 basic_session_run_hooks.py:263] loss = 6.0304313, step = 297900 (0.960 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 298000...\n",
            "I0509 15:58:30.191088 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 298000...\n",
            "INFO:tensorflow:Saving checkpoints for 298000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:58:30.191293 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 298000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 298000...\n",
            "I0509 15:58:30.417715 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 298000...\n",
            "INFO:tensorflow:global_step/sec: 82.4328\n",
            "I0509 15:58:30.436092 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.4328\n",
            "INFO:tensorflow:loss = 6.2421837, step = 298000 (1.213 sec)\n",
            "I0509 15:58:30.436443 140437868455744 basic_session_run_hooks.py:263] loss = 6.2421837, step = 298000 (1.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.06\n",
            "I0509 15:58:31.397083 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.06\n",
            "INFO:tensorflow:loss = 6.1817865, step = 298100 (0.961 sec)\n",
            "I0509 15:58:31.397460 140437868455744 basic_session_run_hooks.py:263] loss = 6.1817865, step = 298100 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.328\n",
            "I0509 15:58:32.355584 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.328\n",
            "INFO:tensorflow:loss = 5.8599625, step = 298200 (0.959 sec)\n",
            "I0509 15:58:32.355963 140437868455744 basic_session_run_hooks.py:263] loss = 5.8599625, step = 298200 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.061\n",
            "I0509 15:58:33.316566 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.061\n",
            "INFO:tensorflow:loss = 6.886373, step = 298300 (0.961 sec)\n",
            "I0509 15:58:33.316950 140437868455744 basic_session_run_hooks.py:263] loss = 6.886373, step = 298300 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.596\n",
            "I0509 15:58:34.272627 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.596\n",
            "INFO:tensorflow:loss = 7.036855, step = 298400 (0.956 sec)\n",
            "I0509 15:58:34.273009 140437868455744 basic_session_run_hooks.py:263] loss = 7.036855, step = 298400 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.8785\n",
            "I0509 15:58:35.493975 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.8785\n",
            "INFO:tensorflow:loss = 6.21985, step = 298500 (1.221 sec)\n",
            "I0509 15:58:35.494275 140437868455744 basic_session_run_hooks.py:263] loss = 6.21985, step = 298500 (1.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.974\n",
            "I0509 15:58:36.684787 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.974\n",
            "INFO:tensorflow:loss = 5.8804, step = 298600 (1.191 sec)\n",
            "I0509 15:58:36.685149 140437868455744 basic_session_run_hooks.py:263] loss = 5.8804, step = 298600 (1.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.9\n",
            "I0509 15:58:37.638091 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.9\n",
            "INFO:tensorflow:loss = 7.3233314, step = 298700 (0.953 sec)\n",
            "I0509 15:58:37.638469 140437868455744 basic_session_run_hooks.py:263] loss = 7.3233314, step = 298700 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.438\n",
            "I0509 15:58:38.586520 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.438\n",
            "INFO:tensorflow:loss = 4.7084374, step = 298800 (0.948 sec)\n",
            "I0509 15:58:38.586897 140437868455744 basic_session_run_hooks.py:263] loss = 4.7084374, step = 298800 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.048\n",
            "I0509 15:58:39.556944 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.048\n",
            "INFO:tensorflow:loss = 6.7632136, step = 298900 (0.970 sec)\n",
            "I0509 15:58:39.557338 140437868455744 basic_session_run_hooks.py:263] loss = 6.7632136, step = 298900 (0.970 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 299000...\n",
            "I0509 15:58:40.482510 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 299000...\n",
            "INFO:tensorflow:Saving checkpoints for 299000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:58:40.482718 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 299000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 299000...\n",
            "I0509 15:58:40.709827 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 299000...\n",
            "INFO:tensorflow:global_step/sec: 85.8218\n",
            "I0509 15:58:40.722134 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.8218\n",
            "INFO:tensorflow:loss = 7.1696987, step = 299000 (1.165 sec)\n",
            "I0509 15:58:40.722476 140437868455744 basic_session_run_hooks.py:263] loss = 7.1696987, step = 299000 (1.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.652\n",
            "I0509 15:58:41.686930 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.652\n",
            "INFO:tensorflow:loss = 6.5847235, step = 299100 (0.965 sec)\n",
            "I0509 15:58:41.687336 140437868455744 basic_session_run_hooks.py:263] loss = 6.5847235, step = 299100 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.128\n",
            "I0509 15:58:42.666081 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.128\n",
            "INFO:tensorflow:loss = 6.7220845, step = 299200 (0.979 sec)\n",
            "I0509 15:58:42.666465 140437868455744 basic_session_run_hooks.py:263] loss = 6.7220845, step = 299200 (0.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.132\n",
            "I0509 15:58:43.664752 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.132\n",
            "INFO:tensorflow:loss = 5.0172577, step = 299300 (0.999 sec)\n",
            "I0509 15:58:43.665044 140437868455744 basic_session_run_hooks.py:263] loss = 5.0172577, step = 299300 (0.999 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.848\n",
            "I0509 15:58:44.627699 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.848\n",
            "INFO:tensorflow:loss = 6.9704723, step = 299400 (0.963 sec)\n",
            "I0509 15:58:44.628122 140437868455744 basic_session_run_hooks.py:263] loss = 6.9704723, step = 299400 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.148\n",
            "I0509 15:58:45.578738 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.148\n",
            "INFO:tensorflow:loss = 6.3648157, step = 299500 (0.951 sec)\n",
            "I0509 15:58:45.579016 140437868455744 basic_session_run_hooks.py:263] loss = 6.3648157, step = 299500 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 90.2065\n",
            "I0509 15:58:46.687311 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 90.2065\n",
            "INFO:tensorflow:loss = 6.9902034, step = 299600 (1.109 sec)\n",
            "I0509 15:58:46.687661 140437868455744 basic_session_run_hooks.py:263] loss = 6.9902034, step = 299600 (1.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.0557\n",
            "I0509 15:58:47.968441 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 78.0557\n",
            "INFO:tensorflow:loss = 7.1480093, step = 299700 (1.281 sec)\n",
            "I0509 15:58:47.968729 140437868455744 basic_session_run_hooks.py:263] loss = 7.1480093, step = 299700 (1.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.351\n",
            "I0509 15:58:48.917654 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.351\n",
            "INFO:tensorflow:loss = 6.63587, step = 299800 (0.950 sec)\n",
            "I0509 15:58:48.918589 140437868455744 basic_session_run_hooks.py:263] loss = 6.63587, step = 299800 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.559\n",
            "I0509 15:58:49.874036 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.559\n",
            "INFO:tensorflow:loss = 6.65686, step = 299900 (0.956 sec)\n",
            "I0509 15:58:49.874345 140437868455744 basic_session_run_hooks.py:263] loss = 6.65686, step = 299900 (0.956 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 300000...\n",
            "I0509 15:58:50.834110 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 300000...\n",
            "INFO:tensorflow:Saving checkpoints for 300000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:58:50.834319 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 300000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 300000...\n",
            "I0509 15:58:51.074844 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 300000...\n",
            "INFO:tensorflow:global_step/sec: 82.4364\n",
            "I0509 15:58:51.087119 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.4364\n",
            "INFO:tensorflow:loss = 7.2712736, step = 300000 (1.213 sec)\n",
            "I0509 15:58:51.087513 140437868455744 basic_session_run_hooks.py:263] loss = 7.2712736, step = 300000 (1.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.528\n",
            "I0509 15:58:52.072037 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.528\n",
            "INFO:tensorflow:loss = 7.244646, step = 300100 (0.985 sec)\n",
            "I0509 15:58:52.072443 140437868455744 basic_session_run_hooks.py:263] loss = 7.244646, step = 300100 (0.985 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.93\n",
            "I0509 15:58:53.062841 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.93\n",
            "INFO:tensorflow:loss = 6.828319, step = 300200 (0.991 sec)\n",
            "I0509 15:58:53.063142 140437868455744 basic_session_run_hooks.py:263] loss = 6.828319, step = 300200 (0.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.127\n",
            "I0509 15:58:54.032506 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.127\n",
            "INFO:tensorflow:loss = 5.4019856, step = 300300 (0.970 sec)\n",
            "I0509 15:58:54.032788 140437868455744 basic_session_run_hooks.py:263] loss = 5.4019856, step = 300300 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.771\n",
            "I0509 15:58:54.977966 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.771\n",
            "INFO:tensorflow:loss = 7.4796157, step = 300400 (0.946 sec)\n",
            "I0509 15:58:54.978343 140437868455744 basic_session_run_hooks.py:263] loss = 7.4796157, step = 300400 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.981\n",
            "I0509 15:58:55.921603 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.981\n",
            "INFO:tensorflow:loss = 8.471477, step = 300500 (0.944 sec)\n",
            "I0509 15:58:55.921988 140437868455744 basic_session_run_hooks.py:263] loss = 8.471477, step = 300500 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.986\n",
            "I0509 15:58:56.865022 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.986\n",
            "INFO:tensorflow:loss = 7.0735326, step = 300600 (0.945 sec)\n",
            "I0509 15:58:56.867246 140437868455744 basic_session_run_hooks.py:263] loss = 7.0735326, step = 300600 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.817\n",
            "I0509 15:58:57.837648 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.817\n",
            "INFO:tensorflow:loss = 5.996896, step = 300700 (0.971 sec)\n",
            "I0509 15:58:57.837954 140437868455744 basic_session_run_hooks.py:263] loss = 5.996896, step = 300700 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9458\n",
            "I0509 15:58:59.227583 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 71.9458\n",
            "INFO:tensorflow:loss = 5.3612366, step = 300800 (1.390 sec)\n",
            "I0509 15:58:59.227873 140437868455744 basic_session_run_hooks.py:263] loss = 5.3612366, step = 300800 (1.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.901\n",
            "I0509 15:59:00.208932 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.901\n",
            "INFO:tensorflow:loss = 6.9090123, step = 300900 (0.981 sec)\n",
            "I0509 15:59:00.209231 140437868455744 basic_session_run_hooks.py:263] loss = 6.9090123, step = 300900 (0.981 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 301000...\n",
            "I0509 15:59:01.146849 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 301000...\n",
            "INFO:tensorflow:Saving checkpoints for 301000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:59:01.147042 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 301000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 301000...\n",
            "I0509 15:59:01.355667 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 301000...\n",
            "INFO:tensorflow:global_step/sec: 86.2837\n",
            "I0509 15:59:01.367882 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.2837\n",
            "INFO:tensorflow:loss = 7.115633, step = 301000 (1.159 sec)\n",
            "I0509 15:59:01.368144 140437868455744 basic_session_run_hooks.py:263] loss = 7.115633, step = 301000 (1.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.729\n",
            "I0509 15:59:02.350883 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.729\n",
            "INFO:tensorflow:loss = 6.0451345, step = 301100 (0.983 sec)\n",
            "I0509 15:59:02.351247 140437868455744 basic_session_run_hooks.py:263] loss = 6.0451345, step = 301100 (0.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.186\n",
            "I0509 15:59:03.301588 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.186\n",
            "INFO:tensorflow:loss = 6.400183, step = 301200 (0.951 sec)\n",
            "I0509 15:59:03.301920 140437868455744 basic_session_run_hooks.py:263] loss = 6.400183, step = 301200 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.741\n",
            "I0509 15:59:04.247300 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.741\n",
            "INFO:tensorflow:loss = 7.175349, step = 301300 (0.946 sec)\n",
            "I0509 15:59:04.247677 140437868455744 basic_session_run_hooks.py:263] loss = 7.175349, step = 301300 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.979\n",
            "I0509 15:59:05.190884 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.979\n",
            "INFO:tensorflow:loss = 4.7374406, step = 301400 (0.944 sec)\n",
            "I0509 15:59:05.191182 140437868455744 basic_session_run_hooks.py:263] loss = 4.7374406, step = 301400 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.04\n",
            "I0509 15:59:06.142899 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.04\n",
            "INFO:tensorflow:loss = 7.2401686, step = 301500 (0.952 sec)\n",
            "I0509 15:59:06.143260 140437868455744 basic_session_run_hooks.py:263] loss = 7.2401686, step = 301500 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.854\n",
            "I0509 15:59:07.105777 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.854\n",
            "INFO:tensorflow:loss = 7.3572483, step = 301600 (0.963 sec)\n",
            "I0509 15:59:07.106055 140437868455744 basic_session_run_hooks.py:263] loss = 7.3572483, step = 301600 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.008\n",
            "I0509 15:59:08.067243 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.008\n",
            "INFO:tensorflow:loss = 7.346718, step = 301700 (0.962 sec)\n",
            "I0509 15:59:08.067610 140437868455744 basic_session_run_hooks.py:263] loss = 7.346718, step = 301700 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.897\n",
            "I0509 15:59:09.029739 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.897\n",
            "INFO:tensorflow:loss = 7.0240984, step = 301800 (0.962 sec)\n",
            "I0509 15:59:09.030015 140437868455744 basic_session_run_hooks.py:263] loss = 7.0240984, step = 301800 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.6407\n",
            "I0509 15:59:10.254635 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.6407\n",
            "INFO:tensorflow:loss = 6.4266706, step = 301900 (1.225 sec)\n",
            "I0509 15:59:10.255004 140437868455744 basic_session_run_hooks.py:263] loss = 6.4266706, step = 301900 (1.225 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 302000...\n",
            "I0509 15:59:11.412011 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 302000...\n",
            "INFO:tensorflow:Saving checkpoints for 302000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:59:11.412323 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 302000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 302000...\n",
            "I0509 15:59:11.622082 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 302000...\n",
            "INFO:tensorflow:global_step/sec: 72.4861\n",
            "I0509 15:59:11.634191 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 72.4861\n",
            "INFO:tensorflow:loss = 6.5736475, step = 302000 (1.379 sec)\n",
            "I0509 15:59:11.634434 140437868455744 basic_session_run_hooks.py:263] loss = 6.5736475, step = 302000 (1.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.085\n",
            "I0509 15:59:12.594963 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.085\n",
            "INFO:tensorflow:loss = 6.9599366, step = 302100 (0.961 sec)\n",
            "I0509 15:59:12.595356 140437868455744 basic_session_run_hooks.py:263] loss = 6.9599366, step = 302100 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.999\n",
            "I0509 15:59:13.547348 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.999\n",
            "INFO:tensorflow:loss = 4.4816146, step = 302200 (0.952 sec)\n",
            "I0509 15:59:13.547727 140437868455744 basic_session_run_hooks.py:263] loss = 4.4816146, step = 302200 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.364\n",
            "I0509 15:59:14.543720 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.364\n",
            "INFO:tensorflow:loss = 7.4782743, step = 302300 (0.996 sec)\n",
            "I0509 15:59:14.544015 140437868455744 basic_session_run_hooks.py:263] loss = 7.4782743, step = 302300 (0.996 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.929\n",
            "I0509 15:59:15.496732 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.929\n",
            "INFO:tensorflow:loss = 4.4367476, step = 302400 (0.953 sec)\n",
            "I0509 15:59:15.497121 140437868455744 basic_session_run_hooks.py:263] loss = 4.4367476, step = 302400 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.655\n",
            "I0509 15:59:16.452263 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.655\n",
            "INFO:tensorflow:loss = 6.7458563, step = 302500 (0.956 sec)\n",
            "I0509 15:59:16.452630 140437868455744 basic_session_run_hooks.py:263] loss = 6.7458563, step = 302500 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.928\n",
            "I0509 15:59:17.405316 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.928\n",
            "INFO:tensorflow:loss = 7.405066, step = 302600 (0.953 sec)\n",
            "I0509 15:59:17.405696 140437868455744 basic_session_run_hooks.py:263] loss = 7.405066, step = 302600 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.78\n",
            "I0509 15:59:18.378252 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.78\n",
            "INFO:tensorflow:loss = 6.6171837, step = 302700 (0.973 sec)\n",
            "I0509 15:59:18.378624 140437868455744 basic_session_run_hooks.py:263] loss = 6.6171837, step = 302700 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.749\n",
            "I0509 15:59:19.323886 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.749\n",
            "INFO:tensorflow:loss = 7.397292, step = 302800 (0.946 sec)\n",
            "I0509 15:59:19.324270 140437868455744 basic_session_run_hooks.py:263] loss = 7.397292, step = 302800 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.579\n",
            "I0509 15:59:20.271044 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.579\n",
            "INFO:tensorflow:loss = 7.146417, step = 302900 (0.947 sec)\n",
            "I0509 15:59:20.271463 140437868455744 basic_session_run_hooks.py:263] loss = 7.146417, step = 302900 (0.947 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 303000...\n",
            "I0509 15:59:21.341706 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 303000...\n",
            "INFO:tensorflow:Saving checkpoints for 303000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:59:21.341912 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 303000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 303000...\n",
            "I0509 15:59:21.731427 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 303000...\n",
            "INFO:tensorflow:global_step/sec: 67.679\n",
            "I0509 15:59:21.748602 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 67.679\n",
            "INFO:tensorflow:loss = 8.0693245, step = 303000 (1.477 sec)\n",
            "I0509 15:59:21.748870 140437868455744 basic_session_run_hooks.py:263] loss = 8.0693245, step = 303000 (1.477 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.457\n",
            "I0509 15:59:22.991493 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 80.457\n",
            "INFO:tensorflow:loss = 7.395198, step = 303100 (1.243 sec)\n",
            "I0509 15:59:22.991873 140437868455744 basic_session_run_hooks.py:263] loss = 7.395198, step = 303100 (1.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.824\n",
            "I0509 15:59:23.964034 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.824\n",
            "INFO:tensorflow:loss = 7.3172765, step = 303200 (0.973 sec)\n",
            "I0509 15:59:23.964423 140437868455744 basic_session_run_hooks.py:263] loss = 7.3172765, step = 303200 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.299\n",
            "I0509 15:59:24.913725 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.299\n",
            "INFO:tensorflow:loss = 5.640012, step = 303300 (0.950 sec)\n",
            "I0509 15:59:24.914133 140437868455744 basic_session_run_hooks.py:263] loss = 5.640012, step = 303300 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.57\n",
            "I0509 15:59:25.860960 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.57\n",
            "INFO:tensorflow:loss = 5.5860662, step = 303400 (0.947 sec)\n",
            "I0509 15:59:25.861248 140437868455744 basic_session_run_hooks.py:263] loss = 5.5860662, step = 303400 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.178\n",
            "I0509 15:59:26.820846 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.178\n",
            "INFO:tensorflow:loss = 7.0802355, step = 303500 (0.960 sec)\n",
            "I0509 15:59:26.821145 140437868455744 basic_session_run_hooks.py:263] loss = 7.0802355, step = 303500 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.237\n",
            "I0509 15:59:27.789491 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.237\n",
            "INFO:tensorflow:loss = 6.902109, step = 303600 (0.969 sec)\n",
            "I0509 15:59:27.789834 140437868455744 basic_session_run_hooks.py:263] loss = 6.902109, step = 303600 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.709\n",
            "I0509 15:59:28.763132 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.709\n",
            "INFO:tensorflow:loss = 6.232381, step = 303700 (0.974 sec)\n",
            "I0509 15:59:28.763406 140437868455744 basic_session_run_hooks.py:263] loss = 6.232381, step = 303700 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.038\n",
            "I0509 15:59:29.724301 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.038\n",
            "INFO:tensorflow:loss = 5.4902196, step = 303800 (0.961 sec)\n",
            "I0509 15:59:29.724667 140437868455744 basic_session_run_hooks.py:263] loss = 5.4902196, step = 303800 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.69\n",
            "I0509 15:59:30.679502 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.69\n",
            "INFO:tensorflow:loss = 6.8438163, step = 303900 (0.955 sec)\n",
            "I0509 15:59:30.679784 140437868455744 basic_session_run_hooks.py:263] loss = 6.8438163, step = 303900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 304000...\n",
            "I0509 15:59:31.614955 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 304000...\n",
            "INFO:tensorflow:Saving checkpoints for 304000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:59:31.615166 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 304000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 304000...\n",
            "I0509 15:59:31.819946 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 304000...\n",
            "INFO:tensorflow:global_step/sec: 86.7813\n",
            "I0509 15:59:31.831797 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.7813\n",
            "INFO:tensorflow:loss = 6.5072703, step = 304000 (1.152 sec)\n",
            "I0509 15:59:31.832047 140437868455744 basic_session_run_hooks.py:263] loss = 6.5072703, step = 304000 (1.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 92.9176\n",
            "I0509 15:59:32.908075 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 92.9176\n",
            "INFO:tensorflow:loss = 6.7539124, step = 304100 (1.076 sec)\n",
            "I0509 15:59:32.908472 140437868455744 basic_session_run_hooks.py:263] loss = 6.7539124, step = 304100 (1.076 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.5613\n",
            "I0509 15:59:34.231501 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 75.5613\n",
            "INFO:tensorflow:loss = 5.4982886, step = 304200 (1.323 sec)\n",
            "I0509 15:59:34.231785 140437868455744 basic_session_run_hooks.py:263] loss = 5.4982886, step = 304200 (1.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.73\n",
            "I0509 15:59:35.186322 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.73\n",
            "INFO:tensorflow:loss = 7.007057, step = 304300 (0.955 sec)\n",
            "I0509 15:59:35.186714 140437868455744 basic_session_run_hooks.py:263] loss = 7.007057, step = 304300 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.01\n",
            "I0509 15:59:36.138588 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.01\n",
            "INFO:tensorflow:loss = 6.6447935, step = 304400 (0.952 sec)\n",
            "I0509 15:59:36.138871 140437868455744 basic_session_run_hooks.py:263] loss = 6.6447935, step = 304400 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.693\n",
            "I0509 15:59:37.121961 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.693\n",
            "INFO:tensorflow:loss = 3.8524349, step = 304500 (0.984 sec)\n",
            "I0509 15:59:37.122475 140437868455744 basic_session_run_hooks.py:263] loss = 3.8524349, step = 304500 (0.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.843\n",
            "I0509 15:59:38.094307 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.843\n",
            "INFO:tensorflow:loss = 6.7296586, step = 304600 (0.972 sec)\n",
            "I0509 15:59:38.094699 140437868455744 basic_session_run_hooks.py:263] loss = 6.7296586, step = 304600 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.631\n",
            "I0509 15:59:39.050043 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.631\n",
            "INFO:tensorflow:loss = 7.148345, step = 304700 (0.956 sec)\n",
            "I0509 15:59:39.050426 140437868455744 basic_session_run_hooks.py:263] loss = 7.148345, step = 304700 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.885\n",
            "I0509 15:59:40.041276 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.885\n",
            "INFO:tensorflow:loss = 7.8755274, step = 304800 (0.991 sec)\n",
            "I0509 15:59:40.041635 140437868455744 basic_session_run_hooks.py:263] loss = 7.8755274, step = 304800 (0.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.471\n",
            "I0509 15:59:41.007716 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.471\n",
            "INFO:tensorflow:loss = 6.2620397, step = 304900 (0.966 sec)\n",
            "I0509 15:59:41.008114 140437868455744 basic_session_run_hooks.py:263] loss = 6.2620397, step = 304900 (0.966 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 305000...\n",
            "I0509 15:59:41.976677 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 305000...\n",
            "INFO:tensorflow:Saving checkpoints for 305000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:59:41.976887 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 305000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 305000...\n",
            "I0509 15:59:42.194708 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 305000...\n",
            "INFO:tensorflow:global_step/sec: 83.1194\n",
            "I0509 15:59:42.210802 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.1194\n",
            "INFO:tensorflow:loss = 6.1673856, step = 305000 (1.203 sec)\n",
            "I0509 15:59:42.211155 140437868455744 basic_session_run_hooks.py:263] loss = 6.1673856, step = 305000 (1.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.019\n",
            "I0509 15:59:43.181514 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.019\n",
            "INFO:tensorflow:loss = 7.1406646, step = 305100 (0.971 sec)\n",
            "I0509 15:59:43.181882 140437868455744 basic_session_run_hooks.py:263] loss = 7.1406646, step = 305100 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.105\n",
            "I0509 15:59:44.142203 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.105\n",
            "INFO:tensorflow:loss = 4.918757, step = 305200 (0.961 sec)\n",
            "I0509 15:59:44.142633 140437868455744 basic_session_run_hooks.py:263] loss = 4.918757, step = 305200 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.4607\n",
            "I0509 15:59:45.503369 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.4607\n",
            "INFO:tensorflow:loss = 5.154411, step = 305300 (1.361 sec)\n",
            "I0509 15:59:45.503678 140437868455744 basic_session_run_hooks.py:263] loss = 5.154411, step = 305300 (1.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.3364\n",
            "I0509 15:59:46.541395 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 96.3364\n",
            "INFO:tensorflow:loss = 7.370469, step = 305400 (1.038 sec)\n",
            "I0509 15:59:46.541804 140437868455744 basic_session_run_hooks.py:263] loss = 7.370469, step = 305400 (1.038 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.071\n",
            "I0509 15:59:47.521098 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.071\n",
            "INFO:tensorflow:loss = 6.386296, step = 305500 (0.980 sec)\n",
            "I0509 15:59:47.521380 140437868455744 basic_session_run_hooks.py:263] loss = 6.386296, step = 305500 (0.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.298\n",
            "I0509 15:59:48.489183 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.298\n",
            "INFO:tensorflow:loss = 7.938652, step = 305600 (0.968 sec)\n",
            "I0509 15:59:48.489458 140437868455744 basic_session_run_hooks.py:263] loss = 7.938652, step = 305600 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.313\n",
            "I0509 15:59:49.438711 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.313\n",
            "INFO:tensorflow:loss = 6.7832704, step = 305700 (0.950 sec)\n",
            "I0509 15:59:49.439094 140437868455744 basic_session_run_hooks.py:263] loss = 6.7832704, step = 305700 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.195\n",
            "I0509 15:59:50.380378 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.195\n",
            "INFO:tensorflow:loss = 5.2629647, step = 305800 (0.942 sec)\n",
            "I0509 15:59:50.380727 140437868455744 basic_session_run_hooks.py:263] loss = 5.2629647, step = 305800 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.96\n",
            "I0509 15:59:51.351633 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.96\n",
            "INFO:tensorflow:loss = 6.4072213, step = 305900 (0.971 sec)\n",
            "I0509 15:59:51.352009 140437868455744 basic_session_run_hooks.py:263] loss = 6.4072213, step = 305900 (0.971 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 306000...\n",
            "I0509 15:59:52.311849 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 306000...\n",
            "INFO:tensorflow:Saving checkpoints for 306000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 15:59:52.312050 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 306000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 306000...\n",
            "I0509 15:59:52.537813 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 306000...\n",
            "INFO:tensorflow:global_step/sec: 83.2978\n",
            "I0509 15:59:52.552145 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.2978\n",
            "INFO:tensorflow:loss = 6.5244374, step = 306000 (1.200 sec)\n",
            "I0509 15:59:52.552500 140437868455744 basic_session_run_hooks.py:263] loss = 6.5244374, step = 306000 (1.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.702\n",
            "I0509 15:59:53.516430 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.702\n",
            "INFO:tensorflow:loss = 5.5682106, step = 306100 (0.964 sec)\n",
            "I0509 15:59:53.516803 140437868455744 basic_session_run_hooks.py:263] loss = 5.5682106, step = 306100 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.357\n",
            "I0509 15:59:54.483973 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.357\n",
            "INFO:tensorflow:loss = 5.9800377, step = 306200 (0.968 sec)\n",
            "I0509 15:59:54.484368 140437868455744 basic_session_run_hooks.py:263] loss = 5.9800377, step = 306200 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.676\n",
            "I0509 15:59:55.430252 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.676\n",
            "INFO:tensorflow:loss = 7.5600076, step = 306300 (0.946 sec)\n",
            "I0509 15:59:55.430526 140437868455744 basic_session_run_hooks.py:263] loss = 7.5600076, step = 306300 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.0403\n",
            "I0509 15:59:56.649183 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.0403\n",
            "INFO:tensorflow:loss = 6.4376464, step = 306400 (1.219 sec)\n",
            "I0509 15:59:56.649479 140437868455744 basic_session_run_hooks.py:263] loss = 6.4376464, step = 306400 (1.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 86.8595\n",
            "I0509 15:59:57.800451 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.8595\n",
            "INFO:tensorflow:loss = 6.9382324, step = 306500 (1.151 sec)\n",
            "I0509 15:59:57.800808 140437868455744 basic_session_run_hooks.py:263] loss = 6.9382324, step = 306500 (1.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.377\n",
            "I0509 15:59:58.749424 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.377\n",
            "INFO:tensorflow:loss = 7.132368, step = 306600 (0.949 sec)\n",
            "I0509 15:59:58.749692 140437868455744 basic_session_run_hooks.py:263] loss = 7.132368, step = 306600 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.136\n",
            "I0509 15:59:59.709698 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.136\n",
            "INFO:tensorflow:loss = 4.8387947, step = 306700 (0.960 sec)\n",
            "I0509 15:59:59.710092 140437868455744 basic_session_run_hooks.py:263] loss = 4.8387947, step = 306700 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.393\n",
            "I0509 16:00:00.658537 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.393\n",
            "INFO:tensorflow:loss = 6.80541, step = 306800 (0.949 sec)\n",
            "I0509 16:00:00.658810 140437868455744 basic_session_run_hooks.py:263] loss = 6.80541, step = 306800 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.657\n",
            "I0509 16:00:01.614044 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.657\n",
            "INFO:tensorflow:loss = 5.8173685, step = 306900 (0.956 sec)\n",
            "I0509 16:00:01.614433 140437868455744 basic_session_run_hooks.py:263] loss = 5.8173685, step = 306900 (0.956 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 307000...\n",
            "I0509 16:00:02.556578 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 307000...\n",
            "INFO:tensorflow:Saving checkpoints for 307000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:00:02.556770 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 307000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 307000...\n",
            "I0509 16:00:02.814361 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 307000...\n",
            "INFO:tensorflow:global_step/sec: 82.4876\n",
            "I0509 16:00:02.826314 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.4876\n",
            "INFO:tensorflow:loss = 4.4472957, step = 307000 (1.212 sec)\n",
            "I0509 16:00:02.826644 140437868455744 basic_session_run_hooks.py:263] loss = 4.4472957, step = 307000 (1.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.428\n",
            "I0509 16:00:03.793216 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.428\n",
            "INFO:tensorflow:loss = 6.4191604, step = 307100 (0.967 sec)\n",
            "I0509 16:00:03.793597 140437868455744 basic_session_run_hooks.py:263] loss = 6.4191604, step = 307100 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.621\n",
            "I0509 16:00:04.739985 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.621\n",
            "INFO:tensorflow:loss = 5.788477, step = 307200 (0.947 sec)\n",
            "I0509 16:00:04.740361 140437868455744 basic_session_run_hooks.py:263] loss = 5.788477, step = 307200 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.664\n",
            "I0509 16:00:05.704642 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.664\n",
            "INFO:tensorflow:loss = 6.3314857, step = 307300 (0.965 sec)\n",
            "I0509 16:00:05.705011 140437868455744 basic_session_run_hooks.py:263] loss = 6.3314857, step = 307300 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.206\n",
            "I0509 16:00:06.655188 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.206\n",
            "INFO:tensorflow:loss = 5.3869486, step = 307400 (0.951 sec)\n",
            "I0509 16:00:06.655569 140437868455744 basic_session_run_hooks.py:263] loss = 5.3869486, step = 307400 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 89.9505\n",
            "I0509 16:00:07.766897 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 89.9505\n",
            "INFO:tensorflow:loss = 6.8448896, step = 307500 (1.112 sec)\n",
            "I0509 16:00:07.767279 140437868455744 basic_session_run_hooks.py:263] loss = 6.8448896, step = 307500 (1.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.9554\n",
            "I0509 16:00:09.066327 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 76.9554\n",
            "INFO:tensorflow:loss = 6.3346643, step = 307600 (1.299 sec)\n",
            "I0509 16:00:09.066692 140437868455744 basic_session_run_hooks.py:263] loss = 6.3346643, step = 307600 (1.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.727\n",
            "I0509 16:00:10.012176 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.727\n",
            "INFO:tensorflow:loss = 6.632098, step = 307700 (0.946 sec)\n",
            "I0509 16:00:10.012562 140437868455744 basic_session_run_hooks.py:263] loss = 6.632098, step = 307700 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.375\n",
            "I0509 16:00:10.970244 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.375\n",
            "INFO:tensorflow:loss = 6.94609, step = 307800 (0.958 sec)\n",
            "I0509 16:00:10.970518 140437868455744 basic_session_run_hooks.py:263] loss = 6.94609, step = 307800 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.747\n",
            "I0509 16:00:11.924920 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.747\n",
            "INFO:tensorflow:loss = 6.6349998, step = 307900 (0.955 sec)\n",
            "I0509 16:00:11.925214 140437868455744 basic_session_run_hooks.py:263] loss = 6.6349998, step = 307900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 308000...\n",
            "I0509 16:00:12.880040 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 308000...\n",
            "INFO:tensorflow:Saving checkpoints for 308000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:00:12.880241 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 308000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 308000...\n",
            "I0509 16:00:13.085108 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 308000...\n",
            "INFO:tensorflow:global_step/sec: 85.2186\n",
            "I0509 16:00:13.098356 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.2186\n",
            "INFO:tensorflow:loss = 6.8666606, step = 308000 (1.173 sec)\n",
            "I0509 16:00:13.098695 140437868455744 basic_session_run_hooks.py:263] loss = 6.8666606, step = 308000 (1.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.606\n",
            "I0509 16:00:14.045299 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.606\n",
            "INFO:tensorflow:loss = 6.366952, step = 308100 (0.947 sec)\n",
            "I0509 16:00:14.045684 140437868455744 basic_session_run_hooks.py:263] loss = 6.366952, step = 308100 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.3313\n",
            "I0509 16:00:15.052029 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.3313\n",
            "INFO:tensorflow:loss = 8.962877, step = 308200 (1.007 sec)\n",
            "I0509 16:00:15.052427 140437868455744 basic_session_run_hooks.py:263] loss = 8.962877, step = 308200 (1.007 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.549\n",
            "I0509 16:00:16.017743 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.549\n",
            "INFO:tensorflow:loss = 6.096334, step = 308300 (0.966 sec)\n",
            "I0509 16:00:16.018125 140437868455744 basic_session_run_hooks.py:263] loss = 6.096334, step = 308300 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.094\n",
            "I0509 16:00:16.987737 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.094\n",
            "INFO:tensorflow:loss = 5.8298206, step = 308400 (0.970 sec)\n",
            "I0509 16:00:16.988135 140437868455744 basic_session_run_hooks.py:263] loss = 5.8298206, step = 308400 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.633\n",
            "I0509 16:00:17.934413 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.633\n",
            "INFO:tensorflow:loss = 6.064489, step = 308500 (0.947 sec)\n",
            "I0509 16:00:17.934800 140437868455744 basic_session_run_hooks.py:263] loss = 6.064489, step = 308500 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.4838\n",
            "I0509 16:00:18.949819 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 98.4838\n",
            "INFO:tensorflow:loss = 7.707016, step = 308600 (1.015 sec)\n",
            "I0509 16:00:18.950255 140437868455744 basic_session_run_hooks.py:263] loss = 7.707016, step = 308600 (1.015 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.207\n",
            "I0509 16:00:20.315813 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.207\n",
            "INFO:tensorflow:loss = 6.3332214, step = 308700 (1.366 sec)\n",
            "I0509 16:00:20.316155 140437868455744 basic_session_run_hooks.py:263] loss = 6.3332214, step = 308700 (1.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.5337\n",
            "I0509 16:00:21.320479 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.5337\n",
            "INFO:tensorflow:loss = 6.985555, step = 308800 (1.005 sec)\n",
            "I0509 16:00:21.320765 140437868455744 basic_session_run_hooks.py:263] loss = 6.985555, step = 308800 (1.005 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.673\n",
            "I0509 16:00:22.266795 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.673\n",
            "INFO:tensorflow:loss = 6.0675035, step = 308900 (0.946 sec)\n",
            "I0509 16:00:22.267183 140437868455744 basic_session_run_hooks.py:263] loss = 6.0675035, step = 308900 (0.946 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 309000...\n",
            "I0509 16:00:23.202693 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 309000...\n",
            "INFO:tensorflow:Saving checkpoints for 309000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:00:23.202892 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 309000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 309000...\n",
            "I0509 16:00:23.426935 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 309000...\n",
            "INFO:tensorflow:global_step/sec: 85.303\n",
            "I0509 16:00:23.439070 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.303\n",
            "INFO:tensorflow:loss = 6.9006624, step = 309000 (1.172 sec)\n",
            "I0509 16:00:23.439406 140437868455744 basic_session_run_hooks.py:263] loss = 6.9006624, step = 309000 (1.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.753\n",
            "I0509 16:00:24.393713 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.753\n",
            "INFO:tensorflow:loss = 6.163965, step = 309100 (0.955 sec)\n",
            "I0509 16:00:24.394128 140437868455744 basic_session_run_hooks.py:263] loss = 6.163965, step = 309100 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.691\n",
            "I0509 16:00:25.358123 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.691\n",
            "INFO:tensorflow:loss = 6.486885, step = 309200 (0.964 sec)\n",
            "I0509 16:00:25.358400 140437868455744 basic_session_run_hooks.py:263] loss = 6.486885, step = 309200 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.378\n",
            "I0509 16:00:26.307091 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.378\n",
            "INFO:tensorflow:loss = 7.3325024, step = 309300 (0.949 sec)\n",
            "I0509 16:00:26.307549 140437868455744 basic_session_run_hooks.py:263] loss = 7.3325024, step = 309300 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.5\n",
            "I0509 16:00:27.264010 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.5\n",
            "INFO:tensorflow:loss = 7.0859637, step = 309400 (0.957 sec)\n",
            "I0509 16:00:27.264375 140437868455744 basic_session_run_hooks.py:263] loss = 7.0859637, step = 309400 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.54\n",
            "I0509 16:00:28.220572 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.54\n",
            "INFO:tensorflow:loss = 7.6201797, step = 309500 (0.957 sec)\n",
            "I0509 16:00:28.220932 140437868455744 basic_session_run_hooks.py:263] loss = 7.6201797, step = 309500 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.119\n",
            "I0509 16:00:29.181029 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.119\n",
            "INFO:tensorflow:loss = 5.951986, step = 309600 (0.960 sec)\n",
            "I0509 16:00:29.181346 140437868455744 basic_session_run_hooks.py:263] loss = 5.951986, step = 309600 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.369\n",
            "I0509 16:00:30.130094 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.369\n",
            "INFO:tensorflow:loss = 6.4642477, step = 309700 (0.949 sec)\n",
            "I0509 16:00:30.130487 140437868455744 basic_session_run_hooks.py:263] loss = 6.4642477, step = 309700 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.9814\n",
            "I0509 16:00:31.380373 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.9814\n",
            "INFO:tensorflow:loss = 6.1109967, step = 309800 (1.251 sec)\n",
            "I0509 16:00:31.381460 140437868455744 basic_session_run_hooks.py:263] loss = 6.1109967, step = 309800 (1.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 87.3023\n",
            "I0509 16:00:32.525794 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.3023\n",
            "INFO:tensorflow:loss = 6.5210457, step = 309900 (1.145 sec)\n",
            "I0509 16:00:32.526085 140437868455744 basic_session_run_hooks.py:263] loss = 6.5210457, step = 309900 (1.145 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 310000...\n",
            "I0509 16:00:33.459528 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 310000...\n",
            "INFO:tensorflow:Saving checkpoints for 310000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:00:33.459714 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 310000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 310000...\n",
            "I0509 16:00:33.672641 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 310000...\n",
            "INFO:tensorflow:global_step/sec: 86.2556\n",
            "I0509 16:00:33.685152 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.2556\n",
            "INFO:tensorflow:loss = 7.7316985, step = 310000 (1.159 sec)\n",
            "I0509 16:00:33.685487 140437868455744 basic_session_run_hooks.py:263] loss = 7.7316985, step = 310000 (1.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.409\n",
            "I0509 16:00:34.652182 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.409\n",
            "INFO:tensorflow:loss = 6.726134, step = 310100 (0.967 sec)\n",
            "I0509 16:00:34.652459 140437868455744 basic_session_run_hooks.py:263] loss = 6.726134, step = 310100 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.243\n",
            "I0509 16:00:35.602380 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.243\n",
            "INFO:tensorflow:loss = 6.1437006, step = 310200 (0.951 sec)\n",
            "I0509 16:00:35.603651 140437868455744 basic_session_run_hooks.py:263] loss = 6.1437006, step = 310200 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.774\n",
            "I0509 16:00:36.538907 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.774\n",
            "INFO:tensorflow:loss = 5.7628403, step = 310300 (0.936 sec)\n",
            "I0509 16:00:36.539271 140437868455744 basic_session_run_hooks.py:263] loss = 5.7628403, step = 310300 (0.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.994\n",
            "I0509 16:00:37.482361 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.994\n",
            "INFO:tensorflow:loss = 7.3443203, step = 310400 (0.943 sec)\n",
            "I0509 16:00:37.482698 140437868455744 basic_session_run_hooks.py:263] loss = 7.3443203, step = 310400 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.409\n",
            "I0509 16:00:38.440165 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.409\n",
            "INFO:tensorflow:loss = 7.1024146, step = 310500 (0.958 sec)\n",
            "I0509 16:00:38.440580 140437868455744 basic_session_run_hooks.py:263] loss = 7.1024146, step = 310500 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.3827\n",
            "I0509 16:00:39.477668 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 96.3827\n",
            "INFO:tensorflow:loss = 6.461975, step = 310600 (1.037 sec)\n",
            "I0509 16:00:39.477948 140437868455744 basic_session_run_hooks.py:263] loss = 6.461975, step = 310600 (1.037 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.063\n",
            "I0509 16:00:40.438624 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.063\n",
            "INFO:tensorflow:loss = 7.325239, step = 310700 (0.961 sec)\n",
            "I0509 16:00:40.438995 140437868455744 basic_session_run_hooks.py:263] loss = 7.325239, step = 310700 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.173\n",
            "I0509 16:00:41.398568 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.173\n",
            "INFO:tensorflow:loss = 5.2926555, step = 310800 (0.960 sec)\n",
            "I0509 16:00:41.398944 140437868455744 basic_session_run_hooks.py:263] loss = 5.2926555, step = 310800 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.9905\n",
            "I0509 16:00:42.575191 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.9905\n",
            "INFO:tensorflow:loss = 6.9012914, step = 310900 (1.177 sec)\n",
            "I0509 16:00:42.575551 140437868455744 basic_session_run_hooks.py:263] loss = 6.9012914, step = 310900 (1.177 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 311000...\n",
            "I0509 16:00:43.806611 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 311000...\n",
            "INFO:tensorflow:Saving checkpoints for 311000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:00:43.806796 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 311000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 311000...\n",
            "I0509 16:00:44.016694 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 311000...\n",
            "INFO:tensorflow:global_step/sec: 68.8007\n",
            "I0509 16:00:44.028635 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 68.8007\n",
            "INFO:tensorflow:loss = 6.2591076, step = 311000 (1.453 sec)\n",
            "I0509 16:00:44.028993 140437868455744 basic_session_run_hooks.py:263] loss = 6.2591076, step = 311000 (1.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.871\n",
            "I0509 16:00:44.982213 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.871\n",
            "INFO:tensorflow:loss = 6.8959227, step = 311100 (0.954 sec)\n",
            "I0509 16:00:44.982583 140437868455744 basic_session_run_hooks.py:263] loss = 6.8959227, step = 311100 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.174\n",
            "I0509 16:00:45.942149 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.174\n",
            "INFO:tensorflow:loss = 7.539742, step = 311200 (0.960 sec)\n",
            "I0509 16:00:45.942552 140437868455744 basic_session_run_hooks.py:263] loss = 7.539742, step = 311200 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.356\n",
            "I0509 16:00:46.900458 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.356\n",
            "INFO:tensorflow:loss = 6.038569, step = 311300 (0.958 sec)\n",
            "I0509 16:00:46.900875 140437868455744 basic_session_run_hooks.py:263] loss = 6.038569, step = 311300 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.994\n",
            "I0509 16:00:47.843855 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.994\n",
            "INFO:tensorflow:loss = 6.5753994, step = 311400 (0.943 sec)\n",
            "I0509 16:00:47.844167 140437868455744 basic_session_run_hooks.py:263] loss = 6.5753994, step = 311400 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.175\n",
            "I0509 16:00:48.785671 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.175\n",
            "INFO:tensorflow:loss = 5.4108863, step = 311500 (0.942 sec)\n",
            "I0509 16:00:48.785963 140437868455744 basic_session_run_hooks.py:263] loss = 5.4108863, step = 311500 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.304\n",
            "I0509 16:00:49.744416 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.304\n",
            "INFO:tensorflow:loss = 6.177979, step = 311600 (0.959 sec)\n",
            "I0509 16:00:49.744783 140437868455744 basic_session_run_hooks.py:263] loss = 6.177979, step = 311600 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.947\n",
            "I0509 16:00:50.706464 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.947\n",
            "INFO:tensorflow:loss = 6.864007, step = 311700 (0.962 sec)\n",
            "I0509 16:00:50.706763 140437868455744 basic_session_run_hooks.py:263] loss = 6.864007, step = 311700 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.959\n",
            "I0509 16:00:51.677713 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.959\n",
            "INFO:tensorflow:loss = 5.8131976, step = 311800 (0.971 sec)\n",
            "I0509 16:00:51.678100 140437868455744 basic_session_run_hooks.py:263] loss = 5.8131976, step = 311800 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.063\n",
            "I0509 16:00:52.657517 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.063\n",
            "INFO:tensorflow:loss = 5.7347107, step = 311900 (0.980 sec)\n",
            "I0509 16:00:52.657790 140437868455744 basic_session_run_hooks.py:263] loss = 5.7347107, step = 311900 (0.980 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 312000...\n",
            "I0509 16:00:53.622891 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 312000...\n",
            "INFO:tensorflow:Saving checkpoints for 312000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:00:53.623170 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 312000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 312000...\n",
            "I0509 16:00:53.989338 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 312000...\n",
            "INFO:tensorflow:global_step/sec: 73.8213\n",
            "I0509 16:00:54.012141 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.8213\n",
            "INFO:tensorflow:loss = 5.4671936, step = 312000 (1.355 sec)\n",
            "I0509 16:00:54.012418 140437868455744 basic_session_run_hooks.py:263] loss = 5.4671936, step = 312000 (1.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.5452\n",
            "I0509 16:00:55.353590 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 74.5452\n",
            "INFO:tensorflow:loss = 5.4094863, step = 312100 (1.342 sec)\n",
            "I0509 16:00:55.353985 140437868455744 basic_session_run_hooks.py:263] loss = 5.4094863, step = 312100 (1.342 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.735\n",
            "I0509 16:00:56.290481 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.735\n",
            "INFO:tensorflow:loss = 6.885585, step = 312200 (0.937 sec)\n",
            "I0509 16:00:56.290835 140437868455744 basic_session_run_hooks.py:263] loss = 6.885585, step = 312200 (0.937 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.063\n",
            "I0509 16:00:57.242302 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.063\n",
            "INFO:tensorflow:loss = 6.512122, step = 312300 (0.952 sec)\n",
            "I0509 16:00:57.242575 140437868455744 basic_session_run_hooks.py:263] loss = 6.512122, step = 312300 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.868\n",
            "I0509 16:00:58.195883 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.868\n",
            "INFO:tensorflow:loss = 6.581315, step = 312400 (0.954 sec)\n",
            "I0509 16:00:58.196261 140437868455744 basic_session_run_hooks.py:263] loss = 6.581315, step = 312400 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.982\n",
            "I0509 16:00:59.176457 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.982\n",
            "INFO:tensorflow:loss = 7.7149363, step = 312500 (0.981 sec)\n",
            "I0509 16:00:59.176828 140437868455744 basic_session_run_hooks.py:263] loss = 7.7149363, step = 312500 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.31\n",
            "I0509 16:01:00.135190 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.31\n",
            "INFO:tensorflow:loss = 6.1714015, step = 312600 (0.959 sec)\n",
            "I0509 16:01:00.135571 140437868455744 basic_session_run_hooks.py:263] loss = 6.1714015, step = 312600 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.417\n",
            "I0509 16:01:01.083739 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.417\n",
            "INFO:tensorflow:loss = 6.682958, step = 312700 (0.948 sec)\n",
            "I0509 16:01:01.084015 140437868455744 basic_session_run_hooks.py:263] loss = 6.682958, step = 312700 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.037\n",
            "I0509 16:01:02.035787 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.037\n",
            "INFO:tensorflow:loss = 6.706704, step = 312800 (0.952 sec)\n",
            "I0509 16:01:02.036169 140437868455744 basic_session_run_hooks.py:263] loss = 6.706704, step = 312800 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.589\n",
            "I0509 16:01:02.982851 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.589\n",
            "INFO:tensorflow:loss = 4.4189878, step = 312900 (0.947 sec)\n",
            "I0509 16:01:02.983246 140437868455744 basic_session_run_hooks.py:263] loss = 4.4189878, step = 312900 (0.947 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 313000...\n",
            "I0509 16:01:03.919248 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 313000...\n",
            "INFO:tensorflow:Saving checkpoints for 313000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:01:03.919449 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 313000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 313000...\n",
            "I0509 16:01:04.136236 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 313000...\n",
            "INFO:tensorflow:global_step/sec: 85.5387\n",
            "I0509 16:01:04.151903 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.5387\n",
            "INFO:tensorflow:loss = 7.1178217, step = 313000 (1.169 sec)\n",
            "I0509 16:01:04.152254 140437868455744 basic_session_run_hooks.py:263] loss = 7.1178217, step = 313000 (1.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.326\n",
            "I0509 16:01:05.119722 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.326\n",
            "INFO:tensorflow:loss = 5.3757896, step = 313100 (0.968 sec)\n",
            "I0509 16:01:05.120112 140437868455744 basic_session_run_hooks.py:263] loss = 5.3757896, step = 313100 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.6717\n",
            "I0509 16:01:06.477189 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.6717\n",
            "INFO:tensorflow:loss = 7.3761406, step = 313200 (1.357 sec)\n",
            "I0509 16:01:06.477608 140437868455744 basic_session_run_hooks.py:263] loss = 7.3761406, step = 313200 (1.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.4733\n",
            "I0509 16:01:07.503023 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 97.4733\n",
            "INFO:tensorflow:loss = 7.0081973, step = 313300 (1.026 sec)\n",
            "I0509 16:01:07.503324 140437868455744 basic_session_run_hooks.py:263] loss = 7.0081973, step = 313300 (1.026 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.537\n",
            "I0509 16:01:08.468867 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.537\n",
            "INFO:tensorflow:loss = 6.5349507, step = 313400 (0.966 sec)\n",
            "I0509 16:01:08.469171 140437868455744 basic_session_run_hooks.py:263] loss = 6.5349507, step = 313400 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.466\n",
            "I0509 16:01:09.426140 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.466\n",
            "INFO:tensorflow:loss = 6.6419535, step = 313500 (0.957 sec)\n",
            "I0509 16:01:09.426437 140437868455744 basic_session_run_hooks.py:263] loss = 6.6419535, step = 313500 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.596\n",
            "I0509 16:01:10.391402 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.596\n",
            "INFO:tensorflow:loss = 7.0756984, step = 313600 (0.965 sec)\n",
            "I0509 16:01:10.391764 140437868455744 basic_session_run_hooks.py:263] loss = 7.0756984, step = 313600 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.929\n",
            "I0509 16:01:11.344430 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.929\n",
            "INFO:tensorflow:loss = 7.2567425, step = 313700 (0.953 sec)\n",
            "I0509 16:01:11.344810 140437868455744 basic_session_run_hooks.py:263] loss = 7.2567425, step = 313700 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.09\n",
            "I0509 16:01:12.296001 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.09\n",
            "INFO:tensorflow:loss = 6.3560324, step = 313800 (0.952 sec)\n",
            "I0509 16:01:12.296390 140437868455744 basic_session_run_hooks.py:263] loss = 6.3560324, step = 313800 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.683\n",
            "I0509 16:01:13.279437 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.683\n",
            "INFO:tensorflow:loss = 7.4630246, step = 313900 (0.983 sec)\n",
            "I0509 16:01:13.279805 140437868455744 basic_session_run_hooks.py:263] loss = 7.4630246, step = 313900 (0.983 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 314000...\n",
            "I0509 16:01:14.219760 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 314000...\n",
            "INFO:tensorflow:Saving checkpoints for 314000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:01:14.219958 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 314000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 314000...\n",
            "I0509 16:01:14.441750 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 314000...\n",
            "INFO:tensorflow:global_step/sec: 85.1696\n",
            "I0509 16:01:14.453536 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.1696\n",
            "INFO:tensorflow:loss = 6.5108113, step = 314000 (1.174 sec)\n",
            "I0509 16:01:14.453769 140437868455744 basic_session_run_hooks.py:263] loss = 6.5108113, step = 314000 (1.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.981\n",
            "I0509 16:01:15.415278 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.981\n",
            "INFO:tensorflow:loss = 6.9158177, step = 314100 (0.962 sec)\n",
            "I0509 16:01:15.415666 140437868455744 basic_session_run_hooks.py:263] loss = 6.9158177, step = 314100 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.1207\n",
            "I0509 16:01:16.424173 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.1207\n",
            "INFO:tensorflow:loss = 7.04857, step = 314200 (1.009 sec)\n",
            "I0509 16:01:16.424541 140437868455744 basic_session_run_hooks.py:263] loss = 7.04857, step = 314200 (1.009 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.7669\n",
            "I0509 16:01:17.677810 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.7669\n",
            "INFO:tensorflow:loss = 9.512188, step = 314300 (1.254 sec)\n",
            "I0509 16:01:17.678116 140437868455744 basic_session_run_hooks.py:263] loss = 9.512188, step = 314300 (1.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 88.0382\n",
            "I0509 16:01:18.813660 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 88.0382\n",
            "INFO:tensorflow:loss = 5.9316654, step = 314400 (1.136 sec)\n",
            "I0509 16:01:18.813950 140437868455744 basic_session_run_hooks.py:263] loss = 5.9316654, step = 314400 (1.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.05\n",
            "I0509 16:01:19.784072 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.05\n",
            "INFO:tensorflow:loss = 6.3517156, step = 314500 (0.970 sec)\n",
            "I0509 16:01:19.784444 140437868455744 basic_session_run_hooks.py:263] loss = 6.3517156, step = 314500 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.462\n",
            "I0509 16:01:20.741356 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.462\n",
            "INFO:tensorflow:loss = 7.358078, step = 314600 (0.957 sec)\n",
            "I0509 16:01:20.741723 140437868455744 basic_session_run_hooks.py:263] loss = 7.358078, step = 314600 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.601\n",
            "I0509 16:01:21.697357 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.601\n",
            "INFO:tensorflow:loss = 6.1708837, step = 314700 (0.956 sec)\n",
            "I0509 16:01:21.697717 140437868455744 basic_session_run_hooks.py:263] loss = 6.1708837, step = 314700 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.746\n",
            "I0509 16:01:22.670634 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.746\n",
            "INFO:tensorflow:loss = 6.9946194, step = 314800 (0.973 sec)\n",
            "I0509 16:01:22.671003 140437868455744 basic_session_run_hooks.py:263] loss = 6.9946194, step = 314800 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.419\n",
            "I0509 16:01:23.619235 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.419\n",
            "INFO:tensorflow:loss = 5.3598194, step = 314900 (0.949 sec)\n",
            "I0509 16:01:23.619616 140437868455744 basic_session_run_hooks.py:263] loss = 5.3598194, step = 314900 (0.949 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 315000...\n",
            "I0509 16:01:24.582838 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 315000...\n",
            "INFO:tensorflow:Saving checkpoints for 315000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:01:24.583025 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 315000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 315000...\n",
            "I0509 16:01:24.783877 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 315000...\n",
            "INFO:tensorflow:global_step/sec: 84.8788\n",
            "I0509 16:01:24.797385 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.8788\n",
            "INFO:tensorflow:loss = 7.2097654, step = 315000 (1.178 sec)\n",
            "I0509 16:01:24.797730 140437868455744 basic_session_run_hooks.py:263] loss = 7.2097654, step = 315000 (1.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.52\n",
            "I0509 16:01:25.763387 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.52\n",
            "INFO:tensorflow:loss = 7.2006955, step = 315100 (0.966 sec)\n",
            "I0509 16:01:25.763755 140437868455744 basic_session_run_hooks.py:263] loss = 7.2006955, step = 315100 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.962\n",
            "I0509 16:01:26.725262 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.962\n",
            "INFO:tensorflow:loss = 7.1046057, step = 315200 (0.962 sec)\n",
            "I0509 16:01:26.725627 140437868455744 basic_session_run_hooks.py:263] loss = 7.1046057, step = 315200 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.082\n",
            "I0509 16:01:27.686049 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.082\n",
            "INFO:tensorflow:loss = 5.7138968, step = 315300 (0.961 sec)\n",
            "I0509 16:01:27.686441 140437868455744 basic_session_run_hooks.py:263] loss = 5.7138968, step = 315300 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 89.1879\n",
            "I0509 16:01:28.807303 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 89.1879\n",
            "INFO:tensorflow:loss = 6.204186, step = 315400 (1.121 sec)\n",
            "I0509 16:01:28.807598 140437868455744 basic_session_run_hooks.py:263] loss = 6.204186, step = 315400 (1.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.6153\n",
            "I0509 16:01:30.095685 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.6153\n",
            "INFO:tensorflow:loss = 5.1947827, step = 315500 (1.288 sec)\n",
            "I0509 16:01:30.096073 140437868455744 basic_session_run_hooks.py:263] loss = 5.1947827, step = 315500 (1.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.479\n",
            "I0509 16:01:31.043742 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.479\n",
            "INFO:tensorflow:loss = 6.9191704, step = 315600 (0.948 sec)\n",
            "I0509 16:01:31.044130 140437868455744 basic_session_run_hooks.py:263] loss = 6.9191704, step = 315600 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.594\n",
            "I0509 16:01:31.999808 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.594\n",
            "INFO:tensorflow:loss = 5.7992616, step = 315700 (0.956 sec)\n",
            "I0509 16:01:32.000179 140437868455744 basic_session_run_hooks.py:263] loss = 5.7992616, step = 315700 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.094\n",
            "I0509 16:01:32.942378 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.094\n",
            "INFO:tensorflow:loss = 7.3470335, step = 315800 (0.942 sec)\n",
            "I0509 16:01:32.942648 140437868455744 basic_session_run_hooks.py:263] loss = 7.3470335, step = 315800 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.627\n",
            "I0509 16:01:33.907379 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.627\n",
            "INFO:tensorflow:loss = 8.157495, step = 315900 (0.965 sec)\n",
            "I0509 16:01:33.907749 140437868455744 basic_session_run_hooks.py:263] loss = 8.157495, step = 315900 (0.965 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 316000...\n",
            "I0509 16:01:34.860623 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 316000...\n",
            "INFO:tensorflow:Saving checkpoints for 316000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:01:34.860806 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 316000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 316000...\n",
            "I0509 16:01:35.072621 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 316000...\n",
            "INFO:tensorflow:global_step/sec: 84.9338\n",
            "I0509 16:01:35.084757 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.9338\n",
            "INFO:tensorflow:loss = 7.228562, step = 316000 (1.177 sec)\n",
            "I0509 16:01:35.085040 140437868455744 basic_session_run_hooks.py:263] loss = 7.228562, step = 316000 (1.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.056\n",
            "I0509 16:01:36.064616 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.056\n",
            "INFO:tensorflow:loss = 6.574158, step = 316100 (0.980 sec)\n",
            "I0509 16:01:36.064985 140437868455744 basic_session_run_hooks.py:263] loss = 6.574158, step = 316100 (0.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.293\n",
            "I0509 16:01:37.023436 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.293\n",
            "INFO:tensorflow:loss = 6.0637417, step = 316200 (0.959 sec)\n",
            "I0509 16:01:37.023869 140437868455744 basic_session_run_hooks.py:263] loss = 6.0637417, step = 316200 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.413\n",
            "I0509 16:01:37.981191 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.413\n",
            "INFO:tensorflow:loss = 7.473367, step = 316300 (0.958 sec)\n",
            "I0509 16:01:37.981468 140437868455744 basic_session_run_hooks.py:263] loss = 7.473367, step = 316300 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.907\n",
            "I0509 16:01:38.952932 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.907\n",
            "INFO:tensorflow:loss = 5.0119824, step = 316400 (0.972 sec)\n",
            "I0509 16:01:38.953343 140437868455744 basic_session_run_hooks.py:263] loss = 5.0119824, step = 316400 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 95.038\n",
            "I0509 16:01:40.005207 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 95.038\n",
            "INFO:tensorflow:loss = 7.0673733, step = 316500 (1.052 sec)\n",
            "I0509 16:01:40.005655 140437868455744 basic_session_run_hooks.py:263] loss = 7.0673733, step = 316500 (1.052 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9998\n",
            "I0509 16:01:41.394045 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 71.9998\n",
            "INFO:tensorflow:loss = 4.346108, step = 316600 (1.389 sec)\n",
            "I0509 16:01:41.394451 140437868455744 basic_session_run_hooks.py:263] loss = 4.346108, step = 316600 (1.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.8974\n",
            "I0509 16:01:42.426054 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 96.8974\n",
            "INFO:tensorflow:loss = 4.862412, step = 316700 (1.032 sec)\n",
            "I0509 16:01:42.426515 140437868455744 basic_session_run_hooks.py:263] loss = 4.862412, step = 316700 (1.032 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.796\n",
            "I0509 16:01:43.389497 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.796\n",
            "INFO:tensorflow:loss = 6.428183, step = 316800 (0.963 sec)\n",
            "I0509 16:01:43.389884 140437868455744 basic_session_run_hooks.py:263] loss = 6.428183, step = 316800 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.719\n",
            "I0509 16:01:44.362997 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.719\n",
            "INFO:tensorflow:loss = 6.380496, step = 316900 (0.973 sec)\n",
            "I0509 16:01:44.363374 140437868455744 basic_session_run_hooks.py:263] loss = 6.380496, step = 316900 (0.973 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 317000...\n",
            "I0509 16:01:45.310985 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 317000...\n",
            "INFO:tensorflow:Saving checkpoints for 317000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:01:45.311195 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 317000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 317000...\n",
            "I0509 16:01:45.523675 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 317000...\n",
            "INFO:tensorflow:global_step/sec: 85.2516\n",
            "I0509 16:01:45.535989 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.2516\n",
            "INFO:tensorflow:loss = 6.1289167, step = 317000 (1.173 sec)\n",
            "I0509 16:01:45.536380 140437868455744 basic_session_run_hooks.py:263] loss = 6.1289167, step = 317000 (1.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.138\n",
            "I0509 16:01:46.496265 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.138\n",
            "INFO:tensorflow:loss = 6.608975, step = 317100 (0.960 sec)\n",
            "I0509 16:01:46.496626 140437868455744 basic_session_run_hooks.py:263] loss = 6.608975, step = 317100 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.7\n",
            "I0509 16:01:47.460599 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.7\n",
            "INFO:tensorflow:loss = 5.3208632, step = 317200 (0.964 sec)\n",
            "I0509 16:01:47.460976 140437868455744 basic_session_run_hooks.py:263] loss = 5.3208632, step = 317200 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.557\n",
            "I0509 16:01:48.435663 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.557\n",
            "INFO:tensorflow:loss = 6.3532085, step = 317300 (0.975 sec)\n",
            "I0509 16:01:48.435961 140437868455744 basic_session_run_hooks.py:263] loss = 6.3532085, step = 317300 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.858\n",
            "I0509 16:01:49.417402 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.858\n",
            "INFO:tensorflow:loss = 6.6911287, step = 317400 (0.982 sec)\n",
            "I0509 16:01:49.417677 140437868455744 basic_session_run_hooks.py:263] loss = 6.6911287, step = 317400 (0.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.822\n",
            "I0509 16:01:50.380599 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.822\n",
            "INFO:tensorflow:loss = 6.215023, step = 317500 (0.963 sec)\n",
            "I0509 16:01:50.380966 140437868455744 basic_session_run_hooks.py:263] loss = 6.215023, step = 317500 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.906\n",
            "I0509 16:01:51.343014 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.906\n",
            "INFO:tensorflow:loss = 7.0321956, step = 317600 (0.962 sec)\n",
            "I0509 16:01:51.343397 140437868455744 basic_session_run_hooks.py:263] loss = 7.0321956, step = 317600 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.0773\n",
            "I0509 16:01:52.640422 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.0773\n",
            "INFO:tensorflow:loss = 6.600706, step = 317700 (1.297 sec)\n",
            "I0509 16:01:52.640739 140437868455744 basic_session_run_hooks.py:263] loss = 6.600706, step = 317700 (1.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 89.4682\n",
            "I0509 16:01:53.758133 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 89.4682\n",
            "INFO:tensorflow:loss = 7.0837317, step = 317800 (1.118 sec)\n",
            "I0509 16:01:53.758413 140437868455744 basic_session_run_hooks.py:263] loss = 7.0837317, step = 317800 (1.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.074\n",
            "I0509 16:01:54.709850 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.074\n",
            "INFO:tensorflow:loss = 4.5232115, step = 317900 (0.952 sec)\n",
            "I0509 16:01:54.710248 140437868455744 basic_session_run_hooks.py:263] loss = 4.5232115, step = 317900 (0.952 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 318000...\n",
            "I0509 16:01:55.680282 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 318000...\n",
            "INFO:tensorflow:Saving checkpoints for 318000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:01:55.680474 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 318000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 318000...\n",
            "I0509 16:01:55.931436 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 318000...\n",
            "INFO:tensorflow:global_step/sec: 81.0761\n",
            "I0509 16:01:55.943240 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.0761\n",
            "INFO:tensorflow:loss = 5.629803, step = 318000 (1.233 sec)\n",
            "I0509 16:01:55.943497 140437868455744 basic_session_run_hooks.py:263] loss = 5.629803, step = 318000 (1.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.972\n",
            "I0509 16:01:56.895884 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.972\n",
            "INFO:tensorflow:loss = 6.3208137, step = 318100 (0.953 sec)\n",
            "I0509 16:01:56.896259 140437868455744 basic_session_run_hooks.py:263] loss = 6.3208137, step = 318100 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.784\n",
            "I0509 16:01:57.859411 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.784\n",
            "INFO:tensorflow:loss = 7.831121, step = 318200 (0.964 sec)\n",
            "I0509 16:01:57.859768 140437868455744 basic_session_run_hooks.py:263] loss = 7.831121, step = 318200 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.792\n",
            "I0509 16:01:58.822885 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.792\n",
            "INFO:tensorflow:loss = 5.96446, step = 318300 (0.964 sec)\n",
            "I0509 16:01:58.823272 140437868455744 basic_session_run_hooks.py:263] loss = 5.96446, step = 318300 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.492\n",
            "I0509 16:01:59.789162 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.492\n",
            "INFO:tensorflow:loss = 5.8770337, step = 318400 (0.966 sec)\n",
            "I0509 16:01:59.789532 140437868455744 basic_session_run_hooks.py:263] loss = 5.8770337, step = 318400 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.425\n",
            "I0509 16:02:00.756035 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.425\n",
            "INFO:tensorflow:loss = 6.5475183, step = 318500 (0.967 sec)\n",
            "I0509 16:02:00.756418 140437868455744 basic_session_run_hooks.py:263] loss = 6.5475183, step = 318500 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.799\n",
            "I0509 16:02:01.738346 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.799\n",
            "INFO:tensorflow:loss = 10.357441, step = 318600 (0.982 sec)\n",
            "I0509 16:02:01.738715 140437868455744 basic_session_run_hooks.py:263] loss = 10.357441, step = 318600 (0.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.598\n",
            "I0509 16:02:02.703619 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.598\n",
            "INFO:tensorflow:loss = 7.4043345, step = 318700 (0.965 sec)\n",
            "I0509 16:02:02.703899 140437868455744 basic_session_run_hooks.py:263] loss = 7.4043345, step = 318700 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.9837\n",
            "I0509 16:02:03.894336 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.9837\n",
            "INFO:tensorflow:loss = 6.3677483, step = 318800 (1.191 sec)\n",
            "I0509 16:02:03.894636 140437868455744 basic_session_run_hooks.py:263] loss = 6.3677483, step = 318800 (1.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.619\n",
            "I0509 16:02:05.090225 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.619\n",
            "INFO:tensorflow:loss = 6.007935, step = 318900 (1.196 sec)\n",
            "I0509 16:02:05.090511 140437868455744 basic_session_run_hooks.py:263] loss = 6.007935, step = 318900 (1.196 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 319000...\n",
            "I0509 16:02:06.035326 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 319000...\n",
            "INFO:tensorflow:Saving checkpoints for 319000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:02:06.035524 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 319000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 319000...\n",
            "I0509 16:02:06.237765 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 319000...\n",
            "INFO:tensorflow:global_step/sec: 86.239\n",
            "I0509 16:02:06.249775 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.239\n",
            "INFO:tensorflow:loss = 7.2602634, step = 319000 (1.160 sec)\n",
            "I0509 16:02:06.250127 140437868455744 basic_session_run_hooks.py:263] loss = 7.2602634, step = 319000 (1.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.08\n",
            "I0509 16:02:07.210602 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.08\n",
            "INFO:tensorflow:loss = 7.6044364, step = 319100 (0.961 sec)\n",
            "I0509 16:02:07.210981 140437868455744 basic_session_run_hooks.py:263] loss = 7.6044364, step = 319100 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.836\n",
            "I0509 16:02:08.164459 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.836\n",
            "INFO:tensorflow:loss = 7.062804, step = 319200 (0.954 sec)\n",
            "I0509 16:02:08.164819 140437868455744 basic_session_run_hooks.py:263] loss = 7.062804, step = 319200 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.17\n",
            "I0509 16:02:09.115305 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.17\n",
            "INFO:tensorflow:loss = 7.031023, step = 319300 (0.951 sec)\n",
            "I0509 16:02:09.115669 140437868455744 basic_session_run_hooks.py:263] loss = 7.031023, step = 319300 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.536\n",
            "I0509 16:02:10.071921 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.536\n",
            "INFO:tensorflow:loss = 6.8569145, step = 319400 (0.957 sec)\n",
            "I0509 16:02:10.072388 140437868455744 basic_session_run_hooks.py:263] loss = 6.8569145, step = 319400 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.068\n",
            "I0509 16:02:11.042158 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.068\n",
            "INFO:tensorflow:loss = 5.559661, step = 319500 (0.970 sec)\n",
            "I0509 16:02:11.042534 140437868455744 basic_session_run_hooks.py:263] loss = 5.559661, step = 319500 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.882\n",
            "I0509 16:02:12.023686 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.882\n",
            "INFO:tensorflow:loss = 8.71009, step = 319600 (0.981 sec)\n",
            "I0509 16:02:12.023988 140437868455744 basic_session_run_hooks.py:263] loss = 8.71009, step = 319600 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.884\n",
            "I0509 16:02:12.995639 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.884\n",
            "INFO:tensorflow:loss = 7.507293, step = 319700 (0.972 sec)\n",
            "I0509 16:02:12.995916 140437868455744 basic_session_run_hooks.py:263] loss = 7.507293, step = 319700 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.803\n",
            "I0509 16:02:13.931947 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.803\n",
            "INFO:tensorflow:loss = 6.6374025, step = 319800 (0.937 sec)\n",
            "I0509 16:02:13.932727 140437868455744 basic_session_run_hooks.py:263] loss = 6.6374025, step = 319800 (0.937 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.1915\n",
            "I0509 16:02:14.971535 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 96.1915\n",
            "INFO:tensorflow:loss = 5.545328, step = 319900 (1.039 sec)\n",
            "I0509 16:02:14.971913 140437868455744 basic_session_run_hooks.py:263] loss = 5.545328, step = 319900 (1.039 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 320000...\n",
            "I0509 16:02:16.309373 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 320000...\n",
            "INFO:tensorflow:Saving checkpoints for 320000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:02:16.309558 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 320000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 320000...\n",
            "I0509 16:02:16.522831 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 320000...\n",
            "INFO:tensorflow:global_step/sec: 63.9655\n",
            "I0509 16:02:16.534869 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 63.9655\n",
            "INFO:tensorflow:loss = 7.555958, step = 320000 (1.563 sec)\n",
            "I0509 16:02:16.535215 140437868455744 basic_session_run_hooks.py:263] loss = 7.555958, step = 320000 (1.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.677\n",
            "I0509 16:02:17.508799 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.677\n",
            "INFO:tensorflow:loss = 6.095079, step = 320100 (0.974 sec)\n",
            "I0509 16:02:17.509161 140437868455744 basic_session_run_hooks.py:263] loss = 6.095079, step = 320100 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.974\n",
            "I0509 16:02:18.479921 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.974\n",
            "INFO:tensorflow:loss = 6.4596977, step = 320200 (0.971 sec)\n",
            "I0509 16:02:18.480323 140437868455744 basic_session_run_hooks.py:263] loss = 6.4596977, step = 320200 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.152\n",
            "I0509 16:02:19.468528 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.152\n",
            "INFO:tensorflow:loss = 6.96339, step = 320300 (0.989 sec)\n",
            "I0509 16:02:19.468877 140437868455744 basic_session_run_hooks.py:263] loss = 6.96339, step = 320300 (0.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.39\n",
            "I0509 16:02:20.426479 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.39\n",
            "INFO:tensorflow:loss = 5.3869677, step = 320400 (0.958 sec)\n",
            "I0509 16:02:20.426909 140437868455744 basic_session_run_hooks.py:263] loss = 5.3869677, step = 320400 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.126\n",
            "I0509 16:02:21.415345 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.126\n",
            "INFO:tensorflow:loss = 6.0355754, step = 320500 (0.989 sec)\n",
            "I0509 16:02:21.415717 140437868455744 basic_session_run_hooks.py:263] loss = 6.0355754, step = 320500 (0.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.846\n",
            "I0509 16:02:22.369150 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.846\n",
            "INFO:tensorflow:loss = 6.639001, step = 320600 (0.954 sec)\n",
            "I0509 16:02:22.369588 140437868455744 basic_session_run_hooks.py:263] loss = 6.639001, step = 320600 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.474\n",
            "I0509 16:02:23.326316 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.474\n",
            "INFO:tensorflow:loss = 6.3722982, step = 320700 (0.957 sec)\n",
            "I0509 16:02:23.326684 140437868455744 basic_session_run_hooks.py:263] loss = 6.3722982, step = 320700 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.882\n",
            "I0509 16:02:24.279772 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.882\n",
            "INFO:tensorflow:loss = 7.6283245, step = 320800 (0.953 sec)\n",
            "I0509 16:02:24.280155 140437868455744 basic_session_run_hooks.py:263] loss = 7.6283245, step = 320800 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.235\n",
            "I0509 16:02:25.267574 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.235\n",
            "INFO:tensorflow:loss = 8.670216, step = 320900 (0.988 sec)\n",
            "I0509 16:02:25.267953 140437868455744 basic_session_run_hooks.py:263] loss = 8.670216, step = 320900 (0.988 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 321000...\n",
            "I0509 16:02:26.225522 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 321000...\n",
            "INFO:tensorflow:Saving checkpoints for 321000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:02:26.225717 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 321000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 321000...\n",
            "I0509 16:02:26.555170 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 321000...\n",
            "INFO:tensorflow:global_step/sec: 76.6108\n",
            "I0509 16:02:26.572906 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 76.6108\n",
            "INFO:tensorflow:loss = 5.925521, step = 321000 (1.305 sec)\n",
            "I0509 16:02:26.573279 140437868455744 basic_session_run_hooks.py:263] loss = 5.925521, step = 321000 (1.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.274\n",
            "I0509 16:02:27.937612 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.274\n",
            "INFO:tensorflow:loss = 5.7312236, step = 321100 (1.365 sec)\n",
            "I0509 16:02:27.937976 140437868455744 basic_session_run_hooks.py:263] loss = 5.7312236, step = 321100 (1.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.845\n",
            "I0509 16:02:28.891405 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.845\n",
            "INFO:tensorflow:loss = 12.464741, step = 321200 (0.954 sec)\n",
            "I0509 16:02:28.891781 140437868455744 basic_session_run_hooks.py:263] loss = 12.464741, step = 321200 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.3855\n",
            "I0509 16:02:29.907820 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 98.3855\n",
            "INFO:tensorflow:loss = 7.4787507, step = 321300 (1.016 sec)\n",
            "I0509 16:02:29.908155 140437868455744 basic_session_run_hooks.py:263] loss = 7.4787507, step = 321300 (1.016 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.724\n",
            "I0509 16:02:30.890866 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.724\n",
            "INFO:tensorflow:loss = 6.6917896, step = 321400 (0.983 sec)\n",
            "I0509 16:02:30.891255 140437868455744 basic_session_run_hooks.py:263] loss = 6.6917896, step = 321400 (0.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.456\n",
            "I0509 16:02:31.876525 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.456\n",
            "INFO:tensorflow:loss = 5.977167, step = 321500 (0.986 sec)\n",
            "I0509 16:02:31.876974 140437868455744 basic_session_run_hooks.py:263] loss = 5.977167, step = 321500 (0.986 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.35\n",
            "I0509 16:02:32.816787 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.35\n",
            "INFO:tensorflow:loss = 6.8263907, step = 321600 (0.940 sec)\n",
            "I0509 16:02:32.817160 140437868455744 basic_session_run_hooks.py:263] loss = 6.8263907, step = 321600 (0.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.192\n",
            "I0509 16:02:33.758477 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.192\n",
            "INFO:tensorflow:loss = 6.9329333, step = 321700 (0.942 sec)\n",
            "I0509 16:02:33.758820 140437868455744 basic_session_run_hooks.py:263] loss = 6.9329333, step = 321700 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.409\n",
            "I0509 16:02:34.707181 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.409\n",
            "INFO:tensorflow:loss = 6.7916746, step = 321800 (0.949 sec)\n",
            "I0509 16:02:34.707456 140437868455744 basic_session_run_hooks.py:263] loss = 6.7916746, step = 321800 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.023\n",
            "I0509 16:02:35.659332 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.023\n",
            "INFO:tensorflow:loss = 6.0382633, step = 321900 (0.952 sec)\n",
            "I0509 16:02:35.659609 140437868455744 basic_session_run_hooks.py:263] loss = 6.0382633, step = 321900 (0.952 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 322000...\n",
            "I0509 16:02:36.596407 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 322000...\n",
            "INFO:tensorflow:Saving checkpoints for 322000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:02:36.596606 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 322000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 322000...\n",
            "I0509 16:02:36.840841 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 322000...\n",
            "INFO:tensorflow:global_step/sec: 83.7877\n",
            "I0509 16:02:36.852818 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.7877\n",
            "INFO:tensorflow:loss = 7.7205276, step = 322000 (1.193 sec)\n",
            "I0509 16:02:36.853080 140437868455744 basic_session_run_hooks.py:263] loss = 7.7205276, step = 322000 (1.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.716\n",
            "I0509 16:02:37.826410 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.716\n",
            "INFO:tensorflow:loss = 6.4666977, step = 322100 (0.974 sec)\n",
            "I0509 16:02:37.826783 140437868455744 basic_session_run_hooks.py:263] loss = 6.4666977, step = 322100 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.9356\n",
            "I0509 16:02:39.197493 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 72.9356\n",
            "INFO:tensorflow:loss = 5.648417, step = 322200 (1.371 sec)\n",
            "I0509 16:02:39.197903 140437868455744 basic_session_run_hooks.py:263] loss = 5.648417, step = 322200 (1.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 95.3937\n",
            "I0509 16:02:40.245755 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 95.3937\n",
            "INFO:tensorflow:loss = 7.9136267, step = 322300 (1.048 sec)\n",
            "I0509 16:02:40.246033 140437868455744 basic_session_run_hooks.py:263] loss = 7.9136267, step = 322300 (1.048 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.673\n",
            "I0509 16:02:41.210336 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.673\n",
            "INFO:tensorflow:loss = 5.4530206, step = 322400 (0.965 sec)\n",
            "I0509 16:02:41.210651 140437868455744 basic_session_run_hooks.py:263] loss = 5.4530206, step = 322400 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.142\n",
            "I0509 16:02:42.199038 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.142\n",
            "INFO:tensorflow:loss = 7.0365915, step = 322500 (0.989 sec)\n",
            "I0509 16:02:42.199449 140437868455744 basic_session_run_hooks.py:263] loss = 7.0365915, step = 322500 (0.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.297\n",
            "I0509 16:02:43.148732 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.297\n",
            "INFO:tensorflow:loss = 6.3830795, step = 322600 (0.950 sec)\n",
            "I0509 16:02:43.149011 140437868455744 basic_session_run_hooks.py:263] loss = 6.3830795, step = 322600 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.033\n",
            "I0509 16:02:44.100804 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.033\n",
            "INFO:tensorflow:loss = 7.5084243, step = 322700 (0.952 sec)\n",
            "I0509 16:02:44.101181 140437868455744 basic_session_run_hooks.py:263] loss = 7.5084243, step = 322700 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.343\n",
            "I0509 16:02:45.041182 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.343\n",
            "INFO:tensorflow:loss = 6.1122956, step = 322800 (0.940 sec)\n",
            "I0509 16:02:45.041456 140437868455744 basic_session_run_hooks.py:263] loss = 6.1122956, step = 322800 (0.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.205\n",
            "I0509 16:02:45.991706 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.205\n",
            "INFO:tensorflow:loss = 5.294204, step = 322900 (0.951 sec)\n",
            "I0509 16:02:45.992112 140437868455744 basic_session_run_hooks.py:263] loss = 5.294204, step = 322900 (0.951 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 323000...\n",
            "I0509 16:02:46.948709 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 323000...\n",
            "INFO:tensorflow:Saving checkpoints for 323000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:02:46.948912 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 323000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 323000...\n",
            "I0509 16:02:47.163531 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 323000...\n",
            "INFO:tensorflow:global_step/sec: 84.4562\n",
            "I0509 16:02:47.175724 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.4562\n",
            "INFO:tensorflow:loss = 6.240123, step = 323000 (1.184 sec)\n",
            "I0509 16:02:47.175978 140437868455744 basic_session_run_hooks.py:263] loss = 6.240123, step = 323000 (1.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.611\n",
            "I0509 16:02:48.131662 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.611\n",
            "INFO:tensorflow:loss = 8.119343, step = 323100 (0.956 sec)\n",
            "I0509 16:02:48.132031 140437868455744 basic_session_run_hooks.py:263] loss = 8.119343, step = 323100 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.19\n",
            "I0509 16:02:49.091449 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.19\n",
            "INFO:tensorflow:loss = 7.115118, step = 323200 (0.960 sec)\n",
            "I0509 16:02:49.091804 140437868455744 basic_session_run_hooks.py:263] loss = 7.115118, step = 323200 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.037\n",
            "I0509 16:02:50.356688 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.037\n",
            "INFO:tensorflow:loss = 6.800816, step = 323300 (1.265 sec)\n",
            "I0509 16:02:50.357051 140437868455744 basic_session_run_hooks.py:263] loss = 6.800816, step = 323300 (1.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 87.0459\n",
            "I0509 16:02:51.505509 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.0459\n",
            "INFO:tensorflow:loss = 6.6891775, step = 323400 (1.149 sec)\n",
            "I0509 16:02:51.505877 140437868455744 basic_session_run_hooks.py:263] loss = 6.6891775, step = 323400 (1.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.331\n",
            "I0509 16:02:52.502213 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.331\n",
            "INFO:tensorflow:loss = 6.603735, step = 323500 (0.997 sec)\n",
            "I0509 16:02:52.502502 140437868455744 basic_session_run_hooks.py:263] loss = 6.603735, step = 323500 (0.997 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.245\n",
            "I0509 16:02:53.452377 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.245\n",
            "INFO:tensorflow:loss = 7.445704, step = 323600 (0.950 sec)\n",
            "I0509 16:02:53.452739 140437868455744 basic_session_run_hooks.py:263] loss = 7.445704, step = 323600 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.956\n",
            "I0509 16:02:54.396172 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.956\n",
            "INFO:tensorflow:loss = 6.043687, step = 323700 (0.944 sec)\n",
            "I0509 16:02:54.396450 140437868455744 basic_session_run_hooks.py:263] loss = 6.043687, step = 323700 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.152\n",
            "I0509 16:02:55.365598 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.152\n",
            "INFO:tensorflow:loss = 2.5682487, step = 323800 (0.970 sec)\n",
            "I0509 16:02:55.365955 140437868455744 basic_session_run_hooks.py:263] loss = 2.5682487, step = 323800 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.708\n",
            "I0509 16:02:56.320637 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.708\n",
            "INFO:tensorflow:loss = 5.763118, step = 323900 (0.955 sec)\n",
            "I0509 16:02:56.321015 140437868455744 basic_session_run_hooks.py:263] loss = 5.763118, step = 323900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 324000...\n",
            "I0509 16:02:57.271150 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 324000...\n",
            "INFO:tensorflow:Saving checkpoints for 324000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:02:57.271335 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 324000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 324000...\n",
            "I0509 16:02:57.498558 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 324000...\n",
            "INFO:tensorflow:global_step/sec: 84.0374\n",
            "I0509 16:02:57.510559 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.0374\n",
            "INFO:tensorflow:loss = 8.44904, step = 324000 (1.190 sec)\n",
            "I0509 16:02:57.510797 140437868455744 basic_session_run_hooks.py:263] loss = 8.44904, step = 324000 (1.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.224\n",
            "I0509 16:02:58.460954 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.224\n",
            "INFO:tensorflow:loss = 6.261101, step = 324100 (0.950 sec)\n",
            "I0509 16:02:58.461251 140437868455744 basic_session_run_hooks.py:263] loss = 6.261101, step = 324100 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.452\n",
            "I0509 16:02:59.409234 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.452\n",
            "INFO:tensorflow:loss = 6.6622744, step = 324200 (0.948 sec)\n",
            "I0509 16:02:59.409616 140437868455744 basic_session_run_hooks.py:263] loss = 6.6622744, step = 324200 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.751\n",
            "I0509 16:03:00.363879 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.751\n",
            "INFO:tensorflow:loss = 8.232742, step = 324300 (0.955 sec)\n",
            "I0509 16:03:00.364260 140437868455744 basic_session_run_hooks.py:263] loss = 8.232742, step = 324300 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 94.0159\n",
            "I0509 16:03:01.427544 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 94.0159\n",
            "INFO:tensorflow:loss = 5.95398, step = 324400 (1.064 sec)\n",
            "I0509 16:03:01.427831 140437868455744 basic_session_run_hooks.py:263] loss = 5.95398, step = 324400 (1.064 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.2928\n",
            "I0509 16:03:02.738267 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 76.2928\n",
            "INFO:tensorflow:loss = 7.215116, step = 324500 (1.311 sec)\n",
            "I0509 16:03:02.738642 140437868455744 basic_session_run_hooks.py:263] loss = 7.215116, step = 324500 (1.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.16\n",
            "I0509 16:03:03.680237 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.16\n",
            "INFO:tensorflow:loss = 4.5098805, step = 324600 (0.942 sec)\n",
            "I0509 16:03:03.680514 140437868455744 basic_session_run_hooks.py:263] loss = 4.5098805, step = 324600 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.809\n",
            "I0509 16:03:04.625336 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.809\n",
            "INFO:tensorflow:loss = 7.356035, step = 324700 (0.945 sec)\n",
            "I0509 16:03:04.625715 140437868455744 basic_session_run_hooks.py:263] loss = 7.356035, step = 324700 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.284\n",
            "I0509 16:03:05.575170 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.284\n",
            "INFO:tensorflow:loss = 7.2896895, step = 324800 (0.950 sec)\n",
            "I0509 16:03:05.575545 140437868455744 basic_session_run_hooks.py:263] loss = 7.2896895, step = 324800 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.587\n",
            "I0509 16:03:06.522248 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.587\n",
            "INFO:tensorflow:loss = 6.6042933, step = 324900 (0.947 sec)\n",
            "I0509 16:03:06.522546 140437868455744 basic_session_run_hooks.py:263] loss = 6.6042933, step = 324900 (0.947 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 325000...\n",
            "I0509 16:03:07.471796 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 325000...\n",
            "INFO:tensorflow:Saving checkpoints for 325000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:03:07.472005 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 325000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 325000...\n",
            "I0509 16:03:07.694650 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 325000...\n",
            "INFO:tensorflow:global_step/sec: 84.4223\n",
            "I0509 16:03:07.706736 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.4223\n",
            "INFO:tensorflow:loss = 6.4092617, step = 325000 (1.185 sec)\n",
            "I0509 16:03:07.707075 140437868455744 basic_session_run_hooks.py:263] loss = 6.4092617, step = 325000 (1.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.251\n",
            "I0509 16:03:08.647924 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.251\n",
            "INFO:tensorflow:loss = 6.995526, step = 325100 (0.941 sec)\n",
            "I0509 16:03:08.648282 140437868455744 basic_session_run_hooks.py:263] loss = 6.995526, step = 325100 (0.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.203\n",
            "I0509 16:03:09.598460 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.203\n",
            "INFO:tensorflow:loss = 5.075157, step = 325200 (0.951 sec)\n",
            "I0509 16:03:09.598828 140437868455744 basic_session_run_hooks.py:263] loss = 5.075157, step = 325200 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.276\n",
            "I0509 16:03:10.557459 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.276\n",
            "INFO:tensorflow:loss = 6.5920987, step = 325300 (0.959 sec)\n",
            "I0509 16:03:10.557822 140437868455744 basic_session_run_hooks.py:263] loss = 6.5920987, step = 325300 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.605\n",
            "I0509 16:03:11.513437 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.605\n",
            "INFO:tensorflow:loss = 4.4247646, step = 325400 (0.956 sec)\n",
            "I0509 16:03:11.513713 140437868455744 basic_session_run_hooks.py:263] loss = 4.4247646, step = 325400 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.638\n",
            "I0509 16:03:12.469141 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.638\n",
            "INFO:tensorflow:loss = 6.204939, step = 325500 (0.956 sec)\n",
            "I0509 16:03:12.469423 140437868455744 basic_session_run_hooks.py:263] loss = 6.204939, step = 325500 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.5555\n",
            "I0509 16:03:13.810410 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 74.5555\n",
            "INFO:tensorflow:loss = 3.7453063, step = 325600 (1.341 sec)\n",
            "I0509 16:03:13.810823 140437868455744 basic_session_run_hooks.py:263] loss = 3.7453063, step = 325600 (1.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 94.9603\n",
            "I0509 16:03:14.863466 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 94.9603\n",
            "INFO:tensorflow:loss = 4.9012294, step = 325700 (1.053 sec)\n",
            "I0509 16:03:14.863823 140437868455744 basic_session_run_hooks.py:263] loss = 4.9012294, step = 325700 (1.053 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.462\n",
            "I0509 16:03:15.811679 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.462\n",
            "INFO:tensorflow:loss = 3.4764895, step = 325800 (0.948 sec)\n",
            "I0509 16:03:15.811960 140437868455744 basic_session_run_hooks.py:263] loss = 3.4764895, step = 325800 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.499\n",
            "I0509 16:03:16.759553 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.499\n",
            "INFO:tensorflow:loss = 6.6339746, step = 325900 (0.948 sec)\n",
            "I0509 16:03:16.759917 140437868455744 basic_session_run_hooks.py:263] loss = 6.6339746, step = 325900 (0.948 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 326000...\n",
            "I0509 16:03:17.706549 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 326000...\n",
            "INFO:tensorflow:Saving checkpoints for 326000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:03:17.706748 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 326000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 326000...\n",
            "I0509 16:03:17.936791 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 326000...\n",
            "INFO:tensorflow:global_step/sec: 84.0315\n",
            "I0509 16:03:17.949575 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.0315\n",
            "INFO:tensorflow:loss = 5.5253997, step = 326000 (1.190 sec)\n",
            "I0509 16:03:17.949937 140437868455744 basic_session_run_hooks.py:263] loss = 5.5253997, step = 326000 (1.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.805\n",
            "I0509 16:03:18.912945 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.805\n",
            "INFO:tensorflow:loss = 6.4306107, step = 326100 (0.964 sec)\n",
            "I0509 16:03:18.913550 140437868455744 basic_session_run_hooks.py:263] loss = 6.4306107, step = 326100 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.577\n",
            "I0509 16:03:19.887804 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.577\n",
            "INFO:tensorflow:loss = 5.3499746, step = 326200 (0.975 sec)\n",
            "I0509 16:03:19.888115 140437868455744 basic_session_run_hooks.py:263] loss = 5.3499746, step = 326200 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.937\n",
            "I0509 16:03:20.859270 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.937\n",
            "INFO:tensorflow:loss = 8.226439, step = 326300 (0.972 sec)\n",
            "I0509 16:03:20.859643 140437868455744 basic_session_run_hooks.py:263] loss = 8.226439, step = 326300 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.772\n",
            "I0509 16:03:21.822932 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.772\n",
            "INFO:tensorflow:loss = 6.1468916, step = 326400 (0.964 sec)\n",
            "I0509 16:03:21.823242 140437868455744 basic_session_run_hooks.py:263] loss = 6.1468916, step = 326400 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.753\n",
            "I0509 16:03:22.777550 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.753\n",
            "INFO:tensorflow:loss = 6.5278807, step = 326500 (0.955 sec)\n",
            "I0509 16:03:22.777924 140437868455744 basic_session_run_hooks.py:263] loss = 6.5278807, step = 326500 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.772\n",
            "I0509 16:03:23.760165 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.772\n",
            "INFO:tensorflow:loss = 6.056224, step = 326600 (0.983 sec)\n",
            "I0509 16:03:23.760445 140437868455744 basic_session_run_hooks.py:263] loss = 6.056224, step = 326600 (0.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.3932\n",
            "I0509 16:03:24.959292 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.3932\n",
            "INFO:tensorflow:loss = 7.1941857, step = 326700 (1.199 sec)\n",
            "I0509 16:03:24.959649 140437868455744 basic_session_run_hooks.py:263] loss = 7.1941857, step = 326700 (1.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.5377\n",
            "I0509 16:03:26.170863 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.5377\n",
            "INFO:tensorflow:loss = 5.0052466, step = 326800 (1.212 sec)\n",
            "I0509 16:03:26.171276 140437868455744 basic_session_run_hooks.py:263] loss = 5.0052466, step = 326800 (1.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.165\n",
            "I0509 16:03:27.121728 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.165\n",
            "INFO:tensorflow:loss = 5.614433, step = 326900 (0.951 sec)\n",
            "I0509 16:03:27.122137 140437868455744 basic_session_run_hooks.py:263] loss = 5.614433, step = 326900 (0.951 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 327000...\n",
            "I0509 16:03:28.070676 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 327000...\n",
            "INFO:tensorflow:Saving checkpoints for 327000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:03:28.070869 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 327000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 327000...\n",
            "I0509 16:03:28.286870 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 327000...\n",
            "INFO:tensorflow:global_step/sec: 84.9288\n",
            "I0509 16:03:28.299193 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.9288\n",
            "INFO:tensorflow:loss = 7.86139, step = 327000 (1.177 sec)\n",
            "I0509 16:03:28.299522 140437868455744 basic_session_run_hooks.py:263] loss = 7.86139, step = 327000 (1.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.667\n",
            "I0509 16:03:29.263822 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.667\n",
            "INFO:tensorflow:loss = 6.2594147, step = 327100 (0.965 sec)\n",
            "I0509 16:03:29.264194 140437868455744 basic_session_run_hooks.py:263] loss = 6.2594147, step = 327100 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.493\n",
            "I0509 16:03:30.211749 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.493\n",
            "INFO:tensorflow:loss = 6.304349, step = 327200 (0.948 sec)\n",
            "I0509 16:03:30.212040 140437868455744 basic_session_run_hooks.py:263] loss = 6.304349, step = 327200 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.086\n",
            "I0509 16:03:31.154388 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.086\n",
            "INFO:tensorflow:loss = 6.951915, step = 327300 (0.943 sec)\n",
            "I0509 16:03:31.154757 140437868455744 basic_session_run_hooks.py:263] loss = 6.951915, step = 327300 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 107.309\n",
            "I0509 16:03:32.086274 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 107.309\n",
            "INFO:tensorflow:loss = 6.8031154, step = 327400 (0.932 sec)\n",
            "I0509 16:03:32.086559 140437868455744 basic_session_run_hooks.py:263] loss = 6.8031154, step = 327400 (0.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.461\n",
            "I0509 16:03:33.034492 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.461\n",
            "INFO:tensorflow:loss = 4.9085393, step = 327500 (0.948 sec)\n",
            "I0509 16:03:33.034861 140437868455744 basic_session_run_hooks.py:263] loss = 4.9085393, step = 327500 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.114\n",
            "I0509 16:03:34.004310 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.114\n",
            "INFO:tensorflow:loss = 6.335529, step = 327600 (0.970 sec)\n",
            "I0509 16:03:34.004593 140437868455744 basic_session_run_hooks.py:263] loss = 6.335529, step = 327600 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.639\n",
            "I0509 16:03:34.969206 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.639\n",
            "INFO:tensorflow:loss = 4.6486907, step = 327700 (0.965 sec)\n",
            "I0509 16:03:34.969607 140437868455744 basic_session_run_hooks.py:263] loss = 4.6486907, step = 327700 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.9283\n",
            "I0509 16:03:36.000899 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 96.9283\n",
            "INFO:tensorflow:loss = 5.6734443, step = 327800 (1.032 sec)\n",
            "I0509 16:03:36.001356 140437868455744 basic_session_run_hooks.py:263] loss = 5.6734443, step = 327800 (1.032 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.8849\n",
            "I0509 16:03:37.354341 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.8849\n",
            "INFO:tensorflow:loss = 6.3268156, step = 327900 (1.353 sec)\n",
            "I0509 16:03:37.354725 140437868455744 basic_session_run_hooks.py:263] loss = 6.3268156, step = 327900 (1.353 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 328000...\n",
            "I0509 16:03:38.286417 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 328000...\n",
            "INFO:tensorflow:Saving checkpoints for 328000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:03:38.286626 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 328000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 328000...\n",
            "I0509 16:03:38.501398 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 328000...\n",
            "INFO:tensorflow:global_step/sec: 86.2548\n",
            "I0509 16:03:38.513677 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.2548\n",
            "INFO:tensorflow:loss = 7.1542625, step = 328000 (1.159 sec)\n",
            "I0509 16:03:38.514040 140437868455744 basic_session_run_hooks.py:263] loss = 7.1542625, step = 328000 (1.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.629\n",
            "I0509 16:03:39.478677 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.629\n",
            "INFO:tensorflow:loss = 5.514904, step = 328100 (0.965 sec)\n",
            "I0509 16:03:39.479074 140437868455744 basic_session_run_hooks.py:263] loss = 5.514904, step = 328100 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.024\n",
            "I0509 16:03:40.449318 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.024\n",
            "INFO:tensorflow:loss = 4.8844976, step = 328200 (0.971 sec)\n",
            "I0509 16:03:40.449590 140437868455744 basic_session_run_hooks.py:263] loss = 4.8844976, step = 328200 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.922\n",
            "I0509 16:03:41.411582 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.922\n",
            "INFO:tensorflow:loss = 5.9091907, step = 328300 (0.962 sec)\n",
            "I0509 16:03:41.411939 140437868455744 basic_session_run_hooks.py:263] loss = 5.9091907, step = 328300 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.659\n",
            "I0509 16:03:42.405051 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.659\n",
            "INFO:tensorflow:loss = 6.8295555, step = 328400 (0.993 sec)\n",
            "I0509 16:03:42.405433 140437868455744 basic_session_run_hooks.py:263] loss = 6.8295555, step = 328400 (0.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.057\n",
            "I0509 16:03:43.356902 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.057\n",
            "INFO:tensorflow:loss = 7.102573, step = 328500 (0.952 sec)\n",
            "I0509 16:03:43.357285 140437868455744 basic_session_run_hooks.py:263] loss = 7.102573, step = 328500 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.49\n",
            "I0509 16:03:44.313972 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.49\n",
            "INFO:tensorflow:loss = 7.7489715, step = 328600 (0.957 sec)\n",
            "I0509 16:03:44.314379 140437868455744 basic_session_run_hooks.py:263] loss = 7.7489715, step = 328600 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.847\n",
            "I0509 16:03:45.267699 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.847\n",
            "INFO:tensorflow:loss = 6.3441525, step = 328700 (0.954 sec)\n",
            "I0509 16:03:45.268092 140437868455744 basic_session_run_hooks.py:263] loss = 6.3441525, step = 328700 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.635\n",
            "I0509 16:03:46.223402 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.635\n",
            "INFO:tensorflow:loss = 7.587228, step = 328800 (0.956 sec)\n",
            "I0509 16:03:46.223771 140437868455744 basic_session_run_hooks.py:263] loss = 7.587228, step = 328800 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.25\n",
            "I0509 16:03:47.182647 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.25\n",
            "INFO:tensorflow:loss = 6.4562626, step = 328900 (0.959 sec)\n",
            "I0509 16:03:47.183095 140437868455744 basic_session_run_hooks.py:263] loss = 6.4562626, step = 328900 (0.959 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 329000...\n",
            "I0509 16:03:48.499301 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 329000...\n",
            "INFO:tensorflow:Saving checkpoints for 329000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:03:48.499509 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 329000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 329000...\n",
            "I0509 16:03:48.843737 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 329000...\n",
            "INFO:tensorflow:global_step/sec: 59.5335\n",
            "I0509 16:03:48.862356 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 59.5335\n",
            "INFO:tensorflow:loss = 6.9756246, step = 329000 (1.680 sec)\n",
            "I0509 16:03:48.862612 140437868455744 basic_session_run_hooks.py:263] loss = 6.9756246, step = 329000 (1.680 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.7886\n",
            "I0509 16:03:49.884975 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 97.7886\n",
            "INFO:tensorflow:loss = 6.3959866, step = 329100 (1.023 sec)\n",
            "I0509 16:03:49.885353 140437868455744 basic_session_run_hooks.py:263] loss = 6.3959866, step = 329100 (1.023 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.559\n",
            "I0509 16:03:50.869627 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.559\n",
            "INFO:tensorflow:loss = 5.978319, step = 329200 (0.985 sec)\n",
            "I0509 16:03:50.870020 140437868455744 basic_session_run_hooks.py:263] loss = 5.978319, step = 329200 (0.985 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.13\n",
            "I0509 16:03:51.829971 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.13\n",
            "INFO:tensorflow:loss = 5.1272306, step = 329300 (0.960 sec)\n",
            "I0509 16:03:51.830354 140437868455744 basic_session_run_hooks.py:263] loss = 5.1272306, step = 329300 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.635\n",
            "I0509 16:03:52.813876 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.635\n",
            "INFO:tensorflow:loss = 6.760328, step = 329400 (0.984 sec)\n",
            "I0509 16:03:52.814265 140437868455744 basic_session_run_hooks.py:263] loss = 6.760328, step = 329400 (0.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.905\n",
            "I0509 16:03:53.785637 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.905\n",
            "INFO:tensorflow:loss = 5.9892907, step = 329500 (0.972 sec)\n",
            "I0509 16:03:53.786028 140437868455744 basic_session_run_hooks.py:263] loss = 5.9892907, step = 329500 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.709\n",
            "I0509 16:03:54.749868 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.709\n",
            "INFO:tensorflow:loss = 7.1402674, step = 329600 (0.964 sec)\n",
            "I0509 16:03:54.750273 140437868455744 basic_session_run_hooks.py:263] loss = 7.1402674, step = 329600 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.75\n",
            "I0509 16:03:55.713726 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.75\n",
            "INFO:tensorflow:loss = 6.646916, step = 329700 (0.964 sec)\n",
            "I0509 16:03:55.714648 140437868455744 basic_session_run_hooks.py:263] loss = 6.646916, step = 329700 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.688\n",
            "I0509 16:03:56.659879 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.688\n",
            "INFO:tensorflow:loss = 6.606852, step = 329800 (0.946 sec)\n",
            "I0509 16:03:56.660254 140437868455744 basic_session_run_hooks.py:263] loss = 6.606852, step = 329800 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.006\n",
            "I0509 16:03:57.612222 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.006\n",
            "INFO:tensorflow:loss = 7.335705, step = 329900 (0.952 sec)\n",
            "I0509 16:03:57.612601 140437868455744 basic_session_run_hooks.py:263] loss = 7.335705, step = 329900 (0.952 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 330000...\n",
            "I0509 16:03:58.564253 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 330000...\n",
            "INFO:tensorflow:Saving checkpoints for 330000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:03:58.564549 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 330000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 330000...\n",
            "I0509 16:03:58.789263 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 330000...\n",
            "INFO:tensorflow:global_step/sec: 83.8386\n",
            "I0509 16:03:58.804985 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.8386\n",
            "INFO:tensorflow:loss = 7.2412457, step = 330000 (1.193 sec)\n",
            "I0509 16:03:58.805342 140437868455744 basic_session_run_hooks.py:263] loss = 7.2412457, step = 330000 (1.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.6062\n",
            "I0509 16:04:00.145369 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 74.6062\n",
            "INFO:tensorflow:loss = 6.768298, step = 330100 (1.340 sec)\n",
            "I0509 16:04:00.145653 140437868455744 basic_session_run_hooks.py:263] loss = 6.768298, step = 330100 (1.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 95.7366\n",
            "I0509 16:04:01.189899 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 95.7366\n",
            "INFO:tensorflow:loss = 6.7193847, step = 330200 (1.045 sec)\n",
            "I0509 16:04:01.190185 140437868455744 basic_session_run_hooks.py:263] loss = 6.7193847, step = 330200 (1.045 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.721\n",
            "I0509 16:04:02.163418 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.721\n",
            "INFO:tensorflow:loss = 6.826776, step = 330300 (0.974 sec)\n",
            "I0509 16:04:02.163728 140437868455744 basic_session_run_hooks.py:263] loss = 6.826776, step = 330300 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.443\n",
            "I0509 16:04:03.139551 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.443\n",
            "INFO:tensorflow:loss = 7.6734185, step = 330400 (0.976 sec)\n",
            "I0509 16:04:03.139831 140437868455744 basic_session_run_hooks.py:263] loss = 7.6734185, step = 330400 (0.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.175\n",
            "I0509 16:04:04.127966 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.175\n",
            "INFO:tensorflow:loss = 5.83258, step = 330500 (0.989 sec)\n",
            "I0509 16:04:04.128353 140437868455744 basic_session_run_hooks.py:263] loss = 5.83258, step = 330500 (0.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.05\n",
            "I0509 16:04:05.079890 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.05\n",
            "INFO:tensorflow:loss = 7.533777, step = 330600 (0.952 sec)\n",
            "I0509 16:04:05.080279 140437868455744 basic_session_run_hooks.py:263] loss = 7.533777, step = 330600 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.354\n",
            "I0509 16:04:06.038182 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.354\n",
            "INFO:tensorflow:loss = 6.7415643, step = 330700 (0.958 sec)\n",
            "I0509 16:04:06.038558 140437868455744 basic_session_run_hooks.py:263] loss = 6.7415643, step = 330700 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.757\n",
            "I0509 16:04:06.983729 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.757\n",
            "INFO:tensorflow:loss = 6.996726, step = 330800 (0.946 sec)\n",
            "I0509 16:04:06.984114 140437868455744 basic_session_run_hooks.py:263] loss = 6.996726, step = 330800 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.648\n",
            "I0509 16:04:07.948536 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.648\n",
            "INFO:tensorflow:loss = 6.9656334, step = 330900 (0.965 sec)\n",
            "I0509 16:04:07.948921 140437868455744 basic_session_run_hooks.py:263] loss = 6.9656334, step = 330900 (0.965 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 331000...\n",
            "I0509 16:04:08.912660 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 331000...\n",
            "INFO:tensorflow:Saving checkpoints for 331000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:04:08.912872 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 331000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 331000...\n",
            "I0509 16:04:09.143684 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 331000...\n",
            "INFO:tensorflow:global_step/sec: 82.8196\n",
            "I0509 16:04:09.155964 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.8196\n",
            "INFO:tensorflow:loss = 6.5602894, step = 331000 (1.207 sec)\n",
            "I0509 16:04:09.156226 140437868455744 basic_session_run_hooks.py:263] loss = 6.5602894, step = 331000 (1.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.447\n",
            "I0509 16:04:10.132107 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.447\n",
            "INFO:tensorflow:loss = 5.9094415, step = 331100 (0.976 sec)\n",
            "I0509 16:04:10.132492 140437868455744 basic_session_run_hooks.py:263] loss = 5.9094415, step = 331100 (0.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.8573\n",
            "I0509 16:04:11.296828 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.8573\n",
            "INFO:tensorflow:loss = 7.5643125, step = 331200 (1.165 sec)\n",
            "I0509 16:04:11.297215 140437868455744 basic_session_run_hooks.py:263] loss = 7.5643125, step = 331200 (1.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.6658\n",
            "I0509 16:04:12.492053 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.6658\n",
            "INFO:tensorflow:loss = 6.1523514, step = 331300 (1.195 sec)\n",
            "I0509 16:04:12.492424 140437868455744 basic_session_run_hooks.py:263] loss = 6.1523514, step = 331300 (1.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.393\n",
            "I0509 16:04:13.440879 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.393\n",
            "INFO:tensorflow:loss = 6.5214086, step = 331400 (0.949 sec)\n",
            "I0509 16:04:13.441252 140437868455744 basic_session_run_hooks.py:263] loss = 6.5214086, step = 331400 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.708\n",
            "I0509 16:04:14.405190 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.708\n",
            "INFO:tensorflow:loss = 6.4532523, step = 331500 (0.964 sec)\n",
            "I0509 16:04:14.405488 140437868455744 basic_session_run_hooks.py:263] loss = 6.4532523, step = 331500 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.454\n",
            "I0509 16:04:15.353407 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.454\n",
            "INFO:tensorflow:loss = 5.824215, step = 331600 (0.948 sec)\n",
            "I0509 16:04:15.353690 140437868455744 basic_session_run_hooks.py:263] loss = 5.824215, step = 331600 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.495\n",
            "I0509 16:04:16.301325 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.495\n",
            "INFO:tensorflow:loss = 6.096232, step = 331700 (0.948 sec)\n",
            "I0509 16:04:16.301638 140437868455744 basic_session_run_hooks.py:263] loss = 6.096232, step = 331700 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.785\n",
            "I0509 16:04:17.274226 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.785\n",
            "INFO:tensorflow:loss = 8.303536, step = 331800 (0.973 sec)\n",
            "I0509 16:04:17.274606 140437868455744 basic_session_run_hooks.py:263] loss = 8.303536, step = 331800 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.54\n",
            "I0509 16:04:18.268855 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.54\n",
            "INFO:tensorflow:loss = 6.3188314, step = 331900 (0.995 sec)\n",
            "I0509 16:04:18.269162 140437868455744 basic_session_run_hooks.py:263] loss = 6.3188314, step = 331900 (0.995 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 332000...\n",
            "I0509 16:04:19.214295 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 332000...\n",
            "INFO:tensorflow:Saving checkpoints for 332000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:04:19.214503 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 332000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 332000...\n",
            "I0509 16:04:19.422455 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 332000...\n",
            "INFO:tensorflow:global_step/sec: 85.7559\n",
            "I0509 16:04:19.434941 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.7559\n",
            "INFO:tensorflow:loss = 7.921598, step = 332000 (1.166 sec)\n",
            "I0509 16:04:19.435199 140437868455744 basic_session_run_hooks.py:263] loss = 7.921598, step = 332000 (1.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.123\n",
            "I0509 16:04:20.404686 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.123\n",
            "INFO:tensorflow:loss = 6.2124963, step = 332100 (0.970 sec)\n",
            "I0509 16:04:20.405117 140437868455744 basic_session_run_hooks.py:263] loss = 6.2124963, step = 332100 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.039\n",
            "I0509 16:04:21.404296 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.039\n",
            "INFO:tensorflow:loss = 8.895107, step = 332200 (1.000 sec)\n",
            "I0509 16:04:21.404666 140437868455744 basic_session_run_hooks.py:263] loss = 8.895107, step = 332200 (1.000 sec)\n",
            "INFO:tensorflow:global_step/sec: 90.7843\n",
            "I0509 16:04:22.505810 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 90.7843\n",
            "INFO:tensorflow:loss = 7.780038, step = 332300 (1.102 sec)\n",
            "I0509 16:04:22.506177 140437868455744 basic_session_run_hooks.py:263] loss = 7.780038, step = 332300 (1.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.8778\n",
            "I0509 16:04:23.823714 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 75.8778\n",
            "INFO:tensorflow:loss = 5.32912, step = 332400 (1.318 sec)\n",
            "I0509 16:04:23.824083 140437868455744 basic_session_run_hooks.py:263] loss = 5.32912, step = 332400 (1.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.035\n",
            "I0509 16:04:24.803775 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.035\n",
            "INFO:tensorflow:loss = 5.7165217, step = 332500 (0.980 sec)\n",
            "I0509 16:04:24.804170 140437868455744 basic_session_run_hooks.py:263] loss = 5.7165217, step = 332500 (0.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.963\n",
            "I0509 16:04:25.784518 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.963\n",
            "INFO:tensorflow:loss = 5.961927, step = 332600 (0.981 sec)\n",
            "I0509 16:04:25.784881 140437868455744 basic_session_run_hooks.py:263] loss = 5.961927, step = 332600 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.244\n",
            "I0509 16:04:26.734714 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.244\n",
            "INFO:tensorflow:loss = 7.3809986, step = 332700 (0.950 sec)\n",
            "I0509 16:04:26.735027 140437868455744 basic_session_run_hooks.py:263] loss = 7.3809986, step = 332700 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.498\n",
            "I0509 16:04:27.691643 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.498\n",
            "INFO:tensorflow:loss = 7.258084, step = 332800 (0.957 sec)\n",
            "I0509 16:04:27.691916 140437868455744 basic_session_run_hooks.py:263] loss = 7.258084, step = 332800 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.959\n",
            "I0509 16:04:28.644403 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.959\n",
            "INFO:tensorflow:loss = 7.3712325, step = 332900 (0.953 sec)\n",
            "I0509 16:04:28.644756 140437868455744 basic_session_run_hooks.py:263] loss = 7.3712325, step = 332900 (0.953 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 333000...\n",
            "I0509 16:04:29.599049 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 333000...\n",
            "INFO:tensorflow:Saving checkpoints for 333000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:04:29.599269 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 333000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 333000...\n",
            "I0509 16:04:29.800155 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 333000...\n",
            "INFO:tensorflow:global_step/sec: 85.615\n",
            "I0509 16:04:29.812398 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.615\n",
            "INFO:tensorflow:loss = 6.520062, step = 333000 (1.168 sec)\n",
            "I0509 16:04:29.812728 140437868455744 basic_session_run_hooks.py:263] loss = 6.520062, step = 333000 (1.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.819\n",
            "I0509 16:04:30.775625 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.819\n",
            "INFO:tensorflow:loss = 5.622325, step = 333100 (0.963 sec)\n",
            "I0509 16:04:30.776009 140437868455744 basic_session_run_hooks.py:263] loss = 5.622325, step = 333100 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.695\n",
            "I0509 16:04:31.721752 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.695\n",
            "INFO:tensorflow:loss = 6.603765, step = 333200 (0.946 sec)\n",
            "I0509 16:04:31.722134 140437868455744 basic_session_run_hooks.py:263] loss = 6.603765, step = 333200 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.273\n",
            "I0509 16:04:32.671655 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.273\n",
            "INFO:tensorflow:loss = 7.083234, step = 333300 (0.950 sec)\n",
            "I0509 16:04:32.672043 140437868455744 basic_session_run_hooks.py:263] loss = 7.083234, step = 333300 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.768\n",
            "I0509 16:04:33.635345 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.768\n",
            "INFO:tensorflow:loss = 5.3750386, step = 333400 (0.964 sec)\n",
            "I0509 16:04:33.635650 140437868455744 basic_session_run_hooks.py:263] loss = 5.3750386, step = 333400 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.6768\n",
            "I0509 16:04:34.992647 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.6768\n",
            "INFO:tensorflow:loss = 6.047868, step = 333500 (1.357 sec)\n",
            "I0509 16:04:34.993025 140437868455744 basic_session_run_hooks.py:263] loss = 6.047868, step = 333500 (1.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.9766\n",
            "I0509 16:04:36.013282 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 97.9766\n",
            "INFO:tensorflow:loss = 5.299839, step = 333600 (1.021 sec)\n",
            "I0509 16:04:36.013666 140437868455744 basic_session_run_hooks.py:263] loss = 5.299839, step = 333600 (1.021 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.254\n",
            "I0509 16:04:36.981759 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.254\n",
            "INFO:tensorflow:loss = 7.2029977, step = 333700 (0.968 sec)\n",
            "I0509 16:04:36.982166 140437868455744 basic_session_run_hooks.py:263] loss = 7.2029977, step = 333700 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.732\n",
            "I0509 16:04:37.936576 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.732\n",
            "INFO:tensorflow:loss = 6.9716, step = 333800 (0.955 sec)\n",
            "I0509 16:04:37.936859 140437868455744 basic_session_run_hooks.py:263] loss = 6.9716, step = 333800 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.616\n",
            "I0509 16:04:38.874530 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.616\n",
            "INFO:tensorflow:loss = 7.084192, step = 333900 (0.938 sec)\n",
            "I0509 16:04:38.874892 140437868455744 basic_session_run_hooks.py:263] loss = 7.084192, step = 333900 (0.938 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 334000...\n",
            "I0509 16:04:39.836051 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 334000...\n",
            "INFO:tensorflow:Saving checkpoints for 334000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:04:39.836250 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 334000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 334000...\n",
            "I0509 16:04:40.037885 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 334000...\n",
            "INFO:tensorflow:global_step/sec: 85.0515\n",
            "I0509 16:04:40.050270 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.0515\n",
            "INFO:tensorflow:loss = 6.728057, step = 334000 (1.176 sec)\n",
            "I0509 16:04:40.050617 140437868455744 basic_session_run_hooks.py:263] loss = 6.728057, step = 334000 (1.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.6088\n",
            "I0509 16:04:41.074788 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 97.6088\n",
            "INFO:tensorflow:loss = 6.428739, step = 334100 (1.025 sec)\n",
            "I0509 16:04:41.075199 140437868455744 basic_session_run_hooks.py:263] loss = 6.428739, step = 334100 (1.025 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.905\n",
            "I0509 16:04:42.056102 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.905\n",
            "INFO:tensorflow:loss = 6.7798247, step = 334200 (0.981 sec)\n",
            "I0509 16:04:42.056468 140437868455744 basic_session_run_hooks.py:263] loss = 6.7798247, step = 334200 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.04\n",
            "I0509 16:04:43.026586 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.04\n",
            "INFO:tensorflow:loss = 6.297918, step = 334300 (0.971 sec)\n",
            "I0509 16:04:43.026971 140437868455744 basic_session_run_hooks.py:263] loss = 6.297918, step = 334300 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.103\n",
            "I0509 16:04:43.978045 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.103\n",
            "INFO:tensorflow:loss = 6.8042245, step = 334400 (0.951 sec)\n",
            "I0509 16:04:43.978345 140437868455744 basic_session_run_hooks.py:263] loss = 6.8042245, step = 334400 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.405\n",
            "I0509 16:04:44.917849 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.405\n",
            "INFO:tensorflow:loss = 5.4796543, step = 334500 (0.940 sec)\n",
            "I0509 16:04:44.918223 140437868455744 basic_session_run_hooks.py:263] loss = 5.4796543, step = 334500 (0.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.932\n",
            "I0509 16:04:46.201027 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.932\n",
            "INFO:tensorflow:loss = 6.3442016, step = 334600 (1.283 sec)\n",
            "I0509 16:04:46.201345 140437868455744 basic_session_run_hooks.py:263] loss = 6.3442016, step = 334600 (1.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 87.3005\n",
            "I0509 16:04:47.346492 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.3005\n",
            "INFO:tensorflow:loss = 5.9070616, step = 334700 (1.146 sec)\n",
            "I0509 16:04:47.346869 140437868455744 basic_session_run_hooks.py:263] loss = 5.9070616, step = 334700 (1.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.8\n",
            "I0509 16:04:48.291659 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.8\n",
            "INFO:tensorflow:loss = 7.273257, step = 334800 (0.945 sec)\n",
            "I0509 16:04:48.291937 140437868455744 basic_session_run_hooks.py:263] loss = 7.273257, step = 334800 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.663\n",
            "I0509 16:04:49.247128 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.663\n",
            "INFO:tensorflow:loss = 5.899387, step = 334900 (0.955 sec)\n",
            "I0509 16:04:49.247405 140437868455744 basic_session_run_hooks.py:263] loss = 5.899387, step = 334900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 335000...\n",
            "I0509 16:04:50.181556 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 335000...\n",
            "INFO:tensorflow:Saving checkpoints for 335000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:04:50.181755 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 335000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 335000...\n",
            "I0509 16:04:50.397789 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 335000...\n",
            "INFO:tensorflow:global_step/sec: 85.9663\n",
            "I0509 16:04:50.410354 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.9663\n",
            "INFO:tensorflow:loss = 4.1271377, step = 335000 (1.163 sec)\n",
            "I0509 16:04:50.410688 140437868455744 basic_session_run_hooks.py:263] loss = 4.1271377, step = 335000 (1.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.753\n",
            "I0509 16:04:51.383584 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.753\n",
            "INFO:tensorflow:loss = 8.150632, step = 335100 (0.973 sec)\n",
            "I0509 16:04:51.383990 140437868455744 basic_session_run_hooks.py:263] loss = 8.150632, step = 335100 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.476\n",
            "I0509 16:04:52.359401 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.476\n",
            "INFO:tensorflow:loss = 7.2799096, step = 335200 (0.976 sec)\n",
            "I0509 16:04:52.359772 140437868455744 basic_session_run_hooks.py:263] loss = 7.2799096, step = 335200 (0.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.914\n",
            "I0509 16:04:53.312565 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.914\n",
            "INFO:tensorflow:loss = 7.008526, step = 335300 (0.953 sec)\n",
            "I0509 16:04:53.312941 140437868455744 basic_session_run_hooks.py:263] loss = 7.008526, step = 335300 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.944\n",
            "I0509 16:04:54.274621 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.944\n",
            "INFO:tensorflow:loss = 6.909541, step = 335400 (0.962 sec)\n",
            "I0509 16:04:54.275007 140437868455744 basic_session_run_hooks.py:263] loss = 6.909541, step = 335400 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.825\n",
            "I0509 16:04:55.228599 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.825\n",
            "INFO:tensorflow:loss = 8.267062, step = 335500 (0.954 sec)\n",
            "I0509 16:04:55.228968 140437868455744 basic_session_run_hooks.py:263] loss = 8.267062, step = 335500 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.8077\n",
            "I0509 16:04:56.240655 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 98.8077\n",
            "INFO:tensorflow:loss = 7.1225495, step = 335600 (1.012 sec)\n",
            "I0509 16:04:56.241086 140437868455744 basic_session_run_hooks.py:263] loss = 7.1225495, step = 335600 (1.012 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.0762\n",
            "I0509 16:04:57.416117 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.0762\n",
            "INFO:tensorflow:loss = 6.3228226, step = 335700 (1.175 sec)\n",
            "I0509 16:04:57.416419 140437868455744 basic_session_run_hooks.py:263] loss = 6.3228226, step = 335700 (1.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.7517\n",
            "I0509 16:04:58.654437 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 80.7517\n",
            "INFO:tensorflow:loss = 7.1005936, step = 335800 (1.238 sec)\n",
            "I0509 16:04:58.654799 140437868455744 basic_session_run_hooks.py:263] loss = 7.1005936, step = 335800 (1.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.137\n",
            "I0509 16:04:59.624026 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.137\n",
            "INFO:tensorflow:loss = 6.049838, step = 335900 (0.970 sec)\n",
            "I0509 16:04:59.624418 140437868455744 basic_session_run_hooks.py:263] loss = 6.049838, step = 335900 (0.970 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 336000...\n",
            "I0509 16:05:00.560217 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 336000...\n",
            "INFO:tensorflow:Saving checkpoints for 336000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:05:00.560413 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 336000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 336000...\n",
            "I0509 16:05:00.780787 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 336000...\n",
            "INFO:tensorflow:global_step/sec: 85.5642\n",
            "I0509 16:05:00.792714 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.5642\n",
            "INFO:tensorflow:loss = 7.039629, step = 336000 (1.169 sec)\n",
            "I0509 16:05:00.793035 140437868455744 basic_session_run_hooks.py:263] loss = 7.039629, step = 336000 (1.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.774\n",
            "I0509 16:05:01.756379 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.774\n",
            "INFO:tensorflow:loss = 7.5026083, step = 336100 (0.964 sec)\n",
            "I0509 16:05:01.756655 140437868455744 basic_session_run_hooks.py:263] loss = 7.5026083, step = 336100 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.257\n",
            "I0509 16:05:02.715544 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.257\n",
            "INFO:tensorflow:loss = 6.9128075, step = 336200 (0.959 sec)\n",
            "I0509 16:05:02.715920 140437868455744 basic_session_run_hooks.py:263] loss = 6.9128075, step = 336200 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.947\n",
            "I0509 16:05:03.677549 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.947\n",
            "INFO:tensorflow:loss = 5.545687, step = 336300 (0.962 sec)\n",
            "I0509 16:05:03.677910 140437868455744 basic_session_run_hooks.py:263] loss = 5.545687, step = 336300 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.214\n",
            "I0509 16:05:04.637132 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.214\n",
            "INFO:tensorflow:loss = 6.3324447, step = 336400 (0.960 sec)\n",
            "I0509 16:05:04.637496 140437868455744 basic_session_run_hooks.py:263] loss = 6.3324447, step = 336400 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.762\n",
            "I0509 16:05:05.600868 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.762\n",
            "INFO:tensorflow:loss = 5.0005264, step = 336500 (0.964 sec)\n",
            "I0509 16:05:05.601231 140437868455744 basic_session_run_hooks.py:263] loss = 5.0005264, step = 336500 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.633\n",
            "I0509 16:05:06.575245 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.633\n",
            "INFO:tensorflow:loss = 6.5370426, step = 336600 (0.974 sec)\n",
            "I0509 16:05:06.575611 140437868455744 basic_session_run_hooks.py:263] loss = 6.5370426, step = 336600 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.912\n",
            "I0509 16:05:07.537562 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.912\n",
            "INFO:tensorflow:loss = 5.1410694, step = 336700 (0.962 sec)\n",
            "I0509 16:05:07.537935 140437868455744 basic_session_run_hooks.py:263] loss = 5.1410694, step = 336700 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 94.4951\n",
            "I0509 16:05:08.595863 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 94.4951\n",
            "INFO:tensorflow:loss = 7.7193394, step = 336800 (1.058 sec)\n",
            "I0509 16:05:08.596191 140437868455744 basic_session_run_hooks.py:263] loss = 7.7193394, step = 336800 (1.058 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.0499\n",
            "I0509 16:05:09.964756 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.0499\n",
            "INFO:tensorflow:loss = 7.402917, step = 336900 (1.369 sec)\n",
            "I0509 16:05:09.965150 140437868455744 basic_session_run_hooks.py:263] loss = 7.402917, step = 336900 (1.369 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 337000...\n",
            "I0509 16:05:10.936645 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 337000...\n",
            "INFO:tensorflow:Saving checkpoints for 337000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:05:10.936919 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 337000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 337000...\n",
            "I0509 16:05:11.144178 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 337000...\n",
            "INFO:tensorflow:global_step/sec: 83.9059\n",
            "I0509 16:05:11.156558 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.9059\n",
            "INFO:tensorflow:loss = 6.1736336, step = 337000 (1.192 sec)\n",
            "I0509 16:05:11.156935 140437868455744 basic_session_run_hooks.py:263] loss = 6.1736336, step = 337000 (1.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.764\n",
            "I0509 16:05:12.120285 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.764\n",
            "INFO:tensorflow:loss = 7.3579645, step = 337100 (0.964 sec)\n",
            "I0509 16:05:12.120640 140437868455744 basic_session_run_hooks.py:263] loss = 7.3579645, step = 337100 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.044\n",
            "I0509 16:05:13.063299 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.044\n",
            "INFO:tensorflow:loss = 7.33626, step = 337200 (0.943 sec)\n",
            "I0509 16:05:13.063671 140437868455744 basic_session_run_hooks.py:263] loss = 7.33626, step = 337200 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.289\n",
            "I0509 16:05:14.022197 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.289\n",
            "INFO:tensorflow:loss = 6.4004564, step = 337300 (0.959 sec)\n",
            "I0509 16:05:14.022475 140437868455744 basic_session_run_hooks.py:263] loss = 6.4004564, step = 337300 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.764\n",
            "I0509 16:05:14.985902 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.764\n",
            "INFO:tensorflow:loss = 6.518267, step = 337400 (0.964 sec)\n",
            "I0509 16:05:14.986285 140437868455744 basic_session_run_hooks.py:263] loss = 6.518267, step = 337400 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.163\n",
            "I0509 16:05:15.945939 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.163\n",
            "INFO:tensorflow:loss = 6.4472365, step = 337500 (0.960 sec)\n",
            "I0509 16:05:15.946328 140437868455744 basic_session_run_hooks.py:263] loss = 6.4472365, step = 337500 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.095\n",
            "I0509 16:05:16.925406 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.095\n",
            "INFO:tensorflow:loss = 6.684939, step = 337600 (0.979 sec)\n",
            "I0509 16:05:16.925774 140437868455744 basic_session_run_hooks.py:263] loss = 6.684939, step = 337600 (0.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.394\n",
            "I0509 16:05:17.874234 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.394\n",
            "INFO:tensorflow:loss = 6.737679, step = 337700 (0.949 sec)\n",
            "I0509 16:05:17.874523 140437868455744 basic_session_run_hooks.py:263] loss = 6.737679, step = 337700 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.135\n",
            "I0509 16:05:18.825386 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.135\n",
            "INFO:tensorflow:loss = 5.56706, step = 337800 (0.951 sec)\n",
            "I0509 16:05:18.825747 140437868455744 basic_session_run_hooks.py:263] loss = 5.56706, step = 337800 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.315\n",
            "I0509 16:05:19.784026 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.315\n",
            "INFO:tensorflow:loss = 6.9069676, step = 337900 (0.959 sec)\n",
            "I0509 16:05:19.784457 140437868455744 basic_session_run_hooks.py:263] loss = 6.9069676, step = 337900 (0.959 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 338000...\n",
            "I0509 16:05:21.120125 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 338000...\n",
            "INFO:tensorflow:Saving checkpoints for 338000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:05:21.120347 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 338000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 338000...\n",
            "I0509 16:05:21.495501 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 338000...\n",
            "INFO:tensorflow:global_step/sec: 57.8871\n",
            "I0509 16:05:21.511530 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 57.8871\n",
            "INFO:tensorflow:loss = 7.4382195, step = 338000 (1.727 sec)\n",
            "I0509 16:05:21.511917 140437868455744 basic_session_run_hooks.py:263] loss = 7.4382195, step = 338000 (1.727 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.3122\n",
            "I0509 16:05:22.518468 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.3122\n",
            "INFO:tensorflow:loss = 7.221609, step = 338100 (1.007 sec)\n",
            "I0509 16:05:22.518747 140437868455744 basic_session_run_hooks.py:263] loss = 7.221609, step = 338100 (1.007 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.367\n",
            "I0509 16:05:23.458587 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.367\n",
            "INFO:tensorflow:loss = 6.533683, step = 338200 (0.940 sec)\n",
            "I0509 16:05:23.458960 140437868455744 basic_session_run_hooks.py:263] loss = 6.533683, step = 338200 (0.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.63\n",
            "I0509 16:05:24.405296 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.63\n",
            "INFO:tensorflow:loss = 5.3822875, step = 338300 (0.947 sec)\n",
            "I0509 16:05:24.405683 140437868455744 basic_session_run_hooks.py:263] loss = 5.3822875, step = 338300 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.882\n",
            "I0509 16:05:25.349743 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.882\n",
            "INFO:tensorflow:loss = 6.792554, step = 338400 (0.944 sec)\n",
            "I0509 16:05:25.350126 140437868455744 basic_session_run_hooks.py:263] loss = 6.792554, step = 338400 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.594\n",
            "I0509 16:05:26.324472 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.594\n",
            "INFO:tensorflow:loss = 7.4698734, step = 338500 (0.975 sec)\n",
            "I0509 16:05:26.324839 140437868455744 basic_session_run_hooks.py:263] loss = 7.4698734, step = 338500 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.766\n",
            "I0509 16:05:27.297547 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.766\n",
            "INFO:tensorflow:loss = 7.073623, step = 338600 (0.973 sec)\n",
            "I0509 16:05:27.297922 140437868455744 basic_session_run_hooks.py:263] loss = 7.073623, step = 338600 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.712\n",
            "I0509 16:05:28.243519 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.712\n",
            "INFO:tensorflow:loss = 6.082226, step = 338700 (0.946 sec)\n",
            "I0509 16:05:28.243877 140437868455744 basic_session_run_hooks.py:263] loss = 6.082226, step = 338700 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.222\n",
            "I0509 16:05:29.193892 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.222\n",
            "INFO:tensorflow:loss = 5.913164, step = 338800 (0.950 sec)\n",
            "I0509 16:05:29.194297 140437868455744 basic_session_run_hooks.py:263] loss = 5.913164, step = 338800 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.163\n",
            "I0509 16:05:30.144782 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.163\n",
            "INFO:tensorflow:loss = 7.1340075, step = 338900 (0.951 sec)\n",
            "I0509 16:05:30.145147 140437868455744 basic_session_run_hooks.py:263] loss = 7.1340075, step = 338900 (0.951 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 339000...\n",
            "I0509 16:05:31.089892 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 339000...\n",
            "INFO:tensorflow:Saving checkpoints for 339000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:05:31.090100 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 339000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 339000...\n",
            "I0509 16:05:31.310192 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 339000...\n",
            "INFO:tensorflow:global_step/sec: 84.9092\n",
            "I0509 16:05:31.322500 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.9092\n",
            "INFO:tensorflow:loss = 7.245034, step = 339000 (1.178 sec)\n",
            "I0509 16:05:31.322844 140437868455744 basic_session_run_hooks.py:263] loss = 7.245034, step = 339000 (1.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.5028\n",
            "I0509 16:05:32.629668 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 76.5028\n",
            "INFO:tensorflow:loss = 5.8386955, step = 339100 (1.307 sec)\n",
            "I0509 16:05:32.630031 140437868455744 basic_session_run_hooks.py:263] loss = 5.8386955, step = 339100 (1.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 93.1027\n",
            "I0509 16:05:33.703757 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 93.1027\n",
            "INFO:tensorflow:loss = 6.27679, step = 339200 (1.074 sec)\n",
            "I0509 16:05:33.704181 140437868455744 basic_session_run_hooks.py:263] loss = 6.27679, step = 339200 (1.074 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.185\n",
            "I0509 16:05:34.663565 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.185\n",
            "INFO:tensorflow:loss = 6.4133787, step = 339300 (0.960 sec)\n",
            "I0509 16:05:34.663927 140437868455744 basic_session_run_hooks.py:263] loss = 6.4133787, step = 339300 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.783\n",
            "I0509 16:05:35.627146 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.783\n",
            "INFO:tensorflow:loss = 7.378745, step = 339400 (0.964 sec)\n",
            "I0509 16:05:35.627534 140437868455744 basic_session_run_hooks.py:263] loss = 7.378745, step = 339400 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.198\n",
            "I0509 16:05:36.605608 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.198\n",
            "INFO:tensorflow:loss = 6.692417, step = 339500 (0.978 sec)\n",
            "I0509 16:05:36.605996 140437868455744 basic_session_run_hooks.py:263] loss = 6.692417, step = 339500 (0.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.728\n",
            "I0509 16:05:37.560486 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.728\n",
            "INFO:tensorflow:loss = 5.6696076, step = 339600 (0.955 sec)\n",
            "I0509 16:05:37.561372 140437868455744 basic_session_run_hooks.py:263] loss = 5.6696076, step = 339600 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.801\n",
            "I0509 16:05:38.514642 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.801\n",
            "INFO:tensorflow:loss = 7.216491, step = 339700 (0.954 sec)\n",
            "I0509 16:05:38.514916 140437868455744 basic_session_run_hooks.py:263] loss = 7.216491, step = 339700 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.763\n",
            "I0509 16:05:39.460168 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.763\n",
            "INFO:tensorflow:loss = 7.006497, step = 339800 (0.946 sec)\n",
            "I0509 16:05:39.460529 140437868455744 basic_session_run_hooks.py:263] loss = 7.006497, step = 339800 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.714\n",
            "I0509 16:05:40.453072 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.714\n",
            "INFO:tensorflow:loss = 7.2407756, step = 339900 (0.993 sec)\n",
            "I0509 16:05:40.453448 140437868455744 basic_session_run_hooks.py:263] loss = 7.2407756, step = 339900 (0.993 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 340000...\n",
            "I0509 16:05:41.397217 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 340000...\n",
            "INFO:tensorflow:Saving checkpoints for 340000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:05:41.397422 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 340000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 340000...\n",
            "I0509 16:05:41.627122 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 340000...\n",
            "INFO:tensorflow:global_step/sec: 84.2203\n",
            "I0509 16:05:41.640435 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.2203\n",
            "INFO:tensorflow:loss = 6.127134, step = 340000 (1.187 sec)\n",
            "I0509 16:05:41.640677 140437868455744 basic_session_run_hooks.py:263] loss = 6.127134, step = 340000 (1.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.336\n",
            "I0509 16:05:42.608167 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.336\n",
            "INFO:tensorflow:loss = 6.090698, step = 340100 (0.968 sec)\n",
            "I0509 16:05:42.608525 140437868455744 basic_session_run_hooks.py:263] loss = 6.090698, step = 340100 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.0111\n",
            "I0509 16:05:43.798506 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.0111\n",
            "INFO:tensorflow:loss = 7.310913, step = 340200 (1.190 sec)\n",
            "I0509 16:05:43.798882 140437868455744 basic_session_run_hooks.py:263] loss = 7.310913, step = 340200 (1.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.0486\n",
            "I0509 16:05:45.002584 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.0486\n",
            "INFO:tensorflow:loss = 5.2851577, step = 340300 (1.204 sec)\n",
            "I0509 16:05:45.002946 140437868455744 basic_session_run_hooks.py:263] loss = 5.2851577, step = 340300 (1.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.755\n",
            "I0509 16:05:45.939305 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.755\n",
            "INFO:tensorflow:loss = 7.0962887, step = 340400 (0.937 sec)\n",
            "I0509 16:05:45.939658 140437868455744 basic_session_run_hooks.py:263] loss = 7.0962887, step = 340400 (0.937 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.521\n",
            "I0509 16:05:46.896084 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.521\n",
            "INFO:tensorflow:loss = 7.331342, step = 340500 (0.957 sec)\n",
            "I0509 16:05:46.896444 140437868455744 basic_session_run_hooks.py:263] loss = 7.331342, step = 340500 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.114\n",
            "I0509 16:05:47.847414 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.114\n",
            "INFO:tensorflow:loss = 8.22209, step = 340600 (0.951 sec)\n",
            "I0509 16:05:47.847794 140437868455744 basic_session_run_hooks.py:263] loss = 8.22209, step = 340600 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.702\n",
            "I0509 16:05:48.802492 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.702\n",
            "INFO:tensorflow:loss = 6.8415875, step = 340700 (0.955 sec)\n",
            "I0509 16:05:48.802854 140437868455744 basic_session_run_hooks.py:263] loss = 6.8415875, step = 340700 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.578\n",
            "I0509 16:05:49.758720 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.578\n",
            "INFO:tensorflow:loss = 6.748698, step = 340800 (0.956 sec)\n",
            "I0509 16:05:49.758996 140437868455744 basic_session_run_hooks.py:263] loss = 6.748698, step = 340800 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.379\n",
            "I0509 16:05:50.707682 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.379\n",
            "INFO:tensorflow:loss = 4.93857, step = 340900 (0.949 sec)\n",
            "I0509 16:05:50.708097 140437868455744 basic_session_run_hooks.py:263] loss = 4.93857, step = 340900 (0.949 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 341000...\n",
            "I0509 16:05:51.661142 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 341000...\n",
            "INFO:tensorflow:Saving checkpoints for 341000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:05:51.661331 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 341000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 341000...\n",
            "I0509 16:05:51.916039 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 341000...\n",
            "INFO:tensorflow:global_step/sec: 81.8261\n",
            "I0509 16:05:51.929946 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.8261\n",
            "INFO:tensorflow:loss = 5.2412696, step = 341000 (1.222 sec)\n",
            "I0509 16:05:51.930224 140437868455744 basic_session_run_hooks.py:263] loss = 5.2412696, step = 341000 (1.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.15\n",
            "I0509 16:05:52.918407 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.15\n",
            "INFO:tensorflow:loss = 6.5820155, step = 341100 (0.989 sec)\n",
            "I0509 16:05:52.918775 140437868455744 basic_session_run_hooks.py:263] loss = 6.5820155, step = 341100 (0.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.818\n",
            "I0509 16:05:53.881637 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.818\n",
            "INFO:tensorflow:loss = 6.999151, step = 341200 (0.963 sec)\n",
            "I0509 16:05:53.881929 140437868455744 basic_session_run_hooks.py:263] loss = 6.999151, step = 341200 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 93.7495\n",
            "I0509 16:05:54.948335 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 93.7495\n",
            "INFO:tensorflow:loss = 5.7609224, step = 341300 (1.067 sec)\n",
            "I0509 16:05:54.948651 140437868455744 basic_session_run_hooks.py:263] loss = 5.7609224, step = 341300 (1.067 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.5899\n",
            "I0509 16:05:56.325917 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 72.5899\n",
            "INFO:tensorflow:loss = 7.4382806, step = 341400 (1.378 sec)\n",
            "I0509 16:05:56.326307 140437868455744 basic_session_run_hooks.py:263] loss = 7.4382806, step = 341400 (1.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.076\n",
            "I0509 16:05:57.286757 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.076\n",
            "INFO:tensorflow:loss = 7.2965517, step = 341500 (0.961 sec)\n",
            "I0509 16:05:57.287048 140437868455744 basic_session_run_hooks.py:263] loss = 7.2965517, step = 341500 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.5\n",
            "I0509 16:05:58.234622 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.5\n",
            "INFO:tensorflow:loss = 6.570609, step = 341600 (0.948 sec)\n",
            "I0509 16:05:58.234993 140437868455744 basic_session_run_hooks.py:263] loss = 6.570609, step = 341600 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.723\n",
            "I0509 16:05:59.189513 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.723\n",
            "INFO:tensorflow:loss = 5.9988885, step = 341700 (0.955 sec)\n",
            "I0509 16:05:59.189814 140437868455744 basic_session_run_hooks.py:263] loss = 5.9988885, step = 341700 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.547\n",
            "I0509 16:06:00.146025 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.547\n",
            "INFO:tensorflow:loss = 6.7776976, step = 341800 (0.957 sec)\n",
            "I0509 16:06:00.146394 140437868455744 basic_session_run_hooks.py:263] loss = 6.7776976, step = 341800 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.671\n",
            "I0509 16:06:01.101394 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.671\n",
            "INFO:tensorflow:loss = 6.7834134, step = 341900 (0.955 sec)\n",
            "I0509 16:06:01.101754 140437868455744 basic_session_run_hooks.py:263] loss = 6.7834134, step = 341900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 342000...\n",
            "I0509 16:06:02.055636 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 342000...\n",
            "INFO:tensorflow:Saving checkpoints for 342000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:06:02.055823 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 342000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 342000...\n",
            "I0509 16:06:02.308794 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 342000...\n",
            "INFO:tensorflow:global_step/sec: 81.7123\n",
            "I0509 16:06:02.325233 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.7123\n",
            "INFO:tensorflow:loss = 6.1533685, step = 342000 (1.224 sec)\n",
            "I0509 16:06:02.325616 140437868455744 basic_session_run_hooks.py:263] loss = 6.1533685, step = 342000 (1.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.613\n",
            "I0509 16:06:03.290339 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.613\n",
            "INFO:tensorflow:loss = 6.7908697, step = 342100 (0.965 sec)\n",
            "I0509 16:06:03.290618 140437868455744 basic_session_run_hooks.py:263] loss = 6.7908697, step = 342100 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.522\n",
            "I0509 16:06:04.256330 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.522\n",
            "INFO:tensorflow:loss = 6.2051325, step = 342200 (0.966 sec)\n",
            "I0509 16:06:04.256708 140437868455744 basic_session_run_hooks.py:263] loss = 6.2051325, step = 342200 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.935\n",
            "I0509 16:06:05.200288 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.935\n",
            "INFO:tensorflow:loss = 5.0997677, step = 342300 (0.944 sec)\n",
            "I0509 16:06:05.200655 140437868455744 basic_session_run_hooks.py:263] loss = 5.0997677, step = 342300 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.958\n",
            "I0509 16:06:06.190832 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.958\n",
            "INFO:tensorflow:loss = 6.5806932, step = 342400 (0.990 sec)\n",
            "I0509 16:06:06.191154 140437868455744 basic_session_run_hooks.py:263] loss = 6.5806932, step = 342400 (0.990 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.4926\n",
            "I0509 16:06:07.609437 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 70.4926\n",
            "INFO:tensorflow:loss = 7.754985, step = 342500 (1.419 sec)\n",
            "I0509 16:06:07.609833 140437868455744 basic_session_run_hooks.py:263] loss = 7.754985, step = 342500 (1.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.937\n",
            "I0509 16:06:08.610029 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.937\n",
            "INFO:tensorflow:loss = 7.3193483, step = 342600 (1.001 sec)\n",
            "I0509 16:06:08.610407 140437868455744 basic_session_run_hooks.py:263] loss = 7.3193483, step = 342600 (1.001 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.435\n",
            "I0509 16:06:09.576814 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.435\n",
            "INFO:tensorflow:loss = 7.4921646, step = 342700 (0.967 sec)\n",
            "I0509 16:06:09.577181 140437868455744 basic_session_run_hooks.py:263] loss = 7.4921646, step = 342700 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.366\n",
            "I0509 16:06:10.544260 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.366\n",
            "INFO:tensorflow:loss = 5.7939844, step = 342800 (0.967 sec)\n",
            "I0509 16:06:10.544538 140437868455744 basic_session_run_hooks.py:263] loss = 5.7939844, step = 342800 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.887\n",
            "I0509 16:06:11.488667 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.887\n",
            "INFO:tensorflow:loss = 8.057427, step = 342900 (0.945 sec)\n",
            "I0509 16:06:11.489044 140437868455744 basic_session_run_hooks.py:263] loss = 8.057427, step = 342900 (0.945 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 343000...\n",
            "I0509 16:06:12.475335 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 343000...\n",
            "INFO:tensorflow:Saving checkpoints for 343000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:06:12.475557 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 343000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 343000...\n",
            "I0509 16:06:12.703734 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 343000...\n",
            "INFO:tensorflow:global_step/sec: 81.5163\n",
            "I0509 16:06:12.715387 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.5163\n",
            "INFO:tensorflow:loss = 7.3318286, step = 343000 (1.227 sec)\n",
            "I0509 16:06:12.715724 140437868455744 basic_session_run_hooks.py:263] loss = 7.3318286, step = 343000 (1.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.593\n",
            "I0509 16:06:13.671494 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.593\n",
            "INFO:tensorflow:loss = 5.0003486, step = 343100 (0.956 sec)\n",
            "I0509 16:06:13.671874 140437868455744 basic_session_run_hooks.py:263] loss = 5.0003486, step = 343100 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.685\n",
            "I0509 16:06:14.635956 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.685\n",
            "INFO:tensorflow:loss = 6.440076, step = 343200 (0.964 sec)\n",
            "I0509 16:06:14.636237 140437868455744 basic_session_run_hooks.py:263] loss = 6.440076, step = 343200 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.783\n",
            "I0509 16:06:15.581286 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.783\n",
            "INFO:tensorflow:loss = 7.3354635, step = 343300 (0.945 sec)\n",
            "I0509 16:06:15.581664 140437868455744 basic_session_run_hooks.py:263] loss = 7.3354635, step = 343300 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.688\n",
            "I0509 16:06:16.536504 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.688\n",
            "INFO:tensorflow:loss = 6.2406473, step = 343400 (0.955 sec)\n",
            "I0509 16:06:16.536871 140437868455744 basic_session_run_hooks.py:263] loss = 6.2406473, step = 343400 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.993\n",
            "I0509 16:06:17.507457 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.993\n",
            "INFO:tensorflow:loss = 6.4005175, step = 343500 (0.971 sec)\n",
            "I0509 16:06:17.507821 140437868455744 basic_session_run_hooks.py:263] loss = 6.4005175, step = 343500 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.0357\n",
            "I0509 16:06:18.805575 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.0357\n",
            "INFO:tensorflow:loss = 6.6430445, step = 343600 (1.298 sec)\n",
            "I0509 16:06:18.805975 140437868455744 basic_session_run_hooks.py:263] loss = 6.6430445, step = 343600 (1.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 90.3989\n",
            "I0509 16:06:19.911765 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 90.3989\n",
            "INFO:tensorflow:loss = 6.935442, step = 343700 (1.106 sec)\n",
            "I0509 16:06:19.912075 140437868455744 basic_session_run_hooks.py:263] loss = 6.935442, step = 343700 (1.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.155\n",
            "I0509 16:06:20.881199 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.155\n",
            "INFO:tensorflow:loss = 6.8250113, step = 343800 (0.969 sec)\n",
            "I0509 16:06:20.881487 140437868455744 basic_session_run_hooks.py:263] loss = 6.8250113, step = 343800 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.311\n",
            "I0509 16:06:21.849143 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.311\n",
            "INFO:tensorflow:loss = 7.5175414, step = 343900 (0.968 sec)\n",
            "I0509 16:06:21.849580 140437868455744 basic_session_run_hooks.py:263] loss = 7.5175414, step = 343900 (0.968 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 344000...\n",
            "I0509 16:06:22.848652 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 344000...\n",
            "INFO:tensorflow:Saving checkpoints for 344000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:06:22.848847 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 344000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 344000...\n",
            "I0509 16:06:23.056618 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 344000...\n",
            "INFO:tensorflow:global_step/sec: 81.5967\n",
            "I0509 16:06:23.074668 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.5967\n",
            "INFO:tensorflow:loss = 5.9806705, step = 344000 (1.225 sec)\n",
            "I0509 16:06:23.074955 140437868455744 basic_session_run_hooks.py:263] loss = 5.9806705, step = 344000 (1.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.253\n",
            "I0509 16:06:24.043196 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.253\n",
            "INFO:tensorflow:loss = 5.5446095, step = 344100 (0.969 sec)\n",
            "I0509 16:06:24.043503 140437868455744 basic_session_run_hooks.py:263] loss = 5.5446095, step = 344100 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.085\n",
            "I0509 16:06:24.994800 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.085\n",
            "INFO:tensorflow:loss = 6.880706, step = 344200 (0.952 sec)\n",
            "I0509 16:06:24.995234 140437868455744 basic_session_run_hooks.py:263] loss = 6.880706, step = 344200 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.756\n",
            "I0509 16:06:25.967953 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.756\n",
            "INFO:tensorflow:loss = 6.1913004, step = 344300 (0.973 sec)\n",
            "I0509 16:06:25.968346 140437868455744 basic_session_run_hooks.py:263] loss = 6.1913004, step = 344300 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.546\n",
            "I0509 16:06:26.952741 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.546\n",
            "INFO:tensorflow:loss = 8.106087, step = 344400 (0.985 sec)\n",
            "I0509 16:06:26.953137 140437868455744 basic_session_run_hooks.py:263] loss = 8.106087, step = 344400 (0.985 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.34\n",
            "I0509 16:06:27.939524 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.34\n",
            "INFO:tensorflow:loss = 7.398011, step = 344500 (0.987 sec)\n",
            "I0509 16:06:27.939797 140437868455744 basic_session_run_hooks.py:263] loss = 7.398011, step = 344500 (0.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.93\n",
            "I0509 16:06:28.892530 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.93\n",
            "INFO:tensorflow:loss = 6.7556415, step = 344600 (0.953 sec)\n",
            "I0509 16:06:28.892880 140437868455744 basic_session_run_hooks.py:263] loss = 6.7556415, step = 344600 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.338\n",
            "I0509 16:06:30.137282 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 80.338\n",
            "INFO:tensorflow:loss = 2.8238077, step = 344700 (1.245 sec)\n",
            "I0509 16:06:30.137578 140437868455744 basic_session_run_hooks.py:263] loss = 2.8238077, step = 344700 (1.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.9782\n",
            "I0509 16:06:31.314057 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.9782\n",
            "INFO:tensorflow:loss = 6.016826, step = 344800 (1.177 sec)\n",
            "I0509 16:06:31.314484 140437868455744 basic_session_run_hooks.py:263] loss = 6.016826, step = 344800 (1.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.596\n",
            "I0509 16:06:32.288753 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.596\n",
            "INFO:tensorflow:loss = 5.8565717, step = 344900 (0.975 sec)\n",
            "I0509 16:06:32.289031 140437868455744 basic_session_run_hooks.py:263] loss = 5.8565717, step = 344900 (0.975 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 345000...\n",
            "I0509 16:06:33.234641 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 345000...\n",
            "INFO:tensorflow:Saving checkpoints for 345000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:06:33.234837 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 345000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 345000...\n",
            "I0509 16:06:33.440331 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 345000...\n",
            "INFO:tensorflow:global_step/sec: 85.9425\n",
            "I0509 16:06:33.452295 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.9425\n",
            "INFO:tensorflow:loss = 6.6739683, step = 345000 (1.164 sec)\n",
            "I0509 16:06:33.452551 140437868455744 basic_session_run_hooks.py:263] loss = 6.6739683, step = 345000 (1.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.523\n",
            "I0509 16:06:34.409039 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.523\n",
            "INFO:tensorflow:loss = 8.795084, step = 345100 (0.957 sec)\n",
            "I0509 16:06:34.409411 140437868455744 basic_session_run_hooks.py:263] loss = 8.795084, step = 345100 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.942\n",
            "I0509 16:06:35.361947 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.942\n",
            "INFO:tensorflow:loss = 6.773205, step = 345200 (0.953 sec)\n",
            "I0509 16:06:35.362412 140437868455744 basic_session_run_hooks.py:263] loss = 6.773205, step = 345200 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.873\n",
            "I0509 16:06:36.324665 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.873\n",
            "INFO:tensorflow:loss = 6.7202177, step = 345300 (0.963 sec)\n",
            "I0509 16:06:36.325041 140437868455744 basic_session_run_hooks.py:263] loss = 6.7202177, step = 345300 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.575\n",
            "I0509 16:06:37.280924 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.575\n",
            "INFO:tensorflow:loss = 6.464891, step = 345400 (0.956 sec)\n",
            "I0509 16:06:37.281312 140437868455744 basic_session_run_hooks.py:263] loss = 6.464891, step = 345400 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.4\n",
            "I0509 16:06:38.229677 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.4\n",
            "INFO:tensorflow:loss = 5.8570423, step = 345500 (0.949 sec)\n",
            "I0509 16:06:38.230055 140437868455744 basic_session_run_hooks.py:263] loss = 5.8570423, step = 345500 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.367\n",
            "I0509 16:06:39.206564 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.367\n",
            "INFO:tensorflow:loss = 5.22763, step = 345600 (0.977 sec)\n",
            "I0509 16:06:39.206838 140437868455744 basic_session_run_hooks.py:263] loss = 5.22763, step = 345600 (0.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.919\n",
            "I0509 16:06:40.178217 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.919\n",
            "INFO:tensorflow:loss = 6.057174, step = 345700 (0.972 sec)\n",
            "I0509 16:06:40.178498 140437868455744 basic_session_run_hooks.py:263] loss = 6.057174, step = 345700 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.8018\n",
            "I0509 16:06:41.211268 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 96.8018\n",
            "INFO:tensorflow:loss = 6.481677, step = 345800 (1.033 sec)\n",
            "I0509 16:06:41.211691 140437868455744 basic_session_run_hooks.py:263] loss = 6.481677, step = 345800 (1.033 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.9287\n",
            "I0509 16:06:42.563900 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.9287\n",
            "INFO:tensorflow:loss = 6.684635, step = 345900 (1.353 sec)\n",
            "I0509 16:06:42.564289 140437868455744 basic_session_run_hooks.py:263] loss = 6.684635, step = 345900 (1.353 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 346000...\n",
            "I0509 16:06:43.496273 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 346000...\n",
            "INFO:tensorflow:Saving checkpoints for 346000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:06:43.496511 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 346000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 346000...\n",
            "I0509 16:06:43.715878 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 346000...\n",
            "INFO:tensorflow:global_step/sec: 85.8858\n",
            "I0509 16:06:43.728223 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.8858\n",
            "INFO:tensorflow:loss = 4.728525, step = 346000 (1.164 sec)\n",
            "I0509 16:06:43.728533 140437868455744 basic_session_run_hooks.py:263] loss = 4.728525, step = 346000 (1.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.86\n",
            "I0509 16:06:44.691051 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.86\n",
            "INFO:tensorflow:loss = 5.8447156, step = 346100 (0.963 sec)\n",
            "I0509 16:06:44.691434 140437868455744 basic_session_run_hooks.py:263] loss = 5.8447156, step = 346100 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.22\n",
            "I0509 16:06:45.641469 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.22\n",
            "INFO:tensorflow:loss = 6.988634, step = 346200 (0.950 sec)\n",
            "I0509 16:06:45.641835 140437868455744 basic_session_run_hooks.py:263] loss = 6.988634, step = 346200 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.917\n",
            "I0509 16:06:46.585593 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.917\n",
            "INFO:tensorflow:loss = 6.2753673, step = 346300 (0.944 sec)\n",
            "I0509 16:06:46.585976 140437868455744 basic_session_run_hooks.py:263] loss = 6.2753673, step = 346300 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.106\n",
            "I0509 16:06:47.555464 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.106\n",
            "INFO:tensorflow:loss = 7.81904, step = 346400 (0.970 sec)\n",
            "I0509 16:06:47.555843 140437868455744 basic_session_run_hooks.py:263] loss = 7.81904, step = 346400 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.329\n",
            "I0509 16:06:48.495945 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.329\n",
            "INFO:tensorflow:loss = 5.126817, step = 346500 (0.941 sec)\n",
            "I0509 16:06:48.496345 140437868455744 basic_session_run_hooks.py:263] loss = 5.126817, step = 346500 (0.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.205\n",
            "I0509 16:06:49.464891 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.205\n",
            "INFO:tensorflow:loss = 6.164861, step = 346600 (0.969 sec)\n",
            "I0509 16:06:49.465270 140437868455744 basic_session_run_hooks.py:263] loss = 6.164861, step = 346600 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.229\n",
            "I0509 16:06:50.415208 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.229\n",
            "INFO:tensorflow:loss = 7.535129, step = 346700 (0.950 sec)\n",
            "I0509 16:06:50.415617 140437868455744 basic_session_run_hooks.py:263] loss = 7.535129, step = 346700 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.497\n",
            "I0509 16:06:51.363082 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.497\n",
            "INFO:tensorflow:loss = 5.225163, step = 346800 (0.948 sec)\n",
            "I0509 16:06:51.363365 140437868455744 basic_session_run_hooks.py:263] loss = 5.225163, step = 346800 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.524\n",
            "I0509 16:06:52.329039 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.524\n",
            "INFO:tensorflow:loss = 5.767079, step = 346900 (0.966 sec)\n",
            "I0509 16:06:52.329423 140437868455744 basic_session_run_hooks.py:263] loss = 5.767079, step = 346900 (0.966 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 347000...\n",
            "I0509 16:06:53.665552 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 347000...\n",
            "INFO:tensorflow:Saving checkpoints for 347000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:06:53.665785 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 347000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 347000...\n",
            "I0509 16:06:54.025361 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 347000...\n",
            "INFO:tensorflow:global_step/sec: 58.2269\n",
            "I0509 16:06:54.046458 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 58.2269\n",
            "INFO:tensorflow:loss = 7.3356824, step = 347000 (1.717 sec)\n",
            "I0509 16:06:54.046806 140437868455744 basic_session_run_hooks.py:263] loss = 7.3356824, step = 347000 (1.717 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.237\n",
            "I0509 16:06:55.024584 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.237\n",
            "INFO:tensorflow:loss = 5.137114, step = 347100 (0.978 sec)\n",
            "I0509 16:06:55.024956 140437868455744 basic_session_run_hooks.py:263] loss = 5.137114, step = 347100 (0.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.705\n",
            "I0509 16:06:55.979641 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.705\n",
            "INFO:tensorflow:loss = 5.0906434, step = 347200 (0.955 sec)\n",
            "I0509 16:06:55.979921 140437868455744 basic_session_run_hooks.py:263] loss = 5.0906434, step = 347200 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.525\n",
            "I0509 16:06:56.955021 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.525\n",
            "INFO:tensorflow:loss = 4.688449, step = 347300 (0.975 sec)\n",
            "I0509 16:06:56.955326 140437868455744 basic_session_run_hooks.py:263] loss = 4.688449, step = 347300 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.783\n",
            "I0509 16:06:57.927950 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.783\n",
            "INFO:tensorflow:loss = 7.583428, step = 347400 (0.973 sec)\n",
            "I0509 16:06:57.928415 140437868455744 basic_session_run_hooks.py:263] loss = 7.583428, step = 347400 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.758\n",
            "I0509 16:06:58.891728 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.758\n",
            "INFO:tensorflow:loss = 6.3803754, step = 347500 (0.964 sec)\n",
            "I0509 16:06:58.893188 140437868455744 basic_session_run_hooks.py:263] loss = 6.3803754, step = 347500 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.038\n",
            "I0509 16:06:59.852909 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.038\n",
            "INFO:tensorflow:loss = 6.3862567, step = 347600 (0.961 sec)\n",
            "I0509 16:06:59.853210 140437868455744 basic_session_run_hooks.py:263] loss = 6.3862567, step = 347600 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.443\n",
            "I0509 16:07:00.801294 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.443\n",
            "INFO:tensorflow:loss = 7.2677236, step = 347700 (0.948 sec)\n",
            "I0509 16:07:00.801576 140437868455744 basic_session_run_hooks.py:263] loss = 7.2677236, step = 347700 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.339\n",
            "I0509 16:07:01.741681 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.339\n",
            "INFO:tensorflow:loss = 6.190781, step = 347800 (0.940 sec)\n",
            "I0509 16:07:01.741955 140437868455744 basic_session_run_hooks.py:263] loss = 6.190781, step = 347800 (0.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.91\n",
            "I0509 16:07:02.685878 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.91\n",
            "INFO:tensorflow:loss = 6.4658647, step = 347900 (0.944 sec)\n",
            "I0509 16:07:02.686164 140437868455744 basic_session_run_hooks.py:263] loss = 6.4658647, step = 347900 (0.944 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 348000...\n",
            "I0509 16:07:03.616049 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 348000...\n",
            "INFO:tensorflow:Saving checkpoints for 348000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:07:03.616262 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 348000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 348000...\n",
            "I0509 16:07:03.815406 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 348000...\n",
            "INFO:tensorflow:global_step/sec: 87.6393\n",
            "I0509 16:07:03.826894 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.6393\n",
            "INFO:tensorflow:loss = 6.60944, step = 348000 (1.141 sec)\n",
            "I0509 16:07:03.827229 140437868455744 basic_session_run_hooks.py:263] loss = 6.60944, step = 348000 (1.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.3727\n",
            "I0509 16:07:05.086812 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.3727\n",
            "INFO:tensorflow:loss = 7.5190606, step = 348100 (1.260 sec)\n",
            "I0509 16:07:05.087205 140437868455744 basic_session_run_hooks.py:263] loss = 7.5190606, step = 348100 (1.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 89.1268\n",
            "I0509 16:07:06.208801 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 89.1268\n",
            "INFO:tensorflow:loss = 7.3791294, step = 348200 (1.122 sec)\n",
            "I0509 16:07:06.209262 140437868455744 basic_session_run_hooks.py:263] loss = 7.3791294, step = 348200 (1.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.087\n",
            "I0509 16:07:07.160392 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.087\n",
            "INFO:tensorflow:loss = 5.8904686, step = 348300 (0.951 sec)\n",
            "I0509 16:07:07.160666 140437868455744 basic_session_run_hooks.py:263] loss = 5.8904686, step = 348300 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.314\n",
            "I0509 16:07:08.100996 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.314\n",
            "INFO:tensorflow:loss = 6.221112, step = 348400 (0.941 sec)\n",
            "I0509 16:07:08.101290 140437868455744 basic_session_run_hooks.py:263] loss = 6.221112, step = 348400 (0.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.001\n",
            "I0509 16:07:09.062537 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.001\n",
            "INFO:tensorflow:loss = 6.4457498, step = 348500 (0.962 sec)\n",
            "I0509 16:07:09.062917 140437868455744 basic_session_run_hooks.py:263] loss = 6.4457498, step = 348500 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.899\n",
            "I0509 16:07:10.015831 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.899\n",
            "INFO:tensorflow:loss = 8.522881, step = 348600 (0.953 sec)\n",
            "I0509 16:07:10.016230 140437868455744 basic_session_run_hooks.py:263] loss = 8.522881, step = 348600 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.226\n",
            "I0509 16:07:10.984572 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.226\n",
            "INFO:tensorflow:loss = 5.7915397, step = 348700 (0.969 sec)\n",
            "I0509 16:07:10.984934 140437868455744 basic_session_run_hooks.py:263] loss = 5.7915397, step = 348700 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.853\n",
            "I0509 16:07:11.947478 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.853\n",
            "INFO:tensorflow:loss = 7.005752, step = 348800 (0.963 sec)\n",
            "I0509 16:07:11.947900 140437868455744 basic_session_run_hooks.py:263] loss = 7.005752, step = 348800 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.443\n",
            "I0509 16:07:12.914191 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.443\n",
            "INFO:tensorflow:loss = 7.192456, step = 348900 (0.967 sec)\n",
            "I0509 16:07:12.914472 140437868455744 basic_session_run_hooks.py:263] loss = 7.192456, step = 348900 (0.967 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 349000...\n",
            "I0509 16:07:13.854877 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 349000...\n",
            "INFO:tensorflow:Saving checkpoints for 349000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:07:13.855089 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 349000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 349000...\n",
            "I0509 16:07:14.057754 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 349000...\n",
            "INFO:tensorflow:global_step/sec: 86.4879\n",
            "I0509 16:07:14.070411 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.4879\n",
            "INFO:tensorflow:loss = 7.26676, step = 349000 (1.156 sec)\n",
            "I0509 16:07:14.070777 140437868455744 basic_session_run_hooks.py:263] loss = 7.26676, step = 349000 (1.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.517\n",
            "I0509 16:07:15.027205 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.517\n",
            "INFO:tensorflow:loss = 7.3524766, step = 349100 (0.957 sec)\n",
            "I0509 16:07:15.027576 140437868455744 basic_session_run_hooks.py:263] loss = 7.3524766, step = 349100 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 95.2743\n",
            "I0509 16:07:16.076809 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 95.2743\n",
            "INFO:tensorflow:loss = 5.502339, step = 349200 (1.050 sec)\n",
            "I0509 16:07:16.077112 140437868455744 basic_session_run_hooks.py:263] loss = 5.502339, step = 349200 (1.050 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.2608\n",
            "I0509 16:07:17.388099 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 76.2608\n",
            "INFO:tensorflow:loss = 5.9222946, step = 349300 (1.311 sec)\n",
            "I0509 16:07:17.388383 140437868455744 basic_session_run_hooks.py:263] loss = 5.9222946, step = 349300 (1.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.576\n",
            "I0509 16:07:18.335283 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.576\n",
            "INFO:tensorflow:loss = 7.230911, step = 349400 (0.947 sec)\n",
            "I0509 16:07:18.335662 140437868455744 basic_session_run_hooks.py:263] loss = 7.230911, step = 349400 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.689\n",
            "I0509 16:07:19.290483 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.689\n",
            "INFO:tensorflow:loss = 7.724716, step = 349500 (0.956 sec)\n",
            "I0509 16:07:19.291338 140437868455744 basic_session_run_hooks.py:263] loss = 7.724716, step = 349500 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.206\n",
            "I0509 16:07:20.250146 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.206\n",
            "INFO:tensorflow:loss = 7.930899, step = 349600 (0.959 sec)\n",
            "I0509 16:07:20.250458 140437868455744 basic_session_run_hooks.py:263] loss = 7.930899, step = 349600 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.629\n",
            "I0509 16:07:21.196845 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.629\n",
            "INFO:tensorflow:loss = 6.1634603, step = 349700 (0.947 sec)\n",
            "I0509 16:07:21.197178 140437868455744 basic_session_run_hooks.py:263] loss = 6.1634603, step = 349700 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.392\n",
            "I0509 16:07:22.154753 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.392\n",
            "INFO:tensorflow:loss = 5.8994646, step = 349800 (0.958 sec)\n",
            "I0509 16:07:22.155078 140437868455744 basic_session_run_hooks.py:263] loss = 5.8994646, step = 349800 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.876\n",
            "I0509 16:07:23.108253 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.876\n",
            "INFO:tensorflow:loss = 6.411421, step = 349900 (0.954 sec)\n",
            "I0509 16:07:23.108622 140437868455744 basic_session_run_hooks.py:263] loss = 6.411421, step = 349900 (0.954 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 350000...\n",
            "I0509 16:07:24.080055 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 350000...\n",
            "INFO:tensorflow:Saving checkpoints for 350000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:07:24.080262 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 350000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 350000...\n",
            "I0509 16:07:24.301661 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 350000...\n",
            "INFO:tensorflow:global_step/sec: 82.9404\n",
            "I0509 16:07:24.313953 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.9404\n",
            "INFO:tensorflow:loss = 6.0728025, step = 350000 (1.206 sec)\n",
            "I0509 16:07:24.314317 140437868455744 basic_session_run_hooks.py:263] loss = 6.0728025, step = 350000 (1.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.152\n",
            "I0509 16:07:25.274091 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.152\n",
            "INFO:tensorflow:loss = 7.2304316, step = 350100 (0.960 sec)\n",
            "I0509 16:07:25.274383 140437868455744 basic_session_run_hooks.py:263] loss = 7.2304316, step = 350100 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.454\n",
            "I0509 16:07:26.222358 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.454\n",
            "INFO:tensorflow:loss = 6.617041, step = 350200 (0.948 sec)\n",
            "I0509 16:07:26.222629 140437868455744 basic_session_run_hooks.py:263] loss = 6.617041, step = 350200 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.939\n",
            "I0509 16:07:27.193808 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.939\n",
            "INFO:tensorflow:loss = 6.2187614, step = 350300 (0.972 sec)\n",
            "I0509 16:07:27.194212 140437868455744 basic_session_run_hooks.py:263] loss = 6.2187614, step = 350300 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.782\n",
            "I0509 16:07:28.549171 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.782\n",
            "INFO:tensorflow:loss = 5.6160126, step = 350400 (1.355 sec)\n",
            "I0509 16:07:28.549450 140437868455744 basic_session_run_hooks.py:263] loss = 5.6160126, step = 350400 (1.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 94.0303\n",
            "I0509 16:07:29.612639 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 94.0303\n",
            "INFO:tensorflow:loss = 5.907128, step = 350500 (1.064 sec)\n",
            "I0509 16:07:29.613019 140437868455744 basic_session_run_hooks.py:263] loss = 5.907128, step = 350500 (1.064 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.446\n",
            "I0509 16:07:30.560988 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.446\n",
            "INFO:tensorflow:loss = 6.424748, step = 350600 (0.948 sec)\n",
            "I0509 16:07:30.561275 140437868455744 basic_session_run_hooks.py:263] loss = 6.424748, step = 350600 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.269\n",
            "I0509 16:07:31.501990 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.269\n",
            "INFO:tensorflow:loss = 5.637289, step = 350700 (0.941 sec)\n",
            "I0509 16:07:31.502376 140437868455744 basic_session_run_hooks.py:263] loss = 5.637289, step = 350700 (0.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.504\n",
            "I0509 16:07:32.458918 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.504\n",
            "INFO:tensorflow:loss = 7.5722466, step = 350800 (0.957 sec)\n",
            "I0509 16:07:32.459287 140437868455744 basic_session_run_hooks.py:263] loss = 7.5722466, step = 350800 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.959\n",
            "I0509 16:07:33.420839 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.959\n",
            "INFO:tensorflow:loss = 6.6575875, step = 350900 (0.962 sec)\n",
            "I0509 16:07:33.421232 140437868455744 basic_session_run_hooks.py:263] loss = 6.6575875, step = 350900 (0.962 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 351000...\n",
            "I0509 16:07:34.370534 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 351000...\n",
            "INFO:tensorflow:Saving checkpoints for 351000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:07:34.370717 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 351000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 351000...\n",
            "I0509 16:07:34.574325 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 351000...\n",
            "INFO:tensorflow:global_step/sec: 85.6952\n",
            "I0509 16:07:34.587736 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.6952\n",
            "INFO:tensorflow:loss = 7.1408043, step = 351000 (1.167 sec)\n",
            "I0509 16:07:34.587994 140437868455744 basic_session_run_hooks.py:263] loss = 7.1408043, step = 351000 (1.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.315\n",
            "I0509 16:07:35.555669 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.315\n",
            "INFO:tensorflow:loss = 8.032866, step = 351100 (0.968 sec)\n",
            "I0509 16:07:35.556051 140437868455744 basic_session_run_hooks.py:263] loss = 8.032866, step = 351100 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.254\n",
            "I0509 16:07:36.505752 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.254\n",
            "INFO:tensorflow:loss = 5.8014827, step = 351200 (0.950 sec)\n",
            "I0509 16:07:36.506025 140437868455744 basic_session_run_hooks.py:263] loss = 5.8014827, step = 351200 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.69\n",
            "I0509 16:07:37.451912 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.69\n",
            "INFO:tensorflow:loss = 6.048314, step = 351300 (0.946 sec)\n",
            "I0509 16:07:37.452341 140437868455744 basic_session_run_hooks.py:263] loss = 6.048314, step = 351300 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.477\n",
            "I0509 16:07:38.391096 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.477\n",
            "INFO:tensorflow:loss = 6.1759586, step = 351400 (0.939 sec)\n",
            "I0509 16:07:38.391473 140437868455744 basic_session_run_hooks.py:263] loss = 6.1759586, step = 351400 (0.939 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.0861\n",
            "I0509 16:07:39.580355 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.0861\n",
            "INFO:tensorflow:loss = 7.280244, step = 351500 (1.189 sec)\n",
            "I0509 16:07:39.580715 140437868455744 basic_session_run_hooks.py:263] loss = 7.280244, step = 351500 (1.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.4984\n",
            "I0509 16:07:40.792479 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.4984\n",
            "INFO:tensorflow:loss = 6.9701467, step = 351600 (1.212 sec)\n",
            "I0509 16:07:40.792845 140437868455744 basic_session_run_hooks.py:263] loss = 6.9701467, step = 351600 (1.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.329\n",
            "I0509 16:07:41.751008 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.329\n",
            "INFO:tensorflow:loss = 7.0561123, step = 351700 (0.959 sec)\n",
            "I0509 16:07:41.751469 140437868455744 basic_session_run_hooks.py:263] loss = 7.0561123, step = 351700 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.4\n",
            "I0509 16:07:42.727538 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.4\n",
            "INFO:tensorflow:loss = 6.3981476, step = 351800 (0.976 sec)\n",
            "I0509 16:07:42.727948 140437868455744 basic_session_run_hooks.py:263] loss = 6.3981476, step = 351800 (0.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.982\n",
            "I0509 16:07:43.671100 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.982\n",
            "INFO:tensorflow:loss = 7.3713975, step = 351900 (0.944 sec)\n",
            "I0509 16:07:43.671454 140437868455744 basic_session_run_hooks.py:263] loss = 7.3713975, step = 351900 (0.944 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 352000...\n",
            "I0509 16:07:44.612455 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 352000...\n",
            "INFO:tensorflow:Saving checkpoints for 352000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:07:44.612657 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 352000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 352000...\n",
            "I0509 16:07:44.814373 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 352000...\n",
            "INFO:tensorflow:global_step/sec: 86.5177\n",
            "I0509 16:07:44.826910 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.5177\n",
            "INFO:tensorflow:loss = 5.640823, step = 352000 (1.156 sec)\n",
            "I0509 16:07:44.827170 140437868455744 basic_session_run_hooks.py:263] loss = 5.640823, step = 352000 (1.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.087\n",
            "I0509 16:07:45.806495 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.087\n",
            "INFO:tensorflow:loss = 5.5567026, step = 352100 (0.980 sec)\n",
            "I0509 16:07:45.806887 140437868455744 basic_session_run_hooks.py:263] loss = 5.5567026, step = 352100 (0.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.157\n",
            "I0509 16:07:46.766570 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.157\n",
            "INFO:tensorflow:loss = 6.8785496, step = 352200 (0.960 sec)\n",
            "I0509 16:07:46.766950 140437868455744 basic_session_run_hooks.py:263] loss = 6.8785496, step = 352200 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.256\n",
            "I0509 16:07:47.735083 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.256\n",
            "INFO:tensorflow:loss = 6.8364334, step = 352300 (0.968 sec)\n",
            "I0509 16:07:47.735372 140437868455744 basic_session_run_hooks.py:263] loss = 6.8364334, step = 352300 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.538\n",
            "I0509 16:07:48.691639 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.538\n",
            "INFO:tensorflow:loss = 5.9194665, step = 352400 (0.957 sec)\n",
            "I0509 16:07:48.692015 140437868455744 basic_session_run_hooks.py:263] loss = 5.9194665, step = 352400 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.772\n",
            "I0509 16:07:49.655281 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.772\n",
            "INFO:tensorflow:loss = 6.4822254, step = 352500 (0.964 sec)\n",
            "I0509 16:07:49.655638 140437868455744 basic_session_run_hooks.py:263] loss = 6.4822254, step = 352500 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 92.0006\n",
            "I0509 16:07:50.742259 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 92.0006\n",
            "INFO:tensorflow:loss = 8.874732, step = 352600 (1.087 sec)\n",
            "I0509 16:07:50.742653 140437868455744 basic_session_run_hooks.py:263] loss = 8.874732, step = 352600 (1.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.0242\n",
            "I0509 16:07:52.093160 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 74.0242\n",
            "INFO:tensorflow:loss = 5.190053, step = 352700 (1.351 sec)\n",
            "I0509 16:07:52.093541 140437868455744 basic_session_run_hooks.py:263] loss = 5.190053, step = 352700 (1.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.95\n",
            "I0509 16:07:53.064500 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.95\n",
            "INFO:tensorflow:loss = 5.9505315, step = 352800 (0.971 sec)\n",
            "I0509 16:07:53.064875 140437868455744 basic_session_run_hooks.py:263] loss = 5.9505315, step = 352800 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.996\n",
            "I0509 16:07:54.016922 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.996\n",
            "INFO:tensorflow:loss = 6.8193917, step = 352900 (0.952 sec)\n",
            "I0509 16:07:54.017233 140437868455744 basic_session_run_hooks.py:263] loss = 6.8193917, step = 352900 (0.952 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 353000...\n",
            "I0509 16:07:54.983793 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 353000...\n",
            "INFO:tensorflow:Saving checkpoints for 353000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:07:54.983986 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 353000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 353000...\n",
            "I0509 16:07:55.185023 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 353000...\n",
            "INFO:tensorflow:global_step/sec: 84.6758\n",
            "I0509 16:07:55.197876 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.6758\n",
            "INFO:tensorflow:loss = 5.4397054, step = 353000 (1.181 sec)\n",
            "I0509 16:07:55.198167 140437868455744 basic_session_run_hooks.py:263] loss = 5.4397054, step = 353000 (1.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.901\n",
            "I0509 16:07:56.160358 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.901\n",
            "INFO:tensorflow:loss = 7.7754326, step = 353100 (0.963 sec)\n",
            "I0509 16:07:56.160728 140437868455744 basic_session_run_hooks.py:263] loss = 7.7754326, step = 353100 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.609\n",
            "I0509 16:07:57.107220 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.609\n",
            "INFO:tensorflow:loss = 5.9403515, step = 353200 (0.947 sec)\n",
            "I0509 16:07:57.107496 140437868455744 basic_session_run_hooks.py:263] loss = 5.9403515, step = 353200 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.715\n",
            "I0509 16:07:58.080800 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.715\n",
            "INFO:tensorflow:loss = 5.0427866, step = 353300 (0.974 sec)\n",
            "I0509 16:07:58.081187 140437868455744 basic_session_run_hooks.py:263] loss = 5.0427866, step = 353300 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.033\n",
            "I0509 16:07:59.042025 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.033\n",
            "INFO:tensorflow:loss = 9.583865, step = 353400 (0.961 sec)\n",
            "I0509 16:07:59.042357 140437868455744 basic_session_run_hooks.py:263] loss = 9.583865, step = 353400 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.952\n",
            "I0509 16:07:59.994838 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.952\n",
            "INFO:tensorflow:loss = 7.232378, step = 353500 (0.953 sec)\n",
            "I0509 16:07:59.995223 140437868455744 basic_session_run_hooks.py:263] loss = 7.232378, step = 353500 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.698\n",
            "I0509 16:08:00.978152 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.698\n",
            "INFO:tensorflow:loss = 6.9810677, step = 353600 (0.983 sec)\n",
            "I0509 16:08:00.978528 140437868455744 basic_session_run_hooks.py:263] loss = 6.9810677, step = 353600 (0.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.895\n",
            "I0509 16:08:01.931480 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.895\n",
            "INFO:tensorflow:loss = 6.772157, step = 353700 (0.953 sec)\n",
            "I0509 16:08:01.931858 140437868455744 basic_session_run_hooks.py:263] loss = 6.772157, step = 353700 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.6755\n",
            "I0509 16:08:03.307470 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 72.6755\n",
            "INFO:tensorflow:loss = 4.90332, step = 353800 (1.376 sec)\n",
            "I0509 16:08:03.307752 140437868455744 basic_session_run_hooks.py:263] loss = 4.90332, step = 353800 (1.376 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.1888\n",
            "I0509 16:08:04.347087 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 96.1888\n",
            "INFO:tensorflow:loss = 7.0226502, step = 353900 (1.040 sec)\n",
            "I0509 16:08:04.347361 140437868455744 basic_session_run_hooks.py:263] loss = 7.0226502, step = 353900 (1.040 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 354000...\n",
            "I0509 16:08:05.291984 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 354000...\n",
            "INFO:tensorflow:Saving checkpoints for 354000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:08:05.292204 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 354000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 354000...\n",
            "I0509 16:08:05.520990 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 354000...\n",
            "INFO:tensorflow:global_step/sec: 84.3389\n",
            "I0509 16:08:05.532750 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.3389\n",
            "INFO:tensorflow:loss = 6.0386086, step = 354000 (1.186 sec)\n",
            "I0509 16:08:05.533004 140437868455744 basic_session_run_hooks.py:263] loss = 6.0386086, step = 354000 (1.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 104\n",
            "I0509 16:08:06.494306 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104\n",
            "INFO:tensorflow:loss = 6.9030414, step = 354100 (0.962 sec)\n",
            "I0509 16:08:06.494672 140437868455744 basic_session_run_hooks.py:263] loss = 6.9030414, step = 354100 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.763\n",
            "I0509 16:08:07.448839 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.763\n",
            "INFO:tensorflow:loss = 6.071276, step = 354200 (0.955 sec)\n",
            "I0509 16:08:07.449232 140437868455744 basic_session_run_hooks.py:263] loss = 6.071276, step = 354200 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.284\n",
            "I0509 16:08:08.398661 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.284\n",
            "INFO:tensorflow:loss = 5.375575, step = 354300 (0.950 sec)\n",
            "I0509 16:08:08.398951 140437868455744 basic_session_run_hooks.py:263] loss = 5.375575, step = 354300 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.168\n",
            "I0509 16:08:09.367955 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.168\n",
            "INFO:tensorflow:loss = 7.309761, step = 354400 (0.969 sec)\n",
            "I0509 16:08:09.368393 140437868455744 basic_session_run_hooks.py:263] loss = 7.309761, step = 354400 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.07\n",
            "I0509 16:08:10.328847 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.07\n",
            "INFO:tensorflow:loss = 5.468335, step = 354500 (0.961 sec)\n",
            "I0509 16:08:10.329153 140437868455744 basic_session_run_hooks.py:263] loss = 5.468335, step = 354500 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.774\n",
            "I0509 16:08:11.301855 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.774\n",
            "INFO:tensorflow:loss = 6.2177753, step = 354600 (0.973 sec)\n",
            "I0509 16:08:11.302298 140437868455744 basic_session_run_hooks.py:263] loss = 6.2177753, step = 354600 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.309\n",
            "I0509 16:08:12.269809 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.309\n",
            "INFO:tensorflow:loss = 5.503281, step = 354700 (0.968 sec)\n",
            "I0509 16:08:12.270110 140437868455744 basic_session_run_hooks.py:263] loss = 5.503281, step = 354700 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.324\n",
            "I0509 16:08:13.237651 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.324\n",
            "INFO:tensorflow:loss = 6.3223314, step = 354800 (0.968 sec)\n",
            "I0509 16:08:13.238039 140437868455744 basic_session_run_hooks.py:263] loss = 6.3223314, step = 354800 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.9997\n",
            "I0509 16:08:14.487658 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.9997\n",
            "INFO:tensorflow:loss = 7.331455, step = 354900 (1.250 sec)\n",
            "I0509 16:08:14.487948 140437868455744 basic_session_run_hooks.py:263] loss = 7.331455, step = 354900 (1.250 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 355000...\n",
            "I0509 16:08:15.618612 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 355000...\n",
            "INFO:tensorflow:Saving checkpoints for 355000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:08:15.618799 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 355000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 355000...\n",
            "I0509 16:08:15.836870 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 355000...\n",
            "INFO:tensorflow:global_step/sec: 73.1626\n",
            "I0509 16:08:15.854470 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.1626\n",
            "INFO:tensorflow:loss = 6.9617486, step = 355000 (1.367 sec)\n",
            "I0509 16:08:15.854736 140437868455744 basic_session_run_hooks.py:263] loss = 6.9617486, step = 355000 (1.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.961\n",
            "I0509 16:08:16.816373 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.961\n",
            "INFO:tensorflow:loss = 6.515075, step = 355100 (0.962 sec)\n",
            "I0509 16:08:16.816652 140437868455744 basic_session_run_hooks.py:263] loss = 6.515075, step = 355100 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.058\n",
            "I0509 16:08:17.786704 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.058\n",
            "INFO:tensorflow:loss = 5.852502, step = 355200 (0.970 sec)\n",
            "I0509 16:08:17.786983 140437868455744 basic_session_run_hooks.py:263] loss = 5.852502, step = 355200 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.709\n",
            "I0509 16:08:18.741717 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.709\n",
            "INFO:tensorflow:loss = 5.3909545, step = 355300 (0.955 sec)\n",
            "I0509 16:08:18.742097 140437868455744 basic_session_run_hooks.py:263] loss = 5.3909545, step = 355300 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.23\n",
            "I0509 16:08:19.701156 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.23\n",
            "INFO:tensorflow:loss = 7.463827, step = 355400 (0.959 sec)\n",
            "I0509 16:08:19.701531 140437868455744 basic_session_run_hooks.py:263] loss = 7.463827, step = 355400 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.625\n",
            "I0509 16:08:20.675581 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.625\n",
            "INFO:tensorflow:loss = 7.434701, step = 355500 (0.974 sec)\n",
            "I0509 16:08:20.675983 140437868455744 basic_session_run_hooks.py:263] loss = 7.434701, step = 355500 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.36\n",
            "I0509 16:08:21.652512 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.36\n",
            "INFO:tensorflow:loss = 7.273044, step = 355600 (0.977 sec)\n",
            "I0509 16:08:21.652890 140437868455744 basic_session_run_hooks.py:263] loss = 7.273044, step = 355600 (0.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.113\n",
            "I0509 16:08:22.603871 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.113\n",
            "INFO:tensorflow:loss = 6.2250123, step = 355700 (0.951 sec)\n",
            "I0509 16:08:22.604161 140437868455744 basic_session_run_hooks.py:263] loss = 6.2250123, step = 355700 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.627\n",
            "I0509 16:08:23.550615 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.627\n",
            "INFO:tensorflow:loss = 6.8260875, step = 355800 (0.947 sec)\n",
            "I0509 16:08:23.551018 140437868455744 basic_session_run_hooks.py:263] loss = 6.8260875, step = 355800 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.177\n",
            "I0509 16:08:24.519809 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.177\n",
            "INFO:tensorflow:loss = 7.6322536, step = 355900 (0.969 sec)\n",
            "I0509 16:08:24.520110 140437868455744 basic_session_run_hooks.py:263] loss = 7.6322536, step = 355900 (0.969 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 356000...\n",
            "I0509 16:08:25.668224 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 356000...\n",
            "INFO:tensorflow:Saving checkpoints for 356000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:08:25.668430 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 356000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 356000...\n",
            "I0509 16:08:26.016056 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 356000...\n",
            "INFO:tensorflow:global_step/sec: 65.9827\n",
            "I0509 16:08:26.035410 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 65.9827\n",
            "INFO:tensorflow:loss = 5.8017087, step = 356000 (1.516 sec)\n",
            "I0509 16:08:26.035738 140437868455744 basic_session_run_hooks.py:263] loss = 5.8017087, step = 356000 (1.516 sec)\n",
            "INFO:tensorflow:global_step/sec: 87.2357\n",
            "I0509 16:08:27.181678 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.2357\n",
            "INFO:tensorflow:loss = 7.1445565, step = 356100 (1.146 sec)\n",
            "I0509 16:08:27.182076 140437868455744 basic_session_run_hooks.py:263] loss = 7.1445565, step = 356100 (1.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.264\n",
            "I0509 16:08:28.150078 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.264\n",
            "INFO:tensorflow:loss = 5.6742206, step = 356200 (0.968 sec)\n",
            "I0509 16:08:28.150450 140437868455744 basic_session_run_hooks.py:263] loss = 5.6742206, step = 356200 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.071\n",
            "I0509 16:08:29.101796 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.071\n",
            "INFO:tensorflow:loss = 6.042266, step = 356300 (0.952 sec)\n",
            "I0509 16:08:29.102206 140437868455744 basic_session_run_hooks.py:263] loss = 6.042266, step = 356300 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.203\n",
            "I0509 16:08:30.043391 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.203\n",
            "INFO:tensorflow:loss = 8.078158, step = 356400 (0.942 sec)\n",
            "I0509 16:08:30.043712 140437868455744 basic_session_run_hooks.py:263] loss = 8.078158, step = 356400 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.744\n",
            "I0509 16:08:30.998119 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.744\n",
            "INFO:tensorflow:loss = 6.190493, step = 356500 (0.955 sec)\n",
            "I0509 16:08:30.998404 140437868455744 basic_session_run_hooks.py:263] loss = 6.190493, step = 356500 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.328\n",
            "I0509 16:08:31.947515 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.328\n",
            "INFO:tensorflow:loss = 5.980409, step = 356600 (0.950 sec)\n",
            "I0509 16:08:31.947922 140437868455744 basic_session_run_hooks.py:263] loss = 5.980409, step = 356600 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.202\n",
            "I0509 16:08:32.907209 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.202\n",
            "INFO:tensorflow:loss = 7.047309, step = 356700 (0.960 sec)\n",
            "I0509 16:08:32.907619 140437868455744 basic_session_run_hooks.py:263] loss = 7.047309, step = 356700 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.168\n",
            "I0509 16:08:33.858049 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.168\n",
            "INFO:tensorflow:loss = 7.9412575, step = 356800 (0.951 sec)\n",
            "I0509 16:08:33.858426 140437868455744 basic_session_run_hooks.py:263] loss = 7.9412575, step = 356800 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.702\n",
            "I0509 16:08:34.813183 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.702\n",
            "INFO:tensorflow:loss = 7.0361476, step = 356900 (0.955 sec)\n",
            "I0509 16:08:34.813556 140437868455744 basic_session_run_hooks.py:263] loss = 7.0361476, step = 356900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 357000...\n",
            "I0509 16:08:35.752481 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 357000...\n",
            "INFO:tensorflow:Saving checkpoints for 357000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:08:35.752671 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 357000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 357000...\n",
            "I0509 16:08:35.965815 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 357000...\n",
            "INFO:tensorflow:global_step/sec: 85.7312\n",
            "I0509 16:08:35.979562 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.7312\n",
            "INFO:tensorflow:loss = 6.7718806, step = 357000 (1.166 sec)\n",
            "I0509 16:08:35.979807 140437868455744 basic_session_run_hooks.py:263] loss = 6.7718806, step = 357000 (1.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 87.1832\n",
            "I0509 16:08:37.126605 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.1832\n",
            "INFO:tensorflow:loss = 6.665999, step = 357100 (1.147 sec)\n",
            "I0509 16:08:37.126895 140437868455744 basic_session_run_hooks.py:263] loss = 6.665999, step = 357100 (1.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.879\n",
            "I0509 16:08:38.410644 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.879\n",
            "INFO:tensorflow:loss = 6.3942323, step = 357200 (1.284 sec)\n",
            "I0509 16:08:38.411013 140437868455744 basic_session_run_hooks.py:263] loss = 6.3942323, step = 357200 (1.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.113\n",
            "I0509 16:08:39.371161 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.113\n",
            "INFO:tensorflow:loss = 5.923116, step = 357300 (0.960 sec)\n",
            "I0509 16:08:39.371452 140437868455744 basic_session_run_hooks.py:263] loss = 5.923116, step = 357300 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.272\n",
            "I0509 16:08:40.348955 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.272\n",
            "INFO:tensorflow:loss = 5.3168, step = 357400 (0.978 sec)\n",
            "I0509 16:08:40.349270 140437868455744 basic_session_run_hooks.py:263] loss = 5.3168, step = 357400 (0.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.157\n",
            "I0509 16:08:41.327808 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.157\n",
            "INFO:tensorflow:loss = 6.673697, step = 357500 (0.979 sec)\n",
            "I0509 16:08:41.328206 140437868455744 basic_session_run_hooks.py:263] loss = 6.673697, step = 357500 (0.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.059\n",
            "I0509 16:08:42.317339 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.059\n",
            "INFO:tensorflow:loss = 6.4500184, step = 357600 (0.989 sec)\n",
            "I0509 16:08:42.317616 140437868455744 basic_session_run_hooks.py:263] loss = 6.4500184, step = 357600 (0.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 107.256\n",
            "I0509 16:08:43.249681 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 107.256\n",
            "INFO:tensorflow:loss = 7.360144, step = 357700 (0.932 sec)\n",
            "I0509 16:08:43.250074 140437868455744 basic_session_run_hooks.py:263] loss = 7.360144, step = 357700 (0.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.101\n",
            "I0509 16:08:44.192201 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.101\n",
            "INFO:tensorflow:loss = 6.1164274, step = 357800 (0.942 sec)\n",
            "I0509 16:08:44.192485 140437868455744 basic_session_run_hooks.py:263] loss = 6.1164274, step = 357800 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.115\n",
            "I0509 16:08:45.134569 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.115\n",
            "INFO:tensorflow:loss = 6.7133055, step = 357900 (0.942 sec)\n",
            "I0509 16:08:45.134944 140437868455744 basic_session_run_hooks.py:263] loss = 6.7133055, step = 357900 (0.942 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 358000...\n",
            "I0509 16:08:46.070371 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 358000...\n",
            "INFO:tensorflow:Saving checkpoints for 358000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:08:46.070564 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 358000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 358000...\n",
            "I0509 16:08:46.289586 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 358000...\n",
            "INFO:tensorflow:global_step/sec: 85.6912\n",
            "I0509 16:08:46.301529 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.6912\n",
            "INFO:tensorflow:loss = 7.957335, step = 358000 (1.167 sec)\n",
            "I0509 16:08:46.301771 140437868455744 basic_session_run_hooks.py:263] loss = 7.957335, step = 358000 (1.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.976\n",
            "I0509 16:08:47.263310 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.976\n",
            "INFO:tensorflow:loss = 6.276824, step = 358100 (0.962 sec)\n",
            "I0509 16:08:47.263683 140437868455744 basic_session_run_hooks.py:263] loss = 6.276824, step = 358100 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.161\n",
            "I0509 16:08:48.223362 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.161\n",
            "INFO:tensorflow:loss = 7.4843197, step = 358200 (0.961 sec)\n",
            "I0509 16:08:48.224359 140437868455744 basic_session_run_hooks.py:263] loss = 7.4843197, step = 358200 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.7959\n",
            "I0509 16:08:49.616223 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 71.7959\n",
            "INFO:tensorflow:loss = 5.8712306, step = 358300 (1.392 sec)\n",
            "I0509 16:08:49.616572 140437868455744 basic_session_run_hooks.py:263] loss = 5.8712306, step = 358300 (1.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.8872\n",
            "I0509 16:08:50.637780 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 97.8872\n",
            "INFO:tensorflow:loss = 6.368034, step = 358400 (1.022 sec)\n",
            "I0509 16:08:50.638182 140437868455744 basic_session_run_hooks.py:263] loss = 6.368034, step = 358400 (1.022 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.353\n",
            "I0509 16:08:51.614793 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.353\n",
            "INFO:tensorflow:loss = 3.9861147, step = 358500 (0.977 sec)\n",
            "I0509 16:08:51.615173 140437868455744 basic_session_run_hooks.py:263] loss = 3.9861147, step = 358500 (0.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.797\n",
            "I0509 16:08:52.597161 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.797\n",
            "INFO:tensorflow:loss = 5.2975407, step = 358600 (0.982 sec)\n",
            "I0509 16:08:52.597428 140437868455744 basic_session_run_hooks.py:263] loss = 5.2975407, step = 358600 (0.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.77\n",
            "I0509 16:08:53.542579 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.77\n",
            "INFO:tensorflow:loss = 5.5217795, step = 358700 (0.945 sec)\n",
            "I0509 16:08:53.542856 140437868455744 basic_session_run_hooks.py:263] loss = 5.5217795, step = 358700 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.904\n",
            "I0509 16:08:54.486846 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.904\n",
            "INFO:tensorflow:loss = 6.8742037, step = 358800 (0.944 sec)\n",
            "I0509 16:08:54.487145 140437868455744 basic_session_run_hooks.py:263] loss = 6.8742037, step = 358800 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.31\n",
            "I0509 16:08:55.464261 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.31\n",
            "INFO:tensorflow:loss = 5.194482, step = 358900 (0.977 sec)\n",
            "I0509 16:08:55.464613 140437868455744 basic_session_run_hooks.py:263] loss = 5.194482, step = 358900 (0.977 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 359000...\n",
            "I0509 16:08:56.392490 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 359000...\n",
            "INFO:tensorflow:Saving checkpoints for 359000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:08:56.392693 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 359000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 359000...\n",
            "I0509 16:08:56.602519 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 359000...\n",
            "INFO:tensorflow:global_step/sec: 86.5266\n",
            "I0509 16:08:56.620018 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.5266\n",
            "INFO:tensorflow:loss = 6.1980605, step = 359000 (1.156 sec)\n",
            "I0509 16:08:56.620468 140437868455744 basic_session_run_hooks.py:263] loss = 6.1980605, step = 359000 (1.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.5655\n",
            "I0509 16:08:57.624330 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.5655\n",
            "INFO:tensorflow:loss = 6.1059475, step = 359100 (1.004 sec)\n",
            "I0509 16:08:57.624711 140437868455744 basic_session_run_hooks.py:263] loss = 6.1059475, step = 359100 (1.004 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.842\n",
            "I0509 16:08:58.606256 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.842\n",
            "INFO:tensorflow:loss = 5.9600544, step = 359200 (0.982 sec)\n",
            "I0509 16:08:58.606537 140437868455744 basic_session_run_hooks.py:263] loss = 5.9600544, step = 359200 (0.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.528\n",
            "I0509 16:08:59.562945 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.528\n",
            "INFO:tensorflow:loss = 7.4171147, step = 359300 (0.957 sec)\n",
            "I0509 16:08:59.563242 140437868455744 basic_session_run_hooks.py:263] loss = 7.4171147, step = 359300 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.0653\n",
            "I0509 16:09:00.796519 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.0653\n",
            "INFO:tensorflow:loss = 7.220668, step = 359400 (1.234 sec)\n",
            "I0509 16:09:00.797594 140437868455744 basic_session_run_hooks.py:263] loss = 7.220668, step = 359400 (1.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 87.2874\n",
            "I0509 16:09:01.942159 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.2874\n",
            "INFO:tensorflow:loss = 6.5073714, step = 359500 (1.145 sec)\n",
            "I0509 16:09:01.942544 140437868455744 basic_session_run_hooks.py:263] loss = 6.5073714, step = 359500 (1.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.081\n",
            "I0509 16:09:02.921746 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.081\n",
            "INFO:tensorflow:loss = 7.5011883, step = 359600 (0.980 sec)\n",
            "I0509 16:09:02.922120 140437868455744 basic_session_run_hooks.py:263] loss = 7.5011883, step = 359600 (0.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.702\n",
            "I0509 16:09:03.886046 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.702\n",
            "INFO:tensorflow:loss = 5.70801, step = 359700 (0.964 sec)\n",
            "I0509 16:09:03.886437 140437868455744 basic_session_run_hooks.py:263] loss = 5.70801, step = 359700 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.409\n",
            "I0509 16:09:04.853106 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.409\n",
            "INFO:tensorflow:loss = 6.0306344, step = 359800 (0.967 sec)\n",
            "I0509 16:09:04.853403 140437868455744 basic_session_run_hooks.py:263] loss = 6.0306344, step = 359800 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.974\n",
            "I0509 16:09:05.814883 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.974\n",
            "INFO:tensorflow:loss = 6.8674464, step = 359900 (0.962 sec)\n",
            "I0509 16:09:05.815204 140437868455744 basic_session_run_hooks.py:263] loss = 6.8674464, step = 359900 (0.962 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 360000...\n",
            "I0509 16:09:06.766825 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 360000...\n",
            "INFO:tensorflow:Saving checkpoints for 360000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:09:06.767056 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 360000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 360000...\n",
            "I0509 16:09:06.989578 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 360000...\n",
            "INFO:tensorflow:global_step/sec: 84.2515\n",
            "I0509 16:09:07.001814 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.2515\n",
            "INFO:tensorflow:loss = 6.5862746, step = 360000 (1.187 sec)\n",
            "I0509 16:09:07.002101 140437868455744 basic_session_run_hooks.py:263] loss = 6.5862746, step = 360000 (1.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.871\n",
            "I0509 16:09:07.964546 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.871\n",
            "INFO:tensorflow:loss = 7.3117604, step = 360100 (0.963 sec)\n",
            "I0509 16:09:07.964842 140437868455744 basic_session_run_hooks.py:263] loss = 7.3117604, step = 360100 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.073\n",
            "I0509 16:09:08.934745 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.073\n",
            "INFO:tensorflow:loss = 4.6497126, step = 360200 (0.970 sec)\n",
            "I0509 16:09:08.935086 140437868455744 basic_session_run_hooks.py:263] loss = 4.6497126, step = 360200 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.755\n",
            "I0509 16:09:09.907933 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.755\n",
            "INFO:tensorflow:loss = 6.4989805, step = 360300 (0.973 sec)\n",
            "I0509 16:09:09.908344 140437868455744 basic_session_run_hooks.py:263] loss = 6.4989805, step = 360300 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.235\n",
            "I0509 16:09:10.876565 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.235\n",
            "INFO:tensorflow:loss = 6.125761, step = 360400 (0.969 sec)\n",
            "I0509 16:09:10.876935 140437868455744 basic_session_run_hooks.py:263] loss = 6.125761, step = 360400 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.67\n",
            "I0509 16:09:12.043873 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.67\n",
            "INFO:tensorflow:loss = 6.387452, step = 360500 (1.167 sec)\n",
            "I0509 16:09:12.044276 140437868455744 basic_session_run_hooks.py:263] loss = 6.387452, step = 360500 (1.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.9972\n",
            "I0509 16:09:13.293931 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.9972\n",
            "INFO:tensorflow:loss = 11.942119, step = 360600 (1.250 sec)\n",
            "I0509 16:09:13.294265 140437868455744 basic_session_run_hooks.py:263] loss = 11.942119, step = 360600 (1.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.407\n",
            "I0509 16:09:14.289829 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.407\n",
            "INFO:tensorflow:loss = 7.3668084, step = 360700 (0.996 sec)\n",
            "I0509 16:09:14.290133 140437868455744 basic_session_run_hooks.py:263] loss = 7.3668084, step = 360700 (0.996 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.335\n",
            "I0509 16:09:15.230269 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.335\n",
            "INFO:tensorflow:loss = 7.0660214, step = 360800 (0.940 sec)\n",
            "I0509 16:09:15.230552 140437868455744 basic_session_run_hooks.py:263] loss = 7.0660214, step = 360800 (0.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.635\n",
            "I0509 16:09:16.176917 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.635\n",
            "INFO:tensorflow:loss = 6.5380826, step = 360900 (0.947 sec)\n",
            "I0509 16:09:16.177287 140437868455744 basic_session_run_hooks.py:263] loss = 6.5380826, step = 360900 (0.947 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 361000...\n",
            "I0509 16:09:17.117388 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 361000...\n",
            "INFO:tensorflow:Saving checkpoints for 361000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:09:17.117575 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 361000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 361000...\n",
            "I0509 16:09:17.330740 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 361000...\n",
            "INFO:tensorflow:global_step/sec: 85.7683\n",
            "I0509 16:09:17.342847 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.7683\n",
            "INFO:tensorflow:loss = 6.373954, step = 361000 (1.166 sec)\n",
            "I0509 16:09:17.343110 140437868455744 basic_session_run_hooks.py:263] loss = 6.373954, step = 361000 (1.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.467\n",
            "I0509 16:09:18.309337 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.467\n",
            "INFO:tensorflow:loss = 5.813971, step = 361100 (0.967 sec)\n",
            "I0509 16:09:18.309712 140437868455744 basic_session_run_hooks.py:263] loss = 5.813971, step = 361100 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.866\n",
            "I0509 16:09:19.253952 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.866\n",
            "INFO:tensorflow:loss = 6.553673, step = 361200 (0.945 sec)\n",
            "I0509 16:09:19.254354 140437868455744 basic_session_run_hooks.py:263] loss = 6.553673, step = 361200 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.939\n",
            "I0509 16:09:20.197887 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.939\n",
            "INFO:tensorflow:loss = 8.092385, step = 361300 (0.944 sec)\n",
            "I0509 16:09:20.198267 140437868455744 basic_session_run_hooks.py:263] loss = 8.092385, step = 361300 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.684\n",
            "I0509 16:09:21.144092 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.684\n",
            "INFO:tensorflow:loss = 6.0774813, step = 361400 (0.946 sec)\n",
            "I0509 16:09:21.144468 140437868455744 basic_session_run_hooks.py:263] loss = 6.0774813, step = 361400 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.2994\n",
            "I0509 16:09:22.161386 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 98.2994\n",
            "INFO:tensorflow:loss = 6.6044965, step = 361500 (1.017 sec)\n",
            "I0509 16:09:22.161689 140437868455744 basic_session_run_hooks.py:263] loss = 6.6044965, step = 361500 (1.017 sec)\n",
            "INFO:tensorflow:global_step/sec: 92.0723\n",
            "I0509 16:09:23.247506 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 92.0723\n",
            "INFO:tensorflow:loss = 5.896916, step = 361600 (1.086 sec)\n",
            "I0509 16:09:23.247875 140437868455744 basic_session_run_hooks.py:263] loss = 5.896916, step = 361600 (1.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.1231\n",
            "I0509 16:09:24.596595 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 74.1231\n",
            "INFO:tensorflow:loss = 4.239549, step = 361700 (1.349 sec)\n",
            "I0509 16:09:24.596968 140437868455744 basic_session_run_hooks.py:263] loss = 4.239549, step = 361700 (1.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.298\n",
            "I0509 16:09:25.564668 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.298\n",
            "INFO:tensorflow:loss = 5.912809, step = 361800 (0.968 sec)\n",
            "I0509 16:09:25.565037 140437868455744 basic_session_run_hooks.py:263] loss = 5.912809, step = 361800 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.916\n",
            "I0509 16:09:26.499994 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.916\n",
            "INFO:tensorflow:loss = 7.6910653, step = 361900 (0.935 sec)\n",
            "I0509 16:09:26.500391 140437868455744 basic_session_run_hooks.py:263] loss = 7.6910653, step = 361900 (0.935 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 362000...\n",
            "I0509 16:09:27.440374 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 362000...\n",
            "INFO:tensorflow:Saving checkpoints for 362000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:09:27.440567 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 362000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 362000...\n",
            "I0509 16:09:27.670573 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 362000...\n",
            "INFO:tensorflow:global_step/sec: 84.5212\n",
            "I0509 16:09:27.683113 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.5212\n",
            "INFO:tensorflow:loss = 6.9411526, step = 362000 (1.183 sec)\n",
            "I0509 16:09:27.683462 140437868455744 basic_session_run_hooks.py:263] loss = 6.9411526, step = 362000 (1.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.667\n",
            "I0509 16:09:28.657155 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.667\n",
            "INFO:tensorflow:loss = 6.593779, step = 362100 (0.974 sec)\n",
            "I0509 16:09:28.657424 140437868455744 basic_session_run_hooks.py:263] loss = 6.593779, step = 362100 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.955\n",
            "I0509 16:09:29.609933 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.955\n",
            "INFO:tensorflow:loss = 7.425796, step = 362200 (0.953 sec)\n",
            "I0509 16:09:29.610233 140437868455744 basic_session_run_hooks.py:263] loss = 7.425796, step = 362200 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.322\n",
            "I0509 16:09:30.559398 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.322\n",
            "INFO:tensorflow:loss = 6.055205, step = 362300 (0.950 sec)\n",
            "I0509 16:09:30.559746 140437868455744 basic_session_run_hooks.py:263] loss = 6.055205, step = 362300 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.854\n",
            "I0509 16:09:31.504112 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.854\n",
            "INFO:tensorflow:loss = 6.180834, step = 362400 (0.945 sec)\n",
            "I0509 16:09:31.504486 140437868455744 basic_session_run_hooks.py:263] loss = 6.180834, step = 362400 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.571\n",
            "I0509 16:09:32.479075 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.571\n",
            "INFO:tensorflow:loss = 6.0723014, step = 362500 (0.975 sec)\n",
            "I0509 16:09:32.479404 140437868455744 basic_session_run_hooks.py:263] loss = 6.0723014, step = 362500 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.861\n",
            "I0509 16:09:33.441857 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.861\n",
            "INFO:tensorflow:loss = 5.9759383, step = 362600 (0.963 sec)\n",
            "I0509 16:09:33.442156 140437868455744 basic_session_run_hooks.py:263] loss = 5.9759383, step = 362600 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.769\n",
            "I0509 16:09:34.396350 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.769\n",
            "INFO:tensorflow:loss = 5.2554746, step = 362700 (0.955 sec)\n",
            "I0509 16:09:34.396716 140437868455744 basic_session_run_hooks.py:263] loss = 5.2554746, step = 362700 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.6584\n",
            "I0509 16:09:35.718088 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 75.6584\n",
            "INFO:tensorflow:loss = 7.2514973, step = 362800 (1.322 sec)\n",
            "I0509 16:09:35.718376 140437868455744 basic_session_run_hooks.py:263] loss = 7.2514973, step = 362800 (1.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 94.9801\n",
            "I0509 16:09:36.770922 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 94.9801\n",
            "INFO:tensorflow:loss = 7.876803, step = 362900 (1.053 sec)\n",
            "I0509 16:09:36.771210 140437868455744 basic_session_run_hooks.py:263] loss = 7.876803, step = 362900 (1.053 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 363000...\n",
            "I0509 16:09:37.737178 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 363000...\n",
            "INFO:tensorflow:Saving checkpoints for 363000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:09:37.737371 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 363000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 363000...\n",
            "I0509 16:09:37.999245 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 363000...\n",
            "INFO:tensorflow:global_step/sec: 80.5471\n",
            "I0509 16:09:38.012449 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 80.5471\n",
            "INFO:tensorflow:loss = 5.776685, step = 363000 (1.242 sec)\n",
            "I0509 16:09:38.012863 140437868455744 basic_session_run_hooks.py:263] loss = 5.776685, step = 363000 (1.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.3893\n",
            "I0509 16:09:39.028806 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 98.3893\n",
            "INFO:tensorflow:loss = 4.992026, step = 363100 (1.016 sec)\n",
            "I0509 16:09:39.029115 140437868455744 basic_session_run_hooks.py:263] loss = 4.992026, step = 363100 (1.016 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.21\n",
            "I0509 16:09:39.997706 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.21\n",
            "INFO:tensorflow:loss = 8.019915, step = 363200 (0.969 sec)\n",
            "I0509 16:09:39.998108 140437868455744 basic_session_run_hooks.py:263] loss = 8.019915, step = 363200 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.473\n",
            "I0509 16:09:40.992999 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.473\n",
            "INFO:tensorflow:loss = 4.5736504, step = 363300 (0.995 sec)\n",
            "I0509 16:09:40.993378 140437868455744 basic_session_run_hooks.py:263] loss = 4.5736504, step = 363300 (0.995 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.95\n",
            "I0509 16:09:41.973902 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.95\n",
            "INFO:tensorflow:loss = 5.3246627, step = 363400 (0.981 sec)\n",
            "I0509 16:09:41.974219 140437868455744 basic_session_run_hooks.py:263] loss = 5.3246627, step = 363400 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 93.786\n",
            "I0509 16:09:43.040143 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 93.786\n",
            "INFO:tensorflow:loss = 10.920866, step = 363500 (1.066 sec)\n",
            "I0509 16:09:43.040625 140437868455744 basic_session_run_hooks.py:263] loss = 10.920866, step = 363500 (1.066 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.374\n",
            "I0509 16:09:44.026576 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.374\n",
            "INFO:tensorflow:loss = 6.0536437, step = 363600 (0.986 sec)\n",
            "I0509 16:09:44.026949 140437868455744 basic_session_run_hooks.py:263] loss = 6.0536437, step = 363600 (0.986 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.436\n",
            "I0509 16:09:45.022241 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.436\n",
            "INFO:tensorflow:loss = 4.943839, step = 363700 (0.996 sec)\n",
            "I0509 16:09:45.022543 140437868455744 basic_session_run_hooks.py:263] loss = 4.943839, step = 363700 (0.996 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.29\n",
            "I0509 16:09:46.019351 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.29\n",
            "INFO:tensorflow:loss = 7.407343, step = 363800 (0.997 sec)\n",
            "I0509 16:09:46.019624 140437868455744 basic_session_run_hooks.py:263] loss = 7.407343, step = 363800 (0.997 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.3802\n",
            "I0509 16:09:47.382143 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.3802\n",
            "INFO:tensorflow:loss = 6.0685096, step = 363900 (1.363 sec)\n",
            "I0509 16:09:47.382431 140437868455744 basic_session_run_hooks.py:263] loss = 6.0685096, step = 363900 (1.363 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 364000...\n",
            "I0509 16:09:48.410078 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 364000...\n",
            "INFO:tensorflow:Saving checkpoints for 364000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:09:48.410280 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 364000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 364000...\n",
            "I0509 16:09:48.631272 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 364000...\n",
            "INFO:tensorflow:global_step/sec: 79.1942\n",
            "I0509 16:09:48.644828 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.1942\n",
            "INFO:tensorflow:loss = 7.494042, step = 364000 (1.263 sec)\n",
            "I0509 16:09:48.645215 140437868455744 basic_session_run_hooks.py:263] loss = 7.494042, step = 364000 (1.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.5016\n",
            "I0509 16:09:49.649845 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.5016\n",
            "INFO:tensorflow:loss = 6.80055, step = 364100 (1.005 sec)\n",
            "I0509 16:09:49.650239 140437868455744 basic_session_run_hooks.py:263] loss = 6.80055, step = 364100 (1.005 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.678\n",
            "I0509 16:09:50.614369 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.678\n",
            "INFO:tensorflow:loss = 7.100433, step = 364200 (0.965 sec)\n",
            "I0509 16:09:50.614741 140437868455744 basic_session_run_hooks.py:263] loss = 7.100433, step = 364200 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.875\n",
            "I0509 16:09:51.586424 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.875\n",
            "INFO:tensorflow:loss = 8.260524, step = 364300 (0.972 sec)\n",
            "I0509 16:09:51.586803 140437868455744 basic_session_run_hooks.py:263] loss = 8.260524, step = 364300 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.795\n",
            "I0509 16:09:52.559243 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.795\n",
            "INFO:tensorflow:loss = 7.0412946, step = 364400 (0.973 sec)\n",
            "I0509 16:09:52.559537 140437868455744 basic_session_run_hooks.py:263] loss = 7.0412946, step = 364400 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.088\n",
            "I0509 16:09:53.548524 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.088\n",
            "INFO:tensorflow:loss = 7.2239466, step = 364500 (0.989 sec)\n",
            "I0509 16:09:53.548999 140437868455744 basic_session_run_hooks.py:263] loss = 7.2239466, step = 364500 (0.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.112\n",
            "I0509 16:09:54.518298 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.112\n",
            "INFO:tensorflow:loss = 6.7470794, step = 364600 (0.970 sec)\n",
            "I0509 16:09:54.518577 140437868455744 basic_session_run_hooks.py:263] loss = 6.7470794, step = 364600 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.591\n",
            "I0509 16:09:55.474397 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.591\n",
            "INFO:tensorflow:loss = 6.93194, step = 364700 (0.956 sec)\n",
            "I0509 16:09:55.474819 140437868455744 basic_session_run_hooks.py:263] loss = 6.93194, step = 364700 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.2344\n",
            "I0509 16:09:56.482151 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.2344\n",
            "INFO:tensorflow:loss = 6.4101396, step = 364800 (1.008 sec)\n",
            "I0509 16:09:56.482535 140437868455744 basic_session_run_hooks.py:263] loss = 6.4101396, step = 364800 (1.008 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.568\n",
            "I0509 16:09:57.447653 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.568\n",
            "INFO:tensorflow:loss = 5.4722705, step = 364900 (0.966 sec)\n",
            "I0509 16:09:57.448043 140437868455744 basic_session_run_hooks.py:263] loss = 5.4722705, step = 364900 (0.966 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 365000...\n",
            "I0509 16:09:58.749989 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 365000...\n",
            "INFO:tensorflow:Saving checkpoints for 365000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:09:58.750221 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 365000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 365000...\n",
            "I0509 16:09:59.127526 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 365000...\n",
            "INFO:tensorflow:global_step/sec: 58.8754\n",
            "I0509 16:09:59.146188 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 58.8754\n",
            "INFO:tensorflow:loss = 7.1418233, step = 365000 (1.699 sec)\n",
            "I0509 16:09:59.146546 140437868455744 basic_session_run_hooks.py:263] loss = 7.1418233, step = 365000 (1.699 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.4101\n",
            "I0509 16:10:00.172752 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 97.4101\n",
            "INFO:tensorflow:loss = 6.164416, step = 365100 (1.027 sec)\n",
            "I0509 16:10:00.173152 140437868455744 basic_session_run_hooks.py:263] loss = 6.164416, step = 365100 (1.027 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.204\n",
            "I0509 16:10:01.151204 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.204\n",
            "INFO:tensorflow:loss = 6.5094404, step = 365200 (0.978 sec)\n",
            "I0509 16:10:01.151621 140437868455744 basic_session_run_hooks.py:263] loss = 6.5094404, step = 365200 (0.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.396\n",
            "I0509 16:10:02.118338 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.396\n",
            "INFO:tensorflow:loss = 6.3321385, step = 365300 (0.967 sec)\n",
            "I0509 16:10:02.118738 140437868455744 basic_session_run_hooks.py:263] loss = 6.3321385, step = 365300 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.13\n",
            "I0509 16:10:03.107174 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.13\n",
            "INFO:tensorflow:loss = 6.6654835, step = 365400 (0.989 sec)\n",
            "I0509 16:10:03.107553 140437868455744 basic_session_run_hooks.py:263] loss = 6.6654835, step = 365400 (0.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.327\n",
            "I0509 16:10:04.074981 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.327\n",
            "INFO:tensorflow:loss = 6.4411073, step = 365500 (0.968 sec)\n",
            "I0509 16:10:04.075267 140437868455744 basic_session_run_hooks.py:263] loss = 6.4411073, step = 365500 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.184\n",
            "I0509 16:10:05.073143 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.184\n",
            "INFO:tensorflow:loss = 7.303708, step = 365600 (0.998 sec)\n",
            "I0509 16:10:05.073528 140437868455744 basic_session_run_hooks.py:263] loss = 7.303708, step = 365600 (0.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.023\n",
            "I0509 16:10:06.034453 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.023\n",
            "INFO:tensorflow:loss = 7.430111, step = 365700 (0.961 sec)\n",
            "I0509 16:10:06.034845 140437868455744 basic_session_run_hooks.py:263] loss = 7.430111, step = 365700 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.424\n",
            "I0509 16:10:07.010792 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.424\n",
            "INFO:tensorflow:loss = 6.7170763, step = 365800 (0.976 sec)\n",
            "I0509 16:10:07.011197 140437868455744 basic_session_run_hooks.py:263] loss = 6.7170763, step = 365800 (0.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.512\n",
            "I0509 16:10:07.976869 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.512\n",
            "INFO:tensorflow:loss = 5.7224307, step = 365900 (0.966 sec)\n",
            "I0509 16:10:07.977267 140437868455744 basic_session_run_hooks.py:263] loss = 5.7224307, step = 365900 (0.966 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 366000...\n",
            "I0509 16:10:08.943911 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 366000...\n",
            "INFO:tensorflow:Saving checkpoints for 366000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:10:08.944128 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 366000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 366000...\n",
            "I0509 16:10:09.159913 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 366000...\n",
            "INFO:tensorflow:global_step/sec: 83.6412\n",
            "I0509 16:10:09.172446 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.6412\n",
            "INFO:tensorflow:loss = 7.718822, step = 366000 (1.196 sec)\n",
            "I0509 16:10:09.172829 140437868455744 basic_session_run_hooks.py:263] loss = 7.718822, step = 366000 (1.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0637\n",
            "I0509 16:10:10.560155 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 72.0637\n",
            "INFO:tensorflow:loss = 6.123634, step = 366100 (1.388 sec)\n",
            "I0509 16:10:10.560557 140437868455744 basic_session_run_hooks.py:263] loss = 6.123634, step = 366100 (1.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 92.945\n",
            "I0509 16:10:11.636017 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 92.945\n",
            "INFO:tensorflow:loss = 7.060866, step = 366200 (1.076 sec)\n",
            "I0509 16:10:11.636411 140437868455744 basic_session_run_hooks.py:263] loss = 7.060866, step = 366200 (1.076 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.825\n",
            "I0509 16:10:12.608548 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.825\n",
            "INFO:tensorflow:loss = 6.642402, step = 366300 (0.973 sec)\n",
            "I0509 16:10:12.608912 140437868455744 basic_session_run_hooks.py:263] loss = 6.642402, step = 366300 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.233\n",
            "I0509 16:10:13.567939 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.233\n",
            "INFO:tensorflow:loss = 6.847337, step = 366400 (0.959 sec)\n",
            "I0509 16:10:13.568338 140437868455744 basic_session_run_hooks.py:263] loss = 6.847337, step = 366400 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.91\n",
            "I0509 16:10:14.530312 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.91\n",
            "INFO:tensorflow:loss = 6.404912, step = 366500 (0.962 sec)\n",
            "I0509 16:10:14.530674 140437868455744 basic_session_run_hooks.py:263] loss = 6.404912, step = 366500 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.752\n",
            "I0509 16:10:15.494157 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.752\n",
            "INFO:tensorflow:loss = 6.812398, step = 366600 (0.964 sec)\n",
            "I0509 16:10:15.494431 140437868455744 basic_session_run_hooks.py:263] loss = 6.812398, step = 366600 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.248\n",
            "I0509 16:10:16.453403 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.248\n",
            "INFO:tensorflow:loss = 6.7222047, step = 366700 (0.959 sec)\n",
            "I0509 16:10:16.453779 140437868455744 basic_session_run_hooks.py:263] loss = 6.7222047, step = 366700 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.784\n",
            "I0509 16:10:17.435882 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.784\n",
            "INFO:tensorflow:loss = 7.526282, step = 366800 (0.982 sec)\n",
            "I0509 16:10:17.436262 140437868455744 basic_session_run_hooks.py:263] loss = 7.526282, step = 366800 (0.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.968\n",
            "I0509 16:10:18.407058 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.968\n",
            "INFO:tensorflow:loss = 7.744475, step = 366900 (0.971 sec)\n",
            "I0509 16:10:18.407441 140437868455744 basic_session_run_hooks.py:263] loss = 7.744475, step = 366900 (0.971 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 367000...\n",
            "I0509 16:10:19.370443 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 367000...\n",
            "INFO:tensorflow:Saving checkpoints for 367000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:10:19.370652 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 367000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 367000...\n",
            "I0509 16:10:19.592246 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 367000...\n",
            "INFO:tensorflow:global_step/sec: 83.4086\n",
            "I0509 16:10:19.605958 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.4086\n",
            "INFO:tensorflow:loss = 6.6338563, step = 367000 (1.199 sec)\n",
            "I0509 16:10:19.606232 140437868455744 basic_session_run_hooks.py:263] loss = 6.6338563, step = 367000 (1.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.048\n",
            "I0509 16:10:20.576390 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.048\n",
            "INFO:tensorflow:loss = 7.2756257, step = 367100 (0.971 sec)\n",
            "I0509 16:10:20.576765 140437868455744 basic_session_run_hooks.py:263] loss = 7.2756257, step = 367100 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.8271\n",
            "I0509 16:10:21.930923 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 73.8271\n",
            "INFO:tensorflow:loss = 6.602539, step = 367200 (1.355 sec)\n",
            "I0509 16:10:21.931331 140437868455744 basic_session_run_hooks.py:263] loss = 6.602539, step = 367200 (1.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 90.4955\n",
            "I0509 16:10:23.035927 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 90.4955\n",
            "INFO:tensorflow:loss = 4.920228, step = 367300 (1.105 sec)\n",
            "I0509 16:10:23.036307 140437868455744 basic_session_run_hooks.py:263] loss = 4.920228, step = 367300 (1.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.77\n",
            "I0509 16:10:23.990400 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.77\n",
            "INFO:tensorflow:loss = 5.497765, step = 367400 (0.954 sec)\n",
            "I0509 16:10:23.990776 140437868455744 basic_session_run_hooks.py:263] loss = 5.497765, step = 367400 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.911\n",
            "I0509 16:10:24.981374 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.911\n",
            "INFO:tensorflow:loss = 6.2224016, step = 367500 (0.991 sec)\n",
            "I0509 16:10:24.981760 140437868455744 basic_session_run_hooks.py:263] loss = 6.2224016, step = 367500 (0.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.174\n",
            "I0509 16:10:25.950615 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.174\n",
            "INFO:tensorflow:loss = 6.2126336, step = 367600 (0.969 sec)\n",
            "I0509 16:10:25.951004 140437868455744 basic_session_run_hooks.py:263] loss = 6.2126336, step = 367600 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.268\n",
            "I0509 16:10:26.928462 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.268\n",
            "INFO:tensorflow:loss = 5.8560786, step = 367700 (0.978 sec)\n",
            "I0509 16:10:26.928862 140437868455744 basic_session_run_hooks.py:263] loss = 5.8560786, step = 367700 (0.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.609\n",
            "I0509 16:10:27.893605 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.609\n",
            "INFO:tensorflow:loss = 6.381653, step = 367800 (0.965 sec)\n",
            "I0509 16:10:27.894008 140437868455744 basic_session_run_hooks.py:263] loss = 6.381653, step = 367800 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.121\n",
            "I0509 16:10:28.872843 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.121\n",
            "INFO:tensorflow:loss = 6.333751, step = 367900 (0.979 sec)\n",
            "I0509 16:10:28.873235 140437868455744 basic_session_run_hooks.py:263] loss = 6.333751, step = 367900 (0.979 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 368000...\n",
            "I0509 16:10:29.814595 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 368000...\n",
            "INFO:tensorflow:Saving checkpoints for 368000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:10:29.814825 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 368000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 368000...\n",
            "I0509 16:10:30.050849 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 368000...\n",
            "INFO:tensorflow:global_step/sec: 83.8832\n",
            "I0509 16:10:30.064965 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.8832\n",
            "INFO:tensorflow:loss = 6.182233, step = 368000 (1.192 sec)\n",
            "I0509 16:10:30.065321 140437868455744 basic_session_run_hooks.py:263] loss = 6.182233, step = 368000 (1.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.556\n",
            "I0509 16:10:31.030625 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.556\n",
            "INFO:tensorflow:loss = 7.0110545, step = 368100 (0.966 sec)\n",
            "I0509 16:10:31.030981 140437868455744 basic_session_run_hooks.py:263] loss = 7.0110545, step = 368100 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.569\n",
            "I0509 16:10:31.986966 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.569\n",
            "INFO:tensorflow:loss = 5.1504703, step = 368200 (0.956 sec)\n",
            "I0509 16:10:31.987350 140437868455744 basic_session_run_hooks.py:263] loss = 5.1504703, step = 368200 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.8511\n",
            "I0509 16:10:33.208673 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.8511\n",
            "INFO:tensorflow:loss = 5.966502, step = 368300 (1.222 sec)\n",
            "I0509 16:10:33.208968 140437868455744 basic_session_run_hooks.py:263] loss = 5.966502, step = 368300 (1.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.6513\n",
            "I0509 16:10:34.389993 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.6513\n",
            "INFO:tensorflow:loss = 6.318756, step = 368400 (1.181 sec)\n",
            "I0509 16:10:34.390359 140437868455744 basic_session_run_hooks.py:263] loss = 6.318756, step = 368400 (1.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.051\n",
            "I0509 16:10:35.369915 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.051\n",
            "INFO:tensorflow:loss = 7.4338336, step = 368500 (0.980 sec)\n",
            "I0509 16:10:35.370316 140437868455744 basic_session_run_hooks.py:263] loss = 7.4338336, step = 368500 (0.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.79\n",
            "I0509 16:10:36.315198 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.79\n",
            "INFO:tensorflow:loss = 4.9665713, step = 368600 (0.945 sec)\n",
            "I0509 16:10:36.315589 140437868455744 basic_session_run_hooks.py:263] loss = 4.9665713, step = 368600 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.288\n",
            "I0509 16:10:37.264930 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.288\n",
            "INFO:tensorflow:loss = 7.2250266, step = 368700 (0.950 sec)\n",
            "I0509 16:10:37.265324 140437868455744 basic_session_run_hooks.py:263] loss = 7.2250266, step = 368700 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.407\n",
            "I0509 16:10:38.213629 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.407\n",
            "INFO:tensorflow:loss = 8.168472, step = 368800 (0.949 sec)\n",
            "I0509 16:10:38.213989 140437868455744 basic_session_run_hooks.py:263] loss = 8.168472, step = 368800 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.39\n",
            "I0509 16:10:39.162492 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.39\n",
            "INFO:tensorflow:loss = 6.9892006, step = 368900 (0.949 sec)\n",
            "I0509 16:10:39.162860 140437868455744 basic_session_run_hooks.py:263] loss = 6.9892006, step = 368900 (0.949 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 369000...\n",
            "I0509 16:10:40.107160 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 369000...\n",
            "INFO:tensorflow:Saving checkpoints for 369000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:10:40.107353 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 369000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 369000...\n",
            "I0509 16:10:40.332840 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 369000...\n",
            "INFO:tensorflow:global_step/sec: 84.4103\n",
            "I0509 16:10:40.347195 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.4103\n",
            "INFO:tensorflow:loss = 6.4820204, step = 369000 (1.185 sec)\n",
            "I0509 16:10:40.347590 140437868455744 basic_session_run_hooks.py:263] loss = 6.4820204, step = 369000 (1.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.732\n",
            "I0509 16:10:41.330175 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.732\n",
            "INFO:tensorflow:loss = 6.2665277, step = 369100 (0.983 sec)\n",
            "I0509 16:10:41.330483 140437868455744 basic_session_run_hooks.py:263] loss = 6.2665277, step = 369100 (0.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.205\n",
            "I0509 16:10:42.308572 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.205\n",
            "INFO:tensorflow:loss = 6.163414, step = 369200 (0.978 sec)\n",
            "I0509 16:10:42.308952 140437868455744 basic_session_run_hooks.py:263] loss = 6.163414, step = 369200 (0.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.63\n",
            "I0509 16:10:43.255273 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.63\n",
            "INFO:tensorflow:loss = 6.234013, step = 369300 (0.947 sec)\n",
            "I0509 16:10:43.256076 140437868455744 basic_session_run_hooks.py:263] loss = 6.234013, step = 369300 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 94.3188\n",
            "I0509 16:10:44.315523 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 94.3188\n",
            "INFO:tensorflow:loss = 7.6193204, step = 369400 (1.060 sec)\n",
            "I0509 16:10:44.315836 140437868455744 basic_session_run_hooks.py:263] loss = 7.6193204, step = 369400 (1.060 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.3133\n",
            "I0509 16:10:45.643275 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 75.3133\n",
            "INFO:tensorflow:loss = 6.2971964, step = 369500 (1.328 sec)\n",
            "I0509 16:10:45.643649 140437868455744 basic_session_run_hooks.py:263] loss = 6.2971964, step = 369500 (1.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.883\n",
            "I0509 16:10:46.605913 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.883\n",
            "INFO:tensorflow:loss = 5.694582, step = 369600 (0.963 sec)\n",
            "I0509 16:10:46.606313 140437868455744 basic_session_run_hooks.py:263] loss = 5.694582, step = 369600 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.851\n",
            "I0509 16:10:47.568826 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.851\n",
            "INFO:tensorflow:loss = 6.3112025, step = 369700 (0.963 sec)\n",
            "I0509 16:10:47.569211 140437868455744 basic_session_run_hooks.py:263] loss = 6.3112025, step = 369700 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.306\n",
            "I0509 16:10:48.518438 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.306\n",
            "INFO:tensorflow:loss = 7.0421467, step = 369800 (0.950 sec)\n",
            "I0509 16:10:48.518825 140437868455744 basic_session_run_hooks.py:263] loss = 7.0421467, step = 369800 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.954\n",
            "I0509 16:10:49.480389 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.954\n",
            "INFO:tensorflow:loss = 6.5786443, step = 369900 (0.962 sec)\n",
            "I0509 16:10:49.480759 140437868455744 basic_session_run_hooks.py:263] loss = 6.5786443, step = 369900 (0.962 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 370000...\n",
            "I0509 16:10:50.429702 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 370000...\n",
            "INFO:tensorflow:Saving checkpoints for 370000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:10:50.429903 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 370000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 370000...\n",
            "I0509 16:10:50.652860 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 370000...\n",
            "INFO:tensorflow:global_step/sec: 83.5824\n",
            "I0509 16:10:50.676824 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.5824\n",
            "INFO:tensorflow:loss = 5.859287, step = 370000 (1.196 sec)\n",
            "I0509 16:10:50.677203 140437868455744 basic_session_run_hooks.py:263] loss = 5.859287, step = 370000 (1.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.58\n",
            "I0509 16:10:51.651672 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.58\n",
            "INFO:tensorflow:loss = 7.6763396, step = 370100 (0.975 sec)\n",
            "I0509 16:10:51.652026 140437868455744 basic_session_run_hooks.py:263] loss = 7.6763396, step = 370100 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.716\n",
            "I0509 16:10:52.634798 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.716\n",
            "INFO:tensorflow:loss = 5.6294403, step = 370200 (0.983 sec)\n",
            "I0509 16:10:52.635182 140437868455744 basic_session_run_hooks.py:263] loss = 5.6294403, step = 370200 (0.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.124\n",
            "I0509 16:10:53.586057 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.124\n",
            "INFO:tensorflow:loss = 5.7736874, step = 370300 (0.951 sec)\n",
            "I0509 16:10:53.586457 140437868455744 basic_session_run_hooks.py:263] loss = 5.7736874, step = 370300 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.847\n",
            "I0509 16:10:54.539830 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.847\n",
            "INFO:tensorflow:loss = 7.433026, step = 370400 (0.954 sec)\n",
            "I0509 16:10:54.540222 140437868455744 basic_session_run_hooks.py:263] loss = 7.433026, step = 370400 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 95.2171\n",
            "I0509 16:10:55.590107 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 95.2171\n",
            "INFO:tensorflow:loss = 6.4113646, step = 370500 (1.050 sec)\n",
            "I0509 16:10:55.590440 140437868455744 basic_session_run_hooks.py:263] loss = 6.4113646, step = 370500 (1.050 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.0338\n",
            "I0509 16:10:56.997862 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 71.0338\n",
            "INFO:tensorflow:loss = 6.873729, step = 370600 (1.408 sec)\n",
            "I0509 16:10:56.998284 140437868455744 basic_session_run_hooks.py:263] loss = 6.873729, step = 370600 (1.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.498\n",
            "I0509 16:10:57.992882 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.498\n",
            "INFO:tensorflow:loss = 6.4762216, step = 370700 (0.995 sec)\n",
            "I0509 16:10:57.993685 140437868455744 basic_session_run_hooks.py:263] loss = 6.4762216, step = 370700 (0.995 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.167\n",
            "I0509 16:10:58.962205 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.167\n",
            "INFO:tensorflow:loss = 7.1472545, step = 370800 (0.969 sec)\n",
            "I0509 16:10:58.962574 140437868455744 basic_session_run_hooks.py:263] loss = 7.1472545, step = 370800 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.607\n",
            "I0509 16:10:59.918158 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.607\n",
            "INFO:tensorflow:loss = 6.3476815, step = 370900 (0.956 sec)\n",
            "I0509 16:10:59.918539 140437868455744 basic_session_run_hooks.py:263] loss = 6.3476815, step = 370900 (0.956 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 371000...\n",
            "I0509 16:11:00.871931 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 371000...\n",
            "INFO:tensorflow:Saving checkpoints for 371000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:11:00.872155 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 371000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 371000...\n",
            "I0509 16:11:01.086468 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 371000...\n",
            "INFO:tensorflow:global_step/sec: 84.7257\n",
            "I0509 16:11:01.098404 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.7257\n",
            "INFO:tensorflow:loss = 7.369468, step = 371000 (1.180 sec)\n",
            "I0509 16:11:01.098741 140437868455744 basic_session_run_hooks.py:263] loss = 7.369468, step = 371000 (1.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.981\n",
            "I0509 16:11:02.041990 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.981\n",
            "INFO:tensorflow:loss = 6.6133523, step = 371100 (0.944 sec)\n",
            "I0509 16:11:02.042383 140437868455744 basic_session_run_hooks.py:263] loss = 6.6133523, step = 371100 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.758\n",
            "I0509 16:11:02.996568 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.758\n",
            "INFO:tensorflow:loss = 6.799298, step = 371200 (0.955 sec)\n",
            "I0509 16:11:02.996943 140437868455744 basic_session_run_hooks.py:263] loss = 6.799298, step = 371200 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.417\n",
            "I0509 16:11:03.945193 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.417\n",
            "INFO:tensorflow:loss = 7.110161, step = 371300 (0.949 sec)\n",
            "I0509 16:11:03.945565 140437868455744 basic_session_run_hooks.py:263] loss = 7.110161, step = 371300 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.082\n",
            "I0509 16:11:04.887857 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.082\n",
            "INFO:tensorflow:loss = 6.5784674, step = 371400 (0.943 sec)\n",
            "I0509 16:11:04.888159 140437868455744 basic_session_run_hooks.py:263] loss = 6.5784674, step = 371400 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.609\n",
            "I0509 16:11:05.834739 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.609\n",
            "INFO:tensorflow:loss = 5.8587785, step = 371500 (0.947 sec)\n",
            "I0509 16:11:05.835103 140437868455744 basic_session_run_hooks.py:263] loss = 5.8587785, step = 371500 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.022\n",
            "I0509 16:11:06.786929 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.022\n",
            "INFO:tensorflow:loss = 6.550388, step = 371600 (0.952 sec)\n",
            "I0509 16:11:06.787315 140437868455744 basic_session_run_hooks.py:263] loss = 6.550388, step = 371600 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.8937\n",
            "I0509 16:11:08.038580 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.8937\n",
            "INFO:tensorflow:loss = 6.4889402, step = 371700 (1.252 sec)\n",
            "I0509 16:11:08.038927 140437868455744 basic_session_run_hooks.py:263] loss = 6.4889402, step = 371700 (1.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 87.5588\n",
            "I0509 16:11:09.180675 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.5588\n",
            "INFO:tensorflow:loss = 6.589347, step = 371800 (1.142 sec)\n",
            "I0509 16:11:09.181047 140437868455744 basic_session_run_hooks.py:263] loss = 6.589347, step = 371800 (1.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.653\n",
            "I0509 16:11:10.136214 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.653\n",
            "INFO:tensorflow:loss = 6.4124336, step = 371900 (0.956 sec)\n",
            "I0509 16:11:10.136579 140437868455744 basic_session_run_hooks.py:263] loss = 6.4124336, step = 371900 (0.956 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 372000...\n",
            "I0509 16:11:11.076134 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 372000...\n",
            "INFO:tensorflow:Saving checkpoints for 372000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:11:11.076333 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 372000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 372000...\n",
            "I0509 16:11:11.300755 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 372000...\n",
            "INFO:tensorflow:global_step/sec: 84.1827\n",
            "I0509 16:11:11.324151 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.1827\n",
            "INFO:tensorflow:loss = 7.358742, step = 372000 (1.188 sec)\n",
            "I0509 16:11:11.324575 140437868455744 basic_session_run_hooks.py:263] loss = 7.358742, step = 372000 (1.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.916\n",
            "I0509 16:11:12.315033 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.916\n",
            "INFO:tensorflow:loss = 6.645266, step = 372100 (0.991 sec)\n",
            "I0509 16:11:12.315367 140437868455744 basic_session_run_hooks.py:263] loss = 6.645266, step = 372100 (0.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.153\n",
            "I0509 16:11:13.313495 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.153\n",
            "INFO:tensorflow:loss = 6.293885, step = 372200 (0.998 sec)\n",
            "I0509 16:11:13.313784 140437868455744 basic_session_run_hooks.py:263] loss = 6.293885, step = 372200 (0.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.107\n",
            "I0509 16:11:14.255934 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.107\n",
            "INFO:tensorflow:loss = 6.3059435, step = 372300 (0.943 sec)\n",
            "I0509 16:11:14.256306 140437868455744 basic_session_run_hooks.py:263] loss = 6.3059435, step = 372300 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.532\n",
            "I0509 16:11:15.194621 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.532\n",
            "INFO:tensorflow:loss = 6.7360334, step = 372400 (0.939 sec)\n",
            "I0509 16:11:15.194902 140437868455744 basic_session_run_hooks.py:263] loss = 6.7360334, step = 372400 (0.939 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.15\n",
            "I0509 16:11:16.136686 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.15\n",
            "INFO:tensorflow:loss = 6.10199, step = 372500 (0.942 sec)\n",
            "I0509 16:11:16.137036 140437868455744 basic_session_run_hooks.py:263] loss = 6.10199, step = 372500 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.517\n",
            "I0509 16:11:17.102709 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.517\n",
            "INFO:tensorflow:loss = 4.401028, step = 372600 (0.966 sec)\n",
            "I0509 16:11:17.102984 140437868455744 basic_session_run_hooks.py:263] loss = 4.401028, step = 372600 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.958\n",
            "I0509 16:11:18.055480 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.958\n",
            "INFO:tensorflow:loss = 5.955774, step = 372700 (0.953 sec)\n",
            "I0509 16:11:18.055835 140437868455744 basic_session_run_hooks.py:263] loss = 5.955774, step = 372700 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 92.0796\n",
            "I0509 16:11:19.141493 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 92.0796\n",
            "INFO:tensorflow:loss = 6.900569, step = 372800 (1.086 sec)\n",
            "I0509 16:11:19.141800 140437868455744 basic_session_run_hooks.py:263] loss = 6.900569, step = 372800 (1.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.1987\n",
            "I0509 16:11:20.436849 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.1987\n",
            "INFO:tensorflow:loss = 7.304454, step = 372900 (1.295 sec)\n",
            "I0509 16:11:20.437155 140437868455744 basic_session_run_hooks.py:263] loss = 7.304454, step = 372900 (1.295 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 373000...\n",
            "I0509 16:11:21.389235 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 373000...\n",
            "INFO:tensorflow:Saving checkpoints for 373000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:11:21.389425 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 373000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 373000...\n",
            "I0509 16:11:21.617085 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 373000...\n",
            "INFO:tensorflow:global_step/sec: 83.885\n",
            "I0509 16:11:21.628935 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.885\n",
            "INFO:tensorflow:loss = 3.7037954, step = 373000 (1.192 sec)\n",
            "I0509 16:11:21.629196 140437868455744 basic_session_run_hooks.py:263] loss = 3.7037954, step = 373000 (1.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.505\n",
            "I0509 16:11:22.614146 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.505\n",
            "INFO:tensorflow:loss = 6.6798916, step = 373100 (0.985 sec)\n",
            "I0509 16:11:22.614443 140437868455744 basic_session_run_hooks.py:263] loss = 6.6798916, step = 373100 (0.985 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.739\n",
            "I0509 16:11:23.568871 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.739\n",
            "INFO:tensorflow:loss = 8.100851, step = 373200 (0.955 sec)\n",
            "I0509 16:11:23.569262 140437868455744 basic_session_run_hooks.py:263] loss = 8.100851, step = 373200 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.101\n",
            "I0509 16:11:24.520345 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.101\n",
            "INFO:tensorflow:loss = 6.670824, step = 373300 (0.951 sec)\n",
            "I0509 16:11:24.520712 140437868455744 basic_session_run_hooks.py:263] loss = 6.670824, step = 373300 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.892\n",
            "I0509 16:11:25.473701 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.892\n",
            "INFO:tensorflow:loss = 6.288229, step = 373400 (0.953 sec)\n",
            "I0509 16:11:25.473994 140437868455744 basic_session_run_hooks.py:263] loss = 6.288229, step = 373400 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.243\n",
            "I0509 16:11:26.414952 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.243\n",
            "INFO:tensorflow:loss = 4.6294713, step = 373500 (0.941 sec)\n",
            "I0509 16:11:26.415324 140437868455744 basic_session_run_hooks.py:263] loss = 4.6294713, step = 373500 (0.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.232\n",
            "I0509 16:11:27.402768 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.232\n",
            "INFO:tensorflow:loss = 6.040495, step = 373600 (0.988 sec)\n",
            "I0509 16:11:27.403068 140437868455744 basic_session_run_hooks.py:263] loss = 6.040495, step = 373600 (0.988 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.318\n",
            "I0509 16:11:28.370645 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.318\n",
            "INFO:tensorflow:loss = 7.790716, step = 373700 (0.968 sec)\n",
            "I0509 16:11:28.371013 140437868455744 basic_session_run_hooks.py:263] loss = 7.790716, step = 373700 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.901\n",
            "I0509 16:11:29.323931 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.901\n",
            "INFO:tensorflow:loss = 7.439195, step = 373800 (0.953 sec)\n",
            "I0509 16:11:29.324223 140437868455744 basic_session_run_hooks.py:263] loss = 7.439195, step = 373800 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.535\n",
            "I0509 16:11:30.271482 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.535\n",
            "INFO:tensorflow:loss = 7.021533, step = 373900 (0.948 sec)\n",
            "I0509 16:11:30.271834 140437868455744 basic_session_run_hooks.py:263] loss = 7.021533, step = 373900 (0.948 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 374000...\n",
            "I0509 16:11:31.616225 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 374000...\n",
            "INFO:tensorflow:Saving checkpoints for 374000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:11:31.616462 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 374000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 374000...\n",
            "I0509 16:11:31.933421 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 374000...\n",
            "INFO:tensorflow:global_step/sec: 59.724\n",
            "I0509 16:11:31.945821 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 59.724\n",
            "INFO:tensorflow:loss = 6.4249263, step = 374000 (1.674 sec)\n",
            "I0509 16:11:31.946081 140437868455744 basic_session_run_hooks.py:263] loss = 6.4249263, step = 374000 (1.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.263\n",
            "I0509 16:11:32.904973 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.263\n",
            "INFO:tensorflow:loss = 6.8603153, step = 374100 (0.959 sec)\n",
            "I0509 16:11:32.905393 140437868455744 basic_session_run_hooks.py:263] loss = 6.8603153, step = 374100 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.935\n",
            "I0509 16:11:33.867120 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.935\n",
            "INFO:tensorflow:loss = 5.3505883, step = 374200 (0.962 sec)\n",
            "I0509 16:11:33.867499 140437868455744 basic_session_run_hooks.py:263] loss = 5.3505883, step = 374200 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.844\n",
            "I0509 16:11:34.820908 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.844\n",
            "INFO:tensorflow:loss = 6.2849035, step = 374300 (0.954 sec)\n",
            "I0509 16:11:34.821293 140437868455744 basic_session_run_hooks.py:263] loss = 6.2849035, step = 374300 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.568\n",
            "I0509 16:11:35.759266 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.568\n",
            "INFO:tensorflow:loss = 7.071849, step = 374400 (0.938 sec)\n",
            "I0509 16:11:35.759628 140437868455744 basic_session_run_hooks.py:263] loss = 7.071849, step = 374400 (0.938 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.594\n",
            "I0509 16:11:36.715357 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.594\n",
            "INFO:tensorflow:loss = 6.9588547, step = 374500 (0.956 sec)\n",
            "I0509 16:11:36.715734 140437868455744 basic_session_run_hooks.py:263] loss = 6.9588547, step = 374500 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.562\n",
            "I0509 16:11:37.680950 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.562\n",
            "INFO:tensorflow:loss = 7.2968626, step = 374600 (0.966 sec)\n",
            "I0509 16:11:37.681354 140437868455744 basic_session_run_hooks.py:263] loss = 7.2968626, step = 374600 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.744\n",
            "I0509 16:11:38.635664 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.744\n",
            "INFO:tensorflow:loss = 6.7610407, step = 374700 (0.955 sec)\n",
            "I0509 16:11:38.635987 140437868455744 basic_session_run_hooks.py:263] loss = 6.7610407, step = 374700 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.686\n",
            "I0509 16:11:39.590904 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.686\n",
            "INFO:tensorflow:loss = 6.7899776, step = 374800 (0.955 sec)\n",
            "I0509 16:11:39.591301 140437868455744 basic_session_run_hooks.py:263] loss = 6.7899776, step = 374800 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.107\n",
            "I0509 16:11:40.570266 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.107\n",
            "INFO:tensorflow:loss = 5.970371, step = 374900 (0.979 sec)\n",
            "I0509 16:11:40.570695 140437868455744 basic_session_run_hooks.py:263] loss = 5.970371, step = 374900 (0.979 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 375000...\n",
            "I0509 16:11:41.530397 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 375000...\n",
            "INFO:tensorflow:Saving checkpoints for 375000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:11:41.530607 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 375000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 375000...\n",
            "I0509 16:11:41.740117 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 375000...\n",
            "INFO:tensorflow:global_step/sec: 84.5388\n",
            "I0509 16:11:41.753166 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.5388\n",
            "INFO:tensorflow:loss = 5.2985206, step = 375000 (1.183 sec)\n",
            "I0509 16:11:41.753486 140437868455744 basic_session_run_hooks.py:263] loss = 5.2985206, step = 375000 (1.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.9652\n",
            "I0509 16:11:43.142713 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 71.9652\n",
            "INFO:tensorflow:loss = 6.999061, step = 375100 (1.390 sec)\n",
            "I0509 16:11:43.143119 140437868455744 basic_session_run_hooks.py:263] loss = 6.999061, step = 375100 (1.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.062\n",
            "I0509 16:11:44.183701 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 96.062\n",
            "INFO:tensorflow:loss = 6.4119353, step = 375200 (1.041 sec)\n",
            "I0509 16:11:44.184107 140437868455744 basic_session_run_hooks.py:263] loss = 6.4119353, step = 375200 (1.041 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.745\n",
            "I0509 16:11:45.138407 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.745\n",
            "INFO:tensorflow:loss = 6.9853854, step = 375300 (0.955 sec)\n",
            "I0509 16:11:45.138768 140437868455744 basic_session_run_hooks.py:263] loss = 6.9853854, step = 375300 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.706\n",
            "I0509 16:11:46.084418 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.706\n",
            "INFO:tensorflow:loss = 5.20957, step = 375400 (0.946 sec)\n",
            "I0509 16:11:46.084793 140437868455744 basic_session_run_hooks.py:263] loss = 5.20957, step = 375400 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.103\n",
            "I0509 16:11:47.035868 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.103\n",
            "INFO:tensorflow:loss = 6.9323564, step = 375500 (0.951 sec)\n",
            "I0509 16:11:47.036256 140437868455744 basic_session_run_hooks.py:263] loss = 6.9323564, step = 375500 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.789\n",
            "I0509 16:11:47.981171 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.789\n",
            "INFO:tensorflow:loss = 6.4199495, step = 375600 (0.945 sec)\n",
            "I0509 16:11:47.981541 140437868455744 basic_session_run_hooks.py:263] loss = 6.4199495, step = 375600 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.147\n",
            "I0509 16:11:48.941316 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.147\n",
            "INFO:tensorflow:loss = 5.645336, step = 375700 (0.960 sec)\n",
            "I0509 16:11:48.941676 140437868455744 basic_session_run_hooks.py:263] loss = 5.645336, step = 375700 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.004\n",
            "I0509 16:11:49.902845 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.004\n",
            "INFO:tensorflow:loss = 7.9643836, step = 375800 (0.962 sec)\n",
            "I0509 16:11:49.903243 140437868455744 basic_session_run_hooks.py:263] loss = 7.9643836, step = 375800 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.326\n",
            "I0509 16:11:50.880106 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.326\n",
            "INFO:tensorflow:loss = 4.863825, step = 375900 (0.977 sec)\n",
            "I0509 16:11:50.880472 140437868455744 basic_session_run_hooks.py:263] loss = 4.863825, step = 375900 (0.977 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 376000...\n",
            "I0509 16:11:51.833810 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 376000...\n",
            "INFO:tensorflow:Saving checkpoints for 376000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:11:51.834053 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 376000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 376000...\n",
            "I0509 16:11:52.048585 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 376000...\n",
            "INFO:tensorflow:global_step/sec: 84.6924\n",
            "I0509 16:11:52.060827 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.6924\n",
            "INFO:tensorflow:loss = 6.142786, step = 376000 (1.181 sec)\n",
            "I0509 16:11:52.061089 140437868455744 basic_session_run_hooks.py:263] loss = 6.142786, step = 376000 (1.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.403\n",
            "I0509 16:11:53.056823 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.403\n",
            "INFO:tensorflow:loss = 5.062665, step = 376100 (0.996 sec)\n",
            "I0509 16:11:53.057210 140437868455744 basic_session_run_hooks.py:263] loss = 5.062665, step = 376100 (0.996 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.4873\n",
            "I0509 16:11:54.284032 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.4873\n",
            "INFO:tensorflow:loss = 6.388028, step = 376200 (1.227 sec)\n",
            "I0509 16:11:54.284422 140437868455744 basic_session_run_hooks.py:263] loss = 6.388028, step = 376200 (1.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.1761\n",
            "I0509 16:11:55.471998 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.1761\n",
            "INFO:tensorflow:loss = 5.351278, step = 376300 (1.188 sec)\n",
            "I0509 16:11:55.472349 140437868455744 basic_session_run_hooks.py:263] loss = 5.351278, step = 376300 (1.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.246\n",
            "I0509 16:11:56.422181 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.246\n",
            "INFO:tensorflow:loss = 6.166686, step = 376400 (0.950 sec)\n",
            "I0509 16:11:56.422580 140437868455744 basic_session_run_hooks.py:263] loss = 6.166686, step = 376400 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.865\n",
            "I0509 16:11:57.384949 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.865\n",
            "INFO:tensorflow:loss = 6.899843, step = 376500 (0.963 sec)\n",
            "I0509 16:11:57.385339 140437868455744 basic_session_run_hooks.py:263] loss = 6.899843, step = 376500 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.518\n",
            "I0509 16:11:58.332659 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.518\n",
            "INFO:tensorflow:loss = 7.256478, step = 376600 (0.948 sec)\n",
            "I0509 16:11:58.333040 140437868455744 basic_session_run_hooks.py:263] loss = 7.256478, step = 376600 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.927\n",
            "I0509 16:11:59.304228 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.927\n",
            "INFO:tensorflow:loss = 6.654977, step = 376700 (0.972 sec)\n",
            "I0509 16:11:59.304598 140437868455744 basic_session_run_hooks.py:263] loss = 6.654977, step = 376700 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.234\n",
            "I0509 16:12:00.272902 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.234\n",
            "INFO:tensorflow:loss = 5.957893, step = 376800 (0.969 sec)\n",
            "I0509 16:12:00.273306 140437868455744 basic_session_run_hooks.py:263] loss = 5.957893, step = 376800 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.724\n",
            "I0509 16:12:01.227775 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.724\n",
            "INFO:tensorflow:loss = 6.8327274, step = 376900 (0.955 sec)\n",
            "I0509 16:12:01.228157 140437868455744 basic_session_run_hooks.py:263] loss = 6.8327274, step = 376900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 377000...\n",
            "I0509 16:12:02.161417 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 377000...\n",
            "INFO:tensorflow:Saving checkpoints for 377000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:12:02.161604 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 377000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 377000...\n",
            "I0509 16:12:02.383913 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 377000...\n",
            "INFO:tensorflow:global_step/sec: 85.609\n",
            "I0509 16:12:02.395873 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.609\n",
            "INFO:tensorflow:loss = 6.177458, step = 377000 (1.168 sec)\n",
            "I0509 16:12:02.396141 140437868455744 basic_session_run_hooks.py:263] loss = 6.177458, step = 377000 (1.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.472\n",
            "I0509 16:12:03.344010 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.472\n",
            "INFO:tensorflow:loss = 7.1574836, step = 377100 (0.948 sec)\n",
            "I0509 16:12:03.344394 140437868455744 basic_session_run_hooks.py:263] loss = 7.1574836, step = 377100 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.652\n",
            "I0509 16:12:04.299558 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.652\n",
            "INFO:tensorflow:loss = 7.3059607, step = 377200 (0.955 sec)\n",
            "I0509 16:12:04.299841 140437868455744 basic_session_run_hooks.py:263] loss = 7.3059607, step = 377200 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 94.1088\n",
            "I0509 16:12:05.362181 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 94.1088\n",
            "INFO:tensorflow:loss = 6.859152, step = 377300 (1.063 sec)\n",
            "I0509 16:12:05.362545 140437868455744 basic_session_run_hooks.py:263] loss = 6.859152, step = 377300 (1.063 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.9041\n",
            "I0509 16:12:06.679611 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 75.9041\n",
            "INFO:tensorflow:loss = 7.322646, step = 377400 (1.317 sec)\n",
            "I0509 16:12:06.680007 140437868455744 basic_session_run_hooks.py:263] loss = 7.322646, step = 377400 (1.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.768\n",
            "I0509 16:12:07.634117 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.768\n",
            "INFO:tensorflow:loss = 6.423747, step = 377500 (0.954 sec)\n",
            "I0509 16:12:07.634415 140437868455744 basic_session_run_hooks.py:263] loss = 6.423747, step = 377500 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.751\n",
            "I0509 16:12:08.597950 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.751\n",
            "INFO:tensorflow:loss = 5.6544375, step = 377600 (0.964 sec)\n",
            "I0509 16:12:08.598324 140437868455744 basic_session_run_hooks.py:263] loss = 5.6544375, step = 377600 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.788\n",
            "I0509 16:12:09.552257 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.788\n",
            "INFO:tensorflow:loss = 6.998945, step = 377700 (0.954 sec)\n",
            "I0509 16:12:09.552637 140437868455744 basic_session_run_hooks.py:263] loss = 6.998945, step = 377700 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.427\n",
            "I0509 16:12:10.509868 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.427\n",
            "INFO:tensorflow:loss = 7.3156676, step = 377800 (0.958 sec)\n",
            "I0509 16:12:10.510154 140437868455744 basic_session_run_hooks.py:263] loss = 7.3156676, step = 377800 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.492\n",
            "I0509 16:12:11.466874 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.492\n",
            "INFO:tensorflow:loss = 6.2237806, step = 377900 (0.957 sec)\n",
            "I0509 16:12:11.467250 140437868455744 basic_session_run_hooks.py:263] loss = 6.2237806, step = 377900 (0.957 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 378000...\n",
            "I0509 16:12:12.415544 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 378000...\n",
            "INFO:tensorflow:Saving checkpoints for 378000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:12:12.415740 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 378000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 378000...\n",
            "I0509 16:12:12.618945 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 378000...\n",
            "INFO:tensorflow:global_step/sec: 85.9004\n",
            "I0509 16:12:12.630991 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.9004\n",
            "INFO:tensorflow:loss = 5.6512837, step = 378000 (1.164 sec)\n",
            "I0509 16:12:12.631252 140437868455744 basic_session_run_hooks.py:263] loss = 5.6512837, step = 378000 (1.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.183\n",
            "I0509 16:12:13.609641 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.183\n",
            "INFO:tensorflow:loss = 5.898272, step = 378100 (0.979 sec)\n",
            "I0509 16:12:13.610013 140437868455744 basic_session_run_hooks.py:263] loss = 5.898272, step = 378100 (0.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.913\n",
            "I0509 16:12:14.562811 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.913\n",
            "INFO:tensorflow:loss = 7.806534, step = 378200 (0.953 sec)\n",
            "I0509 16:12:14.563196 140437868455744 basic_session_run_hooks.py:263] loss = 7.806534, step = 378200 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.862\n",
            "I0509 16:12:15.507443 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.862\n",
            "INFO:tensorflow:loss = 6.671808, step = 378300 (0.945 sec)\n",
            "I0509 16:12:15.507808 140437868455744 basic_session_run_hooks.py:263] loss = 6.671808, step = 378300 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.121\n",
            "I0509 16:12:16.458726 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.121\n",
            "INFO:tensorflow:loss = 8.309783, step = 378400 (0.951 sec)\n",
            "I0509 16:12:16.459094 140437868455744 basic_session_run_hooks.py:263] loss = 8.309783, step = 378400 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.8314\n",
            "I0509 16:12:17.760292 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 76.8314\n",
            "INFO:tensorflow:loss = 6.150447, step = 378500 (1.302 sec)\n",
            "I0509 16:12:17.760672 140437868455744 basic_session_run_hooks.py:263] loss = 6.150447, step = 378500 (1.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 92.7498\n",
            "I0509 16:12:18.838440 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 92.7498\n",
            "INFO:tensorflow:loss = 5.411232, step = 378600 (1.078 sec)\n",
            "I0509 16:12:18.838820 140437868455744 basic_session_run_hooks.py:263] loss = 5.411232, step = 378600 (1.078 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.82\n",
            "I0509 16:12:19.783442 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.82\n",
            "INFO:tensorflow:loss = 5.6804905, step = 378700 (0.945 sec)\n",
            "I0509 16:12:19.783717 140437868455744 basic_session_run_hooks.py:263] loss = 5.6804905, step = 378700 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.285\n",
            "I0509 16:12:20.742370 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.285\n",
            "INFO:tensorflow:loss = 4.966998, step = 378800 (0.959 sec)\n",
            "I0509 16:12:20.742747 140437868455744 basic_session_run_hooks.py:263] loss = 4.966998, step = 378800 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.342\n",
            "I0509 16:12:21.700744 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.342\n",
            "INFO:tensorflow:loss = 6.134664, step = 378900 (0.958 sec)\n",
            "I0509 16:12:21.701141 140437868455744 basic_session_run_hooks.py:263] loss = 6.134664, step = 378900 (0.958 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 379000...\n",
            "I0509 16:12:22.634471 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 379000...\n",
            "INFO:tensorflow:Saving checkpoints for 379000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:12:22.634667 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 379000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 379000...\n",
            "I0509 16:12:22.862478 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 379000...\n",
            "INFO:tensorflow:global_step/sec: 85.1626\n",
            "I0509 16:12:22.874953 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.1626\n",
            "INFO:tensorflow:loss = 6.852208, step = 379000 (1.174 sec)\n",
            "I0509 16:12:22.875297 140437868455744 basic_session_run_hooks.py:263] loss = 6.852208, step = 379000 (1.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.799\n",
            "I0509 16:12:23.847749 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.799\n",
            "INFO:tensorflow:loss = 5.975272, step = 379100 (0.973 sec)\n",
            "I0509 16:12:23.848026 140437868455744 basic_session_run_hooks.py:263] loss = 5.975272, step = 379100 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.997\n",
            "I0509 16:12:24.800184 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.997\n",
            "INFO:tensorflow:loss = 6.856748, step = 379200 (0.953 sec)\n",
            "I0509 16:12:24.800565 140437868455744 basic_session_run_hooks.py:263] loss = 6.856748, step = 379200 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.735\n",
            "I0509 16:12:25.773543 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.735\n",
            "INFO:tensorflow:loss = 3.6351533, step = 379300 (0.973 sec)\n",
            "I0509 16:12:25.773920 140437868455744 basic_session_run_hooks.py:263] loss = 3.6351533, step = 379300 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.829\n",
            "I0509 16:12:26.718458 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.829\n",
            "INFO:tensorflow:loss = 5.765007, step = 379400 (0.945 sec)\n",
            "I0509 16:12:26.719357 140437868455744 basic_session_run_hooks.py:263] loss = 5.765007, step = 379400 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.869\n",
            "I0509 16:12:27.681205 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.869\n",
            "INFO:tensorflow:loss = 6.0355387, step = 379500 (0.962 sec)\n",
            "I0509 16:12:27.681481 140437868455744 basic_session_run_hooks.py:263] loss = 6.0355387, step = 379500 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.2198\n",
            "I0509 16:12:28.882835 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.2198\n",
            "INFO:tensorflow:loss = 6.388091, step = 379600 (1.202 sec)\n",
            "I0509 16:12:28.883201 140437868455744 basic_session_run_hooks.py:263] loss = 6.388091, step = 379600 (1.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.9086\n",
            "I0509 16:12:30.103716 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.9086\n",
            "INFO:tensorflow:loss = 7.6422505, step = 379700 (1.221 sec)\n",
            "I0509 16:12:30.104033 140437868455744 basic_session_run_hooks.py:263] loss = 7.6422505, step = 379700 (1.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.82\n",
            "I0509 16:12:31.066908 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.82\n",
            "INFO:tensorflow:loss = 5.500237, step = 379800 (0.963 sec)\n",
            "I0509 16:12:31.067268 140437868455744 basic_session_run_hooks.py:263] loss = 5.500237, step = 379800 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.39\n",
            "I0509 16:12:32.015763 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.39\n",
            "INFO:tensorflow:loss = 4.388234, step = 379900 (0.949 sec)\n",
            "I0509 16:12:32.016144 140437868455744 basic_session_run_hooks.py:263] loss = 4.388234, step = 379900 (0.949 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 380000...\n",
            "I0509 16:12:32.951591 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 380000...\n",
            "INFO:tensorflow:Saving checkpoints for 380000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:12:32.951787 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 380000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 380000...\n",
            "I0509 16:12:33.171929 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 380000...\n",
            "INFO:tensorflow:global_step/sec: 85.5444\n",
            "I0509 16:12:33.184816 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.5444\n",
            "INFO:tensorflow:loss = 6.2053633, step = 380000 (1.169 sec)\n",
            "I0509 16:12:33.185134 140437868455744 basic_session_run_hooks.py:263] loss = 6.2053633, step = 380000 (1.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.119\n",
            "I0509 16:12:34.154496 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.119\n",
            "INFO:tensorflow:loss = 6.663915, step = 380100 (0.970 sec)\n",
            "I0509 16:12:34.154770 140437868455744 basic_session_run_hooks.py:263] loss = 6.663915, step = 380100 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.141\n",
            "I0509 16:12:35.105611 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.141\n",
            "INFO:tensorflow:loss = 7.0798817, step = 380200 (0.951 sec)\n",
            "I0509 16:12:35.105969 140437868455744 basic_session_run_hooks.py:263] loss = 7.0798817, step = 380200 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.744\n",
            "I0509 16:12:36.051292 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.744\n",
            "INFO:tensorflow:loss = 5.6278133, step = 380300 (0.946 sec)\n",
            "I0509 16:12:36.051693 140437868455744 basic_session_run_hooks.py:263] loss = 5.6278133, step = 380300 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.468\n",
            "I0509 16:12:36.990541 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.468\n",
            "INFO:tensorflow:loss = 7.149228, step = 380400 (0.939 sec)\n",
            "I0509 16:12:36.990947 140437868455744 basic_session_run_hooks.py:263] loss = 7.149228, step = 380400 (0.939 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.383\n",
            "I0509 16:12:37.967265 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.383\n",
            "INFO:tensorflow:loss = 5.8062453, step = 380500 (0.977 sec)\n",
            "I0509 16:12:37.967612 140437868455744 basic_session_run_hooks.py:263] loss = 5.8062453, step = 380500 (0.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.654\n",
            "I0509 16:12:38.932015 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.654\n",
            "INFO:tensorflow:loss = 6.9767222, step = 380600 (0.965 sec)\n",
            "I0509 16:12:38.932311 140437868455744 basic_session_run_hooks.py:263] loss = 6.9767222, step = 380600 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 95.53\n",
            "I0509 16:12:39.978816 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 95.53\n",
            "INFO:tensorflow:loss = 6.674069, step = 380700 (1.047 sec)\n",
            "I0509 16:12:39.979110 140437868455744 basic_session_run_hooks.py:263] loss = 6.674069, step = 380700 (1.047 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.2459\n",
            "I0509 16:12:41.362975 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 72.2459\n",
            "INFO:tensorflow:loss = 7.5133185, step = 380800 (1.384 sec)\n",
            "I0509 16:12:41.363345 140437868455744 basic_session_run_hooks.py:263] loss = 7.5133185, step = 380800 (1.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.133\n",
            "I0509 16:12:42.361631 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.133\n",
            "INFO:tensorflow:loss = 6.6501446, step = 380900 (0.999 sec)\n",
            "I0509 16:12:42.362132 140437868455744 basic_session_run_hooks.py:263] loss = 6.6501446, step = 380900 (0.999 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 381000...\n",
            "I0509 16:12:43.315601 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 381000...\n",
            "INFO:tensorflow:Saving checkpoints for 381000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:12:43.315794 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 381000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 381000...\n",
            "I0509 16:12:43.535049 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 381000...\n",
            "INFO:tensorflow:global_step/sec: 84.3509\n",
            "I0509 16:12:43.547164 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.3509\n",
            "INFO:tensorflow:loss = 6.612732, step = 381000 (1.186 sec)\n",
            "I0509 16:12:43.547784 140437868455744 basic_session_run_hooks.py:263] loss = 6.612732, step = 381000 (1.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.021\n",
            "I0509 16:12:44.517839 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.021\n",
            "INFO:tensorflow:loss = 6.2659736, step = 381100 (0.970 sec)\n",
            "I0509 16:12:44.518139 140437868455744 basic_session_run_hooks.py:263] loss = 6.2659736, step = 381100 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.008\n",
            "I0509 16:12:45.470169 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.008\n",
            "INFO:tensorflow:loss = 6.2425985, step = 381200 (0.952 sec)\n",
            "I0509 16:12:45.470541 140437868455744 basic_session_run_hooks.py:263] loss = 6.2425985, step = 381200 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.742\n",
            "I0509 16:12:46.415841 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.742\n",
            "INFO:tensorflow:loss = 7.122623, step = 381300 (0.946 sec)\n",
            "I0509 16:12:46.416246 140437868455744 basic_session_run_hooks.py:263] loss = 7.122623, step = 381300 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.409\n",
            "I0509 16:12:47.373606 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.409\n",
            "INFO:tensorflow:loss = 5.4958377, step = 381400 (0.958 sec)\n",
            "I0509 16:12:47.373999 140437868455744 basic_session_run_hooks.py:263] loss = 5.4958377, step = 381400 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.624\n",
            "I0509 16:12:48.338639 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.624\n",
            "INFO:tensorflow:loss = 5.5595875, step = 381500 (0.965 sec)\n",
            "I0509 16:12:48.339001 140437868455744 basic_session_run_hooks.py:263] loss = 5.5595875, step = 381500 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.29\n",
            "I0509 16:12:49.297489 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.29\n",
            "INFO:tensorflow:loss = 6.6779294, step = 381600 (0.959 sec)\n",
            "I0509 16:12:49.297869 140437868455744 basic_session_run_hooks.py:263] loss = 6.6779294, step = 381600 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 106\n",
            "I0509 16:12:50.240905 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106\n",
            "INFO:tensorflow:loss = 6.411078, step = 381700 (0.943 sec)\n",
            "I0509 16:12:50.241299 140437868455744 basic_session_run_hooks.py:263] loss = 6.411078, step = 381700 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.827\n",
            "I0509 16:12:51.204039 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.827\n",
            "INFO:tensorflow:loss = 7.7126594, step = 381800 (0.963 sec)\n",
            "I0509 16:12:51.204427 140437868455744 basic_session_run_hooks.py:263] loss = 7.7126594, step = 381800 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.3421\n",
            "I0509 16:12:52.549199 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 74.3421\n",
            "INFO:tensorflow:loss = 5.8479695, step = 381900 (1.348 sec)\n",
            "I0509 16:12:52.552167 140437868455744 basic_session_run_hooks.py:263] loss = 5.8479695, step = 381900 (1.348 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 382000...\n",
            "I0509 16:12:53.621170 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 382000...\n",
            "INFO:tensorflow:Saving checkpoints for 382000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:12:53.621369 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 382000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 382000...\n",
            "I0509 16:12:53.840463 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 382000...\n",
            "INFO:tensorflow:global_step/sec: 76.7186\n",
            "I0509 16:12:53.852616 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 76.7186\n",
            "INFO:tensorflow:loss = 7.4738965, step = 382000 (1.301 sec)\n",
            "I0509 16:12:53.852944 140437868455744 basic_session_run_hooks.py:263] loss = 7.4738965, step = 382000 (1.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.918\n",
            "I0509 16:12:54.805760 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.918\n",
            "INFO:tensorflow:loss = 6.578123, step = 382100 (0.953 sec)\n",
            "I0509 16:12:54.806049 140437868455744 basic_session_run_hooks.py:263] loss = 6.578123, step = 382100 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.919\n",
            "I0509 16:12:55.758877 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.919\n",
            "INFO:tensorflow:loss = 5.381881, step = 382200 (0.953 sec)\n",
            "I0509 16:12:55.759270 140437868455744 basic_session_run_hooks.py:263] loss = 5.381881, step = 382200 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.103\n",
            "I0509 16:12:56.701348 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.103\n",
            "INFO:tensorflow:loss = 4.9419556, step = 382300 (0.942 sec)\n",
            "I0509 16:12:56.701701 140437868455744 basic_session_run_hooks.py:263] loss = 4.9419556, step = 382300 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.504\n",
            "I0509 16:12:57.649201 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.504\n",
            "INFO:tensorflow:loss = 5.738631, step = 382400 (0.948 sec)\n",
            "I0509 16:12:57.649485 140437868455744 basic_session_run_hooks.py:263] loss = 5.738631, step = 382400 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.09\n",
            "I0509 16:12:58.600749 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.09\n",
            "INFO:tensorflow:loss = 5.218671, step = 382500 (0.952 sec)\n",
            "I0509 16:12:58.601029 140437868455744 basic_session_run_hooks.py:263] loss = 5.218671, step = 382500 (0.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.982\n",
            "I0509 16:12:59.571789 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.982\n",
            "INFO:tensorflow:loss = 6.487094, step = 382600 (0.971 sec)\n",
            "I0509 16:12:59.572219 140437868455744 basic_session_run_hooks.py:263] loss = 6.487094, step = 382600 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.431\n",
            "I0509 16:13:00.538625 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.431\n",
            "INFO:tensorflow:loss = 5.6990404, step = 382700 (0.967 sec)\n",
            "I0509 16:13:00.539056 140437868455744 basic_session_run_hooks.py:263] loss = 5.6990404, step = 382700 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.65\n",
            "I0509 16:13:01.503407 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.65\n",
            "INFO:tensorflow:loss = 7.346938, step = 382800 (0.965 sec)\n",
            "I0509 16:13:01.503785 140437868455744 basic_session_run_hooks.py:263] loss = 7.346938, step = 382800 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.667\n",
            "I0509 16:13:02.468022 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.667\n",
            "INFO:tensorflow:loss = 8.213325, step = 382900 (0.965 sec)\n",
            "I0509 16:13:02.468322 140437868455744 basic_session_run_hooks.py:263] loss = 8.213325, step = 382900 (0.965 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 383000...\n",
            "I0509 16:13:03.628537 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 383000...\n",
            "INFO:tensorflow:Saving checkpoints for 383000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:13:03.628746 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 383000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 383000...\n",
            "I0509 16:13:04.012510 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 383000...\n",
            "INFO:tensorflow:global_step/sec: 63.8933\n",
            "I0509 16:13:04.033295 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 63.8933\n",
            "INFO:tensorflow:loss = 7.291751, step = 383000 (1.565 sec)\n",
            "I0509 16:13:04.033635 140437868455744 basic_session_run_hooks.py:263] loss = 7.291751, step = 383000 (1.565 sec)\n",
            "INFO:tensorflow:global_step/sec: 89.7973\n",
            "I0509 16:13:05.146753 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 89.7973\n",
            "INFO:tensorflow:loss = 6.7242084, step = 383100 (1.113 sec)\n",
            "I0509 16:13:05.147119 140437868455744 basic_session_run_hooks.py:263] loss = 6.7242084, step = 383100 (1.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.827\n",
            "I0509 16:13:06.091691 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.827\n",
            "INFO:tensorflow:loss = 6.600453, step = 383200 (0.945 sec)\n",
            "I0509 16:13:06.092077 140437868455744 basic_session_run_hooks.py:263] loss = 6.600453, step = 383200 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.759\n",
            "I0509 16:13:07.064836 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.759\n",
            "INFO:tensorflow:loss = 8.533789, step = 383300 (0.973 sec)\n",
            "I0509 16:13:07.065135 140437868455744 basic_session_run_hooks.py:263] loss = 8.533789, step = 383300 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.683\n",
            "I0509 16:13:08.020109 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.683\n",
            "INFO:tensorflow:loss = 7.118907, step = 383400 (0.955 sec)\n",
            "I0509 16:13:08.020385 140437868455744 basic_session_run_hooks.py:263] loss = 7.118907, step = 383400 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.242\n",
            "I0509 16:13:08.988710 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.242\n",
            "INFO:tensorflow:loss = 6.2828236, step = 383500 (0.969 sec)\n",
            "I0509 16:13:08.989095 140437868455744 basic_session_run_hooks.py:263] loss = 6.2828236, step = 383500 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.187\n",
            "I0509 16:13:09.948523 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.187\n",
            "INFO:tensorflow:loss = 5.8896465, step = 383600 (0.960 sec)\n",
            "I0509 16:13:09.948896 140437868455744 basic_session_run_hooks.py:263] loss = 5.8896465, step = 383600 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.104\n",
            "I0509 16:13:10.909113 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.104\n",
            "INFO:tensorflow:loss = 6.451245, step = 383700 (0.961 sec)\n",
            "I0509 16:13:10.909466 140437868455744 basic_session_run_hooks.py:263] loss = 6.451245, step = 383700 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.797\n",
            "I0509 16:13:11.863334 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.797\n",
            "INFO:tensorflow:loss = 7.927452, step = 383800 (0.954 sec)\n",
            "I0509 16:13:11.863706 140437868455744 basic_session_run_hooks.py:263] loss = 7.927452, step = 383800 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.424\n",
            "I0509 16:13:12.839667 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.424\n",
            "INFO:tensorflow:loss = 6.9710016, step = 383900 (0.976 sec)\n",
            "I0509 16:13:12.840030 140437868455744 basic_session_run_hooks.py:263] loss = 6.9710016, step = 383900 (0.976 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 384000...\n",
            "I0509 16:13:13.790172 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 384000...\n",
            "INFO:tensorflow:Saving checkpoints for 384000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:13:13.790363 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 384000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 384000...\n",
            "I0509 16:13:14.015710 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 384000...\n",
            "INFO:tensorflow:global_step/sec: 84.1638\n",
            "I0509 16:13:14.027819 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.1638\n",
            "INFO:tensorflow:loss = 6.7726536, step = 384000 (1.188 sec)\n",
            "I0509 16:13:14.028185 140437868455744 basic_session_run_hooks.py:263] loss = 6.7726536, step = 384000 (1.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.8987\n",
            "I0509 16:13:15.192001 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.8987\n",
            "INFO:tensorflow:loss = 5.291063, step = 384100 (1.164 sec)\n",
            "I0509 16:13:15.192303 140437868455744 basic_session_run_hooks.py:263] loss = 5.291063, step = 384100 (1.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.2543\n",
            "I0509 16:13:16.453744 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.2543\n",
            "INFO:tensorflow:loss = 6.128942, step = 384200 (1.262 sec)\n",
            "I0509 16:13:16.454140 140437868455744 basic_session_run_hooks.py:263] loss = 6.128942, step = 384200 (1.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.284\n",
            "I0509 16:13:17.394619 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.284\n",
            "INFO:tensorflow:loss = 6.065318, step = 384300 (0.941 sec)\n",
            "I0509 16:13:17.394895 140437868455744 basic_session_run_hooks.py:263] loss = 6.065318, step = 384300 (0.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.877\n",
            "I0509 16:13:18.330282 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.877\n",
            "INFO:tensorflow:loss = 5.5158544, step = 384400 (0.936 sec)\n",
            "I0509 16:13:18.330658 140437868455744 basic_session_run_hooks.py:263] loss = 5.5158544, step = 384400 (0.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.198\n",
            "I0509 16:13:19.299284 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.198\n",
            "INFO:tensorflow:loss = 6.506928, step = 384500 (0.969 sec)\n",
            "I0509 16:13:19.299569 140437868455744 basic_session_run_hooks.py:263] loss = 6.506928, step = 384500 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.63\n",
            "I0509 16:13:20.255041 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.63\n",
            "INFO:tensorflow:loss = 7.1579175, step = 384600 (0.956 sec)\n",
            "I0509 16:13:20.255339 140437868455744 basic_session_run_hooks.py:263] loss = 7.1579175, step = 384600 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.369\n",
            "I0509 16:13:21.213188 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.369\n",
            "INFO:tensorflow:loss = 6.3912926, step = 384700 (0.958 sec)\n",
            "I0509 16:13:21.213566 140437868455744 basic_session_run_hooks.py:263] loss = 6.3912926, step = 384700 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.28\n",
            "I0509 16:13:22.181424 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.28\n",
            "INFO:tensorflow:loss = 6.7471447, step = 384800 (0.968 sec)\n",
            "I0509 16:13:22.181823 140437868455744 basic_session_run_hooks.py:263] loss = 6.7471447, step = 384800 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.463\n",
            "I0509 16:13:23.138673 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.463\n",
            "INFO:tensorflow:loss = 6.810164, step = 384900 (0.957 sec)\n",
            "I0509 16:13:23.139046 140437868455744 basic_session_run_hooks.py:263] loss = 6.810164, step = 384900 (0.957 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 385000...\n",
            "I0509 16:13:24.092601 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 385000...\n",
            "INFO:tensorflow:Saving checkpoints for 385000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:13:24.092791 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 385000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 385000...\n",
            "I0509 16:13:24.314443 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 385000...\n",
            "INFO:tensorflow:global_step/sec: 83.4713\n",
            "I0509 16:13:24.336696 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.4713\n",
            "INFO:tensorflow:loss = 6.4065104, step = 385000 (1.198 sec)\n",
            "I0509 16:13:24.336965 140437868455744 basic_session_run_hooks.py:263] loss = 6.4065104, step = 385000 (1.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.668\n",
            "I0509 16:13:25.292120 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.668\n",
            "INFO:tensorflow:loss = 8.036244, step = 385100 (0.956 sec)\n",
            "I0509 16:13:25.292510 140437868455744 basic_session_run_hooks.py:263] loss = 8.036244, step = 385100 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.393\n",
            "I0509 16:13:26.288226 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.393\n",
            "INFO:tensorflow:loss = 7.355138, step = 385200 (0.996 sec)\n",
            "I0509 16:13:26.288619 140437868455744 basic_session_run_hooks.py:263] loss = 7.355138, step = 385200 (0.996 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.8006\n",
            "I0509 16:13:27.661810 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 72.8006\n",
            "INFO:tensorflow:loss = 6.337861, step = 385300 (1.374 sec)\n",
            "I0509 16:13:27.662208 140437868455744 basic_session_run_hooks.py:263] loss = 6.337861, step = 385300 (1.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.078\n",
            "I0509 16:13:28.604516 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.078\n",
            "INFO:tensorflow:loss = 5.857781, step = 385400 (0.943 sec)\n",
            "I0509 16:13:28.604886 140437868455744 basic_session_run_hooks.py:263] loss = 5.857781, step = 385400 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.055\n",
            "I0509 16:13:29.574868 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.055\n",
            "INFO:tensorflow:loss = 5.9450064, step = 385500 (0.970 sec)\n",
            "I0509 16:13:29.575184 140437868455744 basic_session_run_hooks.py:263] loss = 5.9450064, step = 385500 (0.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.724\n",
            "I0509 16:13:30.529755 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.724\n",
            "INFO:tensorflow:loss = 7.649673, step = 385600 (0.955 sec)\n",
            "I0509 16:13:30.530145 140437868455744 basic_session_run_hooks.py:263] loss = 7.649673, step = 385600 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.626\n",
            "I0509 16:13:31.513753 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.626\n",
            "INFO:tensorflow:loss = 5.967006, step = 385700 (0.984 sec)\n",
            "I0509 16:13:31.514143 140437868455744 basic_session_run_hooks.py:263] loss = 5.967006, step = 385700 (0.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.685\n",
            "I0509 16:13:32.469031 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.685\n",
            "INFO:tensorflow:loss = 5.2535343, step = 385800 (0.955 sec)\n",
            "I0509 16:13:32.469428 140437868455744 basic_session_run_hooks.py:263] loss = 5.2535343, step = 385800 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.976\n",
            "I0509 16:13:33.421587 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.976\n",
            "INFO:tensorflow:loss = 7.563788, step = 385900 (0.953 sec)\n",
            "I0509 16:13:33.421961 140437868455744 basic_session_run_hooks.py:263] loss = 7.563788, step = 385900 (0.953 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 386000...\n",
            "I0509 16:13:34.350844 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 386000...\n",
            "INFO:tensorflow:Saving checkpoints for 386000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:13:34.351047 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 386000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 386000...\n",
            "I0509 16:13:34.557760 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 386000...\n",
            "INFO:tensorflow:global_step/sec: 87.0895\n",
            "I0509 16:13:34.569823 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.0895\n",
            "INFO:tensorflow:loss = 4.7425733, step = 386000 (1.148 sec)\n",
            "I0509 16:13:34.570177 140437868455744 basic_session_run_hooks.py:263] loss = 4.7425733, step = 386000 (1.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.902\n",
            "I0509 16:13:35.551189 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.902\n",
            "INFO:tensorflow:loss = 4.8767195, step = 386100 (0.981 sec)\n",
            "I0509 16:13:35.551563 140437868455744 basic_session_run_hooks.py:263] loss = 4.8767195, step = 386100 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.671\n",
            "I0509 16:13:36.497503 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.671\n",
            "INFO:tensorflow:loss = 6.3306746, step = 386200 (0.946 sec)\n",
            "I0509 16:13:36.497916 140437868455744 basic_session_run_hooks.py:263] loss = 6.3306746, step = 386200 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.698\n",
            "I0509 16:13:37.452633 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.698\n",
            "INFO:tensorflow:loss = 6.6849895, step = 386300 (0.955 sec)\n",
            "I0509 16:13:37.453028 140437868455744 basic_session_run_hooks.py:263] loss = 6.6849895, step = 386300 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.1117\n",
            "I0509 16:13:38.749471 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.1117\n",
            "INFO:tensorflow:loss = 5.60907, step = 386400 (1.297 sec)\n",
            "I0509 16:13:38.749765 140437868455744 basic_session_run_hooks.py:263] loss = 5.60907, step = 386400 (1.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 90.5479\n",
            "I0509 16:13:39.853882 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 90.5479\n",
            "INFO:tensorflow:loss = 5.41472, step = 386500 (1.105 sec)\n",
            "I0509 16:13:39.854269 140437868455744 basic_session_run_hooks.py:263] loss = 5.41472, step = 386500 (1.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.053\n",
            "I0509 16:13:40.814908 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.053\n",
            "INFO:tensorflow:loss = 7.3450227, step = 386600 (0.961 sec)\n",
            "I0509 16:13:40.815333 140437868455744 basic_session_run_hooks.py:263] loss = 7.3450227, step = 386600 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.356\n",
            "I0509 16:13:41.755159 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.356\n",
            "INFO:tensorflow:loss = 6.887487, step = 386700 (0.940 sec)\n",
            "I0509 16:13:41.755454 140437868455744 basic_session_run_hooks.py:263] loss = 6.887487, step = 386700 (0.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.7\n",
            "I0509 16:13:42.738420 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.7\n",
            "INFO:tensorflow:loss = 4.822032, step = 386800 (0.983 sec)\n",
            "I0509 16:13:42.738789 140437868455744 basic_session_run_hooks.py:263] loss = 4.822032, step = 386800 (0.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.249\n",
            "I0509 16:13:43.688534 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.249\n",
            "INFO:tensorflow:loss = 5.8813024, step = 386900 (0.950 sec)\n",
            "I0509 16:13:43.688956 140437868455744 basic_session_run_hooks.py:263] loss = 5.8813024, step = 386900 (0.950 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 387000...\n",
            "I0509 16:13:44.629007 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 387000...\n",
            "INFO:tensorflow:Saving checkpoints for 387000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:13:44.629229 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 387000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 387000...\n",
            "I0509 16:13:44.834926 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 387000...\n",
            "INFO:tensorflow:global_step/sec: 86.2599\n",
            "I0509 16:13:44.847815 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 86.2599\n",
            "INFO:tensorflow:loss = 6.3274097, step = 387000 (1.159 sec)\n",
            "I0509 16:13:44.848127 140437868455744 basic_session_run_hooks.py:263] loss = 6.3274097, step = 387000 (1.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.745\n",
            "I0509 16:13:45.821113 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.745\n",
            "INFO:tensorflow:loss = 7.826784, step = 387100 (0.973 sec)\n",
            "I0509 16:13:45.821501 140437868455744 basic_session_run_hooks.py:263] loss = 7.826784, step = 387100 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.306\n",
            "I0509 16:13:46.770722 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.306\n",
            "INFO:tensorflow:loss = 6.9089317, step = 387200 (0.950 sec)\n",
            "I0509 16:13:46.771121 140437868455744 basic_session_run_hooks.py:263] loss = 6.9089317, step = 387200 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.008\n",
            "I0509 16:13:47.732194 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.008\n",
            "INFO:tensorflow:loss = 7.674763, step = 387300 (0.961 sec)\n",
            "I0509 16:13:47.732552 140437868455744 basic_session_run_hooks.py:263] loss = 7.674763, step = 387300 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.307\n",
            "I0509 16:13:48.700186 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.307\n",
            "INFO:tensorflow:loss = 7.1563926, step = 387400 (0.968 sec)\n",
            "I0509 16:13:48.700561 140437868455744 basic_session_run_hooks.py:263] loss = 7.1563926, step = 387400 (0.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 89.2442\n",
            "I0509 16:13:49.820700 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 89.2442\n",
            "INFO:tensorflow:loss = 6.794425, step = 387500 (1.120 sec)\n",
            "I0509 16:13:49.820999 140437868455744 basic_session_run_hooks.py:263] loss = 6.794425, step = 387500 (1.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.2145\n",
            "I0509 16:13:51.115786 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.2145\n",
            "INFO:tensorflow:loss = 8.440698, step = 387600 (1.295 sec)\n",
            "I0509 16:13:51.116179 140437868455744 basic_session_run_hooks.py:263] loss = 8.440698, step = 387600 (1.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.339\n",
            "I0509 16:13:52.074223 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.339\n",
            "INFO:tensorflow:loss = 6.5723505, step = 387700 (0.959 sec)\n",
            "I0509 16:13:52.074832 140437868455744 basic_session_run_hooks.py:263] loss = 6.5723505, step = 387700 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.837\n",
            "I0509 16:13:53.028075 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.837\n",
            "INFO:tensorflow:loss = 8.5501175, step = 387800 (0.954 sec)\n",
            "I0509 16:13:53.028440 140437868455744 basic_session_run_hooks.py:263] loss = 8.5501175, step = 387800 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.714\n",
            "I0509 16:13:53.983040 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.714\n",
            "INFO:tensorflow:loss = 6.6132884, step = 387900 (0.955 sec)\n",
            "I0509 16:13:53.983454 140437868455744 basic_session_run_hooks.py:263] loss = 6.6132884, step = 387900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 388000...\n",
            "I0509 16:13:54.933217 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 388000...\n",
            "INFO:tensorflow:Saving checkpoints for 388000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:13:54.933411 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 388000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 388000...\n",
            "I0509 16:13:55.148384 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 388000...\n",
            "INFO:tensorflow:global_step/sec: 84.936\n",
            "I0509 16:13:55.160380 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.936\n",
            "INFO:tensorflow:loss = 6.769064, step = 388000 (1.177 sec)\n",
            "I0509 16:13:55.160626 140437868455744 basic_session_run_hooks.py:263] loss = 6.769064, step = 388000 (1.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.875\n",
            "I0509 16:13:56.113938 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.875\n",
            "INFO:tensorflow:loss = 6.198133, step = 388100 (0.954 sec)\n",
            "I0509 16:13:56.114321 140437868455744 basic_session_run_hooks.py:263] loss = 6.198133, step = 388100 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.9\n",
            "I0509 16:13:57.058209 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.9\n",
            "INFO:tensorflow:loss = 6.9257655, step = 388200 (0.944 sec)\n",
            "I0509 16:13:57.058586 140437868455744 basic_session_run_hooks.py:263] loss = 6.9257655, step = 388200 (0.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.189\n",
            "I0509 16:13:58.017990 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.189\n",
            "INFO:tensorflow:loss = 4.8887696, step = 388300 (0.960 sec)\n",
            "I0509 16:13:58.018345 140437868455744 basic_session_run_hooks.py:263] loss = 4.8887696, step = 388300 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.522\n",
            "I0509 16:13:58.974730 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.522\n",
            "INFO:tensorflow:loss = 7.7347627, step = 388400 (0.957 sec)\n",
            "I0509 16:13:58.975113 140437868455744 basic_session_run_hooks.py:263] loss = 7.7347627, step = 388400 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.284\n",
            "I0509 16:13:59.952407 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.284\n",
            "INFO:tensorflow:loss = 9.115722, step = 388500 (0.978 sec)\n",
            "I0509 16:13:59.952771 140437868455744 basic_session_run_hooks.py:263] loss = 9.115722, step = 388500 (0.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.424\n",
            "I0509 16:14:00.948205 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.424\n",
            "INFO:tensorflow:loss = 6.57572, step = 388600 (0.996 sec)\n",
            "I0509 16:14:00.948513 140437868455744 basic_session_run_hooks.py:263] loss = 6.57572, step = 388600 (0.996 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.8025\n",
            "I0509 16:14:02.380816 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 69.8025\n",
            "INFO:tensorflow:loss = 7.0609736, step = 388700 (1.433 sec)\n",
            "I0509 16:14:02.381153 140437868455744 basic_session_run_hooks.py:263] loss = 7.0609736, step = 388700 (1.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.706\n",
            "I0509 16:14:03.373771 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.706\n",
            "INFO:tensorflow:loss = 5.4003034, step = 388800 (0.993 sec)\n",
            "I0509 16:14:03.374079 140437868455744 basic_session_run_hooks.py:263] loss = 5.4003034, step = 388800 (0.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.979\n",
            "I0509 16:14:04.326357 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.979\n",
            "INFO:tensorflow:loss = 5.936368, step = 388900 (0.953 sec)\n",
            "I0509 16:14:04.326736 140437868455744 basic_session_run_hooks.py:263] loss = 5.936368, step = 388900 (0.953 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 389000...\n",
            "I0509 16:14:05.276094 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 389000...\n",
            "INFO:tensorflow:Saving checkpoints for 389000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:14:05.276288 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 389000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 389000...\n",
            "I0509 16:14:05.538535 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 389000...\n",
            "INFO:tensorflow:global_step/sec: 81.6718\n",
            "I0509 16:14:05.550740 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 81.6718\n",
            "INFO:tensorflow:loss = 7.8394074, step = 389000 (1.224 sec)\n",
            "I0509 16:14:05.551091 140437868455744 basic_session_run_hooks.py:263] loss = 7.8394074, step = 389000 (1.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.842\n",
            "I0509 16:14:06.504565 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.842\n",
            "INFO:tensorflow:loss = 5.5368247, step = 389100 (0.954 sec)\n",
            "I0509 16:14:06.504940 140437868455744 basic_session_run_hooks.py:263] loss = 5.5368247, step = 389100 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.26\n",
            "I0509 16:14:07.463715 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.26\n",
            "INFO:tensorflow:loss = 8.570874, step = 389200 (0.959 sec)\n",
            "I0509 16:14:07.464102 140437868455744 basic_session_run_hooks.py:263] loss = 8.570874, step = 389200 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.342\n",
            "I0509 16:14:08.413004 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.342\n",
            "INFO:tensorflow:loss = 5.207235, step = 389300 (0.950 sec)\n",
            "I0509 16:14:08.413867 140437868455744 basic_session_run_hooks.py:263] loss = 5.207235, step = 389300 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 107.419\n",
            "I0509 16:14:09.343913 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 107.419\n",
            "INFO:tensorflow:loss = 7.6162415, step = 389400 (0.930 sec)\n",
            "I0509 16:14:09.344269 140437868455744 basic_session_run_hooks.py:263] loss = 7.6162415, step = 389400 (0.930 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.094\n",
            "I0509 16:14:10.286487 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.094\n",
            "INFO:tensorflow:loss = 7.3400793, step = 389500 (0.943 sec)\n",
            "I0509 16:14:10.286833 140437868455744 basic_session_run_hooks.py:263] loss = 7.3400793, step = 389500 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.792\n",
            "I0509 16:14:11.268882 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.792\n",
            "INFO:tensorflow:loss = 6.52019, step = 389600 (0.982 sec)\n",
            "I0509 16:14:11.269257 140437868455744 basic_session_run_hooks.py:263] loss = 6.52019, step = 389600 (0.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.519\n",
            "I0509 16:14:12.225638 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.519\n",
            "INFO:tensorflow:loss = 6.6467505, step = 389700 (0.957 sec)\n",
            "I0509 16:14:12.225999 140437868455744 basic_session_run_hooks.py:263] loss = 6.6467505, step = 389700 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.3899\n",
            "I0509 16:14:13.501329 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 78.3899\n",
            "INFO:tensorflow:loss = 7.330444, step = 389800 (1.276 sec)\n",
            "I0509 16:14:13.501712 140437868455744 basic_session_run_hooks.py:263] loss = 7.330444, step = 389800 (1.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 88.8203\n",
            "I0509 16:14:14.627208 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 88.8203\n",
            "INFO:tensorflow:loss = 5.3967476, step = 389900 (1.126 sec)\n",
            "I0509 16:14:14.627631 140437868455744 basic_session_run_hooks.py:263] loss = 5.3967476, step = 389900 (1.126 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 390000...\n",
            "I0509 16:14:15.573446 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 390000...\n",
            "INFO:tensorflow:Saving checkpoints for 390000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:14:15.573632 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 390000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 390000...\n",
            "I0509 16:14:15.789155 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 390000...\n",
            "INFO:tensorflow:global_step/sec: 85.1789\n",
            "I0509 16:14:15.801185 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.1789\n",
            "INFO:tensorflow:loss = 5.230021, step = 390000 (1.174 sec)\n",
            "I0509 16:14:15.801430 140437868455744 basic_session_run_hooks.py:263] loss = 5.230021, step = 390000 (1.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.08\n",
            "I0509 16:14:16.761989 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.08\n",
            "INFO:tensorflow:loss = 6.529171, step = 390100 (0.961 sec)\n",
            "I0509 16:14:16.762286 140437868455744 basic_session_run_hooks.py:263] loss = 6.529171, step = 390100 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.501\n",
            "I0509 16:14:17.728169 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.501\n",
            "INFO:tensorflow:loss = 6.260972, step = 390200 (0.966 sec)\n",
            "I0509 16:14:17.728461 140437868455744 basic_session_run_hooks.py:263] loss = 6.260972, step = 390200 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.329\n",
            "I0509 16:14:18.686669 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.329\n",
            "INFO:tensorflow:loss = 6.054336, step = 390300 (0.958 sec)\n",
            "I0509 16:14:18.686948 140437868455744 basic_session_run_hooks.py:263] loss = 6.054336, step = 390300 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.001\n",
            "I0509 16:14:19.648219 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.001\n",
            "INFO:tensorflow:loss = 6.1382585, step = 390400 (0.962 sec)\n",
            "I0509 16:14:19.648502 140437868455744 basic_session_run_hooks.py:263] loss = 6.1382585, step = 390400 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.687\n",
            "I0509 16:14:20.585524 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.687\n",
            "INFO:tensorflow:loss = 5.897769, step = 390500 (0.937 sec)\n",
            "I0509 16:14:20.585806 140437868455744 basic_session_run_hooks.py:263] loss = 5.897769, step = 390500 (0.937 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.525\n",
            "I0509 16:14:21.551476 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.525\n",
            "INFO:tensorflow:loss = 7.854134, step = 390600 (0.966 sec)\n",
            "I0509 16:14:21.551736 140437868455744 basic_session_run_hooks.py:263] loss = 7.854134, step = 390600 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.216\n",
            "I0509 16:14:22.501909 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.216\n",
            "INFO:tensorflow:loss = 5.572639, step = 390700 (0.950 sec)\n",
            "I0509 16:14:22.502201 140437868455744 basic_session_run_hooks.py:263] loss = 5.572639, step = 390700 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.558\n",
            "I0509 16:14:23.458312 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.558\n",
            "INFO:tensorflow:loss = 7.322741, step = 390800 (0.956 sec)\n",
            "I0509 16:14:23.458697 140437868455744 basic_session_run_hooks.py:263] loss = 7.322741, step = 390800 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.3232\n",
            "I0509 16:14:24.630334 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.3232\n",
            "INFO:tensorflow:loss = 5.417076, step = 390900 (1.172 sec)\n",
            "I0509 16:14:24.630625 140437868455744 basic_session_run_hooks.py:263] loss = 5.417076, step = 390900 (1.172 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 391000...\n",
            "I0509 16:14:25.876995 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 391000...\n",
            "INFO:tensorflow:Saving checkpoints for 391000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:14:25.877219 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 391000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 391000...\n",
            "I0509 16:14:26.084431 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 391000...\n",
            "INFO:tensorflow:global_step/sec: 68.2128\n",
            "I0509 16:14:26.096309 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 68.2128\n",
            "INFO:tensorflow:loss = 6.573403, step = 391000 (1.466 sec)\n",
            "I0509 16:14:26.096582 140437868455744 basic_session_run_hooks.py:263] loss = 6.573403, step = 391000 (1.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.305\n",
            "I0509 16:14:27.055121 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.305\n",
            "INFO:tensorflow:loss = 5.962659, step = 391100 (0.959 sec)\n",
            "I0509 16:14:27.055412 140437868455744 basic_session_run_hooks.py:263] loss = 5.962659, step = 391100 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.936\n",
            "I0509 16:14:28.017285 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.936\n",
            "INFO:tensorflow:loss = 4.816028, step = 391200 (0.962 sec)\n",
            "I0509 16:14:28.017667 140437868455744 basic_session_run_hooks.py:263] loss = 4.816028, step = 391200 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.902\n",
            "I0509 16:14:28.979632 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.902\n",
            "INFO:tensorflow:loss = 6.8047957, step = 391300 (0.962 sec)\n",
            "I0509 16:14:28.980040 140437868455744 basic_session_run_hooks.py:263] loss = 6.8047957, step = 391300 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.356\n",
            "I0509 16:14:29.966251 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.356\n",
            "INFO:tensorflow:loss = 7.04397, step = 391400 (0.987 sec)\n",
            "I0509 16:14:29.966621 140437868455744 basic_session_run_hooks.py:263] loss = 7.04397, step = 391400 (0.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.826\n",
            "I0509 16:14:30.929406 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.826\n",
            "INFO:tensorflow:loss = 6.533844, step = 391500 (0.963 sec)\n",
            "I0509 16:14:30.929761 140437868455744 basic_session_run_hooks.py:263] loss = 6.533844, step = 391500 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.587\n",
            "I0509 16:14:31.904240 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.587\n",
            "INFO:tensorflow:loss = 4.9253354, step = 391600 (0.975 sec)\n",
            "I0509 16:14:31.904616 140437868455744 basic_session_run_hooks.py:263] loss = 4.9253354, step = 391600 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.573\n",
            "I0509 16:14:32.860483 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.573\n",
            "INFO:tensorflow:loss = 6.546696, step = 391700 (0.956 sec)\n",
            "I0509 16:14:32.860788 140437868455744 basic_session_run_hooks.py:263] loss = 6.546696, step = 391700 (0.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.733\n",
            "I0509 16:14:33.824462 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.733\n",
            "INFO:tensorflow:loss = 6.326336, step = 391800 (0.964 sec)\n",
            "I0509 16:14:33.824813 140437868455744 basic_session_run_hooks.py:263] loss = 6.326336, step = 391800 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.002\n",
            "I0509 16:14:34.785991 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.002\n",
            "INFO:tensorflow:loss = 6.9198956, step = 391900 (0.962 sec)\n",
            "I0509 16:14:34.786349 140437868455744 basic_session_run_hooks.py:263] loss = 6.9198956, step = 391900 (0.962 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 392000...\n",
            "I0509 16:14:35.800501 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 392000...\n",
            "INFO:tensorflow:Saving checkpoints for 392000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:14:35.800721 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 392000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 392000...\n",
            "I0509 16:14:36.204988 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 392000...\n",
            "INFO:tensorflow:global_step/sec: 69.5959\n",
            "I0509 16:14:36.222865 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 69.5959\n",
            "INFO:tensorflow:loss = 6.352465, step = 392000 (1.437 sec)\n",
            "I0509 16:14:36.223221 140437868455744 basic_session_run_hooks.py:263] loss = 6.352465, step = 392000 (1.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.0466\n",
            "I0509 16:14:37.520763 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.0466\n",
            "INFO:tensorflow:loss = 6.270983, step = 392100 (1.298 sec)\n",
            "I0509 16:14:37.521150 140437868455744 basic_session_run_hooks.py:263] loss = 6.270983, step = 392100 (1.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.538\n",
            "I0509 16:14:38.477370 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.538\n",
            "INFO:tensorflow:loss = 7.439315, step = 392200 (0.957 sec)\n",
            "I0509 16:14:38.477730 140437868455744 basic_session_run_hooks.py:263] loss = 7.439315, step = 392200 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.535\n",
            "I0509 16:14:39.433979 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.535\n",
            "INFO:tensorflow:loss = 5.3723335, step = 392300 (0.957 sec)\n",
            "I0509 16:14:39.434358 140437868455744 basic_session_run_hooks.py:263] loss = 5.3723335, step = 392300 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.97\n",
            "I0509 16:14:40.395792 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.97\n",
            "INFO:tensorflow:loss = 6.5530844, step = 392400 (0.962 sec)\n",
            "I0509 16:14:40.396178 140437868455744 basic_session_run_hooks.py:263] loss = 6.5530844, step = 392400 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.3691\n",
            "I0509 16:14:41.402153 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.3691\n",
            "INFO:tensorflow:loss = 6.367958, step = 392500 (1.006 sec)\n",
            "I0509 16:14:41.402446 140437868455744 basic_session_run_hooks.py:263] loss = 6.367958, step = 392500 (1.006 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.154\n",
            "I0509 16:14:42.400616 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 100.154\n",
            "INFO:tensorflow:loss = 6.62377, step = 392600 (0.998 sec)\n",
            "I0509 16:14:42.400910 140437868455744 basic_session_run_hooks.py:263] loss = 6.62377, step = 392600 (0.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.096\n",
            "I0509 16:14:43.361264 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.096\n",
            "INFO:tensorflow:loss = 6.5627947, step = 392700 (0.961 sec)\n",
            "I0509 16:14:43.361639 140437868455744 basic_session_run_hooks.py:263] loss = 6.5627947, step = 392700 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.547\n",
            "I0509 16:14:44.308700 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.547\n",
            "INFO:tensorflow:loss = 5.0348487, step = 392800 (0.947 sec)\n",
            "I0509 16:14:44.309089 140437868455744 basic_session_run_hooks.py:263] loss = 5.0348487, step = 392800 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.72\n",
            "I0509 16:14:45.263623 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.72\n",
            "INFO:tensorflow:loss = 6.708447, step = 392900 (0.955 sec)\n",
            "I0509 16:14:45.263901 140437868455744 basic_session_run_hooks.py:263] loss = 6.708447, step = 392900 (0.955 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 393000...\n",
            "I0509 16:14:46.212813 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 393000...\n",
            "INFO:tensorflow:Saving checkpoints for 393000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:14:46.213009 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 393000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 393000...\n",
            "I0509 16:14:46.444299 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 393000...\n",
            "INFO:tensorflow:global_step/sec: 83.8226\n",
            "I0509 16:14:46.456609 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.8226\n",
            "INFO:tensorflow:loss = 5.8719487, step = 393000 (1.193 sec)\n",
            "I0509 16:14:46.456855 140437868455744 basic_session_run_hooks.py:263] loss = 5.8719487, step = 393000 (1.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.1754\n",
            "I0509 16:14:47.485701 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 97.1754\n",
            "INFO:tensorflow:loss = 8.128713, step = 393100 (1.029 sec)\n",
            "I0509 16:14:47.486087 140437868455744 basic_session_run_hooks.py:263] loss = 8.128713, step = 393100 (1.029 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.0987\n",
            "I0509 16:14:48.835246 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 74.0987\n",
            "INFO:tensorflow:loss = 7.3365817, step = 393200 (1.350 sec)\n",
            "I0509 16:14:48.835632 140437868455744 basic_session_run_hooks.py:263] loss = 7.3365817, step = 393200 (1.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.899\n",
            "I0509 16:14:49.788536 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.899\n",
            "INFO:tensorflow:loss = 6.9293466, step = 393300 (0.953 sec)\n",
            "I0509 16:14:49.788898 140437868455744 basic_session_run_hooks.py:263] loss = 6.9293466, step = 393300 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.577\n",
            "I0509 16:14:50.735728 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.577\n",
            "INFO:tensorflow:loss = 7.9973264, step = 393400 (0.947 sec)\n",
            "I0509 16:14:50.736133 140437868455744 basic_session_run_hooks.py:263] loss = 7.9973264, step = 393400 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.953\n",
            "I0509 16:14:51.707040 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.953\n",
            "INFO:tensorflow:loss = 5.658688, step = 393500 (0.971 sec)\n",
            "I0509 16:14:51.707423 140437868455744 basic_session_run_hooks.py:263] loss = 5.658688, step = 393500 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.534\n",
            "I0509 16:14:52.672902 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.534\n",
            "INFO:tensorflow:loss = 6.908596, step = 393600 (0.966 sec)\n",
            "I0509 16:14:52.673298 140437868455744 basic_session_run_hooks.py:263] loss = 6.908596, step = 393600 (0.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.583\n",
            "I0509 16:14:53.638314 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.583\n",
            "INFO:tensorflow:loss = 7.4723096, step = 393700 (0.965 sec)\n",
            "I0509 16:14:53.638591 140437868455744 basic_session_run_hooks.py:263] loss = 7.4723096, step = 393700 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.688\n",
            "I0509 16:14:54.602751 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.688\n",
            "INFO:tensorflow:loss = 6.211607, step = 393800 (0.965 sec)\n",
            "I0509 16:14:54.603257 140437868455744 basic_session_run_hooks.py:263] loss = 6.211607, step = 393800 (0.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.539\n",
            "I0509 16:14:55.541373 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.539\n",
            "INFO:tensorflow:loss = 6.3291802, step = 393900 (0.938 sec)\n",
            "I0509 16:14:55.541742 140437868455744 basic_session_run_hooks.py:263] loss = 6.3291802, step = 393900 (0.938 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 394000...\n",
            "I0509 16:14:56.471885 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 394000...\n",
            "INFO:tensorflow:Saving checkpoints for 394000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:14:56.472098 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 394000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 394000...\n",
            "I0509 16:14:56.699136 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 394000...\n",
            "INFO:tensorflow:global_step/sec: 85.0268\n",
            "I0509 16:14:56.717458 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.0268\n",
            "INFO:tensorflow:loss = 5.810744, step = 394000 (1.176 sec)\n",
            "I0509 16:14:56.717783 140437868455744 basic_session_run_hooks.py:263] loss = 5.810744, step = 394000 (1.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.253\n",
            "I0509 16:14:57.667561 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.253\n",
            "INFO:tensorflow:loss = 6.4079556, step = 394100 (0.950 sec)\n",
            "I0509 16:14:57.667927 140437868455744 basic_session_run_hooks.py:263] loss = 6.4079556, step = 394100 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.583\n",
            "I0509 16:14:58.614676 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.583\n",
            "INFO:tensorflow:loss = 5.7398195, step = 394200 (0.947 sec)\n",
            "I0509 16:14:58.615043 140437868455744 basic_session_run_hooks.py:263] loss = 5.7398195, step = 394200 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.2828\n",
            "I0509 16:14:59.925609 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 76.2828\n",
            "INFO:tensorflow:loss = 5.2442594, step = 394300 (1.311 sec)\n",
            "I0509 16:14:59.925930 140437868455744 basic_session_run_hooks.py:263] loss = 5.2442594, step = 394300 (1.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 90.1823\n",
            "I0509 16:15:01.034471 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 90.1823\n",
            "INFO:tensorflow:loss = 7.953999, step = 394400 (1.109 sec)\n",
            "I0509 16:15:01.034854 140437868455744 basic_session_run_hooks.py:263] loss = 7.953999, step = 394400 (1.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.827\n",
            "I0509 16:15:01.997605 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.827\n",
            "INFO:tensorflow:loss = 7.8001676, step = 394500 (0.963 sec)\n",
            "I0509 16:15:01.997983 140437868455744 basic_session_run_hooks.py:263] loss = 7.8001676, step = 394500 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.967\n",
            "I0509 16:15:02.950270 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.967\n",
            "INFO:tensorflow:loss = 4.442348, step = 394600 (0.953 sec)\n",
            "I0509 16:15:02.950665 140437868455744 basic_session_run_hooks.py:263] loss = 4.442348, step = 394600 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.772\n",
            "I0509 16:15:03.895701 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.772\n",
            "INFO:tensorflow:loss = 6.5959525, step = 394700 (0.945 sec)\n",
            "I0509 16:15:03.895977 140437868455744 basic_session_run_hooks.py:263] loss = 6.5959525, step = 394700 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.994\n",
            "I0509 16:15:04.857297 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.994\n",
            "INFO:tensorflow:loss = 5.333361, step = 394800 (0.962 sec)\n",
            "I0509 16:15:04.857569 140437868455744 basic_session_run_hooks.py:263] loss = 5.333361, step = 394800 (0.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.027\n",
            "I0509 16:15:05.827913 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.027\n",
            "INFO:tensorflow:loss = 7.603548, step = 394900 (0.971 sec)\n",
            "I0509 16:15:05.828190 140437868455744 basic_session_run_hooks.py:263] loss = 7.603548, step = 394900 (0.971 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 395000...\n",
            "I0509 16:15:06.772495 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 395000...\n",
            "INFO:tensorflow:Saving checkpoints for 395000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:15:06.772687 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 395000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 395000...\n",
            "I0509 16:15:06.982880 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 395000...\n",
            "INFO:tensorflow:global_step/sec: 85.536\n",
            "I0509 16:15:06.997001 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.536\n",
            "INFO:tensorflow:loss = 6.7473884, step = 395000 (1.169 sec)\n",
            "I0509 16:15:06.997356 140437868455744 basic_session_run_hooks.py:263] loss = 6.7473884, step = 395000 (1.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.394\n",
            "I0509 16:15:07.945841 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.394\n",
            "INFO:tensorflow:loss = 5.915073, step = 395100 (0.949 sec)\n",
            "I0509 16:15:07.946141 140437868455744 basic_session_run_hooks.py:263] loss = 5.915073, step = 395100 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.893\n",
            "I0509 16:15:08.899208 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.893\n",
            "INFO:tensorflow:loss = 8.438287, step = 395200 (0.953 sec)\n",
            "I0509 16:15:08.899587 140437868455744 basic_session_run_hooks.py:263] loss = 8.438287, step = 395200 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.741\n",
            "I0509 16:15:09.844910 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.741\n",
            "INFO:tensorflow:loss = 7.8829637, step = 395300 (0.946 sec)\n",
            "I0509 16:15:09.845282 140437868455744 basic_session_run_hooks.py:263] loss = 7.8829637, step = 395300 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 87.1161\n",
            "I0509 16:15:10.992799 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 87.1161\n",
            "INFO:tensorflow:loss = 6.124495, step = 395400 (1.148 sec)\n",
            "I0509 16:15:10.993103 140437868455744 basic_session_run_hooks.py:263] loss = 6.124495, step = 395400 (1.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.5178\n",
            "I0509 16:15:12.250373 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 79.5178\n",
            "INFO:tensorflow:loss = 6.206526, step = 395500 (1.258 sec)\n",
            "I0509 16:15:12.250751 140437868455744 basic_session_run_hooks.py:263] loss = 6.206526, step = 395500 (1.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.801\n",
            "I0509 16:15:13.195538 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.801\n",
            "INFO:tensorflow:loss = 5.160407, step = 395600 (0.945 sec)\n",
            "I0509 16:15:13.195851 140437868455744 basic_session_run_hooks.py:263] loss = 5.160407, step = 395600 (0.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.777\n",
            "I0509 16:15:14.159158 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.777\n",
            "INFO:tensorflow:loss = 6.5290728, step = 395700 (0.964 sec)\n",
            "I0509 16:15:14.159542 140437868455744 basic_session_run_hooks.py:263] loss = 6.5290728, step = 395700 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.734\n",
            "I0509 16:15:15.113949 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.734\n",
            "INFO:tensorflow:loss = 7.641568, step = 395800 (0.955 sec)\n",
            "I0509 16:15:15.114323 140437868455744 basic_session_run_hooks.py:263] loss = 7.641568, step = 395800 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.309\n",
            "I0509 16:15:16.063533 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.309\n",
            "INFO:tensorflow:loss = 6.3251715, step = 395900 (0.950 sec)\n",
            "I0509 16:15:16.063919 140437868455744 basic_session_run_hooks.py:263] loss = 6.3251715, step = 395900 (0.950 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 396000...\n",
            "I0509 16:15:17.002409 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 396000...\n",
            "INFO:tensorflow:Saving checkpoints for 396000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:15:17.002599 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 396000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 396000...\n",
            "I0509 16:15:17.238158 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 396000...\n",
            "INFO:tensorflow:global_step/sec: 84.2492\n",
            "I0509 16:15:17.250476 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.2492\n",
            "INFO:tensorflow:loss = 5.3186274, step = 396000 (1.187 sec)\n",
            "I0509 16:15:17.250820 140437868455744 basic_session_run_hooks.py:263] loss = 5.3186274, step = 396000 (1.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.781\n",
            "I0509 16:15:18.204871 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.781\n",
            "INFO:tensorflow:loss = 6.845041, step = 396100 (0.954 sec)\n",
            "I0509 16:15:18.205166 140437868455744 basic_session_run_hooks.py:263] loss = 6.845041, step = 396100 (0.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.468\n",
            "I0509 16:15:19.162101 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.468\n",
            "INFO:tensorflow:loss = 5.241914, step = 396200 (0.957 sec)\n",
            "I0509 16:15:19.162384 140437868455744 basic_session_run_hooks.py:263] loss = 5.241914, step = 396200 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.908\n",
            "I0509 16:15:20.115304 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.908\n",
            "INFO:tensorflow:loss = 6.4493504, step = 396300 (0.953 sec)\n",
            "I0509 16:15:20.115583 140437868455744 basic_session_run_hooks.py:263] loss = 6.4493504, step = 396300 (0.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.028\n",
            "I0509 16:15:21.076594 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.028\n",
            "INFO:tensorflow:loss = 7.59181, step = 396400 (0.961 sec)\n",
            "I0509 16:15:21.076966 140437868455744 basic_session_run_hooks.py:263] loss = 7.59181, step = 396400 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.2349\n",
            "I0509 16:15:22.084321 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 99.2349\n",
            "INFO:tensorflow:loss = 6.955136, step = 396500 (1.008 sec)\n",
            "I0509 16:15:22.084625 140437868455744 basic_session_run_hooks.py:263] loss = 6.955136, step = 396500 (1.008 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.5684\n",
            "I0509 16:15:23.501395 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 70.5684\n",
            "INFO:tensorflow:loss = 6.572956, step = 396600 (1.417 sec)\n",
            "I0509 16:15:23.501704 140437868455744 basic_session_run_hooks.py:263] loss = 6.572956, step = 396600 (1.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.741\n",
            "I0509 16:15:24.474681 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.741\n",
            "INFO:tensorflow:loss = 6.147731, step = 396700 (0.973 sec)\n",
            "I0509 16:15:24.475057 140437868455744 basic_session_run_hooks.py:263] loss = 6.147731, step = 396700 (0.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.013\n",
            "I0509 16:15:25.436117 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.013\n",
            "INFO:tensorflow:loss = 4.915623, step = 396800 (0.961 sec)\n",
            "I0509 16:15:25.436410 140437868455744 basic_session_run_hooks.py:263] loss = 4.915623, step = 396800 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.758\n",
            "I0509 16:15:26.381668 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.758\n",
            "INFO:tensorflow:loss = 5.203631, step = 396900 (0.946 sec)\n",
            "I0509 16:15:26.382054 140437868455744 basic_session_run_hooks.py:263] loss = 5.203631, step = 396900 (0.946 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 397000...\n",
            "I0509 16:15:27.318288 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 397000...\n",
            "INFO:tensorflow:Saving checkpoints for 397000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:15:27.318485 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 397000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 397000...\n",
            "I0509 16:15:27.548719 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 397000...\n",
            "INFO:tensorflow:global_step/sec: 84.8048\n",
            "I0509 16:15:27.560821 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 84.8048\n",
            "INFO:tensorflow:loss = 4.600885, step = 397000 (1.179 sec)\n",
            "I0509 16:15:27.561174 140437868455744 basic_session_run_hooks.py:263] loss = 4.600885, step = 397000 (1.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.481\n",
            "I0509 16:15:28.508874 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.481\n",
            "INFO:tensorflow:loss = 6.8555326, step = 397100 (0.948 sec)\n",
            "I0509 16:15:28.509265 140437868455744 basic_session_run_hooks.py:263] loss = 6.8555326, step = 397100 (0.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.268\n",
            "I0509 16:15:29.458829 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.268\n",
            "INFO:tensorflow:loss = 5.6224594, step = 397200 (0.950 sec)\n",
            "I0509 16:15:29.459201 140437868455744 basic_session_run_hooks.py:263] loss = 5.6224594, step = 397200 (0.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.947\n",
            "I0509 16:15:30.439729 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.947\n",
            "INFO:tensorflow:loss = 5.815453, step = 397300 (0.981 sec)\n",
            "I0509 16:15:30.440013 140437868455744 basic_session_run_hooks.py:263] loss = 5.815453, step = 397300 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.401\n",
            "I0509 16:15:31.379582 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.401\n",
            "INFO:tensorflow:loss = 7.3141117, step = 397400 (0.940 sec)\n",
            "I0509 16:15:31.379974 140437868455744 basic_session_run_hooks.py:263] loss = 7.3141117, step = 397400 (0.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.759\n",
            "I0509 16:15:32.334201 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.759\n",
            "INFO:tensorflow:loss = 6.2590823, step = 397500 (0.955 sec)\n",
            "I0509 16:15:32.334583 140437868455744 basic_session_run_hooks.py:263] loss = 6.2590823, step = 397500 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.4061\n",
            "I0509 16:15:33.350392 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 98.4061\n",
            "INFO:tensorflow:loss = 7.040166, step = 397600 (1.016 sec)\n",
            "I0509 16:15:33.350787 140437868455744 basic_session_run_hooks.py:263] loss = 7.040166, step = 397600 (1.016 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.3248\n",
            "I0509 16:15:34.643594 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 77.3248\n",
            "INFO:tensorflow:loss = 6.801879, step = 397700 (1.293 sec)\n",
            "I0509 16:15:34.643951 140437868455744 basic_session_run_hooks.py:263] loss = 6.801879, step = 397700 (1.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 93.6153\n",
            "I0509 16:15:35.711783 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 93.6153\n",
            "INFO:tensorflow:loss = 6.3609653, step = 397800 (1.068 sec)\n",
            "I0509 16:15:35.712199 140437868455744 basic_session_run_hooks.py:263] loss = 6.3609653, step = 397800 (1.068 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.855\n",
            "I0509 16:15:36.665493 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.855\n",
            "INFO:tensorflow:loss = 7.0360384, step = 397900 (0.954 sec)\n",
            "I0509 16:15:36.665768 140437868455744 basic_session_run_hooks.py:263] loss = 7.0360384, step = 397900 (0.954 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 398000...\n",
            "I0509 16:15:37.611645 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 398000...\n",
            "INFO:tensorflow:Saving checkpoints for 398000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:15:37.611845 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 398000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 398000...\n",
            "I0509 16:15:37.826709 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 398000...\n",
            "INFO:tensorflow:global_step/sec: 85.2318\n",
            "I0509 16:15:37.838739 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 85.2318\n",
            "INFO:tensorflow:loss = 5.614771, step = 398000 (1.173 sec)\n",
            "I0509 16:15:37.838991 140437868455744 basic_session_run_hooks.py:263] loss = 5.614771, step = 398000 (1.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.211\n",
            "I0509 16:15:38.780274 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 106.211\n",
            "INFO:tensorflow:loss = 5.126621, step = 398100 (0.942 sec)\n",
            "I0509 16:15:38.780643 140437868455744 basic_session_run_hooks.py:263] loss = 5.126621, step = 398100 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.684\n",
            "I0509 16:15:39.726492 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.684\n",
            "INFO:tensorflow:loss = 6.7801046, step = 398200 (0.946 sec)\n",
            "I0509 16:15:39.726862 140437868455744 basic_session_run_hooks.py:263] loss = 6.7801046, step = 398200 (0.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.383\n",
            "I0509 16:15:40.684507 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.383\n",
            "INFO:tensorflow:loss = 6.4989786, step = 398300 (0.958 sec)\n",
            "I0509 16:15:40.684881 140437868455744 basic_session_run_hooks.py:263] loss = 6.4989786, step = 398300 (0.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.3\n",
            "I0509 16:15:41.662018 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.3\n",
            "INFO:tensorflow:loss = 8.57918, step = 398400 (0.978 sec)\n",
            "I0509 16:15:41.662408 140437868455744 basic_session_run_hooks.py:263] loss = 8.57918, step = 398400 (0.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.2046\n",
            "I0509 16:15:42.680324 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 98.2046\n",
            "INFO:tensorflow:loss = 6.3281503, step = 398500 (1.018 sec)\n",
            "I0509 16:15:42.680616 140437868455744 basic_session_run_hooks.py:263] loss = 6.3281503, step = 398500 (1.018 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.911\n",
            "I0509 16:15:43.652036 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.911\n",
            "INFO:tensorflow:loss = 6.1546526, step = 398600 (0.972 sec)\n",
            "I0509 16:15:43.652449 140437868455744 basic_session_run_hooks.py:263] loss = 6.1546526, step = 398600 (0.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.973\n",
            "I0509 16:15:44.623185 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.973\n",
            "INFO:tensorflow:loss = 8.142948, step = 398700 (0.971 sec)\n",
            "I0509 16:15:44.623568 140437868455744 basic_session_run_hooks.py:263] loss = 8.142948, step = 398700 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.9217\n",
            "I0509 16:15:45.814771 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.9217\n",
            "INFO:tensorflow:loss = 7.55897, step = 398800 (1.192 sec)\n",
            "I0509 16:15:45.815165 140437868455744 basic_session_run_hooks.py:263] loss = 7.55897, step = 398800 (1.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.9242\n",
            "I0509 16:15:47.020666 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 82.9242\n",
            "INFO:tensorflow:loss = 6.659455, step = 398900 (1.206 sec)\n",
            "I0509 16:15:47.021047 140437868455744 basic_session_run_hooks.py:263] loss = 6.659455, step = 398900 (1.206 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 399000...\n",
            "I0509 16:15:47.987546 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 399000...\n",
            "INFO:tensorflow:Saving checkpoints for 399000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:15:47.987735 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 399000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 399000...\n",
            "I0509 16:15:48.206805 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 399000...\n",
            "INFO:tensorflow:global_step/sec: 83.4301\n",
            "I0509 16:15:48.219255 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 83.4301\n",
            "INFO:tensorflow:loss = 5.940101, step = 399000 (1.199 sec)\n",
            "I0509 16:15:48.219586 140437868455744 basic_session_run_hooks.py:263] loss = 5.940101, step = 399000 (1.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.154\n",
            "I0509 16:15:49.179409 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.154\n",
            "INFO:tensorflow:loss = 6.2816706, step = 399100 (0.960 sec)\n",
            "I0509 16:15:49.179780 140437868455744 basic_session_run_hooks.py:263] loss = 6.2816706, step = 399100 (0.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.68\n",
            "I0509 16:15:50.143899 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.68\n",
            "INFO:tensorflow:loss = 5.6977286, step = 399200 (0.964 sec)\n",
            "I0509 16:15:50.144271 140437868455744 basic_session_run_hooks.py:263] loss = 5.6977286, step = 399200 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.563\n",
            "I0509 16:15:51.118904 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 102.563\n",
            "INFO:tensorflow:loss = 6.0233765, step = 399300 (0.975 sec)\n",
            "I0509 16:15:51.119279 140437868455744 basic_session_run_hooks.py:263] loss = 6.0233765, step = 399300 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.897\n",
            "I0509 16:15:52.081400 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.897\n",
            "INFO:tensorflow:loss = 7.2898903, step = 399400 (0.963 sec)\n",
            "I0509 16:15:52.082253 140437868455744 basic_session_run_hooks.py:263] loss = 7.2898903, step = 399400 (0.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.905\n",
            "I0509 16:15:53.062687 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 101.905\n",
            "INFO:tensorflow:loss = 7.106984, step = 399500 (0.981 sec)\n",
            "I0509 16:15:53.063031 140437868455744 basic_session_run_hooks.py:263] loss = 7.106984, step = 399500 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.464\n",
            "I0509 16:15:54.029225 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 103.464\n",
            "INFO:tensorflow:loss = 6.7531686, step = 399600 (0.967 sec)\n",
            "I0509 16:15:54.029585 140437868455744 basic_session_run_hooks.py:263] loss = 6.7531686, step = 399600 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.582\n",
            "I0509 16:15:54.976353 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 105.582\n",
            "INFO:tensorflow:loss = 6.24071, step = 399700 (0.947 sec)\n",
            "I0509 16:15:54.976713 140437868455744 basic_session_run_hooks.py:263] loss = 6.24071, step = 399700 (0.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.661\n",
            "I0509 16:15:55.931818 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 104.661\n",
            "INFO:tensorflow:loss = 7.1074595, step = 399800 (0.955 sec)\n",
            "I0509 16:15:55.932194 140437868455744 basic_session_run_hooks.py:263] loss = 7.1074595, step = 399800 (0.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 91.7637\n",
            "I0509 16:15:57.021586 140437868455744 basic_session_run_hooks.py:716] global_step/sec: 91.7637\n",
            "INFO:tensorflow:loss = 6.4103336, step = 399900 (1.090 sec)\n",
            "I0509 16:15:57.021892 140437868455744 basic_session_run_hooks.py:263] loss = 6.4103336, step = 399900 (1.090 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 400000...\n",
            "I0509 16:15:58.361002 140437868455744 basic_session_run_hooks.py:627] Calling checkpoint listeners before saving checkpoint 400000...\n",
            "INFO:tensorflow:Saving checkpoints for 400000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "I0509 16:15:58.361228 140437868455744 basic_session_run_hooks.py:632] Saving checkpoints for 400000 into ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 400000...\n",
            "I0509 16:15:58.565540 140437868455744 basic_session_run_hooks.py:639] Calling checkpoint listeners after saving checkpoint 400000...\n",
            "INFO:tensorflow:Loss for final step: 6.2036095.\n",
            "I0509 16:15:58.634578 140437868455744 estimator.py:361] Loss for final step: 6.2036095.\n",
            "INFO:tensorflow:***** Running evaluation *****\n",
            "I0509 16:15:58.635197 140437868455744 run.py:606] ***** Running evaluation *****\n",
            "INFO:tensorflow:  Batch size = 1\n",
            "I0509 16:15:58.635303 140437868455744 run.py:607]   Batch size = 1\n",
            "INFO:tensorflow:run init\n",
            "I0509 16:15:58.635404 140437868455744 run.py:135] run init\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0509 16:15:58.758245 140437868455744 estimator.py:1173] Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0509 16:15:58.758426 140437868455744 run.py:273] *** Features ***\n",
            "INFO:tensorflow:  name = info, shape = (None, 1)\n",
            "I0509 16:15:58.758538 140437868455744 run.py:275]   name = info, shape = (None, 1)\n",
            "INFO:tensorflow:  name = input_ids, shape = (None, 200)\n",
            "I0509 16:15:58.758626 140437868455744 run.py:275]   name = input_ids, shape = (None, 200)\n",
            "INFO:tensorflow:  name = input_mask, shape = (None, 200)\n",
            "I0509 16:15:58.758711 140437868455744 run.py:275]   name = input_mask, shape = (None, 200)\n",
            "INFO:tensorflow:  name = masked_lm_ids, shape = (None, 20)\n",
            "I0509 16:15:58.758788 140437868455744 run.py:275]   name = masked_lm_ids, shape = (None, 20)\n",
            "INFO:tensorflow:  name = masked_lm_positions, shape = (None, 20)\n",
            "I0509 16:15:58.758867 140437868455744 run.py:275]   name = masked_lm_positions, shape = (None, 20)\n",
            "INFO:tensorflow:  name = masked_lm_weights, shape = (None, 20)\n",
            "I0509 16:15:58.758939 140437868455744 run.py:275]   name = masked_lm_weights, shape = (None, 20)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0509 16:15:59.202094 140437868455744 run.py:327] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (6885, 256)\n",
            "I0509 16:15:59.202277 140437868455744 run.py:332]   name = bert/embeddings/word_embeddings:0, shape = (6885, 256)\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256)\n",
            "I0509 16:15:59.202367 140437868455744 run.py:332]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 256)\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (200, 256)\n",
            "I0509 16:15:59.202460 140437868455744 run.py:332]   name = bert/embeddings/position_embeddings:0, shape = (200, 256)\n",
            "INFO:tensorflow:  name = bert/embeddings/layer_normalization/gamma:0, shape = (256,)\n",
            "I0509 16:15:59.202531 140437868455744 run.py:332]   name = bert/embeddings/layer_normalization/gamma:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/embeddings/layer_normalization/beta:0, shape = (256,)\n",
            "I0509 16:15:59.202596 140437868455744 run.py:332]   name = bert/embeddings/layer_normalization/beta:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.202656 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,)\n",
            "I0509 16:15:59.202721 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.202781 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,)\n",
            "I0509 16:15:59.202845 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.202905 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,)\n",
            "I0509 16:15:59.202975 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.203035 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,)\n",
            "I0509 16:15:59.203110 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/layer_normalization_1/gamma:0, shape = (256,)\n",
            "I0509 16:15:59.203171 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/output/layer_normalization_1/gamma:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/layer_normalization_1/beta:0, shape = (256,)\n",
            "I0509 16:15:59.203232 140437868455744 run.py:332]   name = bert/encoder/layer_0/attention/output/layer_normalization_1/beta:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024)\n",
            "I0509 16:15:59.203291 140437868455744 run.py:332]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,)\n",
            "I0509 16:15:59.203354 140437868455744 run.py:332]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256)\n",
            "I0509 16:15:59.203415 140437868455744 run.py:332]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,)\n",
            "I0509 16:15:59.203479 140437868455744 run.py:332]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/layer_normalization_2/gamma:0, shape = (256,)\n",
            "I0509 16:15:59.203538 140437868455744 run.py:332]   name = bert/encoder/layer_0/output/layer_normalization_2/gamma:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/layer_normalization_2/beta:0, shape = (256,)\n",
            "I0509 16:15:59.203608 140437868455744 run.py:332]   name = bert/encoder/layer_0/output/layer_normalization_2/beta:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.203664 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,)\n",
            "I0509 16:15:59.203723 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.203778 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,)\n",
            "I0509 16:15:59.203839 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.203894 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,)\n",
            "I0509 16:15:59.203958 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.204015 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,)\n",
            "I0509 16:15:59.204084 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/layer_normalization_3/gamma:0, shape = (256,)\n",
            "I0509 16:15:59.204160 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/output/layer_normalization_3/gamma:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/layer_normalization_3/beta:0, shape = (256,)\n",
            "I0509 16:15:59.204220 140437868455744 run.py:332]   name = bert/encoder/layer_1/attention/output/layer_normalization_3/beta:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024)\n",
            "I0509 16:15:59.204279 140437868455744 run.py:332]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,)\n",
            "I0509 16:15:59.204343 140437868455744 run.py:332]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256)\n",
            "I0509 16:15:59.204402 140437868455744 run.py:332]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,)\n",
            "I0509 16:15:59.204466 140437868455744 run.py:332]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/layer_normalization_4/gamma:0, shape = (256,)\n",
            "I0509 16:15:59.204525 140437868455744 run.py:332]   name = bert/encoder/layer_1/output/layer_normalization_4/gamma:0, shape = (256,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/layer_normalization_4/beta:0, shape = (256,)\n",
            "I0509 16:15:59.204584 140437868455744 run.py:332]   name = bert/encoder/layer_1/output/layer_normalization_4/beta:0, shape = (256,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (256, 256)\n",
            "I0509 16:15:59.204653 140437868455744 run.py:332]   name = cls/predictions/transform/dense/kernel:0, shape = (256, 256)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (256,)\n",
            "I0509 16:15:59.204712 140437868455744 run.py:332]   name = cls/predictions/transform/dense/bias:0, shape = (256,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/layer_normalization_5/gamma:0, shape = (256,)\n",
            "I0509 16:15:59.204767 140437868455744 run.py:332]   name = cls/predictions/transform/layer_normalization_5/gamma:0, shape = (256,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/layer_normalization_5/beta:0, shape = (256,)\n",
            "I0509 16:15:59.204823 140437868455744 run.py:332]   name = cls/predictions/transform/layer_normalization_5/beta:0, shape = (256,)\n",
            "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (6885,)\n",
            "I0509 16:15:59.204876 140437868455744 run.py:332]   name = cls/predictions/output_bias:0, shape = (6885,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0509 16:15:59.301489 140437868455744 estimator.py:1175] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2023-05-09T16:15:59\n",
            "I0509 16:15:59.320045 140437868455744 evaluation.py:250] Starting evaluation at 2023-05-09T16:15:59\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/evaluation.py:260: FinalOpsHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "W0509 16:15:59.320228 140437868455744 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/evaluation.py:260: FinalOpsHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "load user history from :./data/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200.his\n",
            "load vocab from :./data/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200.vocab\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0509 16:15:59.696821 140437868455744 monitored_session.py:240] Graph was finalized.\n",
            "2023-05-09 16:15:59.698652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-09 16:15:59.713021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-09 16:15:59.713302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-09 16:15:59.713582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-09 16:15:59.713763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-09 16:15:59.713917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "INFO:tensorflow:Restoring parameters from ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt-400000\n",
            "I0509 16:15:59.714107 140437868455744 saver.py:1413] Restoring parameters from ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt-400000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0509 16:15:59.828788 140437868455744 session_manager.py:526] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0509 16:15:59.843022 140437868455744 session_manager.py:529] Done running local_init_op.\n",
            "2023-05-09 16:15:59.892678: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            ".......................................................................................................................................................................................................................................................................................................................ndcg@1:0.11808722461301303, hit@1:0.11808722461301303， ndcg@5:0.21797152687515528, hit@5:0.313957222686107, ndcg@10:0.2610393386403508, hit@10:0.4477166163530092, ap:0.22519088466323692, valid_user:31138.0\n",
            "INFO:tensorflow:Inference Time : 262.66479s\n",
            "I0509 16:20:21.985024 140437868455744 evaluation.py:269] Inference Time : 262.66479s\n",
            "INFO:tensorflow:Finished evaluation at 2023-05-09-16:20:21\n",
            "I0509 16:20:21.985526 140437868455744 evaluation.py:271] Finished evaluation at 2023-05-09-16:20:21\n",
            "INFO:tensorflow:Saving dict for global step 400000: global_step = 400000, loss = 6.726047, masked_lm_accuracy = 0.03009185, masked_lm_loss = 6.726118\n",
            "I0509 16:20:21.985707 140437868455744 estimator.py:2083] Saving dict for global step 400000: global_step = 400000, loss = 6.726047, masked_lm_accuracy = 0.03009185, masked_lm_loss = 6.726118\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400000: ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt-400000\n",
            "I0509 16:20:22.082224 140437868455744 estimator.py:2143] Saving 'checkpoint_path' summary for global step 400000: ./bert_train/kion-mp1.0-sw0.5-mlp0.4-df10-mpps20-msl200-256/model.ckpt-400000\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "I0509 16:20:22.102450 140437868455744 run.py:624] ***** Eval results *****\n",
            "INFO:tensorflow:{\n",
            "  \"attention_probs_dropout_prob\": 0.2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.2,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"max_position_embeddings\": 200,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 6885\n",
            "}\n",
            "\n",
            "I0509 16:20:22.102735 140437868455744 run.py:625] {\n",
            "  \"attention_probs_dropout_prob\": 0.2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.2,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"max_position_embeddings\": 200,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 6885\n",
            "}\n",
            "\n",
            "INFO:tensorflow:  global_step = 400000\n",
            "I0509 16:20:22.103273 140437868455744 run.py:628]   global_step = 400000\n",
            "INFO:tensorflow:  loss = 6.726047\n",
            "I0509 16:20:22.103420 140437868455744 run.py:628]   loss = 6.726047\n",
            "INFO:tensorflow:  masked_lm_accuracy = 0.03009185\n",
            "I0509 16:20:22.103504 140437868455744 run.py:628]   masked_lm_accuracy = 0.03009185\n",
            "INFO:tensorflow:  masked_lm_loss = 6.726118\n",
            "I0509 16:20:22.103580 140437868455744 run.py:628]   masked_lm_loss = 6.726118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Проверка точности"
      ],
      "metadata": {
        "id": "p_qwWlv5u3bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_idx_map_inv = {idx:item_id for item_id, idx in item_idx_map.items()}"
      ],
      "metadata": {
        "id": "PAQafrPKlQAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preds_df(path, user_idx_map_inv, item_idx_map_inv):\n",
        "    df = pd.read_csv(path, sep=' ', header=None, names=['user_id', 'item_id'])\n",
        "\n",
        "    df['item_id'] = df['item_id'].str[5:].astype(int)\n",
        "    df['rank'] = df.groupby('user_id').cumcount() + 1 \n",
        "\n",
        "    df['item_id'] = df['item_id'].map(lambda x: item_idx_map_inv[x])\n",
        "    df['user_id'] = df['user_id'].map(lambda x: user_idx_map_inv[x])\n",
        "    return df"
      ],
      "metadata": {
        "id": "-tpyTFcWsqmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_path = 'bert4rec_kion_preds_256.txt'\n",
        "preds_bert4rec_256 = get_preds_df(preds_path, user_idx_map_inv, item_idx_map_inv)\n",
        "preds_bert4rec_256.head()"
      ],
      "metadata": {
        "id": "O209Lj71eQOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0066dabd-22b3-482c-e31e-28db2c2116ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    user_id  item_id  rank\n",
              "20   226847      512     1\n",
              "21   226847     7793     2\n",
              "22   226847     3784     3\n",
              "23   226847     9817     4\n",
              "24   226847    10878     5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d2b21d3-a8e3-49cc-b213-44dfb5bb6f3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>226847</td>\n",
              "      <td>512</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>226847</td>\n",
              "      <td>7793</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>226847</td>\n",
              "      <td>3784</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>226847</td>\n",
              "      <td>9817</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>226847</td>\n",
              "      <td>10878</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d2b21d3-a8e3-49cc-b213-44dfb5bb6f3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d2b21d3-a8e3-49cc-b213-44dfb5bb6f3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d2b21d3-a8e3-49cc-b213-44dfb5bb6f3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hidden_size = 256\n",
        "metrics['BERT4Rec_256'] = compute_metrics(test, preds_bert4rec, 10)"
      ],
      "metadata": {
        "id": "UwCHFwq36pxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_ml-1m.sh"
      ],
      "metadata": {
        "id": "sxPsX4igXN5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_path = 'bert4rec_kion_preds.txt'\n",
        "preds_bert4rec_128 = get_preds_df(preds_path, user_idx_map_inv, item_idx_map_inv)\n",
        "preds_bert4rec_128.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hVCUXBM7sKoO",
        "outputId": "132a2bd8-7303-4d6c-9f6c-21d672bdf8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  rank\n",
              "0  1047828     4495     1\n",
              "1  1047828    12192     2\n",
              "2  1047828    15297     3\n",
              "3  1047828     7829     4\n",
              "4  1047828     3784     5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dda3c03-822b-4cee-ae9d-f3ae5350b4ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1047828</td>\n",
              "      <td>4495</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1047828</td>\n",
              "      <td>12192</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1047828</td>\n",
              "      <td>15297</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1047828</td>\n",
              "      <td>7829</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1047828</td>\n",
              "      <td>3784</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dda3c03-822b-4cee-ae9d-f3ae5350b4ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1dda3c03-822b-4cee-ae9d-f3ae5350b4ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1dda3c03-822b-4cee-ae9d-f3ae5350b4ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hidden_size = 128\n",
        "metrics['BERT4Rec_128'] = compute_metrics(test, preds_bert4rec_128, 10)"
      ],
      "metadata": {
        "id": "6C5hkvakuwXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics = pd.concat([\n",
        "    pd.DataFrame(metrics['BERT4Rec_128']).transpose(),\n",
        "    pd.DataFrame(metrics['BERT4Rec_256']).transpose()\n",
        "])\n",
        "\n",
        "df_metrics.index = ['BERT4Rec_128', 'BERT4Rec_256']\n",
        "\n",
        "df_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "4PzxUj1NulSK",
        "outputId": "f7a5fdfe-5f60-4435-ff94-6054e5f4b8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Precision@1  Recall@1  Precision@2  Recall@2  Precision@3  \\\n",
              "BERT4Rec_128     0.040185  0.014526     0.037563   0.02640     0.035327   \n",
              "BERT4Rec_256     0.042297  0.014966     0.037972   0.02563     0.035894   \n",
              "\n",
              "              Recall@3  Precision@4  Recall@4  Precision@5  Recall@5  ...  \\\n",
              "BERT4Rec_128  0.036685     0.033562   0.04514     0.031944  0.053465  ...   \n",
              "BERT4Rec_256  0.036196     0.034345   0.04623     0.032734  0.053887  ...   \n",
              "\n",
              "              Precision@7  Recall@7  Precision@8  Recall@8  Precision@9  \\\n",
              "BERT4Rec_128     0.029813  0.068840     0.028904  0.074823     0.028304   \n",
              "BERT4Rec_256     0.029988  0.067829     0.028734  0.073015     0.027933   \n",
              "\n",
              "              Recall@9  Precision@10  Recall@10    MAP@10       MRR  \n",
              "BERT4Rec_128  0.081933      0.027578   0.087972  0.033895  0.086145  \n",
              "BERT4Rec_256  0.079889      0.027278   0.086122  0.033808  0.087404  \n",
              "\n",
              "[2 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c997598-eef8-466a-98cb-925654f5d0c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision@1</th>\n",
              "      <th>Recall@1</th>\n",
              "      <th>Precision@2</th>\n",
              "      <th>Recall@2</th>\n",
              "      <th>Precision@3</th>\n",
              "      <th>Recall@3</th>\n",
              "      <th>Precision@4</th>\n",
              "      <th>Recall@4</th>\n",
              "      <th>Precision@5</th>\n",
              "      <th>Recall@5</th>\n",
              "      <th>...</th>\n",
              "      <th>Precision@7</th>\n",
              "      <th>Recall@7</th>\n",
              "      <th>Precision@8</th>\n",
              "      <th>Recall@8</th>\n",
              "      <th>Precision@9</th>\n",
              "      <th>Recall@9</th>\n",
              "      <th>Precision@10</th>\n",
              "      <th>Recall@10</th>\n",
              "      <th>MAP@10</th>\n",
              "      <th>MRR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BERT4Rec_128</th>\n",
              "      <td>0.040185</td>\n",
              "      <td>0.014526</td>\n",
              "      <td>0.037563</td>\n",
              "      <td>0.02640</td>\n",
              "      <td>0.035327</td>\n",
              "      <td>0.036685</td>\n",
              "      <td>0.033562</td>\n",
              "      <td>0.04514</td>\n",
              "      <td>0.031944</td>\n",
              "      <td>0.053465</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029813</td>\n",
              "      <td>0.068840</td>\n",
              "      <td>0.028904</td>\n",
              "      <td>0.074823</td>\n",
              "      <td>0.028304</td>\n",
              "      <td>0.081933</td>\n",
              "      <td>0.027578</td>\n",
              "      <td>0.087972</td>\n",
              "      <td>0.033895</td>\n",
              "      <td>0.086145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BERT4Rec_256</th>\n",
              "      <td>0.042297</td>\n",
              "      <td>0.014966</td>\n",
              "      <td>0.037972</td>\n",
              "      <td>0.02563</td>\n",
              "      <td>0.035894</td>\n",
              "      <td>0.036196</td>\n",
              "      <td>0.034345</td>\n",
              "      <td>0.04623</td>\n",
              "      <td>0.032734</td>\n",
              "      <td>0.053887</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029988</td>\n",
              "      <td>0.067829</td>\n",
              "      <td>0.028734</td>\n",
              "      <td>0.073015</td>\n",
              "      <td>0.027933</td>\n",
              "      <td>0.079889</td>\n",
              "      <td>0.027278</td>\n",
              "      <td>0.086122</td>\n",
              "      <td>0.033808</td>\n",
              "      <td>0.087404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c997598-eef8-466a-98cb-925654f5d0c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c997598-eef8-466a-98cb-925654f5d0c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c997598-eef8-466a-98cb-925654f5d0c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SasRec"
      ],
      "metadata": {
        "id": "8r5ULp_G9xXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pmixer/SASRec.pytorch.git\n",
        "%cd /content/SASRec.pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYZXhRsN9xAo",
        "outputId": "f9390239-27cc-471c-fc6d-23a9acf67bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SASRec.pytorch'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 80 (delta 25), reused 21 (delta 21), pack-reused 50\u001b[K\n",
            "Unpacking objects: 100% (80/80), 17.96 MiB | 4.40 MiB/s, done.\n",
            "/content/SASRec.pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробовал 2 версии SasRec на tf и pytorch, обе выдают нулевую точность, также пробовал получать рекомендации последовательно, но не помогло"
      ],
      "metadata": {
        "id": "c4At5dbCJ2cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --device=cuda --dataset=train --train_dir=default --maxlen=50 --num_epochs=100"
      ],
      "metadata": {
        "id": "-WVcroh_xfHS",
        "outputId": "e5668577-aae7-4735-d128-845a3ebc58d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "loss in epoch 80 iteration 106: 0.5992926359176636\n",
            "loss in epoch 80 iteration 107: 0.5735217332839966\n",
            "loss in epoch 80 iteration 108: 0.5583643913269043\n",
            "loss in epoch 80 iteration 109: 0.5602438449859619\n",
            "loss in epoch 80 iteration 110: 0.5684735774993896\n",
            "loss in epoch 80 iteration 111: 0.5660626888275146\n",
            "loss in epoch 80 iteration 112: 0.5571335554122925\n",
            "loss in epoch 80 iteration 113: 0.549934983253479\n",
            "loss in epoch 80 iteration 114: 0.5453009009361267\n",
            "loss in epoch 80 iteration 115: 0.5630354881286621\n",
            "loss in epoch 80 iteration 116: 0.553153395652771\n",
            "loss in epoch 80 iteration 117: 0.5710519552230835\n",
            "loss in epoch 80 iteration 118: 0.5440434813499451\n",
            "loss in epoch 80 iteration 119: 0.550947904586792\n",
            "loss in epoch 80 iteration 120: 0.5570998787879944\n",
            "loss in epoch 80 iteration 121: 0.5350707769393921\n",
            "loss in epoch 80 iteration 122: 0.5647276639938354\n",
            "loss in epoch 80 iteration 123: 0.5434165000915527\n",
            "loss in epoch 80 iteration 124: 0.565471351146698\n",
            "loss in epoch 80 iteration 125: 0.5560548901557922\n",
            "loss in epoch 80 iteration 126: 0.5720727443695068\n",
            "loss in epoch 80 iteration 127: 0.5653669834136963\n",
            "loss in epoch 80 iteration 128: 0.5937279462814331\n",
            "loss in epoch 80 iteration 129: 0.5614606142044067\n",
            "loss in epoch 80 iteration 130: 0.547816276550293\n",
            "loss in epoch 80 iteration 131: 0.5659381151199341\n",
            "loss in epoch 80 iteration 132: 0.5708931684494019\n",
            "loss in epoch 80 iteration 133: 0.5405179858207703\n",
            "loss in epoch 80 iteration 134: 0.6005240678787231\n",
            "loss in epoch 80 iteration 135: 0.5789585113525391\n",
            "loss in epoch 80 iteration 136: 0.5612824559211731\n",
            "loss in epoch 80 iteration 137: 0.550007164478302\n",
            "loss in epoch 80 iteration 138: 0.5718042850494385\n",
            "loss in epoch 80 iteration 139: 0.5568583011627197\n",
            "loss in epoch 80 iteration 140: 0.5593924522399902\n",
            "loss in epoch 80 iteration 141: 0.5909222364425659\n",
            "loss in epoch 80 iteration 142: 0.5713514089584351\n",
            "loss in epoch 80 iteration 143: 0.5791470408439636\n",
            "loss in epoch 80 iteration 144: 0.5450431108474731\n",
            "loss in epoch 80 iteration 145: 0.5666160583496094\n",
            "loss in epoch 80 iteration 146: 0.5751854181289673\n",
            "loss in epoch 80 iteration 147: 0.5533809661865234\n",
            "loss in epoch 80 iteration 148: 0.5716043710708618\n",
            "loss in epoch 80 iteration 149: 0.5939360857009888\n",
            "loss in epoch 80 iteration 150: 0.5598929524421692\n",
            "loss in epoch 80 iteration 151: 0.5549169778823853\n",
            "loss in epoch 80 iteration 152: 0.5632181167602539\n",
            "loss in epoch 80 iteration 153: 0.5732432007789612\n",
            "loss in epoch 80 iteration 154: 0.5444865226745605\n",
            "loss in epoch 80 iteration 155: 0.5714200139045715\n",
            "loss in epoch 80 iteration 156: 0.5712503790855408\n",
            "loss in epoch 80 iteration 157: 0.5507572889328003\n",
            "loss in epoch 80 iteration 158: 0.5798808336257935\n",
            "loss in epoch 80 iteration 159: 0.6002392172813416\n",
            "loss in epoch 80 iteration 160: 0.5589405298233032\n",
            "loss in epoch 80 iteration 161: 0.5385043621063232\n",
            "loss in epoch 80 iteration 162: 0.5520560145378113\n",
            "loss in epoch 80 iteration 163: 0.5918357968330383\n",
            "loss in epoch 80 iteration 164: 0.5840004682540894\n",
            "loss in epoch 80 iteration 165: 0.5733776092529297\n",
            "loss in epoch 80 iteration 166: 0.5749219655990601\n",
            "loss in epoch 80 iteration 167: 0.5610899925231934\n",
            "loss in epoch 80 iteration 168: 0.5686943531036377\n",
            "loss in epoch 80 iteration 169: 0.5533401966094971\n",
            "loss in epoch 80 iteration 170: 0.5716969966888428\n",
            "loss in epoch 80 iteration 171: 0.5559124946594238\n",
            "loss in epoch 80 iteration 172: 0.5507778525352478\n",
            "loss in epoch 80 iteration 173: 0.5577951669692993\n",
            "loss in epoch 80 iteration 174: 0.5727465152740479\n",
            "loss in epoch 80 iteration 175: 0.576014518737793\n",
            "loss in epoch 80 iteration 176: 0.5261906385421753\n",
            "loss in epoch 80 iteration 177: 0.5436692833900452\n",
            "loss in epoch 80 iteration 178: 0.5450059771537781\n",
            "loss in epoch 80 iteration 179: 0.5580029487609863\n",
            "loss in epoch 80 iteration 180: 0.5814892053604126\n",
            "loss in epoch 80 iteration 181: 0.557738721370697\n",
            "loss in epoch 80 iteration 182: 0.543178141117096\n",
            "loss in epoch 80 iteration 183: 0.530010461807251\n",
            "loss in epoch 80 iteration 184: 0.5418125987052917\n",
            "loss in epoch 80 iteration 185: 0.5495603084564209\n",
            "loss in epoch 80 iteration 186: 0.561569333076477\n",
            "loss in epoch 80 iteration 187: 0.5664505958557129\n",
            "loss in epoch 80 iteration 188: 0.5548141002655029\n",
            "loss in epoch 80 iteration 189: 0.5523788928985596\n",
            "loss in epoch 80 iteration 190: 0.5680838823318481\n",
            "loss in epoch 80 iteration 191: 0.572365939617157\n",
            "loss in epoch 80 iteration 192: 0.5352519154548645\n",
            "loss in epoch 80 iteration 193: 0.5700960159301758\n",
            "loss in epoch 80 iteration 194: 0.565942645072937\n",
            "loss in epoch 80 iteration 195: 0.5579134225845337\n",
            "loss in epoch 80 iteration 196: 0.592671275138855\n",
            "loss in epoch 80 iteration 197: 0.5578232407569885\n",
            "loss in epoch 80 iteration 198: 0.5524625778198242\n",
            "loss in epoch 80 iteration 199: 0.5596042275428772\n",
            "loss in epoch 80 iteration 200: 0.5648089647293091\n",
            "loss in epoch 80 iteration 201: 0.5577394962310791\n",
            "loss in epoch 80 iteration 202: 0.5706909894943237\n",
            "loss in epoch 80 iteration 203: 0.5512072443962097\n",
            "loss in epoch 80 iteration 204: 0.5662891864776611\n",
            "loss in epoch 80 iteration 205: 0.5653625726699829\n",
            "loss in epoch 80 iteration 206: 0.5774863958358765\n",
            "loss in epoch 80 iteration 207: 0.5749404430389404\n",
            "loss in epoch 80 iteration 208: 0.5677766799926758\n",
            "loss in epoch 80 iteration 209: 0.5637367963790894\n",
            "loss in epoch 80 iteration 210: 0.5485228300094604\n",
            "loss in epoch 80 iteration 211: 0.5675524473190308\n",
            "loss in epoch 80 iteration 212: 0.5543120503425598\n",
            "loss in epoch 80 iteration 213: 0.5680999755859375\n",
            "loss in epoch 80 iteration 214: 0.540946364402771\n",
            "loss in epoch 80 iteration 215: 0.570526659488678\n",
            "loss in epoch 80 iteration 216: 0.5738440752029419\n",
            "loss in epoch 80 iteration 217: 0.549503743648529\n",
            "loss in epoch 80 iteration 218: 0.5710406303405762\n",
            "loss in epoch 80 iteration 219: 0.5771298408508301\n",
            "loss in epoch 80 iteration 220: 0.5775038003921509\n",
            "loss in epoch 80 iteration 221: 0.5570635795593262\n",
            "loss in epoch 80 iteration 222: 0.5785645842552185\n",
            "loss in epoch 80 iteration 223: 0.5711194276809692\n",
            "loss in epoch 80 iteration 224: 0.5738573670387268\n",
            "loss in epoch 80 iteration 225: 0.594886839389801\n",
            "loss in epoch 80 iteration 226: 0.58141028881073\n",
            "loss in epoch 80 iteration 227: 0.5610568523406982\n",
            "loss in epoch 80 iteration 228: 0.5591249465942383\n",
            "loss in epoch 80 iteration 229: 0.5533543825149536\n",
            "loss in epoch 80 iteration 230: 0.5439920425415039\n",
            "loss in epoch 80 iteration 231: 0.5866353511810303\n",
            "loss in epoch 80 iteration 232: 0.5573636293411255\n",
            "loss in epoch 80 iteration 233: 0.6007946729660034\n",
            "loss in epoch 80 iteration 234: 0.5641001462936401\n",
            "loss in epoch 80 iteration 235: 0.5431655645370483\n",
            "loss in epoch 80 iteration 236: 0.5690983533859253\n",
            "loss in epoch 80 iteration 237: 0.5505005121231079\n",
            "loss in epoch 80 iteration 238: 0.5736465454101562\n",
            "loss in epoch 80 iteration 239: 0.5657091736793518\n",
            "loss in epoch 80 iteration 240: 0.5651266574859619\n",
            "loss in epoch 80 iteration 241: 0.5422099828720093\n",
            "loss in epoch 80 iteration 242: 0.5552158355712891\n",
            "Evaluating........................................................................................................................................................................................................epoch:80, time: 507.032590(s), valid (NDCG@10: 0.5669, HR@10: 0.8231), test (NDCG@10: 0.5754, HR@10: 0.8256)\n",
            "loss in epoch 81 iteration 0: 0.5701969861984253\n",
            "loss in epoch 81 iteration 1: 0.5521209239959717\n",
            "loss in epoch 81 iteration 2: 0.5734607577323914\n",
            "loss in epoch 81 iteration 3: 0.5707064867019653\n",
            "loss in epoch 81 iteration 4: 0.6017626523971558\n",
            "loss in epoch 81 iteration 5: 0.5949352979660034\n",
            "loss in epoch 81 iteration 6: 0.5512052774429321\n",
            "loss in epoch 81 iteration 7: 0.5771629214286804\n",
            "loss in epoch 81 iteration 8: 0.5381292700767517\n",
            "loss in epoch 81 iteration 9: 0.5432345867156982\n",
            "loss in epoch 81 iteration 10: 0.5814383029937744\n",
            "loss in epoch 81 iteration 11: 0.5461082458496094\n",
            "loss in epoch 81 iteration 12: 0.572323203086853\n",
            "loss in epoch 81 iteration 13: 0.5769003033638\n",
            "loss in epoch 81 iteration 14: 0.5575565099716187\n",
            "loss in epoch 81 iteration 15: 0.5903478264808655\n",
            "loss in epoch 81 iteration 16: 0.55987149477005\n",
            "loss in epoch 81 iteration 17: 0.5556427240371704\n",
            "loss in epoch 81 iteration 18: 0.5654203295707703\n",
            "loss in epoch 81 iteration 19: 0.5589963793754578\n",
            "loss in epoch 81 iteration 20: 0.5821134448051453\n",
            "loss in epoch 81 iteration 21: 0.5508309006690979\n",
            "loss in epoch 81 iteration 22: 0.5327115654945374\n",
            "loss in epoch 81 iteration 23: 0.534914493560791\n",
            "loss in epoch 81 iteration 24: 0.5742944478988647\n",
            "loss in epoch 81 iteration 25: 0.5386378765106201\n",
            "loss in epoch 81 iteration 26: 0.5778334736824036\n",
            "loss in epoch 81 iteration 27: 0.5928598642349243\n",
            "loss in epoch 81 iteration 28: 0.5846585035324097\n",
            "loss in epoch 81 iteration 29: 0.5408624410629272\n",
            "loss in epoch 81 iteration 30: 0.5549992918968201\n",
            "loss in epoch 81 iteration 31: 0.5807368755340576\n",
            "loss in epoch 81 iteration 32: 0.5766275525093079\n",
            "loss in epoch 81 iteration 33: 0.5496863126754761\n",
            "loss in epoch 81 iteration 34: 0.5614711046218872\n",
            "loss in epoch 81 iteration 35: 0.567338228225708\n",
            "loss in epoch 81 iteration 36: 0.5728266835212708\n",
            "loss in epoch 81 iteration 37: 0.5769554972648621\n",
            "loss in epoch 81 iteration 38: 0.5563734173774719\n",
            "loss in epoch 81 iteration 39: 0.588245153427124\n",
            "loss in epoch 81 iteration 40: 0.5720181465148926\n",
            "loss in epoch 81 iteration 41: 0.5529932379722595\n",
            "loss in epoch 81 iteration 42: 0.5792161226272583\n",
            "loss in epoch 81 iteration 43: 0.5574764013290405\n",
            "loss in epoch 81 iteration 44: 0.5482040047645569\n",
            "loss in epoch 81 iteration 45: 0.5329575538635254\n",
            "loss in epoch 81 iteration 46: 0.5855540037155151\n",
            "loss in epoch 81 iteration 47: 0.5997379422187805\n",
            "loss in epoch 81 iteration 48: 0.5601564049720764\n",
            "loss in epoch 81 iteration 49: 0.5640064477920532\n",
            "loss in epoch 81 iteration 50: 0.5637184381484985\n",
            "loss in epoch 81 iteration 51: 0.5527017712593079\n",
            "loss in epoch 81 iteration 52: 0.5572563409805298\n",
            "loss in epoch 81 iteration 53: 0.5596300959587097\n",
            "loss in epoch 81 iteration 54: 0.5788320302963257\n",
            "loss in epoch 81 iteration 55: 0.5850806832313538\n",
            "loss in epoch 81 iteration 56: 0.5331588983535767\n",
            "loss in epoch 81 iteration 57: 0.5586934685707092\n",
            "loss in epoch 81 iteration 58: 0.5608252286911011\n",
            "loss in epoch 81 iteration 59: 0.5704522132873535\n",
            "loss in epoch 81 iteration 60: 0.5513474345207214\n",
            "loss in epoch 81 iteration 61: 0.5630229711532593\n",
            "loss in epoch 81 iteration 62: 0.5625227689743042\n",
            "loss in epoch 81 iteration 63: 0.5460425615310669\n",
            "loss in epoch 81 iteration 64: 0.5673876404762268\n",
            "loss in epoch 81 iteration 65: 0.5713223218917847\n",
            "loss in epoch 81 iteration 66: 0.5793501138687134\n",
            "loss in epoch 81 iteration 67: 0.5597713589668274\n",
            "loss in epoch 81 iteration 68: 0.5574267506599426\n",
            "loss in epoch 81 iteration 69: 0.5821367502212524\n",
            "loss in epoch 81 iteration 70: 0.5570804476737976\n",
            "loss in epoch 81 iteration 71: 0.5554043054580688\n",
            "loss in epoch 81 iteration 72: 0.5703171491622925\n",
            "loss in epoch 81 iteration 73: 0.5812547206878662\n",
            "loss in epoch 81 iteration 74: 0.5587501525878906\n",
            "loss in epoch 81 iteration 75: 0.5624538660049438\n",
            "loss in epoch 81 iteration 76: 0.5738829374313354\n",
            "loss in epoch 81 iteration 77: 0.580272912979126\n",
            "loss in epoch 81 iteration 78: 0.5245040655136108\n",
            "loss in epoch 81 iteration 79: 0.5827981233596802\n",
            "loss in epoch 81 iteration 80: 0.5691291093826294\n",
            "loss in epoch 81 iteration 81: 0.5525090098381042\n",
            "loss in epoch 81 iteration 82: 0.5876040458679199\n",
            "loss in epoch 81 iteration 83: 0.5455193519592285\n",
            "loss in epoch 81 iteration 84: 0.5420989990234375\n",
            "loss in epoch 81 iteration 85: 0.5685708522796631\n",
            "loss in epoch 81 iteration 86: 0.5985254049301147\n",
            "loss in epoch 81 iteration 87: 0.5612156987190247\n",
            "loss in epoch 81 iteration 88: 0.5755189657211304\n",
            "loss in epoch 81 iteration 89: 0.5308228731155396\n",
            "loss in epoch 81 iteration 90: 0.5804368257522583\n",
            "loss in epoch 81 iteration 91: 0.5605785846710205\n",
            "loss in epoch 81 iteration 92: 0.5695133805274963\n",
            "loss in epoch 81 iteration 93: 0.5350151658058167\n",
            "loss in epoch 81 iteration 94: 0.5954649448394775\n",
            "loss in epoch 81 iteration 95: 0.5504485964775085\n",
            "loss in epoch 81 iteration 96: 0.5460571050643921\n",
            "loss in epoch 81 iteration 97: 0.5606089234352112\n",
            "loss in epoch 81 iteration 98: 0.5573540925979614\n",
            "loss in epoch 81 iteration 99: 0.5472948551177979\n",
            "loss in epoch 81 iteration 100: 0.5252282023429871\n",
            "loss in epoch 81 iteration 101: 0.5691535472869873\n",
            "loss in epoch 81 iteration 102: 0.5468485355377197\n",
            "loss in epoch 81 iteration 103: 0.5734922885894775\n",
            "loss in epoch 81 iteration 104: 0.5664781332015991\n",
            "loss in epoch 81 iteration 105: 0.5592151880264282\n",
            "loss in epoch 81 iteration 106: 0.5739001631736755\n",
            "loss in epoch 81 iteration 107: 0.5391645431518555\n",
            "loss in epoch 81 iteration 108: 0.555136501789093\n",
            "loss in epoch 81 iteration 109: 0.5530062913894653\n",
            "loss in epoch 81 iteration 110: 0.5713621377944946\n",
            "loss in epoch 81 iteration 111: 0.5708458423614502\n",
            "loss in epoch 81 iteration 112: 0.571256160736084\n",
            "loss in epoch 81 iteration 113: 0.5775504112243652\n",
            "loss in epoch 81 iteration 114: 0.558404803276062\n",
            "loss in epoch 81 iteration 115: 0.598944902420044\n",
            "loss in epoch 81 iteration 116: 0.5896332263946533\n",
            "loss in epoch 81 iteration 117: 0.5529991984367371\n",
            "loss in epoch 81 iteration 118: 0.5509033799171448\n",
            "loss in epoch 81 iteration 119: 0.5707731246948242\n",
            "loss in epoch 81 iteration 120: 0.5660237073898315\n",
            "loss in epoch 81 iteration 121: 0.5550059080123901\n",
            "loss in epoch 81 iteration 122: 0.5865042209625244\n",
            "loss in epoch 81 iteration 123: 0.5563687086105347\n",
            "loss in epoch 81 iteration 124: 0.545893669128418\n",
            "loss in epoch 81 iteration 125: 0.5716172456741333\n",
            "loss in epoch 81 iteration 126: 0.5674595832824707\n",
            "loss in epoch 81 iteration 127: 0.5527676939964294\n",
            "loss in epoch 81 iteration 128: 0.5603384971618652\n",
            "loss in epoch 81 iteration 129: 0.5543578863143921\n",
            "loss in epoch 81 iteration 130: 0.5543219447135925\n",
            "loss in epoch 81 iteration 131: 0.5328026413917542\n",
            "loss in epoch 81 iteration 132: 0.5431371927261353\n",
            "loss in epoch 81 iteration 133: 0.5311263799667358\n",
            "loss in epoch 81 iteration 134: 0.5509190559387207\n",
            "loss in epoch 81 iteration 135: 0.5734546184539795\n",
            "loss in epoch 81 iteration 136: 0.5567069053649902\n",
            "loss in epoch 81 iteration 137: 0.585519552230835\n",
            "loss in epoch 81 iteration 138: 0.5527170300483704\n",
            "loss in epoch 81 iteration 139: 0.5746396780014038\n",
            "loss in epoch 81 iteration 140: 0.5237995386123657\n",
            "loss in epoch 81 iteration 141: 0.5696526765823364\n",
            "loss in epoch 81 iteration 142: 0.5600501894950867\n",
            "loss in epoch 81 iteration 143: 0.5701794624328613\n",
            "loss in epoch 81 iteration 144: 0.5671844482421875\n",
            "loss in epoch 81 iteration 145: 0.5385851860046387\n",
            "loss in epoch 81 iteration 146: 0.5702141523361206\n",
            "loss in epoch 81 iteration 147: 0.5609874725341797\n",
            "loss in epoch 81 iteration 148: 0.5482425689697266\n",
            "loss in epoch 81 iteration 149: 0.5588642358779907\n",
            "loss in epoch 81 iteration 150: 0.5565218925476074\n",
            "loss in epoch 81 iteration 151: 0.5562362670898438\n",
            "loss in epoch 81 iteration 152: 0.5664080381393433\n",
            "loss in epoch 81 iteration 153: 0.5676285028457642\n",
            "loss in epoch 81 iteration 154: 0.58010333776474\n",
            "loss in epoch 81 iteration 155: 0.5657472610473633\n",
            "loss in epoch 81 iteration 156: 0.5733994245529175\n",
            "loss in epoch 81 iteration 157: 0.5691397190093994\n",
            "loss in epoch 81 iteration 158: 0.5749613046646118\n",
            "loss in epoch 81 iteration 159: 0.5466099977493286\n",
            "loss in epoch 81 iteration 160: 0.5385468602180481\n",
            "loss in epoch 81 iteration 161: 0.576156497001648\n",
            "loss in epoch 81 iteration 162: 0.5667540431022644\n",
            "loss in epoch 81 iteration 163: 0.5576492547988892\n",
            "loss in epoch 81 iteration 164: 0.5786088705062866\n",
            "loss in epoch 81 iteration 165: 0.5551453828811646\n",
            "loss in epoch 81 iteration 166: 0.5694770812988281\n",
            "loss in epoch 81 iteration 167: 0.5499895215034485\n",
            "loss in epoch 81 iteration 168: 0.5768630504608154\n",
            "loss in epoch 81 iteration 169: 0.5514156818389893\n",
            "loss in epoch 81 iteration 170: 0.5782198905944824\n",
            "loss in epoch 81 iteration 171: 0.5588595867156982\n",
            "loss in epoch 81 iteration 172: 0.5527218580245972\n",
            "loss in epoch 81 iteration 173: 0.552026629447937\n",
            "loss in epoch 81 iteration 174: 0.533695638179779\n",
            "loss in epoch 81 iteration 175: 0.57008957862854\n",
            "loss in epoch 81 iteration 176: 0.556056797504425\n",
            "loss in epoch 81 iteration 177: 0.550646185874939\n",
            "loss in epoch 81 iteration 178: 0.5582296848297119\n",
            "loss in epoch 81 iteration 179: 0.54222172498703\n",
            "loss in epoch 81 iteration 180: 0.534940779209137\n",
            "loss in epoch 81 iteration 181: 0.5573378801345825\n",
            "loss in epoch 81 iteration 182: 0.5876299142837524\n",
            "loss in epoch 81 iteration 183: 0.5414814949035645\n",
            "loss in epoch 81 iteration 184: 0.5898971557617188\n",
            "loss in epoch 81 iteration 185: 0.5852009057998657\n",
            "loss in epoch 81 iteration 186: 0.5495575666427612\n",
            "loss in epoch 81 iteration 187: 0.5585975050926208\n",
            "loss in epoch 81 iteration 188: 0.5589543581008911\n",
            "loss in epoch 81 iteration 189: 0.5603034496307373\n",
            "loss in epoch 81 iteration 190: 0.5535753965377808\n",
            "loss in epoch 81 iteration 191: 0.5596636533737183\n",
            "loss in epoch 81 iteration 192: 0.5387214422225952\n",
            "loss in epoch 81 iteration 193: 0.5460055470466614\n",
            "loss in epoch 81 iteration 194: 0.5678964853286743\n",
            "loss in epoch 81 iteration 195: 0.5589434504508972\n",
            "loss in epoch 81 iteration 196: 0.5516018867492676\n",
            "loss in epoch 81 iteration 197: 0.5731428861618042\n",
            "loss in epoch 81 iteration 198: 0.545954704284668\n",
            "loss in epoch 81 iteration 199: 0.553043007850647\n",
            "loss in epoch 81 iteration 200: 0.5608747005462646\n",
            "loss in epoch 81 iteration 201: 0.559374213218689\n",
            "loss in epoch 81 iteration 202: 0.5714142322540283\n",
            "loss in epoch 81 iteration 203: 0.5887141227722168\n",
            "loss in epoch 81 iteration 204: 0.5446833372116089\n",
            "loss in epoch 81 iteration 205: 0.5555075407028198\n",
            "loss in epoch 81 iteration 206: 0.5836384892463684\n",
            "loss in epoch 81 iteration 207: 0.5908956527709961\n",
            "loss in epoch 81 iteration 208: 0.5431056022644043\n",
            "loss in epoch 81 iteration 209: 0.5384507179260254\n",
            "loss in epoch 81 iteration 210: 0.5474586486816406\n",
            "loss in epoch 81 iteration 211: 0.5486315488815308\n",
            "loss in epoch 81 iteration 212: 0.5663881301879883\n",
            "loss in epoch 81 iteration 213: 0.5738732814788818\n",
            "loss in epoch 81 iteration 214: 0.5515249967575073\n",
            "loss in epoch 81 iteration 215: 0.5321319103240967\n",
            "loss in epoch 81 iteration 216: 0.5501386523246765\n",
            "loss in epoch 81 iteration 217: 0.5527224540710449\n",
            "loss in epoch 81 iteration 218: 0.5658861398696899\n",
            "loss in epoch 81 iteration 219: 0.5858980417251587\n",
            "loss in epoch 81 iteration 220: 0.5609354972839355\n",
            "loss in epoch 81 iteration 221: 0.5407344102859497\n",
            "loss in epoch 81 iteration 222: 0.5788060426712036\n",
            "loss in epoch 81 iteration 223: 0.5553454160690308\n",
            "loss in epoch 81 iteration 224: 0.5631593465805054\n",
            "loss in epoch 81 iteration 225: 0.5494062900543213\n",
            "loss in epoch 81 iteration 226: 0.5828230381011963\n",
            "loss in epoch 81 iteration 227: 0.5673011541366577\n",
            "loss in epoch 81 iteration 228: 0.5434632301330566\n",
            "loss in epoch 81 iteration 229: 0.5415855050086975\n",
            "loss in epoch 81 iteration 230: 0.5509408712387085\n",
            "loss in epoch 81 iteration 231: 0.5781234502792358\n",
            "loss in epoch 81 iteration 232: 0.5648857355117798\n",
            "loss in epoch 81 iteration 233: 0.5547131299972534\n",
            "loss in epoch 81 iteration 234: 0.565683901309967\n",
            "loss in epoch 81 iteration 235: 0.5849008560180664\n",
            "loss in epoch 81 iteration 236: 0.5810580253601074\n",
            "loss in epoch 81 iteration 237: 0.5508779883384705\n",
            "loss in epoch 81 iteration 238: 0.5333883762359619\n",
            "loss in epoch 81 iteration 239: 0.5566222071647644\n",
            "loss in epoch 81 iteration 240: 0.5758109092712402\n",
            "loss in epoch 81 iteration 241: 0.5599960088729858\n",
            "loss in epoch 81 iteration 242: 0.5548297166824341\n",
            "loss in epoch 82 iteration 0: 0.5634113550186157\n",
            "loss in epoch 82 iteration 1: 0.5627337694168091\n",
            "loss in epoch 82 iteration 2: 0.5526764392852783\n",
            "loss in epoch 82 iteration 3: 0.5705319046974182\n",
            "loss in epoch 82 iteration 4: 0.5570135116577148\n",
            "loss in epoch 82 iteration 5: 0.5787539482116699\n",
            "loss in epoch 82 iteration 6: 0.5153698921203613\n",
            "loss in epoch 82 iteration 7: 0.5526564717292786\n",
            "loss in epoch 82 iteration 8: 0.5958907604217529\n",
            "loss in epoch 82 iteration 9: 0.5789353847503662\n",
            "loss in epoch 82 iteration 10: 0.5604448914527893\n",
            "loss in epoch 82 iteration 11: 0.567484974861145\n",
            "loss in epoch 82 iteration 12: 0.5531535148620605\n",
            "loss in epoch 82 iteration 13: 0.5831804871559143\n",
            "loss in epoch 82 iteration 14: 0.5796943306922913\n",
            "loss in epoch 82 iteration 15: 0.5523562431335449\n",
            "loss in epoch 82 iteration 16: 0.5472431182861328\n",
            "loss in epoch 82 iteration 17: 0.5720183253288269\n",
            "loss in epoch 82 iteration 18: 0.5663086175918579\n",
            "loss in epoch 82 iteration 19: 0.5647313594818115\n",
            "loss in epoch 82 iteration 20: 0.5677907466888428\n",
            "loss in epoch 82 iteration 21: 0.5495144128799438\n",
            "loss in epoch 82 iteration 22: 0.5614168643951416\n",
            "loss in epoch 82 iteration 23: 0.5305395126342773\n",
            "loss in epoch 82 iteration 24: 0.5490766167640686\n",
            "loss in epoch 82 iteration 25: 0.5353618264198303\n",
            "loss in epoch 82 iteration 26: 0.5558777451515198\n",
            "loss in epoch 82 iteration 27: 0.5560121536254883\n",
            "loss in epoch 82 iteration 28: 0.5815311074256897\n",
            "loss in epoch 82 iteration 29: 0.5771968364715576\n",
            "loss in epoch 82 iteration 30: 0.575883150100708\n",
            "loss in epoch 82 iteration 31: 0.5769879221916199\n",
            "loss in epoch 82 iteration 32: 0.5800127983093262\n",
            "loss in epoch 82 iteration 33: 0.5728744864463806\n",
            "loss in epoch 82 iteration 34: 0.5689592361450195\n",
            "loss in epoch 82 iteration 35: 0.553028404712677\n",
            "loss in epoch 82 iteration 36: 0.5539391040802002\n",
            "loss in epoch 82 iteration 37: 0.5733579397201538\n",
            "loss in epoch 82 iteration 38: 0.5570172667503357\n",
            "loss in epoch 82 iteration 39: 0.5535096526145935\n",
            "loss in epoch 82 iteration 40: 0.5596798062324524\n",
            "loss in epoch 82 iteration 41: 0.5808831453323364\n",
            "loss in epoch 82 iteration 42: 0.5863792896270752\n",
            "loss in epoch 82 iteration 43: 0.5630632638931274\n",
            "loss in epoch 82 iteration 44: 0.6150596141815186\n",
            "loss in epoch 82 iteration 45: 0.582566499710083\n",
            "loss in epoch 82 iteration 46: 0.5682113170623779\n",
            "loss in epoch 82 iteration 47: 0.5758106708526611\n",
            "loss in epoch 82 iteration 48: 0.5515134930610657\n",
            "loss in epoch 82 iteration 49: 0.5739815831184387\n",
            "loss in epoch 82 iteration 50: 0.5677019357681274\n",
            "loss in epoch 82 iteration 51: 0.5267305374145508\n",
            "loss in epoch 82 iteration 52: 0.5706053972244263\n",
            "loss in epoch 82 iteration 53: 0.5746842622756958\n",
            "loss in epoch 82 iteration 54: 0.5699468851089478\n",
            "loss in epoch 82 iteration 55: 0.5385867357254028\n",
            "loss in epoch 82 iteration 56: 0.5604112148284912\n",
            "loss in epoch 82 iteration 57: 0.5551844835281372\n",
            "loss in epoch 82 iteration 58: 0.5589460134506226\n",
            "loss in epoch 82 iteration 59: 0.5747771263122559\n",
            "loss in epoch 82 iteration 60: 0.5632268190383911\n",
            "loss in epoch 82 iteration 61: 0.590947151184082\n",
            "loss in epoch 82 iteration 62: 0.5590996742248535\n",
            "loss in epoch 82 iteration 63: 0.547802209854126\n",
            "loss in epoch 82 iteration 64: 0.5751868486404419\n",
            "loss in epoch 82 iteration 65: 0.5845443606376648\n",
            "loss in epoch 82 iteration 66: 0.5353724956512451\n",
            "loss in epoch 82 iteration 67: 0.5468138456344604\n",
            "loss in epoch 82 iteration 68: 0.5661979913711548\n",
            "loss in epoch 82 iteration 69: 0.53726726770401\n",
            "loss in epoch 82 iteration 70: 0.5417289137840271\n",
            "loss in epoch 82 iteration 71: 0.555759847164154\n",
            "loss in epoch 82 iteration 72: 0.566673994064331\n",
            "loss in epoch 82 iteration 73: 0.5719345808029175\n",
            "loss in epoch 82 iteration 74: 0.5592423677444458\n",
            "loss in epoch 82 iteration 75: 0.5605528354644775\n",
            "loss in epoch 82 iteration 76: 0.549604058265686\n",
            "loss in epoch 82 iteration 77: 0.5784310102462769\n",
            "loss in epoch 82 iteration 78: 0.5776464939117432\n",
            "loss in epoch 82 iteration 79: 0.576548159122467\n",
            "loss in epoch 82 iteration 80: 0.5393584966659546\n",
            "loss in epoch 82 iteration 81: 0.5304890871047974\n",
            "loss in epoch 82 iteration 82: 0.5532786846160889\n",
            "loss in epoch 82 iteration 83: 0.536011815071106\n",
            "loss in epoch 82 iteration 84: 0.5742704272270203\n",
            "loss in epoch 82 iteration 85: 0.5804556608200073\n",
            "loss in epoch 82 iteration 86: 0.5552159547805786\n",
            "loss in epoch 82 iteration 87: 0.5425659418106079\n",
            "loss in epoch 82 iteration 88: 0.5535069108009338\n",
            "loss in epoch 82 iteration 89: 0.5635136961936951\n",
            "loss in epoch 82 iteration 90: 0.5685935020446777\n",
            "loss in epoch 82 iteration 91: 0.5461812615394592\n",
            "loss in epoch 82 iteration 92: 0.5807007551193237\n",
            "loss in epoch 82 iteration 93: 0.5637222528457642\n",
            "loss in epoch 82 iteration 94: 0.5670136213302612\n",
            "loss in epoch 82 iteration 95: 0.5573467016220093\n",
            "loss in epoch 82 iteration 96: 0.5757882595062256\n",
            "loss in epoch 82 iteration 97: 0.5781826972961426\n",
            "loss in epoch 82 iteration 98: 0.5756688117980957\n",
            "loss in epoch 82 iteration 99: 0.5642064809799194\n",
            "loss in epoch 82 iteration 100: 0.5626306533813477\n",
            "loss in epoch 82 iteration 101: 0.5600747466087341\n",
            "loss in epoch 82 iteration 102: 0.5794902443885803\n",
            "loss in epoch 82 iteration 103: 0.5698590278625488\n",
            "loss in epoch 82 iteration 104: 0.5645885467529297\n",
            "loss in epoch 82 iteration 105: 0.575947105884552\n",
            "loss in epoch 82 iteration 106: 0.5739766359329224\n",
            "loss in epoch 82 iteration 107: 0.5693671703338623\n",
            "loss in epoch 82 iteration 108: 0.5364208221435547\n",
            "loss in epoch 82 iteration 109: 0.5437874794006348\n",
            "loss in epoch 82 iteration 110: 0.5661187171936035\n",
            "loss in epoch 82 iteration 111: 0.544425368309021\n",
            "loss in epoch 82 iteration 112: 0.5565794110298157\n",
            "loss in epoch 82 iteration 113: 0.5641298294067383\n",
            "loss in epoch 82 iteration 114: 0.5525615215301514\n",
            "loss in epoch 82 iteration 115: 0.5544406771659851\n",
            "loss in epoch 82 iteration 116: 0.545364499092102\n",
            "loss in epoch 82 iteration 117: 0.5618051290512085\n",
            "loss in epoch 82 iteration 118: 0.5668854713439941\n",
            "loss in epoch 82 iteration 119: 0.5632765293121338\n",
            "loss in epoch 82 iteration 120: 0.5740401744842529\n",
            "loss in epoch 82 iteration 121: 0.5831475257873535\n",
            "loss in epoch 82 iteration 122: 0.5794995427131653\n",
            "loss in epoch 82 iteration 123: 0.5856888294219971\n",
            "loss in epoch 82 iteration 124: 0.5595985651016235\n",
            "loss in epoch 82 iteration 125: 0.5549548268318176\n",
            "loss in epoch 82 iteration 126: 0.5660073757171631\n",
            "loss in epoch 82 iteration 127: 0.5437783598899841\n",
            "loss in epoch 82 iteration 128: 0.5788410902023315\n",
            "loss in epoch 82 iteration 129: 0.5485995411872864\n",
            "loss in epoch 82 iteration 130: 0.56024169921875\n",
            "loss in epoch 82 iteration 131: 0.5398591160774231\n",
            "loss in epoch 82 iteration 132: 0.5650599598884583\n",
            "loss in epoch 82 iteration 133: 0.5329561233520508\n",
            "loss in epoch 82 iteration 134: 0.5641076564788818\n",
            "loss in epoch 82 iteration 135: 0.5508849620819092\n",
            "loss in epoch 82 iteration 136: 0.5414329767227173\n",
            "loss in epoch 82 iteration 137: 0.5744338035583496\n",
            "loss in epoch 82 iteration 138: 0.540371298789978\n",
            "loss in epoch 82 iteration 139: 0.553544282913208\n",
            "loss in epoch 82 iteration 140: 0.541033148765564\n",
            "loss in epoch 82 iteration 141: 0.558377742767334\n",
            "loss in epoch 82 iteration 142: 0.5354140400886536\n",
            "loss in epoch 82 iteration 143: 0.5549224615097046\n",
            "loss in epoch 82 iteration 144: 0.5821081399917603\n",
            "loss in epoch 82 iteration 145: 0.5499027967453003\n",
            "loss in epoch 82 iteration 146: 0.5399795770645142\n",
            "loss in epoch 82 iteration 147: 0.5542154312133789\n",
            "loss in epoch 82 iteration 148: 0.5720182061195374\n",
            "loss in epoch 82 iteration 149: 0.5989866256713867\n",
            "loss in epoch 82 iteration 150: 0.5742871761322021\n",
            "loss in epoch 82 iteration 151: 0.5649013519287109\n",
            "loss in epoch 82 iteration 152: 0.5470170974731445\n",
            "loss in epoch 82 iteration 153: 0.5577452778816223\n",
            "loss in epoch 82 iteration 154: 0.5834188461303711\n",
            "loss in epoch 82 iteration 155: 0.5856602191925049\n",
            "loss in epoch 82 iteration 156: 0.5624585151672363\n",
            "loss in epoch 82 iteration 157: 0.5620546936988831\n",
            "loss in epoch 82 iteration 158: 0.5671834349632263\n",
            "loss in epoch 82 iteration 159: 0.5657979846000671\n",
            "loss in epoch 82 iteration 160: 0.567060112953186\n",
            "loss in epoch 82 iteration 161: 0.5679143667221069\n",
            "loss in epoch 82 iteration 162: 0.5549734830856323\n",
            "loss in epoch 82 iteration 163: 0.5941258668899536\n",
            "loss in epoch 82 iteration 164: 0.5661097764968872\n",
            "loss in epoch 82 iteration 165: 0.5625318288803101\n",
            "loss in epoch 82 iteration 166: 0.5517563819885254\n",
            "loss in epoch 82 iteration 167: 0.5559200048446655\n",
            "loss in epoch 82 iteration 168: 0.5701075792312622\n",
            "loss in epoch 82 iteration 169: 0.566049337387085\n",
            "loss in epoch 82 iteration 170: 0.5707540512084961\n",
            "loss in epoch 82 iteration 171: 0.5396451950073242\n",
            "loss in epoch 82 iteration 172: 0.5383933782577515\n",
            "loss in epoch 82 iteration 173: 0.5828591585159302\n",
            "loss in epoch 82 iteration 174: 0.5863542556762695\n",
            "loss in epoch 82 iteration 175: 0.5418878793716431\n",
            "loss in epoch 82 iteration 176: 0.5605384111404419\n",
            "loss in epoch 82 iteration 177: 0.5702965259552002\n",
            "loss in epoch 82 iteration 178: 0.564906656742096\n",
            "loss in epoch 82 iteration 179: 0.5321449041366577\n",
            "loss in epoch 82 iteration 180: 0.5778670310974121\n",
            "loss in epoch 82 iteration 181: 0.5871970653533936\n",
            "loss in epoch 82 iteration 182: 0.5678278207778931\n",
            "loss in epoch 82 iteration 183: 0.5648771524429321\n",
            "loss in epoch 82 iteration 184: 0.5943251252174377\n",
            "loss in epoch 82 iteration 185: 0.5587268471717834\n",
            "loss in epoch 82 iteration 186: 0.5634256601333618\n",
            "loss in epoch 82 iteration 187: 0.5447819232940674\n",
            "loss in epoch 82 iteration 188: 0.5379083156585693\n",
            "loss in epoch 82 iteration 189: 0.5569863319396973\n",
            "loss in epoch 82 iteration 190: 0.573409914970398\n",
            "loss in epoch 82 iteration 191: 0.5978577136993408\n",
            "loss in epoch 82 iteration 192: 0.5622625350952148\n",
            "loss in epoch 82 iteration 193: 0.5433828830718994\n",
            "loss in epoch 82 iteration 194: 0.5447930693626404\n",
            "loss in epoch 82 iteration 195: 0.5615977048873901\n",
            "loss in epoch 82 iteration 196: 0.575934886932373\n",
            "loss in epoch 82 iteration 197: 0.5729647874832153\n",
            "loss in epoch 82 iteration 198: 0.5704891681671143\n",
            "loss in epoch 82 iteration 199: 0.5603643655776978\n",
            "loss in epoch 82 iteration 200: 0.5894912481307983\n",
            "loss in epoch 82 iteration 201: 0.5823813676834106\n",
            "loss in epoch 82 iteration 202: 0.5543003082275391\n",
            "loss in epoch 82 iteration 203: 0.5615002512931824\n",
            "loss in epoch 82 iteration 204: 0.5717939138412476\n",
            "loss in epoch 82 iteration 205: 0.5819023847579956\n",
            "loss in epoch 82 iteration 206: 0.541790783405304\n",
            "loss in epoch 82 iteration 207: 0.586917519569397\n",
            "loss in epoch 82 iteration 208: 0.5619461536407471\n",
            "loss in epoch 82 iteration 209: 0.5520134568214417\n",
            "loss in epoch 82 iteration 210: 0.5738658308982849\n",
            "loss in epoch 82 iteration 211: 0.5554608106613159\n",
            "loss in epoch 82 iteration 212: 0.5689896941184998\n",
            "loss in epoch 82 iteration 213: 0.5724648833274841\n",
            "loss in epoch 82 iteration 214: 0.557296633720398\n",
            "loss in epoch 82 iteration 215: 0.5918104648590088\n",
            "loss in epoch 82 iteration 216: 0.5537135601043701\n",
            "loss in epoch 82 iteration 217: 0.5383259057998657\n",
            "loss in epoch 82 iteration 218: 0.562919020652771\n",
            "loss in epoch 82 iteration 219: 0.5653565526008606\n",
            "loss in epoch 82 iteration 220: 0.5383553504943848\n",
            "loss in epoch 82 iteration 221: 0.5771260261535645\n",
            "loss in epoch 82 iteration 222: 0.5557579398155212\n",
            "loss in epoch 82 iteration 223: 0.578497588634491\n",
            "loss in epoch 82 iteration 224: 0.5444995164871216\n",
            "loss in epoch 82 iteration 225: 0.5754575729370117\n",
            "loss in epoch 82 iteration 226: 0.5464776754379272\n",
            "loss in epoch 82 iteration 227: 0.5708142518997192\n",
            "loss in epoch 82 iteration 228: 0.5505978465080261\n",
            "loss in epoch 82 iteration 229: 0.574629545211792\n",
            "loss in epoch 82 iteration 230: 0.5525950193405151\n",
            "loss in epoch 82 iteration 231: 0.5468255281448364\n",
            "loss in epoch 82 iteration 232: 0.5805202722549438\n",
            "loss in epoch 82 iteration 233: 0.5810913443565369\n",
            "loss in epoch 82 iteration 234: 0.5528814792633057\n",
            "loss in epoch 82 iteration 235: 0.563506007194519\n",
            "loss in epoch 82 iteration 236: 0.5520678758621216\n",
            "loss in epoch 82 iteration 237: 0.5417307615280151\n",
            "loss in epoch 82 iteration 238: 0.5550669431686401\n",
            "loss in epoch 82 iteration 239: 0.5414311289787292\n",
            "loss in epoch 82 iteration 240: 0.5447422862052917\n",
            "loss in epoch 82 iteration 241: 0.5704854130744934\n",
            "loss in epoch 82 iteration 242: 0.5522459745407104\n",
            "loss in epoch 83 iteration 0: 0.5446131825447083\n",
            "loss in epoch 83 iteration 1: 0.5498596429824829\n",
            "loss in epoch 83 iteration 2: 0.5685418844223022\n",
            "loss in epoch 83 iteration 3: 0.564059853553772\n",
            "loss in epoch 83 iteration 4: 0.5450394749641418\n",
            "loss in epoch 83 iteration 5: 0.553433895111084\n",
            "loss in epoch 83 iteration 6: 0.5518844723701477\n",
            "loss in epoch 83 iteration 7: 0.5754454135894775\n",
            "loss in epoch 83 iteration 8: 0.6136491298675537\n",
            "loss in epoch 83 iteration 9: 0.5636023283004761\n",
            "loss in epoch 83 iteration 10: 0.588321328163147\n",
            "loss in epoch 83 iteration 11: 0.5756564140319824\n",
            "loss in epoch 83 iteration 12: 0.5650174021720886\n",
            "loss in epoch 83 iteration 13: 0.5420570969581604\n",
            "loss in epoch 83 iteration 14: 0.5528489351272583\n",
            "loss in epoch 83 iteration 15: 0.558530330657959\n",
            "loss in epoch 83 iteration 16: 0.5790418982505798\n",
            "loss in epoch 83 iteration 17: 0.5798041820526123\n",
            "loss in epoch 83 iteration 18: 0.5426516532897949\n",
            "loss in epoch 83 iteration 19: 0.5613146424293518\n",
            "loss in epoch 83 iteration 20: 0.5644552111625671\n",
            "loss in epoch 83 iteration 21: 0.5551358461380005\n",
            "loss in epoch 83 iteration 22: 0.5703085660934448\n",
            "loss in epoch 83 iteration 23: 0.592510998249054\n",
            "loss in epoch 83 iteration 24: 0.54364013671875\n",
            "loss in epoch 83 iteration 25: 0.5340854525566101\n",
            "loss in epoch 83 iteration 26: 0.5769572257995605\n",
            "loss in epoch 83 iteration 27: 0.5538579225540161\n",
            "loss in epoch 83 iteration 28: 0.5542687773704529\n",
            "loss in epoch 83 iteration 29: 0.5746824145317078\n",
            "loss in epoch 83 iteration 30: 0.5698424577713013\n",
            "loss in epoch 83 iteration 31: 0.5421034097671509\n",
            "loss in epoch 83 iteration 32: 0.5573340654373169\n",
            "loss in epoch 83 iteration 33: 0.5869020223617554\n",
            "loss in epoch 83 iteration 34: 0.5578116178512573\n",
            "loss in epoch 83 iteration 35: 0.6008284091949463\n",
            "loss in epoch 83 iteration 36: 0.5485397577285767\n",
            "loss in epoch 83 iteration 37: 0.5762324333190918\n",
            "loss in epoch 83 iteration 38: 0.5707889795303345\n",
            "loss in epoch 83 iteration 39: 0.5711071491241455\n",
            "loss in epoch 83 iteration 40: 0.5510634779930115\n",
            "loss in epoch 83 iteration 41: 0.5551815032958984\n",
            "loss in epoch 83 iteration 42: 0.5535390377044678\n",
            "loss in epoch 83 iteration 43: 0.5621896982192993\n",
            "loss in epoch 83 iteration 44: 0.5743763446807861\n",
            "loss in epoch 83 iteration 45: 0.5632233619689941\n",
            "loss in epoch 83 iteration 46: 0.5649492144584656\n",
            "loss in epoch 83 iteration 47: 0.5580946803092957\n",
            "loss in epoch 83 iteration 48: 0.550900936126709\n",
            "loss in epoch 83 iteration 49: 0.5547807812690735\n",
            "loss in epoch 83 iteration 50: 0.5584745407104492\n",
            "loss in epoch 83 iteration 51: 0.5620737075805664\n",
            "loss in epoch 83 iteration 52: 0.5694922208786011\n",
            "loss in epoch 83 iteration 53: 0.5564782619476318\n",
            "loss in epoch 83 iteration 54: 0.5562856197357178\n",
            "loss in epoch 83 iteration 55: 0.5917659401893616\n",
            "loss in epoch 83 iteration 56: 0.6049871444702148\n",
            "loss in epoch 83 iteration 57: 0.5611025094985962\n",
            "loss in epoch 83 iteration 58: 0.5995291471481323\n",
            "loss in epoch 83 iteration 59: 0.5496635437011719\n",
            "loss in epoch 83 iteration 60: 0.5803543329238892\n",
            "loss in epoch 83 iteration 61: 0.5681560039520264\n",
            "loss in epoch 83 iteration 62: 0.5581579208374023\n",
            "loss in epoch 83 iteration 63: 0.555992603302002\n",
            "loss in epoch 83 iteration 64: 0.5566802620887756\n",
            "loss in epoch 83 iteration 65: 0.5587142705917358\n",
            "loss in epoch 83 iteration 66: 0.5478485822677612\n",
            "loss in epoch 83 iteration 67: 0.5908089280128479\n",
            "loss in epoch 83 iteration 68: 0.5871624946594238\n",
            "loss in epoch 83 iteration 69: 0.574938178062439\n",
            "loss in epoch 83 iteration 70: 0.567946195602417\n",
            "loss in epoch 83 iteration 71: 0.5527204275131226\n",
            "loss in epoch 83 iteration 72: 0.5784920454025269\n",
            "loss in epoch 83 iteration 73: 0.5540629625320435\n",
            "loss in epoch 83 iteration 74: 0.5747877359390259\n",
            "loss in epoch 83 iteration 75: 0.5801722407341003\n",
            "loss in epoch 83 iteration 76: 0.5272986888885498\n",
            "loss in epoch 83 iteration 77: 0.5709660053253174\n",
            "loss in epoch 83 iteration 78: 0.5813227891921997\n",
            "loss in epoch 83 iteration 79: 0.5711970329284668\n",
            "loss in epoch 83 iteration 80: 0.5726083517074585\n",
            "loss in epoch 83 iteration 81: 0.5893113613128662\n",
            "loss in epoch 83 iteration 82: 0.5375098586082458\n",
            "loss in epoch 83 iteration 83: 0.5791347026824951\n",
            "loss in epoch 83 iteration 84: 0.5692539811134338\n",
            "loss in epoch 83 iteration 85: 0.5479299426078796\n",
            "loss in epoch 83 iteration 86: 0.545243501663208\n",
            "loss in epoch 83 iteration 87: 0.5489349365234375\n",
            "loss in epoch 83 iteration 88: 0.553394079208374\n",
            "loss in epoch 83 iteration 89: 0.5357979536056519\n",
            "loss in epoch 83 iteration 90: 0.5629552602767944\n",
            "loss in epoch 83 iteration 91: 0.5558322668075562\n",
            "loss in epoch 83 iteration 92: 0.5800211429595947\n",
            "loss in epoch 83 iteration 93: 0.5494087338447571\n",
            "loss in epoch 83 iteration 94: 0.5726022124290466\n",
            "loss in epoch 83 iteration 95: 0.5636510848999023\n",
            "loss in epoch 83 iteration 96: 0.5781877040863037\n",
            "loss in epoch 83 iteration 97: 0.5642217993736267\n",
            "loss in epoch 83 iteration 98: 0.5679539442062378\n",
            "loss in epoch 83 iteration 99: 0.5639572143554688\n",
            "loss in epoch 83 iteration 100: 0.5795451402664185\n",
            "loss in epoch 83 iteration 101: 0.5563392043113708\n",
            "loss in epoch 83 iteration 102: 0.5762707591056824\n",
            "loss in epoch 83 iteration 103: 0.5558291077613831\n",
            "loss in epoch 83 iteration 104: 0.5474271774291992\n",
            "loss in epoch 83 iteration 105: 0.5829249620437622\n",
            "loss in epoch 83 iteration 106: 0.5816490650177002\n",
            "loss in epoch 83 iteration 107: 0.5648771524429321\n",
            "loss in epoch 83 iteration 108: 0.5683242082595825\n",
            "loss in epoch 83 iteration 109: 0.5521533489227295\n",
            "loss in epoch 83 iteration 110: 0.5778838992118835\n",
            "loss in epoch 83 iteration 111: 0.5613284707069397\n",
            "loss in epoch 83 iteration 112: 0.5684048533439636\n",
            "loss in epoch 83 iteration 113: 0.5773258209228516\n",
            "loss in epoch 83 iteration 114: 0.5363500118255615\n",
            "loss in epoch 83 iteration 115: 0.544242799282074\n",
            "loss in epoch 83 iteration 116: 0.5756255388259888\n",
            "loss in epoch 83 iteration 117: 0.5775381326675415\n",
            "loss in epoch 83 iteration 118: 0.5848079919815063\n",
            "loss in epoch 83 iteration 119: 0.5452821254730225\n",
            "loss in epoch 83 iteration 120: 0.5586764216423035\n",
            "loss in epoch 83 iteration 121: 0.571259617805481\n",
            "loss in epoch 83 iteration 122: 0.5766341090202332\n",
            "loss in epoch 83 iteration 123: 0.5438705682754517\n",
            "loss in epoch 83 iteration 124: 0.5921889543533325\n",
            "loss in epoch 83 iteration 125: 0.5689290761947632\n",
            "loss in epoch 83 iteration 126: 0.5281953811645508\n",
            "loss in epoch 83 iteration 127: 0.5633070468902588\n",
            "loss in epoch 83 iteration 128: 0.5764191150665283\n",
            "loss in epoch 83 iteration 129: 0.5613706111907959\n",
            "loss in epoch 83 iteration 130: 0.547146737575531\n",
            "loss in epoch 83 iteration 131: 0.5669718980789185\n",
            "loss in epoch 83 iteration 132: 0.561224102973938\n",
            "loss in epoch 83 iteration 133: 0.5721471309661865\n",
            "loss in epoch 83 iteration 134: 0.5448652505874634\n",
            "loss in epoch 83 iteration 135: 0.5505910515785217\n",
            "loss in epoch 83 iteration 136: 0.6009472608566284\n",
            "loss in epoch 83 iteration 137: 0.5719366073608398\n",
            "loss in epoch 83 iteration 138: 0.5681282877922058\n",
            "loss in epoch 83 iteration 139: 0.578112781047821\n",
            "loss in epoch 83 iteration 140: 0.5582281351089478\n",
            "loss in epoch 83 iteration 141: 0.5537547469139099\n",
            "loss in epoch 83 iteration 142: 0.559412956237793\n",
            "loss in epoch 83 iteration 143: 0.5631927251815796\n",
            "loss in epoch 83 iteration 144: 0.5522746443748474\n",
            "loss in epoch 83 iteration 145: 0.5713675618171692\n",
            "loss in epoch 83 iteration 146: 0.5729359984397888\n",
            "loss in epoch 83 iteration 147: 0.5893664360046387\n",
            "loss in epoch 83 iteration 148: 0.5795434713363647\n",
            "loss in epoch 83 iteration 149: 0.5503959059715271\n",
            "loss in epoch 83 iteration 150: 0.5898674726486206\n",
            "loss in epoch 83 iteration 151: 0.5331301689147949\n",
            "loss in epoch 83 iteration 152: 0.5528427362442017\n",
            "loss in epoch 83 iteration 153: 0.5878032445907593\n",
            "loss in epoch 83 iteration 154: 0.5626500844955444\n",
            "loss in epoch 83 iteration 155: 0.5279487371444702\n",
            "loss in epoch 83 iteration 156: 0.5712082386016846\n",
            "loss in epoch 83 iteration 157: 0.5751962661743164\n",
            "loss in epoch 83 iteration 158: 0.5715525150299072\n",
            "loss in epoch 83 iteration 159: 0.5694454908370972\n",
            "loss in epoch 83 iteration 160: 0.565589964389801\n",
            "loss in epoch 83 iteration 161: 0.5884574055671692\n",
            "loss in epoch 83 iteration 162: 0.5533155798912048\n",
            "loss in epoch 83 iteration 163: 0.558272123336792\n",
            "loss in epoch 83 iteration 164: 0.5387656092643738\n",
            "loss in epoch 83 iteration 165: 0.5753921270370483\n",
            "loss in epoch 83 iteration 166: 0.5690650939941406\n",
            "loss in epoch 83 iteration 167: 0.5473311543464661\n",
            "loss in epoch 83 iteration 168: 0.5324931144714355\n",
            "loss in epoch 83 iteration 169: 0.5736186504364014\n",
            "loss in epoch 83 iteration 170: 0.5941743850708008\n",
            "loss in epoch 83 iteration 171: 0.5501419901847839\n",
            "loss in epoch 83 iteration 172: 0.557571530342102\n",
            "loss in epoch 83 iteration 173: 0.5509941577911377\n",
            "loss in epoch 83 iteration 174: 0.5569390058517456\n",
            "loss in epoch 83 iteration 175: 0.5713024139404297\n",
            "loss in epoch 83 iteration 176: 0.5745866298675537\n",
            "loss in epoch 83 iteration 177: 0.5735711455345154\n",
            "loss in epoch 83 iteration 178: 0.5426057577133179\n",
            "loss in epoch 83 iteration 179: 0.5486621856689453\n",
            "loss in epoch 83 iteration 180: 0.5437936782836914\n",
            "loss in epoch 83 iteration 181: 0.5598964095115662\n",
            "loss in epoch 83 iteration 182: 0.5672113299369812\n",
            "loss in epoch 83 iteration 183: 0.5478636622428894\n",
            "loss in epoch 83 iteration 184: 0.5455423593521118\n",
            "loss in epoch 83 iteration 185: 0.560883641242981\n",
            "loss in epoch 83 iteration 186: 0.5621163845062256\n",
            "loss in epoch 83 iteration 187: 0.565209686756134\n",
            "loss in epoch 83 iteration 188: 0.5606467723846436\n",
            "loss in epoch 83 iteration 189: 0.557496190071106\n",
            "loss in epoch 83 iteration 190: 0.5775473713874817\n",
            "loss in epoch 83 iteration 191: 0.5524388551712036\n",
            "loss in epoch 83 iteration 192: 0.5773036479949951\n",
            "loss in epoch 83 iteration 193: 0.5844279527664185\n",
            "loss in epoch 83 iteration 194: 0.5590042471885681\n",
            "loss in epoch 83 iteration 195: 0.580112874507904\n",
            "loss in epoch 83 iteration 196: 0.5812336206436157\n",
            "loss in epoch 83 iteration 197: 0.5632543563842773\n",
            "loss in epoch 83 iteration 198: 0.5650033950805664\n",
            "loss in epoch 83 iteration 199: 0.5600180625915527\n",
            "loss in epoch 83 iteration 200: 0.5586714148521423\n",
            "loss in epoch 83 iteration 201: 0.5576007962226868\n",
            "loss in epoch 83 iteration 202: 0.5910824537277222\n",
            "loss in epoch 83 iteration 203: 0.5776441097259521\n",
            "loss in epoch 83 iteration 204: 0.5348783731460571\n",
            "loss in epoch 83 iteration 205: 0.5406768321990967\n",
            "loss in epoch 83 iteration 206: 0.5876756906509399\n",
            "loss in epoch 83 iteration 207: 0.54494309425354\n",
            "loss in epoch 83 iteration 208: 0.5639622807502747\n",
            "loss in epoch 83 iteration 209: 0.566232442855835\n",
            "loss in epoch 83 iteration 210: 0.5588487386703491\n",
            "loss in epoch 83 iteration 211: 0.5695229768753052\n",
            "loss in epoch 83 iteration 212: 0.5699596405029297\n",
            "loss in epoch 83 iteration 213: 0.5896357297897339\n",
            "loss in epoch 83 iteration 214: 0.5631304979324341\n",
            "loss in epoch 83 iteration 215: 0.5606440901756287\n",
            "loss in epoch 83 iteration 216: 0.5669116377830505\n",
            "loss in epoch 83 iteration 217: 0.5679334998130798\n",
            "loss in epoch 83 iteration 218: 0.5517289042472839\n",
            "loss in epoch 83 iteration 219: 0.5589531660079956\n",
            "loss in epoch 83 iteration 220: 0.5737340450286865\n",
            "loss in epoch 83 iteration 221: 0.5767717957496643\n",
            "loss in epoch 83 iteration 222: 0.5741432905197144\n",
            "loss in epoch 83 iteration 223: 0.5571351051330566\n",
            "loss in epoch 83 iteration 224: 0.5426161289215088\n",
            "loss in epoch 83 iteration 225: 0.5441870093345642\n",
            "loss in epoch 83 iteration 226: 0.5704512596130371\n",
            "loss in epoch 83 iteration 227: 0.5510829091072083\n",
            "loss in epoch 83 iteration 228: 0.5658668279647827\n",
            "loss in epoch 83 iteration 229: 0.5709415674209595\n",
            "loss in epoch 83 iteration 230: 0.5993427038192749\n",
            "loss in epoch 83 iteration 231: 0.5732566118240356\n",
            "loss in epoch 83 iteration 232: 0.550899863243103\n",
            "loss in epoch 83 iteration 233: 0.5678942799568176\n",
            "loss in epoch 83 iteration 234: 0.5299514532089233\n",
            "loss in epoch 83 iteration 235: 0.549636960029602\n",
            "loss in epoch 83 iteration 236: 0.5609267950057983\n",
            "loss in epoch 83 iteration 237: 0.5579843521118164\n",
            "loss in epoch 83 iteration 238: 0.5564655065536499\n",
            "loss in epoch 83 iteration 239: 0.5566126108169556\n",
            "loss in epoch 83 iteration 240: 0.5680966377258301\n",
            "loss in epoch 83 iteration 241: 0.5655642151832581\n",
            "loss in epoch 83 iteration 242: 0.5830494165420532\n",
            "loss in epoch 84 iteration 0: 0.5834420919418335\n",
            "loss in epoch 84 iteration 1: 0.5566068887710571\n",
            "loss in epoch 84 iteration 2: 0.5759670734405518\n",
            "loss in epoch 84 iteration 3: 0.5477727651596069\n",
            "loss in epoch 84 iteration 4: 0.5641236305236816\n",
            "loss in epoch 84 iteration 5: 0.5535902976989746\n",
            "loss in epoch 84 iteration 6: 0.5535265803337097\n",
            "loss in epoch 84 iteration 7: 0.5737890005111694\n",
            "loss in epoch 84 iteration 8: 0.5600855350494385\n",
            "loss in epoch 84 iteration 9: 0.5633934736251831\n",
            "loss in epoch 84 iteration 10: 0.5393048524856567\n",
            "loss in epoch 84 iteration 11: 0.5808134078979492\n",
            "loss in epoch 84 iteration 12: 0.5524741411209106\n",
            "loss in epoch 84 iteration 13: 0.5555515885353088\n",
            "loss in epoch 84 iteration 14: 0.5479117631912231\n",
            "loss in epoch 84 iteration 15: 0.5830447673797607\n",
            "loss in epoch 84 iteration 16: 0.5358313322067261\n",
            "loss in epoch 84 iteration 17: 0.5813479423522949\n",
            "loss in epoch 84 iteration 18: 0.5734769105911255\n",
            "loss in epoch 84 iteration 19: 0.5856449604034424\n",
            "loss in epoch 84 iteration 20: 0.5489049553871155\n",
            "loss in epoch 84 iteration 21: 0.5498824119567871\n",
            "loss in epoch 84 iteration 22: 0.5510738492012024\n",
            "loss in epoch 84 iteration 23: 0.5371696352958679\n",
            "loss in epoch 84 iteration 24: 0.5716855525970459\n",
            "loss in epoch 84 iteration 25: 0.5574589967727661\n",
            "loss in epoch 84 iteration 26: 0.5734020471572876\n",
            "loss in epoch 84 iteration 27: 0.5673894882202148\n",
            "loss in epoch 84 iteration 28: 0.5724372863769531\n",
            "loss in epoch 84 iteration 29: 0.5772451162338257\n",
            "loss in epoch 84 iteration 30: 0.5746817588806152\n",
            "loss in epoch 84 iteration 31: 0.5747416019439697\n",
            "loss in epoch 84 iteration 32: 0.5820722579956055\n",
            "loss in epoch 84 iteration 33: 0.559977114200592\n",
            "loss in epoch 84 iteration 34: 0.5544891357421875\n",
            "loss in epoch 84 iteration 35: 0.5682708621025085\n",
            "loss in epoch 84 iteration 36: 0.5659215450286865\n",
            "loss in epoch 84 iteration 37: 0.5565994381904602\n",
            "loss in epoch 84 iteration 38: 0.546686053276062\n",
            "loss in epoch 84 iteration 39: 0.5361395478248596\n",
            "loss in epoch 84 iteration 40: 0.5677158832550049\n",
            "loss in epoch 84 iteration 41: 0.55025315284729\n",
            "loss in epoch 84 iteration 42: 0.5769791603088379\n",
            "loss in epoch 84 iteration 43: 0.5918340682983398\n",
            "loss in epoch 84 iteration 44: 0.5545557141304016\n",
            "loss in epoch 84 iteration 45: 0.5439284443855286\n",
            "loss in epoch 84 iteration 46: 0.5684691071510315\n",
            "loss in epoch 84 iteration 47: 0.557604968547821\n",
            "loss in epoch 84 iteration 48: 0.5764911770820618\n",
            "loss in epoch 84 iteration 49: 0.5918951630592346\n",
            "loss in epoch 84 iteration 50: 0.5692594051361084\n",
            "loss in epoch 84 iteration 51: 0.5399792194366455\n",
            "loss in epoch 84 iteration 52: 0.5634946823120117\n",
            "loss in epoch 84 iteration 53: 0.5667896866798401\n",
            "loss in epoch 84 iteration 54: 0.5832860469818115\n",
            "loss in epoch 84 iteration 55: 0.5638787150382996\n",
            "loss in epoch 84 iteration 56: 0.5493311882019043\n",
            "loss in epoch 84 iteration 57: 0.5522727370262146\n",
            "loss in epoch 84 iteration 58: 0.5750503540039062\n",
            "loss in epoch 84 iteration 59: 0.5771884322166443\n",
            "loss in epoch 84 iteration 60: 0.5631188154220581\n",
            "loss in epoch 84 iteration 61: 0.5416585206985474\n",
            "loss in epoch 84 iteration 62: 0.5881504416465759\n",
            "loss in epoch 84 iteration 63: 0.5463225841522217\n",
            "loss in epoch 84 iteration 64: 0.5445075035095215\n",
            "loss in epoch 84 iteration 65: 0.5403966903686523\n",
            "loss in epoch 84 iteration 66: 0.5844569206237793\n",
            "loss in epoch 84 iteration 67: 0.561465859413147\n",
            "loss in epoch 84 iteration 68: 0.5661513209342957\n",
            "loss in epoch 84 iteration 69: 0.5691217184066772\n",
            "loss in epoch 84 iteration 70: 0.551013708114624\n",
            "loss in epoch 84 iteration 71: 0.579963743686676\n",
            "loss in epoch 84 iteration 72: 0.5422441959381104\n",
            "loss in epoch 84 iteration 73: 0.5450856685638428\n",
            "loss in epoch 84 iteration 74: 0.571346640586853\n",
            "loss in epoch 84 iteration 75: 0.585174560546875\n",
            "loss in epoch 84 iteration 76: 0.571091890335083\n",
            "loss in epoch 84 iteration 77: 0.5573675036430359\n",
            "loss in epoch 84 iteration 78: 0.5421859622001648\n",
            "loss in epoch 84 iteration 79: 0.5842517614364624\n",
            "loss in epoch 84 iteration 80: 0.5310667753219604\n",
            "loss in epoch 84 iteration 81: 0.5673319697380066\n",
            "loss in epoch 84 iteration 82: 0.5530030727386475\n",
            "loss in epoch 84 iteration 83: 0.5880506038665771\n",
            "loss in epoch 84 iteration 84: 0.5750242471694946\n",
            "loss in epoch 84 iteration 85: 0.5437050461769104\n",
            "loss in epoch 84 iteration 86: 0.5710012912750244\n",
            "loss in epoch 84 iteration 87: 0.5671181082725525\n",
            "loss in epoch 84 iteration 88: 0.5746792554855347\n",
            "loss in epoch 84 iteration 89: 0.5780379772186279\n",
            "loss in epoch 84 iteration 90: 0.5728693604469299\n",
            "loss in epoch 84 iteration 91: 0.5788350701332092\n",
            "loss in epoch 84 iteration 92: 0.5811277627944946\n",
            "loss in epoch 84 iteration 93: 0.5613641738891602\n",
            "loss in epoch 84 iteration 94: 0.5893668532371521\n",
            "loss in epoch 84 iteration 95: 0.5513112545013428\n",
            "loss in epoch 84 iteration 96: 0.5708494186401367\n",
            "loss in epoch 84 iteration 97: 0.5504966974258423\n",
            "loss in epoch 84 iteration 98: 0.5591942667961121\n",
            "loss in epoch 84 iteration 99: 0.5644797086715698\n",
            "loss in epoch 84 iteration 100: 0.5672783851623535\n",
            "loss in epoch 84 iteration 101: 0.5749413371086121\n",
            "loss in epoch 84 iteration 102: 0.5488577485084534\n",
            "loss in epoch 84 iteration 103: 0.5564691424369812\n",
            "loss in epoch 84 iteration 104: 0.5507763624191284\n",
            "loss in epoch 84 iteration 105: 0.5447732210159302\n",
            "loss in epoch 84 iteration 106: 0.5548360347747803\n",
            "loss in epoch 84 iteration 107: 0.5636945366859436\n",
            "loss in epoch 84 iteration 108: 0.5723345279693604\n",
            "loss in epoch 84 iteration 109: 0.5617930293083191\n",
            "loss in epoch 84 iteration 110: 0.5519070625305176\n",
            "loss in epoch 84 iteration 111: 0.5777608156204224\n",
            "loss in epoch 84 iteration 112: 0.546572208404541\n",
            "loss in epoch 84 iteration 113: 0.5846127271652222\n",
            "loss in epoch 84 iteration 114: 0.5797881484031677\n",
            "loss in epoch 84 iteration 115: 0.5790331363677979\n",
            "loss in epoch 84 iteration 116: 0.5720276832580566\n",
            "loss in epoch 84 iteration 117: 0.5923326015472412\n",
            "loss in epoch 84 iteration 118: 0.566502034664154\n",
            "loss in epoch 84 iteration 119: 0.5554982423782349\n",
            "loss in epoch 84 iteration 120: 0.5532891750335693\n",
            "loss in epoch 84 iteration 121: 0.5311998128890991\n",
            "loss in epoch 84 iteration 122: 0.572594165802002\n",
            "loss in epoch 84 iteration 123: 0.5474932789802551\n",
            "loss in epoch 84 iteration 124: 0.5535541772842407\n",
            "loss in epoch 84 iteration 125: 0.5455167293548584\n",
            "loss in epoch 84 iteration 126: 0.5664184093475342\n",
            "loss in epoch 84 iteration 127: 0.5608201026916504\n",
            "loss in epoch 84 iteration 128: 0.5434391498565674\n",
            "loss in epoch 84 iteration 129: 0.5580720901489258\n",
            "loss in epoch 84 iteration 130: 0.5778408050537109\n",
            "loss in epoch 84 iteration 131: 0.5561867356300354\n",
            "loss in epoch 84 iteration 132: 0.5474183559417725\n",
            "loss in epoch 84 iteration 133: 0.5693151950836182\n",
            "loss in epoch 84 iteration 134: 0.5704869627952576\n",
            "loss in epoch 84 iteration 135: 0.548423707485199\n",
            "loss in epoch 84 iteration 136: 0.5633978843688965\n",
            "loss in epoch 84 iteration 137: 0.549675464630127\n",
            "loss in epoch 84 iteration 138: 0.5482265949249268\n",
            "loss in epoch 84 iteration 139: 0.561102032661438\n",
            "loss in epoch 84 iteration 140: 0.5586867332458496\n",
            "loss in epoch 84 iteration 141: 0.5652386546134949\n",
            "loss in epoch 84 iteration 142: 0.5408656597137451\n",
            "loss in epoch 84 iteration 143: 0.571706235408783\n",
            "loss in epoch 84 iteration 144: 0.5766451358795166\n",
            "loss in epoch 84 iteration 145: 0.5690253973007202\n",
            "loss in epoch 84 iteration 146: 0.579724133014679\n",
            "loss in epoch 84 iteration 147: 0.567726194858551\n",
            "loss in epoch 84 iteration 148: 0.5712695121765137\n",
            "loss in epoch 84 iteration 149: 0.5647974014282227\n",
            "loss in epoch 84 iteration 150: 0.5668730139732361\n",
            "loss in epoch 84 iteration 151: 0.5550903081893921\n",
            "loss in epoch 84 iteration 152: 0.5772238969802856\n",
            "loss in epoch 84 iteration 153: 0.587735652923584\n",
            "loss in epoch 84 iteration 154: 0.5670654773712158\n",
            "loss in epoch 84 iteration 155: 0.5730140209197998\n",
            "loss in epoch 84 iteration 156: 0.5512974858283997\n",
            "loss in epoch 84 iteration 157: 0.5649734735488892\n",
            "loss in epoch 84 iteration 158: 0.5718685388565063\n",
            "loss in epoch 84 iteration 159: 0.5565953254699707\n",
            "loss in epoch 84 iteration 160: 0.5177944302558899\n",
            "loss in epoch 84 iteration 161: 0.5483119487762451\n",
            "loss in epoch 84 iteration 162: 0.5612899661064148\n",
            "loss in epoch 84 iteration 163: 0.5786139369010925\n",
            "loss in epoch 84 iteration 164: 0.575899600982666\n",
            "loss in epoch 84 iteration 165: 0.5662789344787598\n",
            "loss in epoch 84 iteration 166: 0.5653243064880371\n",
            "loss in epoch 84 iteration 167: 0.563125491142273\n",
            "loss in epoch 84 iteration 168: 0.5676370859146118\n",
            "loss in epoch 84 iteration 169: 0.5503538846969604\n",
            "loss in epoch 84 iteration 170: 0.5846354961395264\n",
            "loss in epoch 84 iteration 171: 0.5477386713027954\n",
            "loss in epoch 84 iteration 172: 0.5887914896011353\n",
            "loss in epoch 84 iteration 173: 0.560871958732605\n",
            "loss in epoch 84 iteration 174: 0.5605716109275818\n",
            "loss in epoch 84 iteration 175: 0.5560551881790161\n",
            "loss in epoch 84 iteration 176: 0.5706689357757568\n",
            "loss in epoch 84 iteration 177: 0.569805920124054\n",
            "loss in epoch 84 iteration 178: 0.5676597356796265\n",
            "loss in epoch 84 iteration 179: 0.5655837059020996\n",
            "loss in epoch 84 iteration 180: 0.5326606035232544\n",
            "loss in epoch 84 iteration 181: 0.549997091293335\n",
            "loss in epoch 84 iteration 182: 0.5788463950157166\n",
            "loss in epoch 84 iteration 183: 0.5446683764457703\n",
            "loss in epoch 84 iteration 184: 0.5720822811126709\n",
            "loss in epoch 84 iteration 185: 0.5485194325447083\n",
            "loss in epoch 84 iteration 186: 0.5468143224716187\n",
            "loss in epoch 84 iteration 187: 0.5642045140266418\n",
            "loss in epoch 84 iteration 188: 0.571007251739502\n",
            "loss in epoch 84 iteration 189: 0.5648657083511353\n",
            "loss in epoch 84 iteration 190: 0.5408033132553101\n",
            "loss in epoch 84 iteration 191: 0.5822292566299438\n",
            "loss in epoch 84 iteration 192: 0.5991898775100708\n",
            "loss in epoch 84 iteration 193: 0.5626492500305176\n",
            "loss in epoch 84 iteration 194: 0.576477587223053\n",
            "loss in epoch 84 iteration 195: 0.561118483543396\n",
            "loss in epoch 84 iteration 196: 0.5717788934707642\n",
            "loss in epoch 84 iteration 197: 0.5531470775604248\n",
            "loss in epoch 84 iteration 198: 0.5697870254516602\n",
            "loss in epoch 84 iteration 199: 0.5827275514602661\n",
            "loss in epoch 84 iteration 200: 0.5565518140792847\n",
            "loss in epoch 84 iteration 201: 0.5424643158912659\n",
            "loss in epoch 84 iteration 202: 0.564857542514801\n",
            "loss in epoch 84 iteration 203: 0.5558243989944458\n",
            "loss in epoch 84 iteration 204: 0.5629149675369263\n",
            "loss in epoch 84 iteration 205: 0.525591254234314\n",
            "loss in epoch 84 iteration 206: 0.565983772277832\n",
            "loss in epoch 84 iteration 207: 0.5494816303253174\n",
            "loss in epoch 84 iteration 208: 0.5741572380065918\n",
            "loss in epoch 84 iteration 209: 0.5624933242797852\n",
            "loss in epoch 84 iteration 210: 0.5354161262512207\n",
            "loss in epoch 84 iteration 211: 0.5666484236717224\n",
            "loss in epoch 84 iteration 212: 0.5438584089279175\n",
            "loss in epoch 84 iteration 213: 0.5594316124916077\n",
            "loss in epoch 84 iteration 214: 0.5715668201446533\n",
            "loss in epoch 84 iteration 215: 0.5406016111373901\n",
            "loss in epoch 84 iteration 216: 0.5722881555557251\n",
            "loss in epoch 84 iteration 217: 0.5793464779853821\n",
            "loss in epoch 84 iteration 218: 0.5547277331352234\n",
            "loss in epoch 84 iteration 219: 0.5497453212738037\n",
            "loss in epoch 84 iteration 220: 0.5699164271354675\n",
            "loss in epoch 84 iteration 221: 0.5682660341262817\n",
            "loss in epoch 84 iteration 222: 0.5405980944633484\n",
            "loss in epoch 84 iteration 223: 0.5705711245536804\n",
            "loss in epoch 84 iteration 224: 0.5399240851402283\n",
            "loss in epoch 84 iteration 225: 0.5605728626251221\n",
            "loss in epoch 84 iteration 226: 0.5470726490020752\n",
            "loss in epoch 84 iteration 227: 0.5803073644638062\n",
            "loss in epoch 84 iteration 228: 0.5545089840888977\n",
            "loss in epoch 84 iteration 229: 0.5394601821899414\n",
            "loss in epoch 84 iteration 230: 0.5555022954940796\n",
            "loss in epoch 84 iteration 231: 0.5777685642242432\n",
            "loss in epoch 84 iteration 232: 0.567715048789978\n",
            "loss in epoch 84 iteration 233: 0.5705010890960693\n",
            "loss in epoch 84 iteration 234: 0.5882903933525085\n",
            "loss in epoch 84 iteration 235: 0.562084436416626\n",
            "loss in epoch 84 iteration 236: 0.5588749647140503\n",
            "loss in epoch 84 iteration 237: 0.5590832233428955\n",
            "loss in epoch 84 iteration 238: 0.5764355659484863\n",
            "loss in epoch 84 iteration 239: 0.5415924191474915\n",
            "loss in epoch 84 iteration 240: 0.5608417987823486\n",
            "loss in epoch 84 iteration 241: 0.593692421913147\n",
            "loss in epoch 84 iteration 242: 0.5714428424835205\n",
            "loss in epoch 85 iteration 0: 0.5573514103889465\n",
            "loss in epoch 85 iteration 1: 0.5755836963653564\n",
            "loss in epoch 85 iteration 2: 0.5735199451446533\n",
            "loss in epoch 85 iteration 3: 0.5646917819976807\n",
            "loss in epoch 85 iteration 4: 0.5599571466445923\n",
            "loss in epoch 85 iteration 5: 0.5455542802810669\n",
            "loss in epoch 85 iteration 6: 0.5520839691162109\n",
            "loss in epoch 85 iteration 7: 0.5225397348403931\n",
            "loss in epoch 85 iteration 8: 0.5680561065673828\n",
            "loss in epoch 85 iteration 9: 0.5568190813064575\n",
            "loss in epoch 85 iteration 10: 0.555568516254425\n",
            "loss in epoch 85 iteration 11: 0.5532546043395996\n",
            "loss in epoch 85 iteration 12: 0.5685728788375854\n",
            "loss in epoch 85 iteration 13: 0.5806032419204712\n",
            "loss in epoch 85 iteration 14: 0.5576190948486328\n",
            "loss in epoch 85 iteration 15: 0.5773351192474365\n",
            "loss in epoch 85 iteration 16: 0.5862201452255249\n",
            "loss in epoch 85 iteration 17: 0.5637159943580627\n",
            "loss in epoch 85 iteration 18: 0.5386300086975098\n",
            "loss in epoch 85 iteration 19: 0.5729740858078003\n",
            "loss in epoch 85 iteration 20: 0.5918432474136353\n",
            "loss in epoch 85 iteration 21: 0.5912164449691772\n",
            "loss in epoch 85 iteration 22: 0.5726075172424316\n",
            "loss in epoch 85 iteration 23: 0.5715255737304688\n",
            "loss in epoch 85 iteration 24: 0.5915757417678833\n",
            "loss in epoch 85 iteration 25: 0.5768224000930786\n",
            "loss in epoch 85 iteration 26: 0.5677620768547058\n",
            "loss in epoch 85 iteration 27: 0.5689032673835754\n",
            "loss in epoch 85 iteration 28: 0.5561359524726868\n",
            "loss in epoch 85 iteration 29: 0.5847511291503906\n",
            "loss in epoch 85 iteration 30: 0.5534926652908325\n",
            "loss in epoch 85 iteration 31: 0.5786808729171753\n",
            "loss in epoch 85 iteration 32: 0.5557219386100769\n",
            "loss in epoch 85 iteration 33: 0.5799169540405273\n",
            "loss in epoch 85 iteration 34: 0.591774582862854\n",
            "loss in epoch 85 iteration 35: 0.5722097158432007\n",
            "loss in epoch 85 iteration 36: 0.5490431785583496\n",
            "loss in epoch 85 iteration 37: 0.5472651720046997\n",
            "loss in epoch 85 iteration 38: 0.5333021879196167\n",
            "loss in epoch 85 iteration 39: 0.5851832032203674\n",
            "loss in epoch 85 iteration 40: 0.5554261207580566\n",
            "loss in epoch 85 iteration 41: 0.573418915271759\n",
            "loss in epoch 85 iteration 42: 0.5622703433036804\n",
            "loss in epoch 85 iteration 43: 0.5624912977218628\n",
            "loss in epoch 85 iteration 44: 0.5489283800125122\n",
            "loss in epoch 85 iteration 45: 0.5542306303977966\n",
            "loss in epoch 85 iteration 46: 0.583033561706543\n",
            "loss in epoch 85 iteration 47: 0.5694037079811096\n",
            "loss in epoch 85 iteration 48: 0.5451754331588745\n",
            "loss in epoch 85 iteration 49: 0.5831820964813232\n",
            "loss in epoch 85 iteration 50: 0.5653588771820068\n",
            "loss in epoch 85 iteration 51: 0.5485097169876099\n",
            "loss in epoch 85 iteration 52: 0.5727155208587646\n",
            "loss in epoch 85 iteration 53: 0.5590006113052368\n",
            "loss in epoch 85 iteration 54: 0.5696284174919128\n",
            "loss in epoch 85 iteration 55: 0.5719476342201233\n",
            "loss in epoch 85 iteration 56: 0.5719627141952515\n",
            "loss in epoch 85 iteration 57: 0.581684947013855\n",
            "loss in epoch 85 iteration 58: 0.550141453742981\n",
            "loss in epoch 85 iteration 59: 0.5597237348556519\n",
            "loss in epoch 85 iteration 60: 0.570595383644104\n",
            "loss in epoch 85 iteration 61: 0.5496394038200378\n",
            "loss in epoch 85 iteration 62: 0.5784642696380615\n",
            "loss in epoch 85 iteration 63: 0.5685292482376099\n",
            "loss in epoch 85 iteration 64: 0.5737789869308472\n",
            "loss in epoch 85 iteration 65: 0.5694042444229126\n",
            "loss in epoch 85 iteration 66: 0.5712969303131104\n",
            "loss in epoch 85 iteration 67: 0.5849798917770386\n",
            "loss in epoch 85 iteration 68: 0.5400140285491943\n",
            "loss in epoch 85 iteration 69: 0.5766175985336304\n",
            "loss in epoch 85 iteration 70: 0.5696971416473389\n",
            "loss in epoch 85 iteration 71: 0.579301118850708\n",
            "loss in epoch 85 iteration 72: 0.5373902916908264\n",
            "loss in epoch 85 iteration 73: 0.5604008436203003\n",
            "loss in epoch 85 iteration 74: 0.5434844493865967\n",
            "loss in epoch 85 iteration 75: 0.5498534440994263\n",
            "loss in epoch 85 iteration 76: 0.5770759582519531\n",
            "loss in epoch 85 iteration 77: 0.557007908821106\n",
            "loss in epoch 85 iteration 78: 0.5722599029541016\n",
            "loss in epoch 85 iteration 79: 0.5491524934768677\n",
            "loss in epoch 85 iteration 80: 0.5724599957466125\n",
            "loss in epoch 85 iteration 81: 0.57197105884552\n",
            "loss in epoch 85 iteration 82: 0.5791081786155701\n",
            "loss in epoch 85 iteration 83: 0.5143515467643738\n",
            "loss in epoch 85 iteration 84: 0.539851188659668\n",
            "loss in epoch 85 iteration 85: 0.5411840677261353\n",
            "loss in epoch 85 iteration 86: 0.5636061429977417\n",
            "loss in epoch 85 iteration 87: 0.5674049258232117\n",
            "loss in epoch 85 iteration 88: 0.5660592317581177\n",
            "loss in epoch 85 iteration 89: 0.5657628774642944\n",
            "loss in epoch 85 iteration 90: 0.5535287261009216\n",
            "loss in epoch 85 iteration 91: 0.556242823600769\n",
            "loss in epoch 85 iteration 92: 0.5796413421630859\n",
            "loss in epoch 85 iteration 93: 0.5724300146102905\n",
            "loss in epoch 85 iteration 94: 0.5930401682853699\n",
            "loss in epoch 85 iteration 95: 0.5553427338600159\n",
            "loss in epoch 85 iteration 96: 0.5485444068908691\n",
            "loss in epoch 85 iteration 97: 0.5382215976715088\n",
            "loss in epoch 85 iteration 98: 0.546596884727478\n",
            "loss in epoch 85 iteration 99: 0.5651804208755493\n",
            "loss in epoch 85 iteration 100: 0.5717741847038269\n",
            "loss in epoch 85 iteration 101: 0.5602888464927673\n",
            "loss in epoch 85 iteration 102: 0.5248602628707886\n",
            "loss in epoch 85 iteration 103: 0.5694896578788757\n",
            "loss in epoch 85 iteration 104: 0.5872937440872192\n",
            "loss in epoch 85 iteration 105: 0.5550109148025513\n",
            "loss in epoch 85 iteration 106: 0.5617243051528931\n",
            "loss in epoch 85 iteration 107: 0.5784497261047363\n",
            "loss in epoch 85 iteration 108: 0.5694241523742676\n",
            "loss in epoch 85 iteration 109: 0.579755961894989\n",
            "loss in epoch 85 iteration 110: 0.5700783729553223\n",
            "loss in epoch 85 iteration 111: 0.561198353767395\n",
            "loss in epoch 85 iteration 112: 0.5236436724662781\n",
            "loss in epoch 85 iteration 113: 0.5690818428993225\n",
            "loss in epoch 85 iteration 114: 0.5930346846580505\n",
            "loss in epoch 85 iteration 115: 0.5670653581619263\n",
            "loss in epoch 85 iteration 116: 0.5868042707443237\n",
            "loss in epoch 85 iteration 117: 0.5513378381729126\n",
            "loss in epoch 85 iteration 118: 0.5602201223373413\n",
            "loss in epoch 85 iteration 119: 0.5368335247039795\n",
            "loss in epoch 85 iteration 120: 0.5504916310310364\n",
            "loss in epoch 85 iteration 121: 0.5678333044052124\n",
            "loss in epoch 85 iteration 122: 0.53507000207901\n",
            "loss in epoch 85 iteration 123: 0.5583465099334717\n",
            "loss in epoch 85 iteration 124: 0.5708497762680054\n",
            "loss in epoch 85 iteration 125: 0.5757404565811157\n",
            "loss in epoch 85 iteration 126: 0.5554311275482178\n",
            "loss in epoch 85 iteration 127: 0.5764024257659912\n",
            "loss in epoch 85 iteration 128: 0.5548098087310791\n",
            "loss in epoch 85 iteration 129: 0.5881997346878052\n",
            "loss in epoch 85 iteration 130: 0.5420093536376953\n",
            "loss in epoch 85 iteration 131: 0.5553069114685059\n",
            "loss in epoch 85 iteration 132: 0.5578374266624451\n",
            "loss in epoch 85 iteration 133: 0.5588134527206421\n",
            "loss in epoch 85 iteration 134: 0.5644229650497437\n",
            "loss in epoch 85 iteration 135: 0.5564174056053162\n",
            "loss in epoch 85 iteration 136: 0.542862057685852\n",
            "loss in epoch 85 iteration 137: 0.537585437297821\n",
            "loss in epoch 85 iteration 138: 0.5748741626739502\n",
            "loss in epoch 85 iteration 139: 0.5847241878509521\n",
            "loss in epoch 85 iteration 140: 0.5787979364395142\n",
            "loss in epoch 85 iteration 141: 0.5382837057113647\n",
            "loss in epoch 85 iteration 142: 0.5871381759643555\n",
            "loss in epoch 85 iteration 143: 0.5655215978622437\n",
            "loss in epoch 85 iteration 144: 0.5818710327148438\n",
            "loss in epoch 85 iteration 145: 0.5870150327682495\n",
            "loss in epoch 85 iteration 146: 0.5636327862739563\n",
            "loss in epoch 85 iteration 147: 0.5711889266967773\n",
            "loss in epoch 85 iteration 148: 0.5526185631752014\n",
            "loss in epoch 85 iteration 149: 0.5791427493095398\n",
            "loss in epoch 85 iteration 150: 0.5506662726402283\n",
            "loss in epoch 85 iteration 151: 0.5653802156448364\n",
            "loss in epoch 85 iteration 152: 0.597734808921814\n",
            "loss in epoch 85 iteration 153: 0.5566401481628418\n",
            "loss in epoch 85 iteration 154: 0.6042003631591797\n",
            "loss in epoch 85 iteration 155: 0.5623981356620789\n",
            "loss in epoch 85 iteration 156: 0.5593504905700684\n",
            "loss in epoch 85 iteration 157: 0.5979955196380615\n",
            "loss in epoch 85 iteration 158: 0.5343058705329895\n",
            "loss in epoch 85 iteration 159: 0.5803142786026001\n",
            "loss in epoch 85 iteration 160: 0.5630972385406494\n",
            "loss in epoch 85 iteration 161: 0.5595461130142212\n",
            "loss in epoch 85 iteration 162: 0.5745809078216553\n",
            "loss in epoch 85 iteration 163: 0.5479375123977661\n",
            "loss in epoch 85 iteration 164: 0.5519880056381226\n",
            "loss in epoch 85 iteration 165: 0.5370842814445496\n",
            "loss in epoch 85 iteration 166: 0.5722576379776001\n",
            "loss in epoch 85 iteration 167: 0.5513983964920044\n",
            "loss in epoch 85 iteration 168: 0.5759905576705933\n",
            "loss in epoch 85 iteration 169: 0.5604032278060913\n",
            "loss in epoch 85 iteration 170: 0.5931812524795532\n",
            "loss in epoch 85 iteration 171: 0.5561856031417847\n",
            "loss in epoch 85 iteration 172: 0.5853972434997559\n",
            "loss in epoch 85 iteration 173: 0.552001416683197\n",
            "loss in epoch 85 iteration 174: 0.5681507587432861\n",
            "loss in epoch 85 iteration 175: 0.5826466083526611\n",
            "loss in epoch 85 iteration 176: 0.5739010572433472\n",
            "loss in epoch 85 iteration 177: 0.5582097768783569\n",
            "loss in epoch 85 iteration 178: 0.5795261859893799\n",
            "loss in epoch 85 iteration 179: 0.5588743686676025\n",
            "loss in epoch 85 iteration 180: 0.5438328981399536\n",
            "loss in epoch 85 iteration 181: 0.5708391070365906\n",
            "loss in epoch 85 iteration 182: 0.5590946674346924\n",
            "loss in epoch 85 iteration 183: 0.5749038457870483\n",
            "loss in epoch 85 iteration 184: 0.5584337711334229\n",
            "loss in epoch 85 iteration 185: 0.5545182228088379\n",
            "loss in epoch 85 iteration 186: 0.5821235179901123\n",
            "loss in epoch 85 iteration 187: 0.5741547346115112\n",
            "loss in epoch 85 iteration 188: 0.5480859279632568\n",
            "loss in epoch 85 iteration 189: 0.5325807332992554\n",
            "loss in epoch 85 iteration 190: 0.5850937366485596\n",
            "loss in epoch 85 iteration 191: 0.550713062286377\n",
            "loss in epoch 85 iteration 192: 0.5458354949951172\n",
            "loss in epoch 85 iteration 193: 0.5591857433319092\n",
            "loss in epoch 85 iteration 194: 0.5709642171859741\n",
            "loss in epoch 85 iteration 195: 0.5788759589195251\n",
            "loss in epoch 85 iteration 196: 0.5734519958496094\n",
            "loss in epoch 85 iteration 197: 0.5571880340576172\n",
            "loss in epoch 85 iteration 198: 0.563237190246582\n",
            "loss in epoch 85 iteration 199: 0.5784366130828857\n",
            "loss in epoch 85 iteration 200: 0.5629152059555054\n",
            "loss in epoch 85 iteration 201: 0.573802649974823\n",
            "loss in epoch 85 iteration 202: 0.5713766813278198\n",
            "loss in epoch 85 iteration 203: 0.5700500011444092\n",
            "loss in epoch 85 iteration 204: 0.5630221366882324\n",
            "loss in epoch 85 iteration 205: 0.5411472916603088\n",
            "loss in epoch 85 iteration 206: 0.5509380102157593\n",
            "loss in epoch 85 iteration 207: 0.5680927038192749\n",
            "loss in epoch 85 iteration 208: 0.5571000576019287\n",
            "loss in epoch 85 iteration 209: 0.5732172727584839\n",
            "loss in epoch 85 iteration 210: 0.5931815505027771\n",
            "loss in epoch 85 iteration 211: 0.5627665519714355\n",
            "loss in epoch 85 iteration 212: 0.5715806484222412\n",
            "loss in epoch 85 iteration 213: 0.556363582611084\n",
            "loss in epoch 85 iteration 214: 0.5847340226173401\n",
            "loss in epoch 85 iteration 215: 0.5684428215026855\n",
            "loss in epoch 85 iteration 216: 0.5246759653091431\n",
            "loss in epoch 85 iteration 217: 0.5742284655570984\n",
            "loss in epoch 85 iteration 218: 0.5430498123168945\n",
            "loss in epoch 85 iteration 219: 0.571022629737854\n",
            "loss in epoch 85 iteration 220: 0.5768275260925293\n",
            "loss in epoch 85 iteration 221: 0.5442889928817749\n",
            "loss in epoch 85 iteration 222: 0.5702236890792847\n",
            "loss in epoch 85 iteration 223: 0.5843976736068726\n",
            "loss in epoch 85 iteration 224: 0.5811930894851685\n",
            "loss in epoch 85 iteration 225: 0.5538053512573242\n",
            "loss in epoch 85 iteration 226: 0.5781526565551758\n",
            "loss in epoch 85 iteration 227: 0.5618325471878052\n",
            "loss in epoch 85 iteration 228: 0.5898315906524658\n",
            "loss in epoch 85 iteration 229: 0.5584843754768372\n",
            "loss in epoch 85 iteration 230: 0.5550332069396973\n",
            "loss in epoch 85 iteration 231: 0.567572832107544\n",
            "loss in epoch 85 iteration 232: 0.5518207550048828\n",
            "loss in epoch 85 iteration 233: 0.5706058740615845\n",
            "loss in epoch 85 iteration 234: 0.5778846740722656\n",
            "loss in epoch 85 iteration 235: 0.5377864241600037\n",
            "loss in epoch 85 iteration 236: 0.5355547070503235\n",
            "loss in epoch 85 iteration 237: 0.5479100942611694\n",
            "loss in epoch 85 iteration 238: 0.5873808860778809\n",
            "loss in epoch 85 iteration 239: 0.5521806478500366\n",
            "loss in epoch 85 iteration 240: 0.5580359697341919\n",
            "loss in epoch 85 iteration 241: 0.5786073207855225\n",
            "loss in epoch 85 iteration 242: 0.5592354536056519\n",
            "loss in epoch 86 iteration 0: 0.5597957968711853\n",
            "loss in epoch 86 iteration 1: 0.5656287670135498\n",
            "loss in epoch 86 iteration 2: 0.5613836646080017\n",
            "loss in epoch 86 iteration 3: 0.5566847920417786\n",
            "loss in epoch 86 iteration 4: 0.5864096283912659\n",
            "loss in epoch 86 iteration 5: 0.5545661449432373\n",
            "loss in epoch 86 iteration 6: 0.5622908473014832\n",
            "loss in epoch 86 iteration 7: 0.5662184953689575\n",
            "loss in epoch 86 iteration 8: 0.5597401857376099\n",
            "loss in epoch 86 iteration 9: 0.569146990776062\n",
            "loss in epoch 86 iteration 10: 0.5609161853790283\n",
            "loss in epoch 86 iteration 11: 0.5579279661178589\n",
            "loss in epoch 86 iteration 12: 0.5592793226242065\n",
            "loss in epoch 86 iteration 13: 0.5446164011955261\n",
            "loss in epoch 86 iteration 14: 0.6063645482063293\n",
            "loss in epoch 86 iteration 15: 0.5476415157318115\n",
            "loss in epoch 86 iteration 16: 0.5779030323028564\n",
            "loss in epoch 86 iteration 17: 0.5628252625465393\n",
            "loss in epoch 86 iteration 18: 0.5989620685577393\n",
            "loss in epoch 86 iteration 19: 0.5692669749259949\n",
            "loss in epoch 86 iteration 20: 0.5422103404998779\n",
            "loss in epoch 86 iteration 21: 0.5744051337242126\n",
            "loss in epoch 86 iteration 22: 0.56436687707901\n",
            "loss in epoch 86 iteration 23: 0.5663371682167053\n",
            "loss in epoch 86 iteration 24: 0.5526608824729919\n",
            "loss in epoch 86 iteration 25: 0.566659688949585\n",
            "loss in epoch 86 iteration 26: 0.5895015001296997\n",
            "loss in epoch 86 iteration 27: 0.5645196437835693\n",
            "loss in epoch 86 iteration 28: 0.557694673538208\n",
            "loss in epoch 86 iteration 29: 0.5676891803741455\n",
            "loss in epoch 86 iteration 30: 0.5697259902954102\n",
            "loss in epoch 86 iteration 31: 0.5532187223434448\n",
            "loss in epoch 86 iteration 32: 0.5856809616088867\n",
            "loss in epoch 86 iteration 33: 0.5822809934616089\n",
            "loss in epoch 86 iteration 34: 0.5564296245574951\n",
            "loss in epoch 86 iteration 35: 0.5732600688934326\n",
            "loss in epoch 86 iteration 36: 0.5562183856964111\n",
            "loss in epoch 86 iteration 37: 0.5679903030395508\n",
            "loss in epoch 86 iteration 38: 0.5556949377059937\n",
            "loss in epoch 86 iteration 39: 0.5674299001693726\n",
            "loss in epoch 86 iteration 40: 0.5507853627204895\n",
            "loss in epoch 86 iteration 41: 0.5566459894180298\n",
            "loss in epoch 86 iteration 42: 0.5651509761810303\n",
            "loss in epoch 86 iteration 43: 0.5673449635505676\n",
            "loss in epoch 86 iteration 44: 0.5459290742874146\n",
            "loss in epoch 86 iteration 45: 0.564213752746582\n",
            "loss in epoch 86 iteration 46: 0.5717092752456665\n",
            "loss in epoch 86 iteration 47: 0.5733482837677002\n",
            "loss in epoch 86 iteration 48: 0.5632227063179016\n",
            "loss in epoch 86 iteration 49: 0.5546469688415527\n",
            "loss in epoch 86 iteration 50: 0.5655992031097412\n",
            "loss in epoch 86 iteration 51: 0.5629419088363647\n",
            "loss in epoch 86 iteration 52: 0.5456985235214233\n",
            "loss in epoch 86 iteration 53: 0.5650965571403503\n",
            "loss in epoch 86 iteration 54: 0.5473212599754333\n",
            "loss in epoch 86 iteration 55: 0.5880549550056458\n",
            "loss in epoch 86 iteration 56: 0.5517080426216125\n",
            "loss in epoch 86 iteration 57: 0.5608320236206055\n",
            "loss in epoch 86 iteration 58: 0.5447652339935303\n",
            "loss in epoch 86 iteration 59: 0.5542623400688171\n",
            "loss in epoch 86 iteration 60: 0.5635217428207397\n",
            "loss in epoch 86 iteration 61: 0.5593124032020569\n",
            "loss in epoch 86 iteration 62: 0.580626904964447\n",
            "loss in epoch 86 iteration 63: 0.5311132073402405\n",
            "loss in epoch 86 iteration 64: 0.5511749982833862\n",
            "loss in epoch 86 iteration 65: 0.5507372617721558\n",
            "loss in epoch 86 iteration 66: 0.5699828267097473\n",
            "loss in epoch 86 iteration 67: 0.5372415781021118\n",
            "loss in epoch 86 iteration 68: 0.56069016456604\n",
            "loss in epoch 86 iteration 69: 0.5755693316459656\n",
            "loss in epoch 86 iteration 70: 0.5604227781295776\n",
            "loss in epoch 86 iteration 71: 0.5620168447494507\n",
            "loss in epoch 86 iteration 72: 0.5465614795684814\n",
            "loss in epoch 86 iteration 73: 0.5579910278320312\n",
            "loss in epoch 86 iteration 74: 0.5572858452796936\n",
            "loss in epoch 86 iteration 75: 0.5449776649475098\n",
            "loss in epoch 86 iteration 76: 0.5790225267410278\n",
            "loss in epoch 86 iteration 77: 0.560390830039978\n",
            "loss in epoch 86 iteration 78: 0.5463622808456421\n",
            "loss in epoch 86 iteration 79: 0.5759692192077637\n",
            "loss in epoch 86 iteration 80: 0.5599194765090942\n",
            "loss in epoch 86 iteration 81: 0.5677169561386108\n",
            "loss in epoch 86 iteration 82: 0.5692997574806213\n",
            "loss in epoch 86 iteration 83: 0.5378215909004211\n",
            "loss in epoch 86 iteration 84: 0.5783877372741699\n",
            "loss in epoch 86 iteration 85: 0.5443460941314697\n",
            "loss in epoch 86 iteration 86: 0.581488311290741\n",
            "loss in epoch 86 iteration 87: 0.523298978805542\n",
            "loss in epoch 86 iteration 88: 0.5620732307434082\n",
            "loss in epoch 86 iteration 89: 0.5755376815795898\n",
            "loss in epoch 86 iteration 90: 0.5726321935653687\n",
            "loss in epoch 86 iteration 91: 0.5516420602798462\n",
            "loss in epoch 86 iteration 92: 0.5572384595870972\n",
            "loss in epoch 86 iteration 93: 0.5897483825683594\n",
            "loss in epoch 86 iteration 94: 0.5539427399635315\n",
            "loss in epoch 86 iteration 95: 0.5607751607894897\n",
            "loss in epoch 86 iteration 96: 0.5607478618621826\n",
            "loss in epoch 86 iteration 97: 0.5739763975143433\n",
            "loss in epoch 86 iteration 98: 0.5562175512313843\n",
            "loss in epoch 86 iteration 99: 0.5561074018478394\n",
            "loss in epoch 86 iteration 100: 0.5684096813201904\n",
            "loss in epoch 86 iteration 101: 0.5684851408004761\n",
            "loss in epoch 86 iteration 102: 0.5672096014022827\n",
            "loss in epoch 86 iteration 103: 0.5513911247253418\n",
            "loss in epoch 86 iteration 104: 0.5387170314788818\n",
            "loss in epoch 86 iteration 105: 0.5576507449150085\n",
            "loss in epoch 86 iteration 106: 0.5327372550964355\n",
            "loss in epoch 86 iteration 107: 0.56337970495224\n",
            "loss in epoch 86 iteration 108: 0.5689743757247925\n",
            "loss in epoch 86 iteration 109: 0.559525728225708\n",
            "loss in epoch 86 iteration 110: 0.5484339594841003\n",
            "loss in epoch 86 iteration 111: 0.5638505220413208\n",
            "loss in epoch 86 iteration 112: 0.567420244216919\n",
            "loss in epoch 86 iteration 113: 0.5926341414451599\n",
            "loss in epoch 86 iteration 114: 0.5643066167831421\n",
            "loss in epoch 86 iteration 115: 0.5757551193237305\n",
            "loss in epoch 86 iteration 116: 0.5510812997817993\n",
            "loss in epoch 86 iteration 117: 0.558944582939148\n",
            "loss in epoch 86 iteration 118: 0.573944091796875\n",
            "loss in epoch 86 iteration 119: 0.5964776277542114\n",
            "loss in epoch 86 iteration 120: 0.5836089849472046\n",
            "loss in epoch 86 iteration 121: 0.5536600351333618\n",
            "loss in epoch 86 iteration 122: 0.5981991291046143\n",
            "loss in epoch 86 iteration 123: 0.5929220914840698\n",
            "loss in epoch 86 iteration 124: 0.6032989025115967\n",
            "loss in epoch 86 iteration 125: 0.5621343851089478\n",
            "loss in epoch 86 iteration 126: 0.5594485998153687\n",
            "loss in epoch 86 iteration 127: 0.5846762657165527\n",
            "loss in epoch 86 iteration 128: 0.5537583827972412\n",
            "loss in epoch 86 iteration 129: 0.5754353404045105\n",
            "loss in epoch 86 iteration 130: 0.5671168565750122\n",
            "loss in epoch 86 iteration 131: 0.5704007148742676\n",
            "loss in epoch 86 iteration 132: 0.5859717130661011\n",
            "loss in epoch 86 iteration 133: 0.5647974014282227\n",
            "loss in epoch 86 iteration 134: 0.5523626208305359\n",
            "loss in epoch 86 iteration 135: 0.5635989904403687\n",
            "loss in epoch 86 iteration 136: 0.5600460767745972\n",
            "loss in epoch 86 iteration 137: 0.542699933052063\n",
            "loss in epoch 86 iteration 138: 0.5522445440292358\n",
            "loss in epoch 86 iteration 139: 0.5317634344100952\n",
            "loss in epoch 86 iteration 140: 0.5544975996017456\n",
            "loss in epoch 86 iteration 141: 0.5576564073562622\n",
            "loss in epoch 86 iteration 142: 0.5627169013023376\n",
            "loss in epoch 86 iteration 143: 0.5565214157104492\n",
            "loss in epoch 86 iteration 144: 0.5785913467407227\n",
            "loss in epoch 86 iteration 145: 0.5730192065238953\n",
            "loss in epoch 86 iteration 146: 0.5273029804229736\n",
            "loss in epoch 86 iteration 147: 0.5523910522460938\n",
            "loss in epoch 86 iteration 148: 0.5369004607200623\n",
            "loss in epoch 86 iteration 149: 0.5900688171386719\n",
            "loss in epoch 86 iteration 150: 0.5551855564117432\n",
            "loss in epoch 86 iteration 151: 0.5590867400169373\n",
            "loss in epoch 86 iteration 152: 0.5488870739936829\n",
            "loss in epoch 86 iteration 153: 0.564873993396759\n",
            "loss in epoch 86 iteration 154: 0.5746653079986572\n",
            "loss in epoch 86 iteration 155: 0.6099650263786316\n",
            "loss in epoch 86 iteration 156: 0.5405565500259399\n",
            "loss in epoch 86 iteration 157: 0.5679330825805664\n",
            "loss in epoch 86 iteration 158: 0.5741660594940186\n",
            "loss in epoch 86 iteration 159: 0.568954348564148\n",
            "loss in epoch 86 iteration 160: 0.5639672875404358\n",
            "loss in epoch 86 iteration 161: 0.5713567733764648\n",
            "loss in epoch 86 iteration 162: 0.5301492214202881\n",
            "loss in epoch 86 iteration 163: 0.5837491750717163\n",
            "loss in epoch 86 iteration 164: 0.5674089193344116\n",
            "loss in epoch 86 iteration 165: 0.5386664867401123\n",
            "loss in epoch 86 iteration 166: 0.5769569277763367\n",
            "loss in epoch 86 iteration 167: 0.5817557573318481\n",
            "loss in epoch 86 iteration 168: 0.561203122138977\n",
            "loss in epoch 86 iteration 169: 0.5383925437927246\n",
            "loss in epoch 86 iteration 170: 0.5587626099586487\n",
            "loss in epoch 86 iteration 171: 0.5667737722396851\n",
            "loss in epoch 86 iteration 172: 0.5323088765144348\n",
            "loss in epoch 86 iteration 173: 0.5478565096855164\n",
            "loss in epoch 86 iteration 174: 0.5709385871887207\n",
            "loss in epoch 86 iteration 175: 0.5675051212310791\n",
            "loss in epoch 86 iteration 176: 0.5567943453788757\n",
            "loss in epoch 86 iteration 177: 0.5470752716064453\n",
            "loss in epoch 86 iteration 178: 0.5566954612731934\n",
            "loss in epoch 86 iteration 179: 0.5488916635513306\n",
            "loss in epoch 86 iteration 180: 0.5701411962509155\n",
            "loss in epoch 86 iteration 181: 0.578424870967865\n",
            "loss in epoch 86 iteration 182: 0.5588736534118652\n",
            "loss in epoch 86 iteration 183: 0.6004155874252319\n",
            "loss in epoch 86 iteration 184: 0.5256168842315674\n",
            "loss in epoch 86 iteration 185: 0.5624510049819946\n",
            "loss in epoch 86 iteration 186: 0.5661420226097107\n",
            "loss in epoch 86 iteration 187: 0.5901432037353516\n",
            "loss in epoch 86 iteration 188: 0.5733622312545776\n",
            "loss in epoch 86 iteration 189: 0.5906078815460205\n",
            "loss in epoch 86 iteration 190: 0.5627161264419556\n",
            "loss in epoch 86 iteration 191: 0.5890723466873169\n",
            "loss in epoch 86 iteration 192: 0.5615288019180298\n",
            "loss in epoch 86 iteration 193: 0.5668035745620728\n",
            "loss in epoch 86 iteration 194: 0.5564408302307129\n",
            "loss in epoch 86 iteration 195: 0.5757167339324951\n",
            "loss in epoch 86 iteration 196: 0.5483611822128296\n",
            "loss in epoch 86 iteration 197: 0.5565774440765381\n",
            "loss in epoch 86 iteration 198: 0.5713720321655273\n",
            "loss in epoch 86 iteration 199: 0.544812798500061\n",
            "loss in epoch 86 iteration 200: 0.5349910855293274\n",
            "loss in epoch 86 iteration 201: 0.5548139810562134\n",
            "loss in epoch 86 iteration 202: 0.5662914514541626\n",
            "loss in epoch 86 iteration 203: 0.5684015154838562\n",
            "loss in epoch 86 iteration 204: 0.5704501867294312\n",
            "loss in epoch 86 iteration 205: 0.5639830827713013\n",
            "loss in epoch 86 iteration 206: 0.5538809299468994\n",
            "loss in epoch 86 iteration 207: 0.579719066619873\n",
            "loss in epoch 86 iteration 208: 0.5907596349716187\n",
            "loss in epoch 86 iteration 209: 0.5299572944641113\n",
            "loss in epoch 86 iteration 210: 0.5477190613746643\n",
            "loss in epoch 86 iteration 211: 0.5803103446960449\n",
            "loss in epoch 86 iteration 212: 0.5175589323043823\n",
            "loss in epoch 86 iteration 213: 0.5948469042778015\n",
            "loss in epoch 86 iteration 214: 0.5690021514892578\n",
            "loss in epoch 86 iteration 215: 0.5466209650039673\n",
            "loss in epoch 86 iteration 216: 0.5557088255882263\n",
            "loss in epoch 86 iteration 217: 0.5492607951164246\n",
            "loss in epoch 86 iteration 218: 0.5905002951622009\n",
            "loss in epoch 86 iteration 219: 0.5592421889305115\n",
            "loss in epoch 86 iteration 220: 0.5585940480232239\n",
            "loss in epoch 86 iteration 221: 0.5674611330032349\n",
            "loss in epoch 86 iteration 222: 0.556637167930603\n",
            "loss in epoch 86 iteration 223: 0.5588425397872925\n",
            "loss in epoch 86 iteration 224: 0.5596044063568115\n",
            "loss in epoch 86 iteration 225: 0.567987859249115\n",
            "loss in epoch 86 iteration 226: 0.5537738800048828\n",
            "loss in epoch 86 iteration 227: 0.5481071472167969\n",
            "loss in epoch 86 iteration 228: 0.5631872415542603\n",
            "loss in epoch 86 iteration 229: 0.5671060085296631\n",
            "loss in epoch 86 iteration 230: 0.5366166830062866\n",
            "loss in epoch 86 iteration 231: 0.5875750780105591\n",
            "loss in epoch 86 iteration 232: 0.5583580732345581\n",
            "loss in epoch 86 iteration 233: 0.5687151551246643\n",
            "loss in epoch 86 iteration 234: 0.5445623993873596\n",
            "loss in epoch 86 iteration 235: 0.5399064421653748\n",
            "loss in epoch 86 iteration 236: 0.5519671440124512\n",
            "loss in epoch 86 iteration 237: 0.5941557884216309\n",
            "loss in epoch 86 iteration 238: 0.5628091096878052\n",
            "loss in epoch 86 iteration 239: 0.550773561000824\n",
            "loss in epoch 86 iteration 240: 0.5431502461433411\n",
            "loss in epoch 86 iteration 241: 0.5854616165161133\n",
            "loss in epoch 86 iteration 242: 0.5598231554031372\n",
            "loss in epoch 87 iteration 0: 0.5439667105674744\n",
            "loss in epoch 87 iteration 1: 0.565153956413269\n",
            "loss in epoch 87 iteration 2: 0.5443472266197205\n",
            "loss in epoch 87 iteration 3: 0.5595582723617554\n",
            "loss in epoch 87 iteration 4: 0.547229528427124\n",
            "loss in epoch 87 iteration 5: 0.5768252611160278\n",
            "loss in epoch 87 iteration 6: 0.5952560901641846\n",
            "loss in epoch 87 iteration 7: 0.5703694224357605\n",
            "loss in epoch 87 iteration 8: 0.5710002183914185\n",
            "loss in epoch 87 iteration 9: 0.5913885831832886\n",
            "loss in epoch 87 iteration 10: 0.578424334526062\n",
            "loss in epoch 87 iteration 11: 0.5576668977737427\n",
            "loss in epoch 87 iteration 12: 0.5614307522773743\n",
            "loss in epoch 87 iteration 13: 0.5961931943893433\n",
            "loss in epoch 87 iteration 14: 0.5826984643936157\n",
            "loss in epoch 87 iteration 15: 0.5659210085868835\n",
            "loss in epoch 87 iteration 16: 0.562664806842804\n",
            "loss in epoch 87 iteration 17: 0.5456323027610779\n",
            "loss in epoch 87 iteration 18: 0.5645769238471985\n",
            "loss in epoch 87 iteration 19: 0.613985538482666\n",
            "loss in epoch 87 iteration 20: 0.5620306730270386\n",
            "loss in epoch 87 iteration 21: 0.5590965747833252\n",
            "loss in epoch 87 iteration 22: 0.5388413667678833\n",
            "loss in epoch 87 iteration 23: 0.5771530866622925\n",
            "loss in epoch 87 iteration 24: 0.5831446647644043\n",
            "loss in epoch 87 iteration 25: 0.5721010565757751\n",
            "loss in epoch 87 iteration 26: 0.5885568261146545\n",
            "loss in epoch 87 iteration 27: 0.5670766830444336\n",
            "loss in epoch 87 iteration 28: 0.5964561700820923\n",
            "loss in epoch 87 iteration 29: 0.5672000646591187\n",
            "loss in epoch 87 iteration 30: 0.5682903528213501\n",
            "loss in epoch 87 iteration 31: 0.5690479278564453\n",
            "loss in epoch 87 iteration 32: 0.5535025596618652\n",
            "loss in epoch 87 iteration 33: 0.5481745600700378\n",
            "loss in epoch 87 iteration 34: 0.5693460702896118\n",
            "loss in epoch 87 iteration 35: 0.5539060235023499\n",
            "loss in epoch 87 iteration 36: 0.5768176317214966\n",
            "loss in epoch 87 iteration 37: 0.5661842823028564\n",
            "loss in epoch 87 iteration 38: 0.5786083936691284\n",
            "loss in epoch 87 iteration 39: 0.5688978433609009\n",
            "loss in epoch 87 iteration 40: 0.5777113437652588\n",
            "loss in epoch 87 iteration 41: 0.5555585622787476\n",
            "loss in epoch 87 iteration 42: 0.5491713285446167\n",
            "loss in epoch 87 iteration 43: 0.529365599155426\n",
            "loss in epoch 87 iteration 44: 0.5726332068443298\n",
            "loss in epoch 87 iteration 45: 0.5529556274414062\n",
            "loss in epoch 87 iteration 46: 0.5939010381698608\n",
            "loss in epoch 87 iteration 47: 0.5895193815231323\n",
            "loss in epoch 87 iteration 48: 0.5606852173805237\n",
            "loss in epoch 87 iteration 49: 0.5473482012748718\n",
            "loss in epoch 87 iteration 50: 0.5536639094352722\n",
            "loss in epoch 87 iteration 51: 0.580935001373291\n",
            "loss in epoch 87 iteration 52: 0.5519625544548035\n",
            "loss in epoch 87 iteration 53: 0.5337063074111938\n",
            "loss in epoch 87 iteration 54: 0.5599012970924377\n",
            "loss in epoch 87 iteration 55: 0.5433546900749207\n",
            "loss in epoch 87 iteration 56: 0.5676169395446777\n",
            "loss in epoch 87 iteration 57: 0.5693862438201904\n",
            "loss in epoch 87 iteration 58: 0.5661795139312744\n",
            "loss in epoch 87 iteration 59: 0.5305221080780029\n",
            "loss in epoch 87 iteration 60: 0.5753740668296814\n",
            "loss in epoch 87 iteration 61: 0.563462495803833\n",
            "loss in epoch 87 iteration 62: 0.5645864009857178\n",
            "loss in epoch 87 iteration 63: 0.5478643178939819\n",
            "loss in epoch 87 iteration 64: 0.5350673198699951\n",
            "loss in epoch 87 iteration 65: 0.5537654161453247\n",
            "loss in epoch 87 iteration 66: 0.5527641177177429\n",
            "loss in epoch 87 iteration 67: 0.5406991243362427\n",
            "loss in epoch 87 iteration 68: 0.5617711544036865\n",
            "loss in epoch 87 iteration 69: 0.5507961511611938\n",
            "loss in epoch 87 iteration 70: 0.5724226236343384\n",
            "loss in epoch 87 iteration 71: 0.5758967399597168\n",
            "loss in epoch 87 iteration 72: 0.5727975368499756\n",
            "loss in epoch 87 iteration 73: 0.5352470874786377\n",
            "loss in epoch 87 iteration 74: 0.5761957168579102\n",
            "loss in epoch 87 iteration 75: 0.5367476940155029\n",
            "loss in epoch 87 iteration 76: 0.5532681941986084\n",
            "loss in epoch 87 iteration 77: 0.5623090863227844\n",
            "loss in epoch 87 iteration 78: 0.5512281656265259\n",
            "loss in epoch 87 iteration 79: 0.5509970188140869\n",
            "loss in epoch 87 iteration 80: 0.552090048789978\n",
            "loss in epoch 87 iteration 81: 0.5781848430633545\n",
            "loss in epoch 87 iteration 82: 0.5561299324035645\n",
            "loss in epoch 87 iteration 83: 0.5484073162078857\n",
            "loss in epoch 87 iteration 84: 0.5428434014320374\n",
            "loss in epoch 87 iteration 85: 0.5713299512863159\n",
            "loss in epoch 87 iteration 86: 0.5509612560272217\n",
            "loss in epoch 87 iteration 87: 0.5494954586029053\n",
            "loss in epoch 87 iteration 88: 0.5667428970336914\n",
            "loss in epoch 87 iteration 89: 0.5590176582336426\n",
            "loss in epoch 87 iteration 90: 0.5758618116378784\n",
            "loss in epoch 87 iteration 91: 0.5716326236724854\n",
            "loss in epoch 87 iteration 92: 0.554696798324585\n",
            "loss in epoch 87 iteration 93: 0.5625762939453125\n",
            "loss in epoch 87 iteration 94: 0.5710327625274658\n",
            "loss in epoch 87 iteration 95: 0.5422114133834839\n",
            "loss in epoch 87 iteration 96: 0.5713410377502441\n",
            "loss in epoch 87 iteration 97: 0.5509050488471985\n",
            "loss in epoch 87 iteration 98: 0.5655831098556519\n",
            "loss in epoch 87 iteration 99: 0.5837042927742004\n",
            "loss in epoch 87 iteration 100: 0.5784852504730225\n",
            "loss in epoch 87 iteration 101: 0.5949251651763916\n",
            "loss in epoch 87 iteration 102: 0.5608388185501099\n",
            "loss in epoch 87 iteration 103: 0.5598248839378357\n",
            "loss in epoch 87 iteration 104: 0.5678439140319824\n",
            "loss in epoch 87 iteration 105: 0.5684191584587097\n",
            "loss in epoch 87 iteration 106: 0.56853187084198\n",
            "loss in epoch 87 iteration 107: 0.5786005258560181\n",
            "loss in epoch 87 iteration 108: 0.5835041999816895\n",
            "loss in epoch 87 iteration 109: 0.5525444746017456\n",
            "loss in epoch 87 iteration 110: 0.5540401339530945\n",
            "loss in epoch 87 iteration 111: 0.58042311668396\n",
            "loss in epoch 87 iteration 112: 0.5418752431869507\n",
            "loss in epoch 87 iteration 113: 0.5386295318603516\n",
            "loss in epoch 87 iteration 114: 0.5325287580490112\n",
            "loss in epoch 87 iteration 115: 0.5636462569236755\n",
            "loss in epoch 87 iteration 116: 0.5556069016456604\n",
            "loss in epoch 87 iteration 117: 0.5575752258300781\n",
            "loss in epoch 87 iteration 118: 0.5610469579696655\n",
            "loss in epoch 87 iteration 119: 0.5343766808509827\n",
            "loss in epoch 87 iteration 120: 0.5464474558830261\n",
            "loss in epoch 87 iteration 121: 0.5666038990020752\n",
            "loss in epoch 87 iteration 122: 0.5732057094573975\n",
            "loss in epoch 87 iteration 123: 0.5611013174057007\n",
            "loss in epoch 87 iteration 124: 0.5694273710250854\n",
            "loss in epoch 87 iteration 125: 0.5495464205741882\n",
            "loss in epoch 87 iteration 126: 0.5873720645904541\n",
            "loss in epoch 87 iteration 127: 0.5737685561180115\n",
            "loss in epoch 87 iteration 128: 0.5654264092445374\n",
            "loss in epoch 87 iteration 129: 0.5674859881401062\n",
            "loss in epoch 87 iteration 130: 0.5674222111701965\n",
            "loss in epoch 87 iteration 131: 0.5449607372283936\n",
            "loss in epoch 87 iteration 132: 0.5453488826751709\n",
            "loss in epoch 87 iteration 133: 0.5951536297798157\n",
            "loss in epoch 87 iteration 134: 0.5632933378219604\n",
            "loss in epoch 87 iteration 135: 0.5508265495300293\n",
            "loss in epoch 87 iteration 136: 0.570885419845581\n",
            "loss in epoch 87 iteration 137: 0.5607192516326904\n",
            "loss in epoch 87 iteration 138: 0.5725241303443909\n",
            "loss in epoch 87 iteration 139: 0.5785287618637085\n",
            "loss in epoch 87 iteration 140: 0.5745006799697876\n",
            "loss in epoch 87 iteration 141: 0.5761544704437256\n",
            "loss in epoch 87 iteration 142: 0.565597653388977\n",
            "loss in epoch 87 iteration 143: 0.5401611328125\n",
            "loss in epoch 87 iteration 144: 0.5432982444763184\n",
            "loss in epoch 87 iteration 145: 0.5299198627471924\n",
            "loss in epoch 87 iteration 146: 0.5422687530517578\n",
            "loss in epoch 87 iteration 147: 0.5695544481277466\n",
            "loss in epoch 87 iteration 148: 0.5533155202865601\n",
            "loss in epoch 87 iteration 149: 0.5284145474433899\n",
            "loss in epoch 87 iteration 150: 0.5745917558670044\n",
            "loss in epoch 87 iteration 151: 0.5632545948028564\n",
            "loss in epoch 87 iteration 152: 0.5350283980369568\n",
            "loss in epoch 87 iteration 153: 0.5628457069396973\n",
            "loss in epoch 87 iteration 154: 0.5594271421432495\n",
            "loss in epoch 87 iteration 155: 0.5501354932785034\n",
            "loss in epoch 87 iteration 156: 0.5628093481063843\n",
            "loss in epoch 87 iteration 157: 0.5579337477684021\n",
            "loss in epoch 87 iteration 158: 0.5876073837280273\n",
            "loss in epoch 87 iteration 159: 0.5532926321029663\n",
            "loss in epoch 87 iteration 160: 0.5904587507247925\n",
            "loss in epoch 87 iteration 161: 0.5774297714233398\n",
            "loss in epoch 87 iteration 162: 0.5660372972488403\n",
            "loss in epoch 87 iteration 163: 0.5927431583404541\n",
            "loss in epoch 87 iteration 164: 0.5775115489959717\n",
            "loss in epoch 87 iteration 165: 0.5628070831298828\n",
            "loss in epoch 87 iteration 166: 0.5567307472229004\n",
            "loss in epoch 87 iteration 167: 0.5492148995399475\n",
            "loss in epoch 87 iteration 168: 0.5628302097320557\n",
            "loss in epoch 87 iteration 169: 0.545541524887085\n",
            "loss in epoch 87 iteration 170: 0.5550922155380249\n",
            "loss in epoch 87 iteration 171: 0.5683532953262329\n",
            "loss in epoch 87 iteration 172: 0.5641889572143555\n",
            "loss in epoch 87 iteration 173: 0.5600917339324951\n",
            "loss in epoch 87 iteration 174: 0.5429619550704956\n",
            "loss in epoch 87 iteration 175: 0.5611222386360168\n",
            "loss in epoch 87 iteration 176: 0.5689555406570435\n",
            "loss in epoch 87 iteration 177: 0.5592238903045654\n",
            "loss in epoch 87 iteration 178: 0.5712388753890991\n",
            "loss in epoch 87 iteration 179: 0.5707683563232422\n",
            "loss in epoch 87 iteration 180: 0.5722966194152832\n",
            "loss in epoch 87 iteration 181: 0.5462339520454407\n",
            "loss in epoch 87 iteration 182: 0.5444183349609375\n",
            "loss in epoch 87 iteration 183: 0.5526216626167297\n",
            "loss in epoch 87 iteration 184: 0.5525151491165161\n",
            "loss in epoch 87 iteration 185: 0.556902289390564\n",
            "loss in epoch 87 iteration 186: 0.5445141792297363\n",
            "loss in epoch 87 iteration 187: 0.5582050681114197\n",
            "loss in epoch 87 iteration 188: 0.5705878734588623\n",
            "loss in epoch 87 iteration 189: 0.5295886993408203\n",
            "loss in epoch 87 iteration 190: 0.5446985363960266\n",
            "loss in epoch 87 iteration 191: 0.5581076145172119\n",
            "loss in epoch 87 iteration 192: 0.5638784170150757\n",
            "loss in epoch 87 iteration 193: 0.5742955803871155\n",
            "loss in epoch 87 iteration 194: 0.5988901853561401\n",
            "loss in epoch 87 iteration 195: 0.5666523575782776\n",
            "loss in epoch 87 iteration 196: 0.5579187870025635\n",
            "loss in epoch 87 iteration 197: 0.5918766856193542\n",
            "loss in epoch 87 iteration 198: 0.5510643720626831\n",
            "loss in epoch 87 iteration 199: 0.5678902864456177\n",
            "loss in epoch 87 iteration 200: 0.5599856376647949\n",
            "loss in epoch 87 iteration 201: 0.5307905077934265\n",
            "loss in epoch 87 iteration 202: 0.5795598030090332\n",
            "loss in epoch 87 iteration 203: 0.5573108196258545\n",
            "loss in epoch 87 iteration 204: 0.5516664981842041\n",
            "loss in epoch 87 iteration 205: 0.546303391456604\n",
            "loss in epoch 87 iteration 206: 0.5969230532646179\n",
            "loss in epoch 87 iteration 207: 0.5479524731636047\n",
            "loss in epoch 87 iteration 208: 0.5681858658790588\n",
            "loss in epoch 87 iteration 209: 0.5677908062934875\n",
            "loss in epoch 87 iteration 210: 0.5716345310211182\n",
            "loss in epoch 87 iteration 211: 0.5703277587890625\n",
            "loss in epoch 87 iteration 212: 0.5297894477844238\n",
            "loss in epoch 87 iteration 213: 0.5554696321487427\n",
            "loss in epoch 87 iteration 214: 0.5526256561279297\n",
            "loss in epoch 87 iteration 215: 0.5705661773681641\n",
            "loss in epoch 87 iteration 216: 0.5935406684875488\n",
            "loss in epoch 87 iteration 217: 0.5652013421058655\n",
            "loss in epoch 87 iteration 218: 0.5536309480667114\n",
            "loss in epoch 87 iteration 219: 0.5315576195716858\n",
            "loss in epoch 87 iteration 220: 0.5499390363693237\n",
            "loss in epoch 87 iteration 221: 0.5497337579727173\n",
            "loss in epoch 87 iteration 222: 0.575603723526001\n",
            "loss in epoch 87 iteration 223: 0.5649497509002686\n",
            "loss in epoch 87 iteration 224: 0.580532431602478\n",
            "loss in epoch 87 iteration 225: 0.5511046648025513\n",
            "loss in epoch 87 iteration 226: 0.5639572143554688\n",
            "loss in epoch 87 iteration 227: 0.5596630573272705\n",
            "loss in epoch 87 iteration 228: 0.5484490394592285\n",
            "loss in epoch 87 iteration 229: 0.562812089920044\n",
            "loss in epoch 87 iteration 230: 0.5786958932876587\n",
            "loss in epoch 87 iteration 231: 0.5321410894393921\n",
            "loss in epoch 87 iteration 232: 0.567867636680603\n",
            "loss in epoch 87 iteration 233: 0.5554232001304626\n",
            "loss in epoch 87 iteration 234: 0.5607431530952454\n",
            "loss in epoch 87 iteration 235: 0.5676663517951965\n",
            "loss in epoch 87 iteration 236: 0.5568024516105652\n",
            "loss in epoch 87 iteration 237: 0.5666184425354004\n",
            "loss in epoch 87 iteration 238: 0.5722443461418152\n",
            "loss in epoch 87 iteration 239: 0.5680069327354431\n",
            "loss in epoch 87 iteration 240: 0.5302513241767883\n",
            "loss in epoch 87 iteration 241: 0.5191441178321838\n",
            "loss in epoch 87 iteration 242: 0.5732306241989136\n",
            "loss in epoch 88 iteration 0: 0.5439537167549133\n",
            "loss in epoch 88 iteration 1: 0.5544998645782471\n",
            "loss in epoch 88 iteration 2: 0.5688780546188354\n",
            "loss in epoch 88 iteration 3: 0.5682637691497803\n",
            "loss in epoch 88 iteration 4: 0.5514293313026428\n",
            "loss in epoch 88 iteration 5: 0.5544924139976501\n",
            "loss in epoch 88 iteration 6: 0.5344773530960083\n",
            "loss in epoch 88 iteration 7: 0.5320727825164795\n",
            "loss in epoch 88 iteration 8: 0.5456603765487671\n",
            "loss in epoch 88 iteration 9: 0.5804969072341919\n",
            "loss in epoch 88 iteration 10: 0.5758422613143921\n",
            "loss in epoch 88 iteration 11: 0.5863666534423828\n",
            "loss in epoch 88 iteration 12: 0.5478068590164185\n",
            "loss in epoch 88 iteration 13: 0.5563157796859741\n",
            "loss in epoch 88 iteration 14: 0.5707259178161621\n",
            "loss in epoch 88 iteration 15: 0.537081778049469\n",
            "loss in epoch 88 iteration 16: 0.5659680366516113\n",
            "loss in epoch 88 iteration 17: 0.5717507600784302\n",
            "loss in epoch 88 iteration 18: 0.5304088592529297\n",
            "loss in epoch 88 iteration 19: 0.5626972913742065\n",
            "loss in epoch 88 iteration 20: 0.5737597942352295\n",
            "loss in epoch 88 iteration 21: 0.5777477025985718\n",
            "loss in epoch 88 iteration 22: 0.5396746397018433\n",
            "loss in epoch 88 iteration 23: 0.5589650869369507\n",
            "loss in epoch 88 iteration 24: 0.5639485120773315\n",
            "loss in epoch 88 iteration 25: 0.5583505630493164\n",
            "loss in epoch 88 iteration 26: 0.5532960295677185\n",
            "loss in epoch 88 iteration 27: 0.5691093802452087\n",
            "loss in epoch 88 iteration 28: 0.5823777914047241\n",
            "loss in epoch 88 iteration 29: 0.5879784226417542\n",
            "loss in epoch 88 iteration 30: 0.5276609063148499\n",
            "loss in epoch 88 iteration 31: 0.5673611164093018\n",
            "loss in epoch 88 iteration 32: 0.5644910335540771\n",
            "loss in epoch 88 iteration 33: 0.544650137424469\n",
            "loss in epoch 88 iteration 34: 0.5418127179145813\n",
            "loss in epoch 88 iteration 35: 0.544682502746582\n",
            "loss in epoch 88 iteration 36: 0.5790798664093018\n",
            "loss in epoch 88 iteration 37: 0.5476005673408508\n",
            "loss in epoch 88 iteration 38: 0.5753731727600098\n",
            "loss in epoch 88 iteration 39: 0.573329746723175\n",
            "loss in epoch 88 iteration 40: 0.5821995735168457\n",
            "loss in epoch 88 iteration 41: 0.5647037029266357\n",
            "loss in epoch 88 iteration 42: 0.543653666973114\n",
            "loss in epoch 88 iteration 43: 0.5558210611343384\n",
            "loss in epoch 88 iteration 44: 0.5287262201309204\n",
            "loss in epoch 88 iteration 45: 0.5569095611572266\n",
            "loss in epoch 88 iteration 46: 0.5618455410003662\n",
            "loss in epoch 88 iteration 47: 0.5505566596984863\n",
            "loss in epoch 88 iteration 48: 0.592540442943573\n",
            "loss in epoch 88 iteration 49: 0.5552433729171753\n",
            "loss in epoch 88 iteration 50: 0.5867345929145813\n",
            "loss in epoch 88 iteration 51: 0.5804678797721863\n",
            "loss in epoch 88 iteration 52: 0.552199125289917\n",
            "loss in epoch 88 iteration 53: 0.5685190558433533\n",
            "loss in epoch 88 iteration 54: 0.5716440677642822\n",
            "loss in epoch 88 iteration 55: 0.5470362901687622\n",
            "loss in epoch 88 iteration 56: 0.5680623054504395\n",
            "loss in epoch 88 iteration 57: 0.5325495004653931\n",
            "loss in epoch 88 iteration 58: 0.5743167996406555\n",
            "loss in epoch 88 iteration 59: 0.5764057040214539\n",
            "loss in epoch 88 iteration 60: 0.5722448229789734\n",
            "loss in epoch 88 iteration 61: 0.5547624230384827\n",
            "loss in epoch 88 iteration 62: 0.5746394395828247\n",
            "loss in epoch 88 iteration 63: 0.5909812450408936\n",
            "loss in epoch 88 iteration 64: 0.5546274781227112\n",
            "loss in epoch 88 iteration 65: 0.5510162115097046\n",
            "loss in epoch 88 iteration 66: 0.5592788457870483\n",
            "loss in epoch 88 iteration 67: 0.5632797479629517\n",
            "loss in epoch 88 iteration 68: 0.555152952671051\n",
            "loss in epoch 88 iteration 69: 0.5624944567680359\n",
            "loss in epoch 88 iteration 70: 0.5666123628616333\n",
            "loss in epoch 88 iteration 71: 0.5545597076416016\n",
            "loss in epoch 88 iteration 72: 0.5490925312042236\n",
            "loss in epoch 88 iteration 73: 0.5206064581871033\n",
            "loss in epoch 88 iteration 74: 0.5789610147476196\n",
            "loss in epoch 88 iteration 75: 0.5664364099502563\n",
            "loss in epoch 88 iteration 76: 0.5522841811180115\n",
            "loss in epoch 88 iteration 77: 0.5581792593002319\n",
            "loss in epoch 88 iteration 78: 0.5888713598251343\n",
            "loss in epoch 88 iteration 79: 0.5432581901550293\n",
            "loss in epoch 88 iteration 80: 0.5477874279022217\n",
            "loss in epoch 88 iteration 81: 0.5676809549331665\n",
            "loss in epoch 88 iteration 82: 0.5341508984565735\n",
            "loss in epoch 88 iteration 83: 0.590758204460144\n",
            "loss in epoch 88 iteration 84: 0.5545468926429749\n",
            "loss in epoch 88 iteration 85: 0.5752843618392944\n",
            "loss in epoch 88 iteration 86: 0.5587005615234375\n",
            "loss in epoch 88 iteration 87: 0.5688513517379761\n",
            "loss in epoch 88 iteration 88: 0.5709332227706909\n",
            "loss in epoch 88 iteration 89: 0.5740481019020081\n",
            "loss in epoch 88 iteration 90: 0.5583999156951904\n",
            "loss in epoch 88 iteration 91: 0.5726836323738098\n",
            "loss in epoch 88 iteration 92: 0.5638439655303955\n",
            "loss in epoch 88 iteration 93: 0.5579103231430054\n",
            "loss in epoch 88 iteration 94: 0.5700173377990723\n",
            "loss in epoch 88 iteration 95: 0.5652269124984741\n",
            "loss in epoch 88 iteration 96: 0.567814826965332\n",
            "loss in epoch 88 iteration 97: 0.5709700584411621\n",
            "loss in epoch 88 iteration 98: 0.5501075983047485\n",
            "loss in epoch 88 iteration 99: 0.5558108687400818\n",
            "loss in epoch 88 iteration 100: 0.5940811634063721\n",
            "loss in epoch 88 iteration 101: 0.5568252205848694\n",
            "loss in epoch 88 iteration 102: 0.5803545713424683\n",
            "loss in epoch 88 iteration 103: 0.5545634031295776\n",
            "loss in epoch 88 iteration 104: 0.582308292388916\n",
            "loss in epoch 88 iteration 105: 0.5685156583786011\n",
            "loss in epoch 88 iteration 106: 0.5492115020751953\n",
            "loss in epoch 88 iteration 107: 0.5589073896408081\n",
            "loss in epoch 88 iteration 108: 0.5907220244407654\n",
            "loss in epoch 88 iteration 109: 0.5880016088485718\n",
            "loss in epoch 88 iteration 110: 0.5577789545059204\n",
            "loss in epoch 88 iteration 111: 0.5543645620346069\n",
            "loss in epoch 88 iteration 112: 0.5666577219963074\n",
            "loss in epoch 88 iteration 113: 0.5343537330627441\n",
            "loss in epoch 88 iteration 114: 0.5715410709381104\n",
            "loss in epoch 88 iteration 115: 0.5599828958511353\n",
            "loss in epoch 88 iteration 116: 0.5608235597610474\n",
            "loss in epoch 88 iteration 117: 0.5409719347953796\n",
            "loss in epoch 88 iteration 118: 0.5794396996498108\n",
            "loss in epoch 88 iteration 119: 0.5866885185241699\n",
            "loss in epoch 88 iteration 120: 0.5775191187858582\n",
            "loss in epoch 88 iteration 121: 0.5566063523292542\n",
            "loss in epoch 88 iteration 122: 0.5998827219009399\n",
            "loss in epoch 88 iteration 123: 0.573720395565033\n",
            "loss in epoch 88 iteration 124: 0.5518518686294556\n",
            "loss in epoch 88 iteration 125: 0.5353306531906128\n",
            "loss in epoch 88 iteration 126: 0.5483850836753845\n",
            "loss in epoch 88 iteration 127: 0.544516921043396\n",
            "loss in epoch 88 iteration 128: 0.5733555555343628\n",
            "loss in epoch 88 iteration 129: 0.5679890513420105\n",
            "loss in epoch 88 iteration 130: 0.5330480337142944\n",
            "loss in epoch 88 iteration 131: 0.5728153586387634\n",
            "loss in epoch 88 iteration 132: 0.586805522441864\n",
            "loss in epoch 88 iteration 133: 0.5572652816772461\n",
            "loss in epoch 88 iteration 134: 0.5479570627212524\n",
            "loss in epoch 88 iteration 135: 0.5586119294166565\n",
            "loss in epoch 88 iteration 136: 0.5715163350105286\n",
            "loss in epoch 88 iteration 137: 0.5483804941177368\n",
            "loss in epoch 88 iteration 138: 0.5517845153808594\n",
            "loss in epoch 88 iteration 139: 0.561166524887085\n",
            "loss in epoch 88 iteration 140: 0.5685664415359497\n",
            "loss in epoch 88 iteration 141: 0.5706838965415955\n",
            "loss in epoch 88 iteration 142: 0.5491291284561157\n",
            "loss in epoch 88 iteration 143: 0.5218831896781921\n",
            "loss in epoch 88 iteration 144: 0.5628311038017273\n",
            "loss in epoch 88 iteration 145: 0.5475189089775085\n",
            "loss in epoch 88 iteration 146: 0.543450117111206\n",
            "loss in epoch 88 iteration 147: 0.5765041708946228\n",
            "loss in epoch 88 iteration 148: 0.5538384318351746\n",
            "loss in epoch 88 iteration 149: 0.5689622163772583\n",
            "loss in epoch 88 iteration 150: 0.5588669776916504\n",
            "loss in epoch 88 iteration 151: 0.5688170194625854\n",
            "loss in epoch 88 iteration 152: 0.5451810956001282\n",
            "loss in epoch 88 iteration 153: 0.5491472482681274\n",
            "loss in epoch 88 iteration 154: 0.5517884492874146\n",
            "loss in epoch 88 iteration 155: 0.5716931223869324\n",
            "loss in epoch 88 iteration 156: 0.5579522848129272\n",
            "loss in epoch 88 iteration 157: 0.57167649269104\n",
            "loss in epoch 88 iteration 158: 0.5774725675582886\n",
            "loss in epoch 88 iteration 159: 0.567314624786377\n",
            "loss in epoch 88 iteration 160: 0.5659249424934387\n",
            "loss in epoch 88 iteration 161: 0.5656088590621948\n",
            "loss in epoch 88 iteration 162: 0.5795239806175232\n",
            "loss in epoch 88 iteration 163: 0.5411084890365601\n",
            "loss in epoch 88 iteration 164: 0.6038369536399841\n",
            "loss in epoch 88 iteration 165: 0.5710457563400269\n",
            "loss in epoch 88 iteration 166: 0.5301246643066406\n",
            "loss in epoch 88 iteration 167: 0.5619056224822998\n",
            "loss in epoch 88 iteration 168: 0.5547333359718323\n",
            "loss in epoch 88 iteration 169: 0.5818455219268799\n",
            "loss in epoch 88 iteration 170: 0.5680509805679321\n",
            "loss in epoch 88 iteration 171: 0.556921124458313\n",
            "loss in epoch 88 iteration 172: 0.5534861087799072\n",
            "loss in epoch 88 iteration 173: 0.535280704498291\n",
            "loss in epoch 88 iteration 174: 0.5450676679611206\n",
            "loss in epoch 88 iteration 175: 0.5365426540374756\n",
            "loss in epoch 88 iteration 176: 0.5634679198265076\n",
            "loss in epoch 88 iteration 177: 0.5826127529144287\n",
            "loss in epoch 88 iteration 178: 0.5621762871742249\n",
            "loss in epoch 88 iteration 179: 0.5661320686340332\n",
            "loss in epoch 88 iteration 180: 0.5651000738143921\n",
            "loss in epoch 88 iteration 181: 0.5680478811264038\n",
            "loss in epoch 88 iteration 182: 0.5427104830741882\n",
            "loss in epoch 88 iteration 183: 0.5246783494949341\n",
            "loss in epoch 88 iteration 184: 0.5885596871376038\n",
            "loss in epoch 88 iteration 185: 0.5669167637825012\n",
            "loss in epoch 88 iteration 186: 0.5629661083221436\n",
            "loss in epoch 88 iteration 187: 0.5645017623901367\n",
            "loss in epoch 88 iteration 188: 0.56840980052948\n",
            "loss in epoch 88 iteration 189: 0.5998207330703735\n",
            "loss in epoch 88 iteration 190: 0.568192720413208\n",
            "loss in epoch 88 iteration 191: 0.5584750175476074\n",
            "loss in epoch 88 iteration 192: 0.552287220954895\n",
            "loss in epoch 88 iteration 193: 0.545883059501648\n",
            "loss in epoch 88 iteration 194: 0.5444339513778687\n",
            "loss in epoch 88 iteration 195: 0.5528537034988403\n",
            "loss in epoch 88 iteration 196: 0.5683544278144836\n",
            "loss in epoch 88 iteration 197: 0.5635004639625549\n",
            "loss in epoch 88 iteration 198: 0.5672482252120972\n",
            "loss in epoch 88 iteration 199: 0.5636285543441772\n",
            "loss in epoch 88 iteration 200: 0.5758333802223206\n",
            "loss in epoch 88 iteration 201: 0.5517832040786743\n",
            "loss in epoch 88 iteration 202: 0.5370721817016602\n",
            "loss in epoch 88 iteration 203: 0.5461626052856445\n",
            "loss in epoch 88 iteration 204: 0.5515932440757751\n",
            "loss in epoch 88 iteration 205: 0.5632438659667969\n",
            "loss in epoch 88 iteration 206: 0.5566370487213135\n",
            "loss in epoch 88 iteration 207: 0.5458709001541138\n",
            "loss in epoch 88 iteration 208: 0.55238276720047\n",
            "loss in epoch 88 iteration 209: 0.5628645420074463\n",
            "loss in epoch 88 iteration 210: 0.5713030099868774\n",
            "loss in epoch 88 iteration 211: 0.5829574465751648\n",
            "loss in epoch 88 iteration 212: 0.5961276292800903\n",
            "loss in epoch 88 iteration 213: 0.5913678407669067\n",
            "loss in epoch 88 iteration 214: 0.581099271774292\n",
            "loss in epoch 88 iteration 215: 0.5629253387451172\n",
            "loss in epoch 88 iteration 216: 0.5516358017921448\n",
            "loss in epoch 88 iteration 217: 0.5624343156814575\n",
            "loss in epoch 88 iteration 218: 0.5710057616233826\n",
            "loss in epoch 88 iteration 219: 0.576840877532959\n",
            "loss in epoch 88 iteration 220: 0.5447566509246826\n",
            "loss in epoch 88 iteration 221: 0.5671535134315491\n",
            "loss in epoch 88 iteration 222: 0.5456565618515015\n",
            "loss in epoch 88 iteration 223: 0.537411093711853\n",
            "loss in epoch 88 iteration 224: 0.5799221992492676\n",
            "loss in epoch 88 iteration 225: 0.576011061668396\n",
            "loss in epoch 88 iteration 226: 0.5571173429489136\n",
            "loss in epoch 88 iteration 227: 0.5550446510314941\n",
            "loss in epoch 88 iteration 228: 0.5632877945899963\n",
            "loss in epoch 88 iteration 229: 0.5798192620277405\n",
            "loss in epoch 88 iteration 230: 0.547067403793335\n",
            "loss in epoch 88 iteration 231: 0.5575639009475708\n",
            "loss in epoch 88 iteration 232: 0.5658031702041626\n",
            "loss in epoch 88 iteration 233: 0.6015437841415405\n",
            "loss in epoch 88 iteration 234: 0.5445884466171265\n",
            "loss in epoch 88 iteration 235: 0.5642451047897339\n",
            "loss in epoch 88 iteration 236: 0.5942205190658569\n",
            "loss in epoch 88 iteration 237: 0.5379680395126343\n",
            "loss in epoch 88 iteration 238: 0.5535976886749268\n",
            "loss in epoch 88 iteration 239: 0.5563339591026306\n",
            "loss in epoch 88 iteration 240: 0.5536422729492188\n",
            "loss in epoch 88 iteration 241: 0.578180730342865\n",
            "loss in epoch 88 iteration 242: 0.5635347962379456\n",
            "loss in epoch 89 iteration 0: 0.551591157913208\n",
            "loss in epoch 89 iteration 1: 0.5548480153083801\n",
            "loss in epoch 89 iteration 2: 0.5729424953460693\n",
            "loss in epoch 89 iteration 3: 0.5578618049621582\n",
            "loss in epoch 89 iteration 4: 0.5822945833206177\n",
            "loss in epoch 89 iteration 5: 0.53952956199646\n",
            "loss in epoch 89 iteration 6: 0.5696040391921997\n",
            "loss in epoch 89 iteration 7: 0.5569019317626953\n",
            "loss in epoch 89 iteration 8: 0.5652703046798706\n",
            "loss in epoch 89 iteration 9: 0.5674743056297302\n",
            "loss in epoch 89 iteration 10: 0.5627890825271606\n",
            "loss in epoch 89 iteration 11: 0.5864275693893433\n",
            "loss in epoch 89 iteration 12: 0.5730599164962769\n",
            "loss in epoch 89 iteration 13: 0.556090235710144\n",
            "loss in epoch 89 iteration 14: 0.5721858739852905\n",
            "loss in epoch 89 iteration 15: 0.5555669069290161\n",
            "loss in epoch 89 iteration 16: 0.5712686777114868\n",
            "loss in epoch 89 iteration 17: 0.5553260445594788\n",
            "loss in epoch 89 iteration 18: 0.5387730598449707\n",
            "loss in epoch 89 iteration 19: 0.5685204863548279\n",
            "loss in epoch 89 iteration 20: 0.5814437866210938\n",
            "loss in epoch 89 iteration 21: 0.5604665875434875\n",
            "loss in epoch 89 iteration 22: 0.5580196380615234\n",
            "loss in epoch 89 iteration 23: 0.5829252600669861\n",
            "loss in epoch 89 iteration 24: 0.5681084990501404\n",
            "loss in epoch 89 iteration 25: 0.5801947116851807\n",
            "loss in epoch 89 iteration 26: 0.564410924911499\n",
            "loss in epoch 89 iteration 27: 0.5679056644439697\n",
            "loss in epoch 89 iteration 28: 0.565834641456604\n",
            "loss in epoch 89 iteration 29: 0.5280464887619019\n",
            "loss in epoch 89 iteration 30: 0.5746363997459412\n",
            "loss in epoch 89 iteration 31: 0.5773597955703735\n",
            "loss in epoch 89 iteration 32: 0.586545467376709\n",
            "loss in epoch 89 iteration 33: 0.5709946155548096\n",
            "loss in epoch 89 iteration 34: 0.537406861782074\n",
            "loss in epoch 89 iteration 35: 0.5718561410903931\n",
            "loss in epoch 89 iteration 36: 0.5747566223144531\n",
            "loss in epoch 89 iteration 37: 0.5530452728271484\n",
            "loss in epoch 89 iteration 38: 0.5584406852722168\n",
            "loss in epoch 89 iteration 39: 0.5613336563110352\n",
            "loss in epoch 89 iteration 40: 0.5788509249687195\n",
            "loss in epoch 89 iteration 41: 0.5657005310058594\n",
            "loss in epoch 89 iteration 42: 0.5851839184761047\n",
            "loss in epoch 89 iteration 43: 0.5864930152893066\n",
            "loss in epoch 89 iteration 44: 0.5750483274459839\n",
            "loss in epoch 89 iteration 45: 0.5310034155845642\n",
            "loss in epoch 89 iteration 46: 0.5339245796203613\n",
            "loss in epoch 89 iteration 47: 0.574291467666626\n",
            "loss in epoch 89 iteration 48: 0.5619447231292725\n",
            "loss in epoch 89 iteration 49: 0.5778532028198242\n",
            "loss in epoch 89 iteration 50: 0.5668119192123413\n",
            "loss in epoch 89 iteration 51: 0.5544514060020447\n",
            "loss in epoch 89 iteration 52: 0.556266188621521\n",
            "loss in epoch 89 iteration 53: 0.5433853268623352\n",
            "loss in epoch 89 iteration 54: 0.5634918212890625\n",
            "loss in epoch 89 iteration 55: 0.5721442699432373\n",
            "loss in epoch 89 iteration 56: 0.5414794683456421\n",
            "loss in epoch 89 iteration 57: 0.5842366218566895\n",
            "loss in epoch 89 iteration 58: 0.5802721381187439\n",
            "loss in epoch 89 iteration 59: 0.5582255125045776\n",
            "loss in epoch 89 iteration 60: 0.5440254211425781\n",
            "loss in epoch 89 iteration 61: 0.57100510597229\n",
            "loss in epoch 89 iteration 62: 0.5611786842346191\n",
            "loss in epoch 89 iteration 63: 0.5572388172149658\n",
            "loss in epoch 89 iteration 64: 0.5560963153839111\n",
            "loss in epoch 89 iteration 65: 0.5429408550262451\n",
            "loss in epoch 89 iteration 66: 0.5487049221992493\n",
            "loss in epoch 89 iteration 67: 0.5684677362442017\n",
            "loss in epoch 89 iteration 68: 0.5642239451408386\n",
            "loss in epoch 89 iteration 69: 0.5519324541091919\n",
            "loss in epoch 89 iteration 70: 0.5481276512145996\n",
            "loss in epoch 89 iteration 71: 0.566270112991333\n",
            "loss in epoch 89 iteration 72: 0.570082426071167\n",
            "loss in epoch 89 iteration 73: 0.5622319579124451\n",
            "loss in epoch 89 iteration 74: 0.5537005066871643\n",
            "loss in epoch 89 iteration 75: 0.5815964937210083\n",
            "loss in epoch 89 iteration 76: 0.5407663583755493\n",
            "loss in epoch 89 iteration 77: 0.5347269177436829\n",
            "loss in epoch 89 iteration 78: 0.5529744625091553\n",
            "loss in epoch 89 iteration 79: 0.5596269369125366\n",
            "loss in epoch 89 iteration 80: 0.5521575212478638\n",
            "loss in epoch 89 iteration 81: 0.5590535402297974\n",
            "loss in epoch 89 iteration 82: 0.5789240002632141\n",
            "loss in epoch 89 iteration 83: 0.5464893579483032\n",
            "loss in epoch 89 iteration 84: 0.5506812930107117\n",
            "loss in epoch 89 iteration 85: 0.5834743976593018\n",
            "loss in epoch 89 iteration 86: 0.5758634805679321\n",
            "loss in epoch 89 iteration 87: 0.5367470383644104\n",
            "loss in epoch 89 iteration 88: 0.5444337725639343\n",
            "loss in epoch 89 iteration 89: 0.568885326385498\n",
            "loss in epoch 89 iteration 90: 0.5446666479110718\n",
            "loss in epoch 89 iteration 91: 0.548457145690918\n",
            "loss in epoch 89 iteration 92: 0.554612398147583\n",
            "loss in epoch 89 iteration 93: 0.5716148018836975\n",
            "loss in epoch 89 iteration 94: 0.5479550361633301\n",
            "loss in epoch 89 iteration 95: 0.5636422634124756\n",
            "loss in epoch 89 iteration 96: 0.5549449920654297\n",
            "loss in epoch 89 iteration 97: 0.5633424520492554\n",
            "loss in epoch 89 iteration 98: 0.5458517670631409\n",
            "loss in epoch 89 iteration 99: 0.5492420196533203\n",
            "loss in epoch 89 iteration 100: 0.5615437030792236\n",
            "loss in epoch 89 iteration 101: 0.5450044870376587\n",
            "loss in epoch 89 iteration 102: 0.5503267049789429\n",
            "loss in epoch 89 iteration 103: 0.5880235433578491\n",
            "loss in epoch 89 iteration 104: 0.5683844089508057\n",
            "loss in epoch 89 iteration 105: 0.5994528532028198\n",
            "loss in epoch 89 iteration 106: 0.5518340468406677\n",
            "loss in epoch 89 iteration 107: 0.5621806383132935\n",
            "loss in epoch 89 iteration 108: 0.5751050710678101\n",
            "loss in epoch 89 iteration 109: 0.5615878701210022\n",
            "loss in epoch 89 iteration 110: 0.5977668762207031\n",
            "loss in epoch 89 iteration 111: 0.5853126645088196\n",
            "loss in epoch 89 iteration 112: 0.5374561548233032\n",
            "loss in epoch 89 iteration 113: 0.5436556339263916\n",
            "loss in epoch 89 iteration 114: 0.5486313104629517\n",
            "loss in epoch 89 iteration 115: 0.5741857290267944\n",
            "loss in epoch 89 iteration 116: 0.5405294895172119\n",
            "loss in epoch 89 iteration 117: 0.5188071727752686\n",
            "loss in epoch 89 iteration 118: 0.5666912794113159\n",
            "loss in epoch 89 iteration 119: 0.5724736452102661\n",
            "loss in epoch 89 iteration 120: 0.5571197271347046\n",
            "loss in epoch 89 iteration 121: 0.5295426845550537\n",
            "loss in epoch 89 iteration 122: 0.5363717079162598\n",
            "loss in epoch 89 iteration 123: 0.5686134099960327\n",
            "loss in epoch 89 iteration 124: 0.5470101833343506\n",
            "loss in epoch 89 iteration 125: 0.5536019802093506\n",
            "loss in epoch 89 iteration 126: 0.5620062351226807\n",
            "loss in epoch 89 iteration 127: 0.5525336861610413\n",
            "loss in epoch 89 iteration 128: 0.5669757127761841\n",
            "loss in epoch 89 iteration 129: 0.5421581268310547\n",
            "loss in epoch 89 iteration 130: 0.5381313562393188\n",
            "loss in epoch 89 iteration 131: 0.5716776847839355\n",
            "loss in epoch 89 iteration 132: 0.5458483099937439\n",
            "loss in epoch 89 iteration 133: 0.560498833656311\n",
            "loss in epoch 89 iteration 134: 0.5623964071273804\n",
            "loss in epoch 89 iteration 135: 0.5471541881561279\n",
            "loss in epoch 89 iteration 136: 0.5717582702636719\n",
            "loss in epoch 89 iteration 137: 0.5677330493927002\n",
            "loss in epoch 89 iteration 138: 0.5514283180236816\n",
            "loss in epoch 89 iteration 139: 0.5470640063285828\n",
            "loss in epoch 89 iteration 140: 0.5786569118499756\n",
            "loss in epoch 89 iteration 141: 0.5779610872268677\n",
            "loss in epoch 89 iteration 142: 0.5598955154418945\n",
            "loss in epoch 89 iteration 143: 0.5525479316711426\n",
            "loss in epoch 89 iteration 144: 0.5686790943145752\n",
            "loss in epoch 89 iteration 145: 0.5585405230522156\n",
            "loss in epoch 89 iteration 146: 0.570213794708252\n",
            "loss in epoch 89 iteration 147: 0.5417594909667969\n",
            "loss in epoch 89 iteration 148: 0.5614246129989624\n",
            "loss in epoch 89 iteration 149: 0.5552989840507507\n",
            "loss in epoch 89 iteration 150: 0.5344996452331543\n",
            "loss in epoch 89 iteration 151: 0.5690159201622009\n",
            "loss in epoch 89 iteration 152: 0.5698022842407227\n",
            "loss in epoch 89 iteration 153: 0.5357522964477539\n",
            "loss in epoch 89 iteration 154: 0.5506010055541992\n",
            "loss in epoch 89 iteration 155: 0.5747098922729492\n",
            "loss in epoch 89 iteration 156: 0.5695882439613342\n",
            "loss in epoch 89 iteration 157: 0.5505871176719666\n",
            "loss in epoch 89 iteration 158: 0.5494230389595032\n",
            "loss in epoch 89 iteration 159: 0.5238193273544312\n",
            "loss in epoch 89 iteration 160: 0.5652298331260681\n",
            "loss in epoch 89 iteration 161: 0.564955472946167\n",
            "loss in epoch 89 iteration 162: 0.5896354913711548\n",
            "loss in epoch 89 iteration 163: 0.5769426822662354\n",
            "loss in epoch 89 iteration 164: 0.5333873629570007\n",
            "loss in epoch 89 iteration 165: 0.5582903027534485\n",
            "loss in epoch 89 iteration 166: 0.5478410720825195\n",
            "loss in epoch 89 iteration 167: 0.5658024549484253\n",
            "loss in epoch 89 iteration 168: 0.5482845306396484\n",
            "loss in epoch 89 iteration 169: 0.5664896368980408\n",
            "loss in epoch 89 iteration 170: 0.5776036977767944\n",
            "loss in epoch 89 iteration 171: 0.5351855754852295\n",
            "loss in epoch 89 iteration 172: 0.570598840713501\n",
            "loss in epoch 89 iteration 173: 0.550873875617981\n",
            "loss in epoch 89 iteration 174: 0.5490215420722961\n",
            "loss in epoch 89 iteration 175: 0.5860555171966553\n",
            "loss in epoch 89 iteration 176: 0.5621299147605896\n",
            "loss in epoch 89 iteration 177: 0.5662939548492432\n",
            "loss in epoch 89 iteration 178: 0.5527891516685486\n",
            "loss in epoch 89 iteration 179: 0.574759840965271\n",
            "loss in epoch 89 iteration 180: 0.5670798420906067\n",
            "loss in epoch 89 iteration 181: 0.578494668006897\n",
            "loss in epoch 89 iteration 182: 0.6033008098602295\n",
            "loss in epoch 89 iteration 183: 0.5540651082992554\n",
            "loss in epoch 89 iteration 184: 0.5610197186470032\n",
            "loss in epoch 89 iteration 185: 0.5747435688972473\n",
            "loss in epoch 89 iteration 186: 0.5398757457733154\n",
            "loss in epoch 89 iteration 187: 0.5541239976882935\n",
            "loss in epoch 89 iteration 188: 0.5400582551956177\n",
            "loss in epoch 89 iteration 189: 0.5555126070976257\n",
            "loss in epoch 89 iteration 190: 0.5624034404754639\n",
            "loss in epoch 89 iteration 191: 0.5660161972045898\n",
            "loss in epoch 89 iteration 192: 0.5722087621688843\n",
            "loss in epoch 89 iteration 193: 0.564098596572876\n",
            "loss in epoch 89 iteration 194: 0.5569770336151123\n",
            "loss in epoch 89 iteration 195: 0.5530983805656433\n",
            "loss in epoch 89 iteration 196: 0.5604131817817688\n",
            "loss in epoch 89 iteration 197: 0.5763469934463501\n",
            "loss in epoch 89 iteration 198: 0.573251485824585\n",
            "loss in epoch 89 iteration 199: 0.5702608823776245\n",
            "loss in epoch 89 iteration 200: 0.5562456846237183\n",
            "loss in epoch 89 iteration 201: 0.541449248790741\n",
            "loss in epoch 89 iteration 202: 0.559876561164856\n",
            "loss in epoch 89 iteration 203: 0.5690407156944275\n",
            "loss in epoch 89 iteration 204: 0.5590037107467651\n",
            "loss in epoch 89 iteration 205: 0.5407657623291016\n",
            "loss in epoch 89 iteration 206: 0.5770671367645264\n",
            "loss in epoch 89 iteration 207: 0.5325071811676025\n",
            "loss in epoch 89 iteration 208: 0.5564450025558472\n",
            "loss in epoch 89 iteration 209: 0.5337084531784058\n",
            "loss in epoch 89 iteration 210: 0.5676963329315186\n",
            "loss in epoch 89 iteration 211: 0.5431462526321411\n",
            "loss in epoch 89 iteration 212: 0.5810186862945557\n",
            "loss in epoch 89 iteration 213: 0.5571310520172119\n",
            "loss in epoch 89 iteration 214: 0.5548039674758911\n",
            "loss in epoch 89 iteration 215: 0.5750975608825684\n",
            "loss in epoch 89 iteration 216: 0.559833824634552\n",
            "loss in epoch 89 iteration 217: 0.5691066980361938\n",
            "loss in epoch 89 iteration 218: 0.558894157409668\n",
            "loss in epoch 89 iteration 219: 0.5732887983322144\n",
            "loss in epoch 89 iteration 220: 0.5597525238990784\n",
            "loss in epoch 89 iteration 221: 0.556492030620575\n",
            "loss in epoch 89 iteration 222: 0.5660867691040039\n",
            "loss in epoch 89 iteration 223: 0.5631512403488159\n",
            "loss in epoch 89 iteration 224: 0.5635775923728943\n",
            "loss in epoch 89 iteration 225: 0.5651342272758484\n",
            "loss in epoch 89 iteration 226: 0.529960036277771\n",
            "loss in epoch 89 iteration 227: 0.5803449153900146\n",
            "loss in epoch 89 iteration 228: 0.5314483046531677\n",
            "loss in epoch 89 iteration 229: 0.5624434947967529\n",
            "loss in epoch 89 iteration 230: 0.5848623514175415\n",
            "loss in epoch 89 iteration 231: 0.5402889847755432\n",
            "loss in epoch 89 iteration 232: 0.5522173643112183\n",
            "loss in epoch 89 iteration 233: 0.5692157745361328\n",
            "loss in epoch 89 iteration 234: 0.5819823741912842\n",
            "loss in epoch 89 iteration 235: 0.5536618232727051\n",
            "loss in epoch 89 iteration 236: 0.5827057361602783\n",
            "loss in epoch 89 iteration 237: 0.5610809922218323\n",
            "loss in epoch 89 iteration 238: 0.5499809384346008\n",
            "loss in epoch 89 iteration 239: 0.559913158416748\n",
            "loss in epoch 89 iteration 240: 0.5548766851425171\n",
            "loss in epoch 89 iteration 241: 0.5631110668182373\n",
            "loss in epoch 89 iteration 242: 0.5448758602142334\n",
            "loss in epoch 90 iteration 0: 0.5645701885223389\n",
            "loss in epoch 90 iteration 1: 0.5660965442657471\n",
            "loss in epoch 90 iteration 2: 0.5688064694404602\n",
            "loss in epoch 90 iteration 3: 0.5588618516921997\n",
            "loss in epoch 90 iteration 4: 0.5553979873657227\n",
            "loss in epoch 90 iteration 5: 0.5577065944671631\n",
            "loss in epoch 90 iteration 6: 0.5306978225708008\n",
            "loss in epoch 90 iteration 7: 0.555827260017395\n",
            "loss in epoch 90 iteration 8: 0.5620745420455933\n",
            "loss in epoch 90 iteration 9: 0.5759857892990112\n",
            "loss in epoch 90 iteration 10: 0.5441259741783142\n",
            "loss in epoch 90 iteration 11: 0.559756875038147\n",
            "loss in epoch 90 iteration 12: 0.5358867645263672\n",
            "loss in epoch 90 iteration 13: 0.5254700183868408\n",
            "loss in epoch 90 iteration 14: 0.5854809880256653\n",
            "loss in epoch 90 iteration 15: 0.547897219657898\n",
            "loss in epoch 90 iteration 16: 0.5590595006942749\n",
            "loss in epoch 90 iteration 17: 0.5688696503639221\n",
            "loss in epoch 90 iteration 18: 0.5752660632133484\n",
            "loss in epoch 90 iteration 19: 0.5512980818748474\n",
            "loss in epoch 90 iteration 20: 0.5770376920700073\n",
            "loss in epoch 90 iteration 21: 0.5660480260848999\n",
            "loss in epoch 90 iteration 22: 0.5959587097167969\n",
            "loss in epoch 90 iteration 23: 0.5445618629455566\n",
            "loss in epoch 90 iteration 24: 0.552679717540741\n",
            "loss in epoch 90 iteration 25: 0.5566277503967285\n",
            "loss in epoch 90 iteration 26: 0.554772138595581\n",
            "loss in epoch 90 iteration 27: 0.5723456740379333\n",
            "loss in epoch 90 iteration 28: 0.585239827632904\n",
            "loss in epoch 90 iteration 29: 0.5416992902755737\n",
            "loss in epoch 90 iteration 30: 0.5450431108474731\n",
            "loss in epoch 90 iteration 31: 0.5439650416374207\n",
            "loss in epoch 90 iteration 32: 0.5438146591186523\n",
            "loss in epoch 90 iteration 33: 0.5873664617538452\n",
            "loss in epoch 90 iteration 34: 0.5700176954269409\n",
            "loss in epoch 90 iteration 35: 0.5428495407104492\n",
            "loss in epoch 90 iteration 36: 0.5794438123703003\n",
            "loss in epoch 90 iteration 37: 0.5742972493171692\n",
            "loss in epoch 90 iteration 38: 0.5852344036102295\n",
            "loss in epoch 90 iteration 39: 0.5697334408760071\n",
            "loss in epoch 90 iteration 40: 0.5767554044723511\n",
            "loss in epoch 90 iteration 41: 0.554373025894165\n",
            "loss in epoch 90 iteration 42: 0.5427942276000977\n",
            "loss in epoch 90 iteration 43: 0.5566246509552002\n",
            "loss in epoch 90 iteration 44: 0.5762046575546265\n",
            "loss in epoch 90 iteration 45: 0.5650556087493896\n",
            "loss in epoch 90 iteration 46: 0.5403108596801758\n",
            "loss in epoch 90 iteration 47: 0.5744767189025879\n",
            "loss in epoch 90 iteration 48: 0.5846471786499023\n",
            "loss in epoch 90 iteration 49: 0.5728334188461304\n",
            "loss in epoch 90 iteration 50: 0.5535426139831543\n",
            "loss in epoch 90 iteration 51: 0.5637098550796509\n",
            "loss in epoch 90 iteration 52: 0.5643267631530762\n",
            "loss in epoch 90 iteration 53: 0.5698096752166748\n",
            "loss in epoch 90 iteration 54: 0.5645297169685364\n",
            "loss in epoch 90 iteration 55: 0.564264178276062\n",
            "loss in epoch 90 iteration 56: 0.5478523373603821\n",
            "loss in epoch 90 iteration 57: 0.5903335809707642\n",
            "loss in epoch 90 iteration 58: 0.557539701461792\n",
            "loss in epoch 90 iteration 59: 0.5708533525466919\n",
            "loss in epoch 90 iteration 60: 0.5595307350158691\n",
            "loss in epoch 90 iteration 61: 0.5437009334564209\n",
            "loss in epoch 90 iteration 62: 0.5735191106796265\n",
            "loss in epoch 90 iteration 63: 0.5729478001594543\n",
            "loss in epoch 90 iteration 64: 0.579413890838623\n",
            "loss in epoch 90 iteration 65: 0.5477524995803833\n",
            "loss in epoch 90 iteration 66: 0.54047691822052\n",
            "loss in epoch 90 iteration 67: 0.5626602172851562\n",
            "loss in epoch 90 iteration 68: 0.5592923164367676\n",
            "loss in epoch 90 iteration 69: 0.5447617769241333\n",
            "loss in epoch 90 iteration 70: 0.5285189747810364\n",
            "loss in epoch 90 iteration 71: 0.570170521736145\n",
            "loss in epoch 90 iteration 72: 0.5558068156242371\n",
            "loss in epoch 90 iteration 73: 0.5688140392303467\n",
            "loss in epoch 90 iteration 74: 0.5591588020324707\n",
            "loss in epoch 90 iteration 75: 0.5638078451156616\n",
            "loss in epoch 90 iteration 76: 0.5795067548751831\n",
            "loss in epoch 90 iteration 77: 0.5696661472320557\n",
            "loss in epoch 90 iteration 78: 0.5344895124435425\n",
            "loss in epoch 90 iteration 79: 0.5652895569801331\n",
            "loss in epoch 90 iteration 80: 0.5433223247528076\n",
            "loss in epoch 90 iteration 81: 0.5694520473480225\n",
            "loss in epoch 90 iteration 82: 0.5522244572639465\n",
            "loss in epoch 90 iteration 83: 0.5610164999961853\n",
            "loss in epoch 90 iteration 84: 0.5417613983154297\n",
            "loss in epoch 90 iteration 85: 0.6028863787651062\n",
            "loss in epoch 90 iteration 86: 0.5681201219558716\n",
            "loss in epoch 90 iteration 87: 0.5416969060897827\n",
            "loss in epoch 90 iteration 88: 0.5521036386489868\n",
            "loss in epoch 90 iteration 89: 0.5625288486480713\n",
            "loss in epoch 90 iteration 90: 0.561083972454071\n",
            "loss in epoch 90 iteration 91: 0.5559029579162598\n",
            "loss in epoch 90 iteration 92: 0.5401030778884888\n",
            "loss in epoch 90 iteration 93: 0.5796985626220703\n",
            "loss in epoch 90 iteration 94: 0.5868829488754272\n",
            "loss in epoch 90 iteration 95: 0.5241552591323853\n",
            "loss in epoch 90 iteration 96: 0.5602375268936157\n",
            "loss in epoch 90 iteration 97: 0.5404390692710876\n",
            "loss in epoch 90 iteration 98: 0.5683318972587585\n",
            "loss in epoch 90 iteration 99: 0.5591292977333069\n",
            "loss in epoch 90 iteration 100: 0.5482417941093445\n",
            "loss in epoch 90 iteration 101: 0.5841426849365234\n",
            "loss in epoch 90 iteration 102: 0.5451672077178955\n",
            "loss in epoch 90 iteration 103: 0.6167762875556946\n",
            "loss in epoch 90 iteration 104: 0.5746458768844604\n",
            "loss in epoch 90 iteration 105: 0.5568820238113403\n",
            "loss in epoch 90 iteration 106: 0.5639846324920654\n",
            "loss in epoch 90 iteration 107: 0.5466450452804565\n",
            "loss in epoch 90 iteration 108: 0.5822746753692627\n",
            "loss in epoch 90 iteration 109: 0.5592607259750366\n",
            "loss in epoch 90 iteration 110: 0.5464441776275635\n",
            "loss in epoch 90 iteration 111: 0.5604000091552734\n",
            "loss in epoch 90 iteration 112: 0.5531050562858582\n",
            "loss in epoch 90 iteration 113: 0.5410947203636169\n",
            "loss in epoch 90 iteration 114: 0.5334744453430176\n",
            "loss in epoch 90 iteration 115: 0.5691173076629639\n",
            "loss in epoch 90 iteration 116: 0.5681504011154175\n",
            "loss in epoch 90 iteration 117: 0.572737455368042\n",
            "loss in epoch 90 iteration 118: 0.5327624082565308\n",
            "loss in epoch 90 iteration 119: 0.5754277110099792\n",
            "loss in epoch 90 iteration 120: 0.5642755031585693\n",
            "loss in epoch 90 iteration 121: 0.5772000551223755\n",
            "loss in epoch 90 iteration 122: 0.5593074560165405\n",
            "loss in epoch 90 iteration 123: 0.5526090264320374\n",
            "loss in epoch 90 iteration 124: 0.5452082753181458\n",
            "loss in epoch 90 iteration 125: 0.5581198334693909\n",
            "loss in epoch 90 iteration 126: 0.5755270719528198\n",
            "loss in epoch 90 iteration 127: 0.5507950782775879\n",
            "loss in epoch 90 iteration 128: 0.5724509954452515\n",
            "loss in epoch 90 iteration 129: 0.5725033283233643\n",
            "loss in epoch 90 iteration 130: 0.5480775833129883\n",
            "loss in epoch 90 iteration 131: 0.5436639785766602\n",
            "loss in epoch 90 iteration 132: 0.5651712417602539\n",
            "loss in epoch 90 iteration 133: 0.5479279160499573\n",
            "loss in epoch 90 iteration 134: 0.5574332475662231\n",
            "loss in epoch 90 iteration 135: 0.5709970593452454\n",
            "loss in epoch 90 iteration 136: 0.558218777179718\n",
            "loss in epoch 90 iteration 137: 0.5234219431877136\n",
            "loss in epoch 90 iteration 138: 0.5586405992507935\n",
            "loss in epoch 90 iteration 139: 0.5601038336753845\n",
            "loss in epoch 90 iteration 140: 0.5549029111862183\n",
            "loss in epoch 90 iteration 141: 0.5560893416404724\n",
            "loss in epoch 90 iteration 142: 0.582480788230896\n",
            "loss in epoch 90 iteration 143: 0.5783270001411438\n",
            "loss in epoch 90 iteration 144: 0.5801804661750793\n",
            "loss in epoch 90 iteration 145: 0.5593556761741638\n",
            "loss in epoch 90 iteration 146: 0.5359607338905334\n",
            "loss in epoch 90 iteration 147: 0.5200508832931519\n",
            "loss in epoch 90 iteration 148: 0.5609780550003052\n",
            "loss in epoch 90 iteration 149: 0.568838357925415\n",
            "loss in epoch 90 iteration 150: 0.5587953329086304\n",
            "loss in epoch 90 iteration 151: 0.5291663408279419\n",
            "loss in epoch 90 iteration 152: 0.5410205125808716\n",
            "loss in epoch 90 iteration 153: 0.5618907809257507\n",
            "loss in epoch 90 iteration 154: 0.5662535429000854\n",
            "loss in epoch 90 iteration 155: 0.5852786302566528\n",
            "loss in epoch 90 iteration 156: 0.5384505987167358\n",
            "loss in epoch 90 iteration 157: 0.5724911093711853\n",
            "loss in epoch 90 iteration 158: 0.5590412616729736\n",
            "loss in epoch 90 iteration 159: 0.5664199590682983\n",
            "loss in epoch 90 iteration 160: 0.5459743142127991\n",
            "loss in epoch 90 iteration 161: 0.5706168413162231\n",
            "loss in epoch 90 iteration 162: 0.5698807835578918\n",
            "loss in epoch 90 iteration 163: 0.5641838312149048\n",
            "loss in epoch 90 iteration 164: 0.5638818740844727\n",
            "loss in epoch 90 iteration 165: 0.5642174482345581\n",
            "loss in epoch 90 iteration 166: 0.5367428660392761\n",
            "loss in epoch 90 iteration 167: 0.5571248531341553\n",
            "loss in epoch 90 iteration 168: 0.5665827393531799\n",
            "loss in epoch 90 iteration 169: 0.5557705163955688\n",
            "loss in epoch 90 iteration 170: 0.5533857941627502\n",
            "loss in epoch 90 iteration 171: 0.5508074760437012\n",
            "loss in epoch 90 iteration 172: 0.5798450708389282\n",
            "loss in epoch 90 iteration 173: 0.5287997126579285\n",
            "loss in epoch 90 iteration 174: 0.5463677048683167\n",
            "loss in epoch 90 iteration 175: 0.5649451017379761\n",
            "loss in epoch 90 iteration 176: 0.5637534260749817\n",
            "loss in epoch 90 iteration 177: 0.5515010356903076\n",
            "loss in epoch 90 iteration 178: 0.57137531042099\n",
            "loss in epoch 90 iteration 179: 0.5552002191543579\n",
            "loss in epoch 90 iteration 180: 0.5737497806549072\n",
            "loss in epoch 90 iteration 181: 0.5824736952781677\n",
            "loss in epoch 90 iteration 182: 0.5480368137359619\n",
            "loss in epoch 90 iteration 183: 0.5503395795822144\n",
            "loss in epoch 90 iteration 184: 0.5621354579925537\n",
            "loss in epoch 90 iteration 185: 0.5697104930877686\n",
            "loss in epoch 90 iteration 186: 0.5532092452049255\n",
            "loss in epoch 90 iteration 187: 0.5703921914100647\n",
            "loss in epoch 90 iteration 188: 0.5542582273483276\n",
            "loss in epoch 90 iteration 189: 0.5551825761795044\n",
            "loss in epoch 90 iteration 190: 0.5456011295318604\n",
            "loss in epoch 90 iteration 191: 0.5521114468574524\n",
            "loss in epoch 90 iteration 192: 0.513316810131073\n",
            "loss in epoch 90 iteration 193: 0.5476663112640381\n",
            "loss in epoch 90 iteration 194: 0.5438574552536011\n",
            "loss in epoch 90 iteration 195: 0.565855860710144\n",
            "loss in epoch 90 iteration 196: 0.5713616609573364\n",
            "loss in epoch 90 iteration 197: 0.5863711833953857\n",
            "loss in epoch 90 iteration 198: 0.5861451625823975\n",
            "loss in epoch 90 iteration 199: 0.5719696283340454\n",
            "loss in epoch 90 iteration 200: 0.573434054851532\n",
            "loss in epoch 90 iteration 201: 0.5584022998809814\n",
            "loss in epoch 90 iteration 202: 0.5777928829193115\n",
            "loss in epoch 90 iteration 203: 0.5782945156097412\n",
            "loss in epoch 90 iteration 204: 0.5666826963424683\n",
            "loss in epoch 90 iteration 205: 0.5652711987495422\n",
            "loss in epoch 90 iteration 206: 0.5911011099815369\n",
            "loss in epoch 90 iteration 207: 0.5321654677391052\n",
            "loss in epoch 90 iteration 208: 0.5792404413223267\n",
            "loss in epoch 90 iteration 209: 0.574203610420227\n",
            "loss in epoch 90 iteration 210: 0.5471978187561035\n",
            "loss in epoch 90 iteration 211: 0.5565460324287415\n",
            "loss in epoch 90 iteration 212: 0.5565953254699707\n",
            "loss in epoch 90 iteration 213: 0.5810074806213379\n",
            "loss in epoch 90 iteration 214: 0.5742444396018982\n",
            "loss in epoch 90 iteration 215: 0.566274106502533\n",
            "loss in epoch 90 iteration 216: 0.5377706289291382\n",
            "loss in epoch 90 iteration 217: 0.5640627145767212\n",
            "loss in epoch 90 iteration 218: 0.5795906186103821\n",
            "loss in epoch 90 iteration 219: 0.5548849105834961\n",
            "loss in epoch 90 iteration 220: 0.5739381313323975\n",
            "loss in epoch 90 iteration 221: 0.5276829600334167\n",
            "loss in epoch 90 iteration 222: 0.5383738279342651\n",
            "loss in epoch 90 iteration 223: 0.5789995789527893\n",
            "loss in epoch 90 iteration 224: 0.5669084191322327\n",
            "loss in epoch 90 iteration 225: 0.5516061186790466\n",
            "loss in epoch 90 iteration 226: 0.5708397626876831\n",
            "loss in epoch 90 iteration 227: 0.5694308876991272\n",
            "loss in epoch 90 iteration 228: 0.5704269409179688\n",
            "loss in epoch 90 iteration 229: 0.5550267696380615\n",
            "loss in epoch 90 iteration 230: 0.5470526814460754\n",
            "loss in epoch 90 iteration 231: 0.5756750106811523\n",
            "loss in epoch 90 iteration 232: 0.5609123706817627\n",
            "loss in epoch 90 iteration 233: 0.5545483827590942\n",
            "loss in epoch 90 iteration 234: 0.5550645589828491\n",
            "loss in epoch 90 iteration 235: 0.5745503902435303\n",
            "loss in epoch 90 iteration 236: 0.5592694282531738\n",
            "loss in epoch 90 iteration 237: 0.5515557527542114\n",
            "loss in epoch 90 iteration 238: 0.554837703704834\n",
            "loss in epoch 90 iteration 239: 0.5637686252593994\n",
            "loss in epoch 90 iteration 240: 0.5900826454162598\n",
            "loss in epoch 90 iteration 241: 0.5953094959259033\n",
            "loss in epoch 90 iteration 242: 0.5806803703308105\n",
            "loss in epoch 91 iteration 0: 0.5508074760437012\n",
            "loss in epoch 91 iteration 1: 0.5714421272277832\n",
            "loss in epoch 91 iteration 2: 0.5533344745635986\n",
            "loss in epoch 91 iteration 3: 0.5546878576278687\n",
            "loss in epoch 91 iteration 4: 0.5822197198867798\n",
            "loss in epoch 91 iteration 5: 0.5565482378005981\n",
            "loss in epoch 91 iteration 6: 0.5736314058303833\n",
            "loss in epoch 91 iteration 7: 0.557706356048584\n",
            "loss in epoch 91 iteration 8: 0.5641558170318604\n",
            "loss in epoch 91 iteration 9: 0.5835801959037781\n",
            "loss in epoch 91 iteration 10: 0.5591038465499878\n",
            "loss in epoch 91 iteration 11: 0.5604090690612793\n",
            "loss in epoch 91 iteration 12: 0.5568444728851318\n",
            "loss in epoch 91 iteration 13: 0.5594696998596191\n",
            "loss in epoch 91 iteration 14: 0.5662636756896973\n",
            "loss in epoch 91 iteration 15: 0.5500001311302185\n",
            "loss in epoch 91 iteration 16: 0.5891081690788269\n",
            "loss in epoch 91 iteration 17: 0.5667556524276733\n",
            "loss in epoch 91 iteration 18: 0.5599418878555298\n",
            "loss in epoch 91 iteration 19: 0.5813071727752686\n",
            "loss in epoch 91 iteration 20: 0.5761342644691467\n",
            "loss in epoch 91 iteration 21: 0.5741190314292908\n",
            "loss in epoch 91 iteration 22: 0.5808185338973999\n",
            "loss in epoch 91 iteration 23: 0.5945690870285034\n",
            "loss in epoch 91 iteration 24: 0.5627741813659668\n",
            "loss in epoch 91 iteration 25: 0.5722167491912842\n",
            "loss in epoch 91 iteration 26: 0.5526407361030579\n",
            "loss in epoch 91 iteration 27: 0.5699633359909058\n",
            "loss in epoch 91 iteration 28: 0.584484338760376\n",
            "loss in epoch 91 iteration 29: 0.5526809692382812\n",
            "loss in epoch 91 iteration 30: 0.5601561069488525\n",
            "loss in epoch 91 iteration 31: 0.5477428436279297\n",
            "loss in epoch 91 iteration 32: 0.5719539523124695\n",
            "loss in epoch 91 iteration 33: 0.5707606077194214\n",
            "loss in epoch 91 iteration 34: 0.5508182048797607\n",
            "loss in epoch 91 iteration 35: 0.5472572445869446\n",
            "loss in epoch 91 iteration 36: 0.5922523736953735\n",
            "loss in epoch 91 iteration 37: 0.5665827989578247\n",
            "loss in epoch 91 iteration 38: 0.5685831308364868\n",
            "loss in epoch 91 iteration 39: 0.5530484914779663\n",
            "loss in epoch 91 iteration 40: 0.5632637739181519\n",
            "loss in epoch 91 iteration 41: 0.545907735824585\n",
            "loss in epoch 91 iteration 42: 0.585731029510498\n",
            "loss in epoch 91 iteration 43: 0.5561220645904541\n",
            "loss in epoch 91 iteration 44: 0.5886358618736267\n",
            "loss in epoch 91 iteration 45: 0.5599254369735718\n",
            "loss in epoch 91 iteration 46: 0.5587194561958313\n",
            "loss in epoch 91 iteration 47: 0.5504066944122314\n",
            "loss in epoch 91 iteration 48: 0.5737494230270386\n",
            "loss in epoch 91 iteration 49: 0.5341993570327759\n",
            "loss in epoch 91 iteration 50: 0.5752435922622681\n",
            "loss in epoch 91 iteration 51: 0.5556110143661499\n",
            "loss in epoch 91 iteration 52: 0.5202165842056274\n",
            "loss in epoch 91 iteration 53: 0.5486725568771362\n",
            "loss in epoch 91 iteration 54: 0.5608699321746826\n",
            "loss in epoch 91 iteration 55: 0.5529155135154724\n",
            "loss in epoch 91 iteration 56: 0.5662374496459961\n",
            "loss in epoch 91 iteration 57: 0.5390071272850037\n",
            "loss in epoch 91 iteration 58: 0.5795835256576538\n",
            "loss in epoch 91 iteration 59: 0.542540431022644\n",
            "loss in epoch 91 iteration 60: 0.5438963770866394\n",
            "loss in epoch 91 iteration 61: 0.5319089293479919\n",
            "loss in epoch 91 iteration 62: 0.5405664443969727\n",
            "loss in epoch 91 iteration 63: 0.5853268504142761\n",
            "loss in epoch 91 iteration 64: 0.5703035593032837\n",
            "loss in epoch 91 iteration 65: 0.5527023077011108\n",
            "loss in epoch 91 iteration 66: 0.5366909503936768\n",
            "loss in epoch 91 iteration 67: 0.5567063093185425\n",
            "loss in epoch 91 iteration 68: 0.566298246383667\n",
            "loss in epoch 91 iteration 69: 0.575981855392456\n",
            "loss in epoch 91 iteration 70: 0.5929410457611084\n",
            "loss in epoch 91 iteration 71: 0.5817952156066895\n",
            "loss in epoch 91 iteration 72: 0.562877893447876\n",
            "loss in epoch 91 iteration 73: 0.5652093887329102\n",
            "loss in epoch 91 iteration 74: 0.593351423740387\n",
            "loss in epoch 91 iteration 75: 0.5624840259552002\n",
            "loss in epoch 91 iteration 76: 0.5511260032653809\n",
            "loss in epoch 91 iteration 77: 0.5644345879554749\n",
            "loss in epoch 91 iteration 78: 0.5783443450927734\n",
            "loss in epoch 91 iteration 79: 0.5611026287078857\n",
            "loss in epoch 91 iteration 80: 0.5739060044288635\n",
            "loss in epoch 91 iteration 81: 0.5761660933494568\n",
            "loss in epoch 91 iteration 82: 0.5880056619644165\n",
            "loss in epoch 91 iteration 83: 0.5622092485427856\n",
            "loss in epoch 91 iteration 84: 0.5502837300300598\n",
            "loss in epoch 91 iteration 85: 0.5461916923522949\n",
            "loss in epoch 91 iteration 86: 0.5456904768943787\n",
            "loss in epoch 91 iteration 87: 0.5630062222480774\n",
            "loss in epoch 91 iteration 88: 0.5768771171569824\n",
            "loss in epoch 91 iteration 89: 0.5652675032615662\n",
            "loss in epoch 91 iteration 90: 0.5442602634429932\n",
            "loss in epoch 91 iteration 91: 0.5545332431793213\n",
            "loss in epoch 91 iteration 92: 0.567350447177887\n",
            "loss in epoch 91 iteration 93: 0.565285325050354\n",
            "loss in epoch 91 iteration 94: 0.5786670446395874\n",
            "loss in epoch 91 iteration 95: 0.5564855337142944\n",
            "loss in epoch 91 iteration 96: 0.5532767176628113\n",
            "loss in epoch 91 iteration 97: 0.521933376789093\n",
            "loss in epoch 91 iteration 98: 0.5718098878860474\n",
            "loss in epoch 91 iteration 99: 0.5766704082489014\n",
            "loss in epoch 91 iteration 100: 0.5712425708770752\n",
            "loss in epoch 91 iteration 101: 0.5343418121337891\n",
            "loss in epoch 91 iteration 102: 0.535984992980957\n",
            "loss in epoch 91 iteration 103: 0.557766318321228\n",
            "loss in epoch 91 iteration 104: 0.5663055777549744\n",
            "loss in epoch 91 iteration 105: 0.5340133309364319\n",
            "loss in epoch 91 iteration 106: 0.5704023838043213\n",
            "loss in epoch 91 iteration 107: 0.5365243554115295\n",
            "loss in epoch 91 iteration 108: 0.547242283821106\n",
            "loss in epoch 91 iteration 109: 0.5573993921279907\n",
            "loss in epoch 91 iteration 110: 0.549640417098999\n",
            "loss in epoch 91 iteration 111: 0.5561869740486145\n",
            "loss in epoch 91 iteration 112: 0.5993087291717529\n",
            "loss in epoch 91 iteration 113: 0.563772976398468\n",
            "loss in epoch 91 iteration 114: 0.5609097480773926\n",
            "loss in epoch 91 iteration 115: 0.5749275088310242\n",
            "loss in epoch 91 iteration 116: 0.5403544306755066\n",
            "loss in epoch 91 iteration 117: 0.5114958882331848\n",
            "loss in epoch 91 iteration 118: 0.554489016532898\n",
            "loss in epoch 91 iteration 119: 0.562947154045105\n",
            "loss in epoch 91 iteration 120: 0.5768585801124573\n",
            "loss in epoch 91 iteration 121: 0.5453811883926392\n",
            "loss in epoch 91 iteration 122: 0.583519697189331\n",
            "loss in epoch 91 iteration 123: 0.5751850008964539\n",
            "loss in epoch 91 iteration 124: 0.5553671717643738\n",
            "loss in epoch 91 iteration 125: 0.5501604080200195\n",
            "loss in epoch 91 iteration 126: 0.5886403322219849\n",
            "loss in epoch 91 iteration 127: 0.5468572974205017\n",
            "loss in epoch 91 iteration 128: 0.5853739380836487\n",
            "loss in epoch 91 iteration 129: 0.539042055606842\n",
            "loss in epoch 91 iteration 130: 0.5761295557022095\n",
            "loss in epoch 91 iteration 131: 0.5551684498786926\n",
            "loss in epoch 91 iteration 132: 0.564346194267273\n",
            "loss in epoch 91 iteration 133: 0.5484695434570312\n",
            "loss in epoch 91 iteration 134: 0.5856914520263672\n",
            "loss in epoch 91 iteration 135: 0.5604713559150696\n",
            "loss in epoch 91 iteration 136: 0.5611483454704285\n",
            "loss in epoch 91 iteration 137: 0.52516770362854\n",
            "loss in epoch 91 iteration 138: 0.5833108425140381\n",
            "loss in epoch 91 iteration 139: 0.5621621608734131\n",
            "loss in epoch 91 iteration 140: 0.5797109007835388\n",
            "loss in epoch 91 iteration 141: 0.5570119619369507\n",
            "loss in epoch 91 iteration 142: 0.5602997541427612\n",
            "loss in epoch 91 iteration 143: 0.5812239050865173\n",
            "loss in epoch 91 iteration 144: 0.5696933269500732\n",
            "loss in epoch 91 iteration 145: 0.5665323734283447\n",
            "loss in epoch 91 iteration 146: 0.5788332223892212\n",
            "loss in epoch 91 iteration 147: 0.5682302713394165\n",
            "loss in epoch 91 iteration 148: 0.5415310263633728\n",
            "loss in epoch 91 iteration 149: 0.5608087778091431\n",
            "loss in epoch 91 iteration 150: 0.564720869064331\n",
            "loss in epoch 91 iteration 151: 0.5660631656646729\n",
            "loss in epoch 91 iteration 152: 0.5695756673812866\n",
            "loss in epoch 91 iteration 153: 0.5655770301818848\n",
            "loss in epoch 91 iteration 154: 0.5634990930557251\n",
            "loss in epoch 91 iteration 155: 0.5490595698356628\n",
            "loss in epoch 91 iteration 156: 0.5496348142623901\n",
            "loss in epoch 91 iteration 157: 0.5576618909835815\n",
            "loss in epoch 91 iteration 158: 0.5633398294448853\n",
            "loss in epoch 91 iteration 159: 0.5719954967498779\n",
            "loss in epoch 91 iteration 160: 0.5271043181419373\n",
            "loss in epoch 91 iteration 161: 0.5533556938171387\n",
            "loss in epoch 91 iteration 162: 0.5756996273994446\n",
            "loss in epoch 91 iteration 163: 0.56715327501297\n",
            "loss in epoch 91 iteration 164: 0.5650604963302612\n",
            "loss in epoch 91 iteration 165: 0.5776544809341431\n",
            "loss in epoch 91 iteration 166: 0.5306403040885925\n",
            "loss in epoch 91 iteration 167: 0.5698890089988708\n",
            "loss in epoch 91 iteration 168: 0.5606639385223389\n",
            "loss in epoch 91 iteration 169: 0.5484890937805176\n",
            "loss in epoch 91 iteration 170: 0.5872271060943604\n",
            "loss in epoch 91 iteration 171: 0.5550733804702759\n",
            "loss in epoch 91 iteration 172: 0.5607017874717712\n",
            "loss in epoch 91 iteration 173: 0.585029125213623\n",
            "loss in epoch 91 iteration 174: 0.5547498464584351\n",
            "loss in epoch 91 iteration 175: 0.5697785019874573\n",
            "loss in epoch 91 iteration 176: 0.5320355892181396\n",
            "loss in epoch 91 iteration 177: 0.5694538354873657\n",
            "loss in epoch 91 iteration 178: 0.5915201902389526\n",
            "loss in epoch 91 iteration 179: 0.518855094909668\n",
            "loss in epoch 91 iteration 180: 0.5451850891113281\n",
            "loss in epoch 91 iteration 181: 0.5656626224517822\n",
            "loss in epoch 91 iteration 182: 0.5654429197311401\n",
            "loss in epoch 91 iteration 183: 0.5465011596679688\n",
            "loss in epoch 91 iteration 184: 0.5967124700546265\n",
            "loss in epoch 91 iteration 185: 0.5241149067878723\n",
            "loss in epoch 91 iteration 186: 0.5625135898590088\n",
            "loss in epoch 91 iteration 187: 0.5497273802757263\n",
            "loss in epoch 91 iteration 188: 0.5579812526702881\n",
            "loss in epoch 91 iteration 189: 0.5536336898803711\n",
            "loss in epoch 91 iteration 190: 0.5465012788772583\n",
            "loss in epoch 91 iteration 191: 0.5520646572113037\n",
            "loss in epoch 91 iteration 192: 0.5462779998779297\n",
            "loss in epoch 91 iteration 193: 0.5583095550537109\n",
            "loss in epoch 91 iteration 194: 0.562140703201294\n",
            "loss in epoch 91 iteration 195: 0.5659507513046265\n",
            "loss in epoch 91 iteration 196: 0.5549659729003906\n",
            "loss in epoch 91 iteration 197: 0.5636218190193176\n",
            "loss in epoch 91 iteration 198: 0.5680028796195984\n",
            "loss in epoch 91 iteration 199: 0.5359026789665222\n",
            "loss in epoch 91 iteration 200: 0.5663065314292908\n",
            "loss in epoch 91 iteration 201: 0.5444316267967224\n",
            "loss in epoch 91 iteration 202: 0.5530993342399597\n",
            "loss in epoch 91 iteration 203: 0.5710145831108093\n",
            "loss in epoch 91 iteration 204: 0.5511727929115295\n",
            "loss in epoch 91 iteration 205: 0.553780198097229\n",
            "loss in epoch 91 iteration 206: 0.5651847720146179\n",
            "loss in epoch 91 iteration 207: 0.553828239440918\n",
            "loss in epoch 91 iteration 208: 0.5566281080245972\n",
            "loss in epoch 91 iteration 209: 0.5584256052970886\n",
            "loss in epoch 91 iteration 210: 0.5389212965965271\n",
            "loss in epoch 91 iteration 211: 0.5611268281936646\n",
            "loss in epoch 91 iteration 212: 0.5241655111312866\n",
            "loss in epoch 91 iteration 213: 0.5677316188812256\n",
            "loss in epoch 91 iteration 214: 0.5484303832054138\n",
            "loss in epoch 91 iteration 215: 0.5515924692153931\n",
            "loss in epoch 91 iteration 216: 0.5350545644760132\n",
            "loss in epoch 91 iteration 217: 0.5442618727684021\n",
            "loss in epoch 91 iteration 218: 0.5591152906417847\n",
            "loss in epoch 91 iteration 219: 0.543452799320221\n",
            "loss in epoch 91 iteration 220: 0.572338342666626\n",
            "loss in epoch 91 iteration 221: 0.5535069704055786\n",
            "loss in epoch 91 iteration 222: 0.574742317199707\n",
            "loss in epoch 91 iteration 223: 0.5802510380744934\n",
            "loss in epoch 91 iteration 224: 0.5443359613418579\n",
            "loss in epoch 91 iteration 225: 0.552696943283081\n",
            "loss in epoch 91 iteration 226: 0.5625210404396057\n",
            "loss in epoch 91 iteration 227: 0.557849109172821\n",
            "loss in epoch 91 iteration 228: 0.5377669334411621\n",
            "loss in epoch 91 iteration 229: 0.555335283279419\n",
            "loss in epoch 91 iteration 230: 0.5852875113487244\n",
            "loss in epoch 91 iteration 231: 0.567133903503418\n",
            "loss in epoch 91 iteration 232: 0.5589889287948608\n",
            "loss in epoch 91 iteration 233: 0.5776417851448059\n",
            "loss in epoch 91 iteration 234: 0.5339095592498779\n",
            "loss in epoch 91 iteration 235: 0.576454758644104\n",
            "loss in epoch 91 iteration 236: 0.56182461977005\n",
            "loss in epoch 91 iteration 237: 0.5927395820617676\n",
            "loss in epoch 91 iteration 238: 0.5286451578140259\n",
            "loss in epoch 91 iteration 239: 0.568673849105835\n",
            "loss in epoch 91 iteration 240: 0.5707067251205444\n",
            "loss in epoch 91 iteration 241: 0.5505536198616028\n",
            "loss in epoch 91 iteration 242: 0.5625472068786621\n",
            "loss in epoch 92 iteration 0: 0.5612318515777588\n",
            "loss in epoch 92 iteration 1: 0.5646389722824097\n",
            "loss in epoch 92 iteration 2: 0.5702942609786987\n",
            "loss in epoch 92 iteration 3: 0.5762761831283569\n",
            "loss in epoch 92 iteration 4: 0.5473877191543579\n",
            "loss in epoch 92 iteration 5: 0.5671491622924805\n",
            "loss in epoch 92 iteration 6: 0.5675610303878784\n",
            "loss in epoch 92 iteration 7: 0.5514931678771973\n",
            "loss in epoch 92 iteration 8: 0.5917031168937683\n",
            "loss in epoch 92 iteration 9: 0.5724309086799622\n",
            "loss in epoch 92 iteration 10: 0.570633590221405\n",
            "loss in epoch 92 iteration 11: 0.5540534257888794\n",
            "loss in epoch 92 iteration 12: 0.5293489694595337\n",
            "loss in epoch 92 iteration 13: 0.5797329545021057\n",
            "loss in epoch 92 iteration 14: 0.5773153305053711\n",
            "loss in epoch 92 iteration 15: 0.5599280595779419\n",
            "loss in epoch 92 iteration 16: 0.5384522676467896\n",
            "loss in epoch 92 iteration 17: 0.5659480094909668\n",
            "loss in epoch 92 iteration 18: 0.5463008880615234\n",
            "loss in epoch 92 iteration 19: 0.5548288822174072\n",
            "loss in epoch 92 iteration 20: 0.5627402663230896\n",
            "loss in epoch 92 iteration 21: 0.5331786870956421\n",
            "loss in epoch 92 iteration 22: 0.5306086540222168\n",
            "loss in epoch 92 iteration 23: 0.5421782732009888\n",
            "loss in epoch 92 iteration 24: 0.579184889793396\n",
            "loss in epoch 92 iteration 25: 0.5797984600067139\n",
            "loss in epoch 92 iteration 26: 0.5275382995605469\n",
            "loss in epoch 92 iteration 27: 0.5650762319564819\n",
            "loss in epoch 92 iteration 28: 0.555858850479126\n",
            "loss in epoch 92 iteration 29: 0.5511817932128906\n",
            "loss in epoch 92 iteration 30: 0.5828183889389038\n",
            "loss in epoch 92 iteration 31: 0.5654633045196533\n",
            "loss in epoch 92 iteration 32: 0.5516284704208374\n",
            "loss in epoch 92 iteration 33: 0.5803591012954712\n",
            "loss in epoch 92 iteration 34: 0.5338173508644104\n",
            "loss in epoch 92 iteration 35: 0.5510878562927246\n",
            "loss in epoch 92 iteration 36: 0.5582334399223328\n",
            "loss in epoch 92 iteration 37: 0.5589308738708496\n",
            "loss in epoch 92 iteration 38: 0.5285483598709106\n",
            "loss in epoch 92 iteration 39: 0.541405439376831\n",
            "loss in epoch 92 iteration 40: 0.5453567504882812\n",
            "loss in epoch 92 iteration 41: 0.5477679967880249\n",
            "loss in epoch 92 iteration 42: 0.566739559173584\n",
            "loss in epoch 92 iteration 43: 0.562816858291626\n",
            "loss in epoch 92 iteration 44: 0.5459566116333008\n",
            "loss in epoch 92 iteration 45: 0.578406572341919\n",
            "loss in epoch 92 iteration 46: 0.575416624546051\n",
            "loss in epoch 92 iteration 47: 0.5444454550743103\n",
            "loss in epoch 92 iteration 48: 0.5671065449714661\n",
            "loss in epoch 92 iteration 49: 0.555724024772644\n",
            "loss in epoch 92 iteration 50: 0.5790767669677734\n",
            "loss in epoch 92 iteration 51: 0.5459849834442139\n",
            "loss in epoch 92 iteration 52: 0.5712958574295044\n",
            "loss in epoch 92 iteration 53: 0.5654253363609314\n",
            "loss in epoch 92 iteration 54: 0.5626165866851807\n",
            "loss in epoch 92 iteration 55: 0.5461727976799011\n",
            "loss in epoch 92 iteration 56: 0.5519518852233887\n",
            "loss in epoch 92 iteration 57: 0.5517832636833191\n",
            "loss in epoch 92 iteration 58: 0.5376316905021667\n",
            "loss in epoch 92 iteration 59: 0.5570603609085083\n",
            "loss in epoch 92 iteration 60: 0.5380494594573975\n",
            "loss in epoch 92 iteration 61: 0.5398876667022705\n",
            "loss in epoch 92 iteration 62: 0.5452165603637695\n",
            "loss in epoch 92 iteration 63: 0.597623348236084\n",
            "loss in epoch 92 iteration 64: 0.5822480916976929\n",
            "loss in epoch 92 iteration 65: 0.5713120102882385\n",
            "loss in epoch 92 iteration 66: 0.5507950186729431\n",
            "loss in epoch 92 iteration 67: 0.5695629119873047\n",
            "loss in epoch 92 iteration 68: 0.5649417042732239\n",
            "loss in epoch 92 iteration 69: 0.5849800705909729\n",
            "loss in epoch 92 iteration 70: 0.5645542144775391\n",
            "loss in epoch 92 iteration 71: 0.5835749506950378\n",
            "loss in epoch 92 iteration 72: 0.5711458921432495\n",
            "loss in epoch 92 iteration 73: 0.5838085412979126\n",
            "loss in epoch 92 iteration 74: 0.542394757270813\n",
            "loss in epoch 92 iteration 75: 0.565488874912262\n",
            "loss in epoch 92 iteration 76: 0.5629242062568665\n",
            "loss in epoch 92 iteration 77: 0.5494415163993835\n",
            "loss in epoch 92 iteration 78: 0.5612187385559082\n",
            "loss in epoch 92 iteration 79: 0.5597010850906372\n",
            "loss in epoch 92 iteration 80: 0.5792679190635681\n",
            "loss in epoch 92 iteration 81: 0.5651965141296387\n",
            "loss in epoch 92 iteration 82: 0.5674166679382324\n",
            "loss in epoch 92 iteration 83: 0.5959465503692627\n",
            "loss in epoch 92 iteration 84: 0.5606421232223511\n",
            "loss in epoch 92 iteration 85: 0.5349963903427124\n",
            "loss in epoch 92 iteration 86: 0.571776270866394\n",
            "loss in epoch 92 iteration 87: 0.5490585565567017\n",
            "loss in epoch 92 iteration 88: 0.5498741865158081\n",
            "loss in epoch 92 iteration 89: 0.5660678744316101\n",
            "loss in epoch 92 iteration 90: 0.538011908531189\n",
            "loss in epoch 92 iteration 91: 0.5434705018997192\n",
            "loss in epoch 92 iteration 92: 0.5899460315704346\n",
            "loss in epoch 92 iteration 93: 0.5632317662239075\n",
            "loss in epoch 92 iteration 94: 0.5542727708816528\n",
            "loss in epoch 92 iteration 95: 0.58973628282547\n",
            "loss in epoch 92 iteration 96: 0.5781683325767517\n",
            "loss in epoch 92 iteration 97: 0.5572171807289124\n",
            "loss in epoch 92 iteration 98: 0.5779060125350952\n",
            "loss in epoch 92 iteration 99: 0.5547237396240234\n",
            "loss in epoch 92 iteration 100: 0.560092031955719\n",
            "loss in epoch 92 iteration 101: 0.5883288979530334\n",
            "loss in epoch 92 iteration 102: 0.5766664147377014\n",
            "loss in epoch 92 iteration 103: 0.5639485120773315\n",
            "loss in epoch 92 iteration 104: 0.5507467985153198\n",
            "loss in epoch 92 iteration 105: 0.5755307674407959\n",
            "loss in epoch 92 iteration 106: 0.5845752954483032\n",
            "loss in epoch 92 iteration 107: 0.5587909817695618\n",
            "loss in epoch 92 iteration 108: 0.5697126388549805\n",
            "loss in epoch 92 iteration 109: 0.558637261390686\n",
            "loss in epoch 92 iteration 110: 0.5617204308509827\n",
            "loss in epoch 92 iteration 111: 0.5685169696807861\n",
            "loss in epoch 92 iteration 112: 0.5596230030059814\n",
            "loss in epoch 92 iteration 113: 0.5548603534698486\n",
            "loss in epoch 92 iteration 114: 0.5655691027641296\n",
            "loss in epoch 92 iteration 115: 0.547273576259613\n",
            "loss in epoch 92 iteration 116: 0.5516449213027954\n",
            "loss in epoch 92 iteration 117: 0.565041720867157\n",
            "loss in epoch 92 iteration 118: 0.5314623117446899\n",
            "loss in epoch 92 iteration 119: 0.5506260991096497\n",
            "loss in epoch 92 iteration 120: 0.5633234977722168\n",
            "loss in epoch 92 iteration 121: 0.576124370098114\n",
            "loss in epoch 92 iteration 122: 0.5876139998435974\n",
            "loss in epoch 92 iteration 123: 0.541358232498169\n",
            "loss in epoch 92 iteration 124: 0.5674891471862793\n",
            "loss in epoch 92 iteration 125: 0.5536619424819946\n",
            "loss in epoch 92 iteration 126: 0.5442780256271362\n",
            "loss in epoch 92 iteration 127: 0.5772715210914612\n",
            "loss in epoch 92 iteration 128: 0.5764816403388977\n",
            "loss in epoch 92 iteration 129: 0.5658305883407593\n",
            "loss in epoch 92 iteration 130: 0.5646612644195557\n",
            "loss in epoch 92 iteration 131: 0.5728491544723511\n",
            "loss in epoch 92 iteration 132: 0.5474525690078735\n",
            "loss in epoch 92 iteration 133: 0.5407991409301758\n",
            "loss in epoch 92 iteration 134: 0.5783262848854065\n",
            "loss in epoch 92 iteration 135: 0.549426794052124\n",
            "loss in epoch 92 iteration 136: 0.5492825508117676\n",
            "loss in epoch 92 iteration 137: 0.566740870475769\n",
            "loss in epoch 92 iteration 138: 0.5411118865013123\n",
            "loss in epoch 92 iteration 139: 0.5518118143081665\n",
            "loss in epoch 92 iteration 140: 0.542621374130249\n",
            "loss in epoch 92 iteration 141: 0.5511412024497986\n",
            "loss in epoch 92 iteration 142: 0.5537552833557129\n",
            "loss in epoch 92 iteration 143: 0.5819189548492432\n",
            "loss in epoch 92 iteration 144: 0.5756893157958984\n",
            "loss in epoch 92 iteration 145: 0.5676026344299316\n",
            "loss in epoch 92 iteration 146: 0.534387469291687\n",
            "loss in epoch 92 iteration 147: 0.5302320718765259\n",
            "loss in epoch 92 iteration 148: 0.5658016204833984\n",
            "loss in epoch 92 iteration 149: 0.5637167692184448\n",
            "loss in epoch 92 iteration 150: 0.6002073287963867\n",
            "loss in epoch 92 iteration 151: 0.5768849849700928\n",
            "loss in epoch 92 iteration 152: 0.5560177564620972\n",
            "loss in epoch 92 iteration 153: 0.5591946840286255\n",
            "loss in epoch 92 iteration 154: 0.5665856599807739\n",
            "loss in epoch 92 iteration 155: 0.5901873111724854\n",
            "loss in epoch 92 iteration 156: 0.5421505570411682\n",
            "loss in epoch 92 iteration 157: 0.586372435092926\n",
            "loss in epoch 92 iteration 158: 0.5558490753173828\n",
            "loss in epoch 92 iteration 159: 0.5431646704673767\n",
            "loss in epoch 92 iteration 160: 0.5679061412811279\n",
            "loss in epoch 92 iteration 161: 0.5261293649673462\n",
            "loss in epoch 92 iteration 162: 0.5464708805084229\n",
            "loss in epoch 92 iteration 163: 0.5560915470123291\n",
            "loss in epoch 92 iteration 164: 0.5588462352752686\n",
            "loss in epoch 92 iteration 165: 0.570944607257843\n",
            "loss in epoch 92 iteration 166: 0.5579885840415955\n",
            "loss in epoch 92 iteration 167: 0.5705028772354126\n",
            "loss in epoch 92 iteration 168: 0.5673725008964539\n",
            "loss in epoch 92 iteration 169: 0.5798885822296143\n",
            "loss in epoch 92 iteration 170: 0.5944089889526367\n",
            "loss in epoch 92 iteration 171: 0.5756286382675171\n",
            "loss in epoch 92 iteration 172: 0.5530650615692139\n",
            "loss in epoch 92 iteration 173: 0.5585190057754517\n",
            "loss in epoch 92 iteration 174: 0.5321277976036072\n",
            "loss in epoch 92 iteration 175: 0.5452899932861328\n",
            "loss in epoch 92 iteration 176: 0.5551487803459167\n",
            "loss in epoch 92 iteration 177: 0.5802097320556641\n",
            "loss in epoch 92 iteration 178: 0.5642489194869995\n",
            "loss in epoch 92 iteration 179: 0.5450653433799744\n",
            "loss in epoch 92 iteration 180: 0.5677016973495483\n",
            "loss in epoch 92 iteration 181: 0.5649598836898804\n",
            "loss in epoch 92 iteration 182: 0.5585578083992004\n",
            "loss in epoch 92 iteration 183: 0.5585354566574097\n",
            "loss in epoch 92 iteration 184: 0.5491485595703125\n",
            "loss in epoch 92 iteration 185: 0.5603022575378418\n",
            "loss in epoch 92 iteration 186: 0.5509787201881409\n",
            "loss in epoch 92 iteration 187: 0.5693881511688232\n",
            "loss in epoch 92 iteration 188: 0.5643267035484314\n",
            "loss in epoch 92 iteration 189: 0.5564731359481812\n",
            "loss in epoch 92 iteration 190: 0.566698431968689\n",
            "loss in epoch 92 iteration 191: 0.5649437308311462\n",
            "loss in epoch 92 iteration 192: 0.5706495046615601\n",
            "loss in epoch 92 iteration 193: 0.5644702911376953\n",
            "loss in epoch 92 iteration 194: 0.5740232467651367\n",
            "loss in epoch 92 iteration 195: 0.5780729651451111\n",
            "loss in epoch 92 iteration 196: 0.5895678997039795\n",
            "loss in epoch 92 iteration 197: 0.5570593476295471\n",
            "loss in epoch 92 iteration 198: 0.5498160123825073\n",
            "loss in epoch 92 iteration 199: 0.5470069646835327\n",
            "loss in epoch 92 iteration 200: 0.555432915687561\n",
            "loss in epoch 92 iteration 201: 0.5627027750015259\n",
            "loss in epoch 92 iteration 202: 0.5633819103240967\n",
            "loss in epoch 92 iteration 203: 0.5260858535766602\n",
            "loss in epoch 92 iteration 204: 0.5524532794952393\n",
            "loss in epoch 92 iteration 205: 0.5749521255493164\n",
            "loss in epoch 92 iteration 206: 0.5376776456832886\n",
            "loss in epoch 92 iteration 207: 0.5791295766830444\n",
            "loss in epoch 92 iteration 208: 0.5692234039306641\n",
            "loss in epoch 92 iteration 209: 0.5716639757156372\n",
            "loss in epoch 92 iteration 210: 0.5585202574729919\n",
            "loss in epoch 92 iteration 211: 0.5502703189849854\n",
            "loss in epoch 92 iteration 212: 0.5495022535324097\n",
            "loss in epoch 92 iteration 213: 0.5950264930725098\n",
            "loss in epoch 92 iteration 214: 0.5795129537582397\n",
            "loss in epoch 92 iteration 215: 0.5434269309043884\n",
            "loss in epoch 92 iteration 216: 0.5441511869430542\n",
            "loss in epoch 92 iteration 217: 0.5279886722564697\n",
            "loss in epoch 92 iteration 218: 0.583233118057251\n",
            "loss in epoch 92 iteration 219: 0.5698333978652954\n",
            "loss in epoch 92 iteration 220: 0.5843621492385864\n",
            "loss in epoch 92 iteration 221: 0.5685626268386841\n",
            "loss in epoch 92 iteration 222: 0.518763542175293\n",
            "loss in epoch 92 iteration 223: 0.5425205826759338\n",
            "loss in epoch 92 iteration 224: 0.5389416217803955\n",
            "loss in epoch 92 iteration 225: 0.5782110691070557\n",
            "loss in epoch 92 iteration 226: 0.5595687627792358\n",
            "loss in epoch 92 iteration 227: 0.5197880268096924\n",
            "loss in epoch 92 iteration 228: 0.5589698553085327\n",
            "loss in epoch 92 iteration 229: 0.5567374229431152\n",
            "loss in epoch 92 iteration 230: 0.5574504137039185\n",
            "loss in epoch 92 iteration 231: 0.593246340751648\n",
            "loss in epoch 92 iteration 232: 0.5790395736694336\n",
            "loss in epoch 92 iteration 233: 0.5773310661315918\n",
            "loss in epoch 92 iteration 234: 0.5312530994415283\n",
            "loss in epoch 92 iteration 235: 0.5499088764190674\n",
            "loss in epoch 92 iteration 236: 0.5820767283439636\n",
            "loss in epoch 92 iteration 237: 0.5481576323509216\n",
            "loss in epoch 92 iteration 238: 0.572472333908081\n",
            "loss in epoch 92 iteration 239: 0.5881038904190063\n",
            "loss in epoch 92 iteration 240: 0.5780302286148071\n",
            "loss in epoch 92 iteration 241: 0.5623458027839661\n",
            "loss in epoch 92 iteration 242: 0.5628253817558289\n",
            "loss in epoch 93 iteration 0: 0.5477148294448853\n",
            "loss in epoch 93 iteration 1: 0.5410556793212891\n",
            "loss in epoch 93 iteration 2: 0.5810553431510925\n",
            "loss in epoch 93 iteration 3: 0.5648427605628967\n",
            "loss in epoch 93 iteration 4: 0.5723069906234741\n",
            "loss in epoch 93 iteration 5: 0.5573883056640625\n",
            "loss in epoch 93 iteration 6: 0.5602431893348694\n",
            "loss in epoch 93 iteration 7: 0.5494025349617004\n",
            "loss in epoch 93 iteration 8: 0.5731698870658875\n",
            "loss in epoch 93 iteration 9: 0.5441645979881287\n",
            "loss in epoch 93 iteration 10: 0.6019056439399719\n",
            "loss in epoch 93 iteration 11: 0.5498020648956299\n",
            "loss in epoch 93 iteration 12: 0.5501461029052734\n",
            "loss in epoch 93 iteration 13: 0.5648812055587769\n",
            "loss in epoch 93 iteration 14: 0.5611458420753479\n",
            "loss in epoch 93 iteration 15: 0.5499184727668762\n",
            "loss in epoch 93 iteration 16: 0.5418308973312378\n",
            "loss in epoch 93 iteration 17: 0.546800971031189\n",
            "loss in epoch 93 iteration 18: 0.5351250171661377\n",
            "loss in epoch 93 iteration 19: 0.5586739778518677\n",
            "loss in epoch 93 iteration 20: 0.5604153871536255\n",
            "loss in epoch 93 iteration 21: 0.5748714208602905\n",
            "loss in epoch 93 iteration 22: 0.5670366287231445\n",
            "loss in epoch 93 iteration 23: 0.5765537023544312\n",
            "loss in epoch 93 iteration 24: 0.5401818752288818\n",
            "loss in epoch 93 iteration 25: 0.5492478609085083\n",
            "loss in epoch 93 iteration 26: 0.5687217712402344\n",
            "loss in epoch 93 iteration 27: 0.5617702603340149\n",
            "loss in epoch 93 iteration 28: 0.569042980670929\n",
            "loss in epoch 93 iteration 29: 0.5594558715820312\n",
            "loss in epoch 93 iteration 30: 0.558380663394928\n",
            "loss in epoch 93 iteration 31: 0.5636332035064697\n",
            "loss in epoch 93 iteration 32: 0.5487468242645264\n",
            "loss in epoch 93 iteration 33: 0.5704948902130127\n",
            "loss in epoch 93 iteration 34: 0.5461519360542297\n",
            "loss in epoch 93 iteration 35: 0.5519804954528809\n",
            "loss in epoch 93 iteration 36: 0.5666161179542542\n",
            "loss in epoch 93 iteration 37: 0.5742367506027222\n",
            "loss in epoch 93 iteration 38: 0.5502853989601135\n",
            "loss in epoch 93 iteration 39: 0.5425900220870972\n",
            "loss in epoch 93 iteration 40: 0.5707082748413086\n",
            "loss in epoch 93 iteration 41: 0.5747310519218445\n",
            "loss in epoch 93 iteration 42: 0.5594778656959534\n",
            "loss in epoch 93 iteration 43: 0.5507378578186035\n",
            "loss in epoch 93 iteration 44: 0.5329805612564087\n",
            "loss in epoch 93 iteration 45: 0.5494415760040283\n",
            "loss in epoch 93 iteration 46: 0.5561676025390625\n",
            "loss in epoch 93 iteration 47: 0.5559495687484741\n",
            "loss in epoch 93 iteration 48: 0.584680438041687\n",
            "loss in epoch 93 iteration 49: 0.5317055583000183\n",
            "loss in epoch 93 iteration 50: 0.5651719570159912\n",
            "loss in epoch 93 iteration 51: 0.5608782768249512\n",
            "loss in epoch 93 iteration 52: 0.545134425163269\n",
            "loss in epoch 93 iteration 53: 0.5505550503730774\n",
            "loss in epoch 93 iteration 54: 0.5670560598373413\n",
            "loss in epoch 93 iteration 55: 0.5560041666030884\n",
            "loss in epoch 93 iteration 56: 0.589885950088501\n",
            "loss in epoch 93 iteration 57: 0.5658551454544067\n",
            "loss in epoch 93 iteration 58: 0.5454474091529846\n",
            "loss in epoch 93 iteration 59: 0.572489857673645\n",
            "loss in epoch 93 iteration 60: 0.5605155825614929\n",
            "loss in epoch 93 iteration 61: 0.5654489994049072\n",
            "loss in epoch 93 iteration 62: 0.5587811470031738\n",
            "loss in epoch 93 iteration 63: 0.5610055327415466\n",
            "loss in epoch 93 iteration 64: 0.5615571737289429\n",
            "loss in epoch 93 iteration 65: 0.5464146137237549\n",
            "loss in epoch 93 iteration 66: 0.5597814321517944\n",
            "loss in epoch 93 iteration 67: 0.5750049352645874\n",
            "loss in epoch 93 iteration 68: 0.5419028997421265\n",
            "loss in epoch 93 iteration 69: 0.5377088785171509\n",
            "loss in epoch 93 iteration 70: 0.5489473342895508\n",
            "loss in epoch 93 iteration 71: 0.5892634391784668\n",
            "loss in epoch 93 iteration 72: 0.54923015832901\n",
            "loss in epoch 93 iteration 73: 0.5388801097869873\n",
            "loss in epoch 93 iteration 74: 0.5747341513633728\n",
            "loss in epoch 93 iteration 75: 0.5612483024597168\n",
            "loss in epoch 93 iteration 76: 0.5612319707870483\n",
            "loss in epoch 93 iteration 77: 0.5488021373748779\n",
            "loss in epoch 93 iteration 78: 0.5760900974273682\n",
            "loss in epoch 93 iteration 79: 0.5664488077163696\n",
            "loss in epoch 93 iteration 80: 0.5558410882949829\n",
            "loss in epoch 93 iteration 81: 0.5592954754829407\n",
            "loss in epoch 93 iteration 82: 0.5464171171188354\n",
            "loss in epoch 93 iteration 83: 0.5681376457214355\n",
            "loss in epoch 93 iteration 84: 0.5516637563705444\n",
            "loss in epoch 93 iteration 85: 0.574561357498169\n",
            "loss in epoch 93 iteration 86: 0.570065438747406\n",
            "loss in epoch 93 iteration 87: 0.5327131152153015\n",
            "loss in epoch 93 iteration 88: 0.5433332920074463\n",
            "loss in epoch 93 iteration 89: 0.5528684854507446\n",
            "loss in epoch 93 iteration 90: 0.5627293586730957\n",
            "loss in epoch 93 iteration 91: 0.5949549078941345\n",
            "loss in epoch 93 iteration 92: 0.5791637897491455\n",
            "loss in epoch 93 iteration 93: 0.5329196453094482\n",
            "loss in epoch 93 iteration 94: 0.5731275677680969\n",
            "loss in epoch 93 iteration 95: 0.5708016157150269\n",
            "loss in epoch 93 iteration 96: 0.570314347743988\n",
            "loss in epoch 93 iteration 97: 0.5600521564483643\n",
            "loss in epoch 93 iteration 98: 0.5650027990341187\n",
            "loss in epoch 93 iteration 99: 0.5603353977203369\n",
            "loss in epoch 93 iteration 100: 0.5648462772369385\n",
            "loss in epoch 93 iteration 101: 0.5681594610214233\n",
            "loss in epoch 93 iteration 102: 0.5335968732833862\n",
            "loss in epoch 93 iteration 103: 0.5528302192687988\n",
            "loss in epoch 93 iteration 104: 0.5618569850921631\n",
            "loss in epoch 93 iteration 105: 0.5593361854553223\n",
            "loss in epoch 93 iteration 106: 0.545668363571167\n",
            "loss in epoch 93 iteration 107: 0.5640830993652344\n",
            "loss in epoch 93 iteration 108: 0.5557541251182556\n",
            "loss in epoch 93 iteration 109: 0.5806470513343811\n",
            "loss in epoch 93 iteration 110: 0.581758975982666\n",
            "loss in epoch 93 iteration 111: 0.5808329582214355\n",
            "loss in epoch 93 iteration 112: 0.5394240617752075\n",
            "loss in epoch 93 iteration 113: 0.5627619028091431\n",
            "loss in epoch 93 iteration 114: 0.5495537519454956\n",
            "loss in epoch 93 iteration 115: 0.560996413230896\n",
            "loss in epoch 93 iteration 116: 0.5442696809768677\n",
            "loss in epoch 93 iteration 117: 0.564545214176178\n",
            "loss in epoch 93 iteration 118: 0.5629241466522217\n",
            "loss in epoch 93 iteration 119: 0.5699323415756226\n",
            "loss in epoch 93 iteration 120: 0.5595242977142334\n",
            "loss in epoch 93 iteration 121: 0.5587946772575378\n",
            "loss in epoch 93 iteration 122: 0.5473321676254272\n",
            "loss in epoch 93 iteration 123: 0.5551584362983704\n",
            "loss in epoch 93 iteration 124: 0.5598745346069336\n",
            "loss in epoch 93 iteration 125: 0.5737980008125305\n",
            "loss in epoch 93 iteration 126: 0.5571426749229431\n",
            "loss in epoch 93 iteration 127: 0.5895206928253174\n",
            "loss in epoch 93 iteration 128: 0.5481410026550293\n",
            "loss in epoch 93 iteration 129: 0.5734906196594238\n",
            "loss in epoch 93 iteration 130: 0.5376326441764832\n",
            "loss in epoch 93 iteration 131: 0.5661078691482544\n",
            "loss in epoch 93 iteration 132: 0.5518436431884766\n",
            "loss in epoch 93 iteration 133: 0.5509803295135498\n",
            "loss in epoch 93 iteration 134: 0.5725927352905273\n",
            "loss in epoch 93 iteration 135: 0.5553290843963623\n",
            "loss in epoch 93 iteration 136: 0.5450947880744934\n",
            "loss in epoch 93 iteration 137: 0.5630555152893066\n",
            "loss in epoch 93 iteration 138: 0.5467268228530884\n",
            "loss in epoch 93 iteration 139: 0.5683754682540894\n",
            "loss in epoch 93 iteration 140: 0.5463415384292603\n",
            "loss in epoch 93 iteration 141: 0.5768817663192749\n",
            "loss in epoch 93 iteration 142: 0.5514265894889832\n",
            "loss in epoch 93 iteration 143: 0.5929425954818726\n",
            "loss in epoch 93 iteration 144: 0.5628269910812378\n",
            "loss in epoch 93 iteration 145: 0.5486075282096863\n",
            "loss in epoch 93 iteration 146: 0.5636594295501709\n",
            "loss in epoch 93 iteration 147: 0.5834140181541443\n",
            "loss in epoch 93 iteration 148: 0.5740752220153809\n",
            "loss in epoch 93 iteration 149: 0.5279502868652344\n",
            "loss in epoch 93 iteration 150: 0.5551860928535461\n",
            "loss in epoch 93 iteration 151: 0.5884615182876587\n",
            "loss in epoch 93 iteration 152: 0.5731733441352844\n",
            "loss in epoch 93 iteration 153: 0.5166842937469482\n",
            "loss in epoch 93 iteration 154: 0.541146993637085\n",
            "loss in epoch 93 iteration 155: 0.5700386762619019\n",
            "loss in epoch 93 iteration 156: 0.5660728812217712\n",
            "loss in epoch 93 iteration 157: 0.5679599046707153\n",
            "loss in epoch 93 iteration 158: 0.5587583780288696\n",
            "loss in epoch 93 iteration 159: 0.554523766040802\n",
            "loss in epoch 93 iteration 160: 0.5350868701934814\n",
            "loss in epoch 93 iteration 161: 0.5283483266830444\n",
            "loss in epoch 93 iteration 162: 0.5575338006019592\n",
            "loss in epoch 93 iteration 163: 0.5611705780029297\n",
            "loss in epoch 93 iteration 164: 0.5393009781837463\n",
            "loss in epoch 93 iteration 165: 0.5653562545776367\n",
            "loss in epoch 93 iteration 166: 0.5632224082946777\n",
            "loss in epoch 93 iteration 167: 0.5673163533210754\n",
            "loss in epoch 93 iteration 168: 0.5474926233291626\n",
            "loss in epoch 93 iteration 169: 0.54790860414505\n",
            "loss in epoch 93 iteration 170: 0.5874340534210205\n",
            "loss in epoch 93 iteration 171: 0.589819073677063\n",
            "loss in epoch 93 iteration 172: 0.5997177958488464\n",
            "loss in epoch 93 iteration 173: 0.5537418127059937\n",
            "loss in epoch 93 iteration 174: 0.6013281345367432\n",
            "loss in epoch 93 iteration 175: 0.5671493411064148\n",
            "loss in epoch 93 iteration 176: 0.5729447603225708\n",
            "loss in epoch 93 iteration 177: 0.5984154343605042\n",
            "loss in epoch 93 iteration 178: 0.5288234949111938\n",
            "loss in epoch 93 iteration 179: 0.5569137334823608\n",
            "loss in epoch 93 iteration 180: 0.5472052693367004\n",
            "loss in epoch 93 iteration 181: 0.5653408169746399\n",
            "loss in epoch 93 iteration 182: 0.5572240948677063\n",
            "loss in epoch 93 iteration 183: 0.5624876618385315\n",
            "loss in epoch 93 iteration 184: 0.5816526412963867\n",
            "loss in epoch 93 iteration 185: 0.5325751304626465\n",
            "loss in epoch 93 iteration 186: 0.5986212491989136\n",
            "loss in epoch 93 iteration 187: 0.5619596242904663\n",
            "loss in epoch 93 iteration 188: 0.5608289241790771\n",
            "loss in epoch 93 iteration 189: 0.5565921664237976\n",
            "loss in epoch 93 iteration 190: 0.5859883427619934\n",
            "loss in epoch 93 iteration 191: 0.5503079891204834\n",
            "loss in epoch 93 iteration 192: 0.5770306587219238\n",
            "loss in epoch 93 iteration 193: 0.5235162377357483\n",
            "loss in epoch 93 iteration 194: 0.5528659820556641\n",
            "loss in epoch 93 iteration 195: 0.5534663200378418\n",
            "loss in epoch 93 iteration 196: 0.5517324805259705\n",
            "loss in epoch 93 iteration 197: 0.5341522693634033\n",
            "loss in epoch 93 iteration 198: 0.5486336350440979\n",
            "loss in epoch 93 iteration 199: 0.5602079629898071\n",
            "loss in epoch 93 iteration 200: 0.5636820793151855\n",
            "loss in epoch 93 iteration 201: 0.5384633541107178\n",
            "loss in epoch 93 iteration 202: 0.5670366287231445\n",
            "loss in epoch 93 iteration 203: 0.5341379642486572\n",
            "loss in epoch 93 iteration 204: 0.5526821613311768\n",
            "loss in epoch 93 iteration 205: 0.5940759181976318\n",
            "loss in epoch 93 iteration 206: 0.536429226398468\n",
            "loss in epoch 93 iteration 207: 0.5204252004623413\n",
            "loss in epoch 93 iteration 208: 0.5413881540298462\n",
            "loss in epoch 93 iteration 209: 0.5258086919784546\n",
            "loss in epoch 93 iteration 210: 0.5457177758216858\n",
            "loss in epoch 93 iteration 211: 0.5397802591323853\n",
            "loss in epoch 93 iteration 212: 0.5581659078598022\n",
            "loss in epoch 93 iteration 213: 0.5623642206192017\n",
            "loss in epoch 93 iteration 214: 0.5779179334640503\n",
            "loss in epoch 93 iteration 215: 0.5537927150726318\n",
            "loss in epoch 93 iteration 216: 0.570176362991333\n",
            "loss in epoch 93 iteration 217: 0.5931496620178223\n",
            "loss in epoch 93 iteration 218: 0.5538284778594971\n",
            "loss in epoch 93 iteration 219: 0.5595837831497192\n",
            "loss in epoch 93 iteration 220: 0.5547906160354614\n",
            "loss in epoch 93 iteration 221: 0.5498268604278564\n",
            "loss in epoch 93 iteration 222: 0.56514573097229\n",
            "loss in epoch 93 iteration 223: 0.5424176454544067\n",
            "loss in epoch 93 iteration 224: 0.5911998152732849\n",
            "loss in epoch 93 iteration 225: 0.5573201179504395\n",
            "loss in epoch 93 iteration 226: 0.584242045879364\n",
            "loss in epoch 93 iteration 227: 0.5662931799888611\n",
            "loss in epoch 93 iteration 228: 0.5671119689941406\n",
            "loss in epoch 93 iteration 229: 0.5769506692886353\n",
            "loss in epoch 93 iteration 230: 0.573201596736908\n",
            "loss in epoch 93 iteration 231: 0.5336005091667175\n",
            "loss in epoch 93 iteration 232: 0.5718896389007568\n",
            "loss in epoch 93 iteration 233: 0.5370736122131348\n",
            "loss in epoch 93 iteration 234: 0.5730451345443726\n",
            "loss in epoch 93 iteration 235: 0.5569932460784912\n",
            "loss in epoch 93 iteration 236: 0.5722949504852295\n",
            "loss in epoch 93 iteration 237: 0.5207335948944092\n",
            "loss in epoch 93 iteration 238: 0.5384042263031006\n",
            "loss in epoch 93 iteration 239: 0.5556473731994629\n",
            "loss in epoch 93 iteration 240: 0.5740025043487549\n",
            "loss in epoch 93 iteration 241: 0.5463847517967224\n",
            "loss in epoch 93 iteration 242: 0.5684659481048584\n",
            "loss in epoch 94 iteration 0: 0.5571565628051758\n",
            "loss in epoch 94 iteration 1: 0.5565425157546997\n",
            "loss in epoch 94 iteration 2: 0.5444110631942749\n",
            "loss in epoch 94 iteration 3: 0.5600757598876953\n",
            "loss in epoch 94 iteration 4: 0.5750480890274048\n",
            "loss in epoch 94 iteration 5: 0.5530439615249634\n",
            "loss in epoch 94 iteration 6: 0.5644677877426147\n",
            "loss in epoch 94 iteration 7: 0.5669313669204712\n",
            "loss in epoch 94 iteration 8: 0.5353145599365234\n",
            "loss in epoch 94 iteration 9: 0.5755043029785156\n",
            "loss in epoch 94 iteration 10: 0.5653610229492188\n",
            "loss in epoch 94 iteration 11: 0.5767505168914795\n",
            "loss in epoch 94 iteration 12: 0.5789171457290649\n",
            "loss in epoch 94 iteration 13: 0.5624100565910339\n",
            "loss in epoch 94 iteration 14: 0.5533751845359802\n",
            "loss in epoch 94 iteration 15: 0.5601246356964111\n",
            "loss in epoch 94 iteration 16: 0.5674721002578735\n",
            "loss in epoch 94 iteration 17: 0.5612080097198486\n",
            "loss in epoch 94 iteration 18: 0.5438343286514282\n",
            "loss in epoch 94 iteration 19: 0.5640059113502502\n",
            "loss in epoch 94 iteration 20: 0.5501432418823242\n",
            "loss in epoch 94 iteration 21: 0.5385830402374268\n",
            "loss in epoch 94 iteration 22: 0.5655470490455627\n",
            "loss in epoch 94 iteration 23: 0.5498626232147217\n",
            "loss in epoch 94 iteration 24: 0.5573642253875732\n",
            "loss in epoch 94 iteration 25: 0.5545663833618164\n",
            "loss in epoch 94 iteration 26: 0.5687699317932129\n",
            "loss in epoch 94 iteration 27: 0.5568007230758667\n",
            "loss in epoch 94 iteration 28: 0.5498535633087158\n",
            "loss in epoch 94 iteration 29: 0.5674632787704468\n",
            "loss in epoch 94 iteration 30: 0.6131870150566101\n",
            "loss in epoch 94 iteration 31: 0.5409331917762756\n",
            "loss in epoch 94 iteration 32: 0.5547307729721069\n",
            "loss in epoch 94 iteration 33: 0.5615989565849304\n",
            "loss in epoch 94 iteration 34: 0.5583863854408264\n",
            "loss in epoch 94 iteration 35: 0.5522851943969727\n",
            "loss in epoch 94 iteration 36: 0.5767892599105835\n",
            "loss in epoch 94 iteration 37: 0.5512794852256775\n",
            "loss in epoch 94 iteration 38: 0.5718230605125427\n",
            "loss in epoch 94 iteration 39: 0.5534486770629883\n",
            "loss in epoch 94 iteration 40: 0.5516213178634644\n",
            "loss in epoch 94 iteration 41: 0.5749571323394775\n",
            "loss in epoch 94 iteration 42: 0.5712082982063293\n",
            "loss in epoch 94 iteration 43: 0.6034982800483704\n",
            "loss in epoch 94 iteration 44: 0.5698083639144897\n",
            "loss in epoch 94 iteration 45: 0.552344024181366\n",
            "loss in epoch 94 iteration 46: 0.5684900283813477\n",
            "loss in epoch 94 iteration 47: 0.5520040988922119\n",
            "loss in epoch 94 iteration 48: 0.5567036867141724\n",
            "loss in epoch 94 iteration 49: 0.5787909030914307\n",
            "loss in epoch 94 iteration 50: 0.5498725175857544\n",
            "loss in epoch 94 iteration 51: 0.5779471397399902\n",
            "loss in epoch 94 iteration 52: 0.5725264549255371\n",
            "loss in epoch 94 iteration 53: 0.556032657623291\n",
            "loss in epoch 94 iteration 54: 0.5392943024635315\n",
            "loss in epoch 94 iteration 55: 0.5471240282058716\n",
            "loss in epoch 94 iteration 56: 0.5659613609313965\n",
            "loss in epoch 94 iteration 57: 0.5621861219406128\n",
            "loss in epoch 94 iteration 58: 0.5889309644699097\n",
            "loss in epoch 94 iteration 59: 0.5829411745071411\n",
            "loss in epoch 94 iteration 60: 0.5668220520019531\n",
            "loss in epoch 94 iteration 61: 0.5485703945159912\n",
            "loss in epoch 94 iteration 62: 0.5494060516357422\n",
            "loss in epoch 94 iteration 63: 0.5591074228286743\n",
            "loss in epoch 94 iteration 64: 0.5626444816589355\n",
            "loss in epoch 94 iteration 65: 0.5397270917892456\n",
            "loss in epoch 94 iteration 66: 0.5557948350906372\n",
            "loss in epoch 94 iteration 67: 0.5703732967376709\n",
            "loss in epoch 94 iteration 68: 0.5764703750610352\n",
            "loss in epoch 94 iteration 69: 0.5642542243003845\n",
            "loss in epoch 94 iteration 70: 0.5789339542388916\n",
            "loss in epoch 94 iteration 71: 0.5200799107551575\n",
            "loss in epoch 94 iteration 72: 0.5745653510093689\n",
            "loss in epoch 94 iteration 73: 0.5516477227210999\n",
            "loss in epoch 94 iteration 74: 0.5770071744918823\n",
            "loss in epoch 94 iteration 75: 0.5680463314056396\n",
            "loss in epoch 94 iteration 76: 0.543111264705658\n",
            "loss in epoch 94 iteration 77: 0.5597043037414551\n",
            "loss in epoch 94 iteration 78: 0.5895437002182007\n",
            "loss in epoch 94 iteration 79: 0.5533237457275391\n",
            "loss in epoch 94 iteration 80: 0.5444358587265015\n",
            "loss in epoch 94 iteration 81: 0.5623722076416016\n",
            "loss in epoch 94 iteration 82: 0.5305397510528564\n",
            "loss in epoch 94 iteration 83: 0.5829607248306274\n",
            "loss in epoch 94 iteration 84: 0.5709940791130066\n",
            "loss in epoch 94 iteration 85: 0.5644925236701965\n",
            "loss in epoch 94 iteration 86: 0.541416585445404\n",
            "loss in epoch 94 iteration 87: 0.5586286783218384\n",
            "loss in epoch 94 iteration 88: 0.5688238143920898\n",
            "loss in epoch 94 iteration 89: 0.55064457654953\n",
            "loss in epoch 94 iteration 90: 0.5701627731323242\n",
            "loss in epoch 94 iteration 91: 0.5540233254432678\n",
            "loss in epoch 94 iteration 92: 0.5671831369400024\n",
            "loss in epoch 94 iteration 93: 0.5728433132171631\n",
            "loss in epoch 94 iteration 94: 0.5354429483413696\n",
            "loss in epoch 94 iteration 95: 0.5692634582519531\n",
            "loss in epoch 94 iteration 96: 0.5723751187324524\n",
            "loss in epoch 94 iteration 97: 0.5677159428596497\n",
            "loss in epoch 94 iteration 98: 0.5693961381912231\n",
            "loss in epoch 94 iteration 99: 0.5836979746818542\n",
            "loss in epoch 94 iteration 100: 0.5553049445152283\n",
            "loss in epoch 94 iteration 101: 0.5744982957839966\n",
            "loss in epoch 94 iteration 102: 0.5474345088005066\n",
            "loss in epoch 94 iteration 103: 0.5605669021606445\n",
            "loss in epoch 94 iteration 104: 0.5541905760765076\n",
            "loss in epoch 94 iteration 105: 0.5458835959434509\n",
            "loss in epoch 94 iteration 106: 0.5719369649887085\n",
            "loss in epoch 94 iteration 107: 0.5400437712669373\n",
            "loss in epoch 94 iteration 108: 0.565190315246582\n",
            "loss in epoch 94 iteration 109: 0.5566152334213257\n",
            "loss in epoch 94 iteration 110: 0.5400733351707458\n",
            "loss in epoch 94 iteration 111: 0.5580816268920898\n",
            "loss in epoch 94 iteration 112: 0.5276017189025879\n",
            "loss in epoch 94 iteration 113: 0.5560380220413208\n",
            "loss in epoch 94 iteration 114: 0.5490157604217529\n",
            "loss in epoch 94 iteration 115: 0.5802814960479736\n",
            "loss in epoch 94 iteration 116: 0.5617131590843201\n",
            "loss in epoch 94 iteration 117: 0.5607688426971436\n",
            "loss in epoch 94 iteration 118: 0.5593305230140686\n",
            "loss in epoch 94 iteration 119: 0.5408909916877747\n",
            "loss in epoch 94 iteration 120: 0.5564017295837402\n",
            "loss in epoch 94 iteration 121: 0.5611594915390015\n",
            "loss in epoch 94 iteration 122: 0.5673813819885254\n",
            "loss in epoch 94 iteration 123: 0.5614300966262817\n",
            "loss in epoch 94 iteration 124: 0.5596810579299927\n",
            "loss in epoch 94 iteration 125: 0.5589913129806519\n",
            "loss in epoch 94 iteration 126: 0.5114365220069885\n",
            "loss in epoch 94 iteration 127: 0.5725727677345276\n",
            "loss in epoch 94 iteration 128: 0.5573937296867371\n",
            "loss in epoch 94 iteration 129: 0.556925892829895\n",
            "loss in epoch 94 iteration 130: 0.5453997254371643\n",
            "loss in epoch 94 iteration 131: 0.5574398040771484\n",
            "loss in epoch 94 iteration 132: 0.5634320974349976\n",
            "loss in epoch 94 iteration 133: 0.5599588751792908\n",
            "loss in epoch 94 iteration 134: 0.5587363243103027\n",
            "loss in epoch 94 iteration 135: 0.5811887979507446\n",
            "loss in epoch 94 iteration 136: 0.575014054775238\n",
            "loss in epoch 94 iteration 137: 0.5598698854446411\n",
            "loss in epoch 94 iteration 138: 0.5620955228805542\n",
            "loss in epoch 94 iteration 139: 0.5242398977279663\n",
            "loss in epoch 94 iteration 140: 0.562569260597229\n",
            "loss in epoch 94 iteration 141: 0.569176435470581\n",
            "loss in epoch 94 iteration 142: 0.5449681282043457\n",
            "loss in epoch 94 iteration 143: 0.5528005957603455\n",
            "loss in epoch 94 iteration 144: 0.5395190119743347\n",
            "loss in epoch 94 iteration 145: 0.5585695505142212\n",
            "loss in epoch 94 iteration 146: 0.5620013475418091\n",
            "loss in epoch 94 iteration 147: 0.5654992461204529\n",
            "loss in epoch 94 iteration 148: 0.5678092837333679\n",
            "loss in epoch 94 iteration 149: 0.5742367506027222\n",
            "loss in epoch 94 iteration 150: 0.5638132691383362\n",
            "loss in epoch 94 iteration 151: 0.5517358183860779\n",
            "loss in epoch 94 iteration 152: 0.5580443143844604\n",
            "loss in epoch 94 iteration 153: 0.5549469590187073\n",
            "loss in epoch 94 iteration 154: 0.5725024938583374\n",
            "loss in epoch 94 iteration 155: 0.5477349162101746\n",
            "loss in epoch 94 iteration 156: 0.551063060760498\n",
            "loss in epoch 94 iteration 157: 0.5594662427902222\n",
            "loss in epoch 94 iteration 158: 0.5652958154678345\n",
            "loss in epoch 94 iteration 159: 0.5758355259895325\n",
            "loss in epoch 94 iteration 160: 0.5605268478393555\n",
            "loss in epoch 94 iteration 161: 0.5697789192199707\n",
            "loss in epoch 94 iteration 162: 0.5649430751800537\n",
            "loss in epoch 94 iteration 163: 0.568718671798706\n",
            "loss in epoch 94 iteration 164: 0.5757997035980225\n",
            "loss in epoch 94 iteration 165: 0.5599082708358765\n",
            "loss in epoch 94 iteration 166: 0.5721701383590698\n",
            "loss in epoch 94 iteration 167: 0.5789981484413147\n",
            "loss in epoch 94 iteration 168: 0.5710316896438599\n",
            "loss in epoch 94 iteration 169: 0.5648118257522583\n",
            "loss in epoch 94 iteration 170: 0.533765435218811\n",
            "loss in epoch 94 iteration 171: 0.5966918468475342\n",
            "loss in epoch 94 iteration 172: 0.5473338961601257\n",
            "loss in epoch 94 iteration 173: 0.583099365234375\n",
            "loss in epoch 94 iteration 174: 0.5908246040344238\n",
            "loss in epoch 94 iteration 175: 0.5552845001220703\n",
            "loss in epoch 94 iteration 176: 0.5909894704818726\n",
            "loss in epoch 94 iteration 177: 0.547788143157959\n",
            "loss in epoch 94 iteration 178: 0.5844316482543945\n",
            "loss in epoch 94 iteration 179: 0.6118448972702026\n",
            "loss in epoch 94 iteration 180: 0.5520054697990417\n",
            "loss in epoch 94 iteration 181: 0.5403811931610107\n",
            "loss in epoch 94 iteration 182: 0.5816154479980469\n",
            "loss in epoch 94 iteration 183: 0.5217220187187195\n",
            "loss in epoch 94 iteration 184: 0.5524911880493164\n",
            "loss in epoch 94 iteration 185: 0.5317448377609253\n",
            "loss in epoch 94 iteration 186: 0.5320315361022949\n",
            "loss in epoch 94 iteration 187: 0.5679763555526733\n",
            "loss in epoch 94 iteration 188: 0.5405215620994568\n",
            "loss in epoch 94 iteration 189: 0.5519248247146606\n",
            "loss in epoch 94 iteration 190: 0.5773895978927612\n",
            "loss in epoch 94 iteration 191: 0.5497997999191284\n",
            "loss in epoch 94 iteration 192: 0.5300853252410889\n",
            "loss in epoch 94 iteration 193: 0.580539345741272\n",
            "loss in epoch 94 iteration 194: 0.5609825849533081\n",
            "loss in epoch 94 iteration 195: 0.5449718832969666\n",
            "loss in epoch 94 iteration 196: 0.5673983097076416\n",
            "loss in epoch 94 iteration 197: 0.5396093726158142\n",
            "loss in epoch 94 iteration 198: 0.5673003196716309\n",
            "loss in epoch 94 iteration 199: 0.5422074794769287\n",
            "loss in epoch 94 iteration 200: 0.547988772392273\n",
            "loss in epoch 94 iteration 201: 0.5294770002365112\n",
            "loss in epoch 94 iteration 202: 0.5800225138664246\n",
            "loss in epoch 94 iteration 203: 0.5597977042198181\n",
            "loss in epoch 94 iteration 204: 0.5899598598480225\n",
            "loss in epoch 94 iteration 205: 0.5448837280273438\n",
            "loss in epoch 94 iteration 206: 0.5108180642127991\n",
            "loss in epoch 94 iteration 207: 0.5621398687362671\n",
            "loss in epoch 94 iteration 208: 0.5633178949356079\n",
            "loss in epoch 94 iteration 209: 0.5741024017333984\n",
            "loss in epoch 94 iteration 210: 0.5586994886398315\n",
            "loss in epoch 94 iteration 211: 0.5771521329879761\n",
            "loss in epoch 94 iteration 212: 0.5643669366836548\n",
            "loss in epoch 94 iteration 213: 0.5814551711082458\n",
            "loss in epoch 94 iteration 214: 0.5741506814956665\n",
            "loss in epoch 94 iteration 215: 0.5618478059768677\n",
            "loss in epoch 94 iteration 216: 0.5575627088546753\n",
            "loss in epoch 94 iteration 217: 0.5576711297035217\n",
            "loss in epoch 94 iteration 218: 0.5504778027534485\n",
            "loss in epoch 94 iteration 219: 0.5941864252090454\n",
            "loss in epoch 94 iteration 220: 0.5676074028015137\n",
            "loss in epoch 94 iteration 221: 0.5632107257843018\n",
            "loss in epoch 94 iteration 222: 0.5467844605445862\n",
            "loss in epoch 94 iteration 223: 0.5498099327087402\n",
            "loss in epoch 94 iteration 224: 0.5374677181243896\n",
            "loss in epoch 94 iteration 225: 0.5610721707344055\n",
            "loss in epoch 94 iteration 226: 0.5700221061706543\n",
            "loss in epoch 94 iteration 227: 0.5622713565826416\n",
            "loss in epoch 94 iteration 228: 0.5463988780975342\n",
            "loss in epoch 94 iteration 229: 0.5533732175827026\n",
            "loss in epoch 94 iteration 230: 0.550779402256012\n",
            "loss in epoch 94 iteration 231: 0.5393092036247253\n",
            "loss in epoch 94 iteration 232: 0.5872677564620972\n",
            "loss in epoch 94 iteration 233: 0.5564090013504028\n",
            "loss in epoch 94 iteration 234: 0.5735965967178345\n",
            "loss in epoch 94 iteration 235: 0.5785683989524841\n",
            "loss in epoch 94 iteration 236: 0.582716703414917\n",
            "loss in epoch 94 iteration 237: 0.5772870182991028\n",
            "loss in epoch 94 iteration 238: 0.5332763195037842\n",
            "loss in epoch 94 iteration 239: 0.5621119141578674\n",
            "loss in epoch 94 iteration 240: 0.556172251701355\n",
            "loss in epoch 94 iteration 241: 0.5543466210365295\n",
            "loss in epoch 94 iteration 242: 0.5460785627365112\n",
            "loss in epoch 95 iteration 0: 0.5584856271743774\n",
            "loss in epoch 95 iteration 1: 0.5412894487380981\n",
            "loss in epoch 95 iteration 2: 0.559554934501648\n",
            "loss in epoch 95 iteration 3: 0.5682014226913452\n",
            "loss in epoch 95 iteration 4: 0.5276105403900146\n",
            "loss in epoch 95 iteration 5: 0.5652732849121094\n",
            "loss in epoch 95 iteration 6: 0.544535219669342\n",
            "loss in epoch 95 iteration 7: 0.5912779569625854\n",
            "loss in epoch 95 iteration 8: 0.5592228174209595\n",
            "loss in epoch 95 iteration 9: 0.5663940906524658\n",
            "loss in epoch 95 iteration 10: 0.5554335117340088\n",
            "loss in epoch 95 iteration 11: 0.5847598314285278\n",
            "loss in epoch 95 iteration 12: 0.5776644349098206\n",
            "loss in epoch 95 iteration 13: 0.558984100818634\n",
            "loss in epoch 95 iteration 14: 0.5866312980651855\n",
            "loss in epoch 95 iteration 15: 0.5662392377853394\n",
            "loss in epoch 95 iteration 16: 0.5692840814590454\n",
            "loss in epoch 95 iteration 17: 0.5660913586616516\n",
            "loss in epoch 95 iteration 18: 0.5492787957191467\n",
            "loss in epoch 95 iteration 19: 0.5914920568466187\n",
            "loss in epoch 95 iteration 20: 0.5342868566513062\n",
            "loss in epoch 95 iteration 21: 0.6075006127357483\n",
            "loss in epoch 95 iteration 22: 0.5578292608261108\n",
            "loss in epoch 95 iteration 23: 0.571151077747345\n",
            "loss in epoch 95 iteration 24: 0.5514131784439087\n",
            "loss in epoch 95 iteration 25: 0.5353926420211792\n",
            "loss in epoch 95 iteration 26: 0.5614903569221497\n",
            "loss in epoch 95 iteration 27: 0.5628777742385864\n",
            "loss in epoch 95 iteration 28: 0.5690752267837524\n",
            "loss in epoch 95 iteration 29: 0.5694828033447266\n",
            "loss in epoch 95 iteration 30: 0.5612404346466064\n",
            "loss in epoch 95 iteration 31: 0.5493476390838623\n",
            "loss in epoch 95 iteration 32: 0.5837964415550232\n",
            "loss in epoch 95 iteration 33: 0.5682730078697205\n",
            "loss in epoch 95 iteration 34: 0.555152177810669\n",
            "loss in epoch 95 iteration 35: 0.5607446432113647\n",
            "loss in epoch 95 iteration 36: 0.5320441126823425\n",
            "loss in epoch 95 iteration 37: 0.5585672855377197\n",
            "loss in epoch 95 iteration 38: 0.58111572265625\n",
            "loss in epoch 95 iteration 39: 0.5634486675262451\n",
            "loss in epoch 95 iteration 40: 0.5568943619728088\n",
            "loss in epoch 95 iteration 41: 0.5552600622177124\n",
            "loss in epoch 95 iteration 42: 0.5577123165130615\n",
            "loss in epoch 95 iteration 43: 0.5796589851379395\n",
            "loss in epoch 95 iteration 44: 0.5621815919876099\n",
            "loss in epoch 95 iteration 45: 0.5618985891342163\n",
            "loss in epoch 95 iteration 46: 0.5637745261192322\n",
            "loss in epoch 95 iteration 47: 0.5684309005737305\n",
            "loss in epoch 95 iteration 48: 0.5958963632583618\n",
            "loss in epoch 95 iteration 49: 0.553952693939209\n",
            "loss in epoch 95 iteration 50: 0.542086124420166\n",
            "loss in epoch 95 iteration 51: 0.5555346012115479\n",
            "loss in epoch 95 iteration 52: 0.5373598337173462\n",
            "loss in epoch 95 iteration 53: 0.576001763343811\n",
            "loss in epoch 95 iteration 54: 0.5522351264953613\n",
            "loss in epoch 95 iteration 55: 0.5905226469039917\n",
            "loss in epoch 95 iteration 56: 0.5819964408874512\n",
            "loss in epoch 95 iteration 57: 0.5695397853851318\n",
            "loss in epoch 95 iteration 58: 0.5932025909423828\n",
            "loss in epoch 95 iteration 59: 0.5641833543777466\n",
            "loss in epoch 95 iteration 60: 0.547034502029419\n",
            "loss in epoch 95 iteration 61: 0.5525651574134827\n",
            "loss in epoch 95 iteration 62: 0.5680923461914062\n",
            "loss in epoch 95 iteration 63: 0.5377993583679199\n",
            "loss in epoch 95 iteration 64: 0.5769944787025452\n",
            "loss in epoch 95 iteration 65: 0.5851628184318542\n",
            "loss in epoch 95 iteration 66: 0.5694124698638916\n",
            "loss in epoch 95 iteration 67: 0.5531314611434937\n",
            "loss in epoch 95 iteration 68: 0.5632226467132568\n",
            "loss in epoch 95 iteration 69: 0.560308039188385\n",
            "loss in epoch 95 iteration 70: 0.5674344301223755\n",
            "loss in epoch 95 iteration 71: 0.563399076461792\n",
            "loss in epoch 95 iteration 72: 0.5608651041984558\n",
            "loss in epoch 95 iteration 73: 0.5468068718910217\n",
            "loss in epoch 95 iteration 74: 0.5556460618972778\n",
            "loss in epoch 95 iteration 75: 0.5521656274795532\n",
            "loss in epoch 95 iteration 76: 0.5619168281555176\n",
            "loss in epoch 95 iteration 77: 0.5383169651031494\n",
            "loss in epoch 95 iteration 78: 0.5388318300247192\n",
            "loss in epoch 95 iteration 79: 0.5878034830093384\n",
            "loss in epoch 95 iteration 80: 0.5641306042671204\n",
            "loss in epoch 95 iteration 81: 0.5547372102737427\n",
            "loss in epoch 95 iteration 82: 0.5803791284561157\n",
            "loss in epoch 95 iteration 83: 0.5557221174240112\n",
            "loss in epoch 95 iteration 84: 0.5685208439826965\n",
            "loss in epoch 95 iteration 85: 0.5623579025268555\n",
            "loss in epoch 95 iteration 86: 0.5386289358139038\n",
            "loss in epoch 95 iteration 87: 0.5661362409591675\n",
            "loss in epoch 95 iteration 88: 0.5475503206253052\n",
            "loss in epoch 95 iteration 89: 0.5653858184814453\n",
            "loss in epoch 95 iteration 90: 0.5265142321586609\n",
            "loss in epoch 95 iteration 91: 0.5726251006126404\n",
            "loss in epoch 95 iteration 92: 0.5810628533363342\n",
            "loss in epoch 95 iteration 93: 0.5553114414215088\n",
            "loss in epoch 95 iteration 94: 0.5653630495071411\n",
            "loss in epoch 95 iteration 95: 0.5511083006858826\n",
            "loss in epoch 95 iteration 96: 0.5608607530593872\n",
            "loss in epoch 95 iteration 97: 0.5886131525039673\n",
            "loss in epoch 95 iteration 98: 0.600654125213623\n",
            "loss in epoch 95 iteration 99: 0.5667845010757446\n",
            "loss in epoch 95 iteration 100: 0.5267310738563538\n",
            "loss in epoch 95 iteration 101: 0.5654206275939941\n",
            "loss in epoch 95 iteration 102: 0.5428812503814697\n",
            "loss in epoch 95 iteration 103: 0.55817049741745\n",
            "loss in epoch 95 iteration 104: 0.5590771436691284\n",
            "loss in epoch 95 iteration 105: 0.5844499468803406\n",
            "loss in epoch 95 iteration 106: 0.5545179843902588\n",
            "loss in epoch 95 iteration 107: 0.5599617958068848\n",
            "loss in epoch 95 iteration 108: 0.5259412527084351\n",
            "loss in epoch 95 iteration 109: 0.567590057849884\n",
            "loss in epoch 95 iteration 110: 0.5559114217758179\n",
            "loss in epoch 95 iteration 111: 0.5687062740325928\n",
            "loss in epoch 95 iteration 112: 0.564924955368042\n",
            "loss in epoch 95 iteration 113: 0.5992581248283386\n",
            "loss in epoch 95 iteration 114: 0.5570654273033142\n",
            "loss in epoch 95 iteration 115: 0.5558226108551025\n",
            "loss in epoch 95 iteration 116: 0.5623821020126343\n",
            "loss in epoch 95 iteration 117: 0.5600442886352539\n",
            "loss in epoch 95 iteration 118: 0.5607722997665405\n",
            "loss in epoch 95 iteration 119: 0.5579830408096313\n",
            "loss in epoch 95 iteration 120: 0.5698496103286743\n",
            "loss in epoch 95 iteration 121: 0.5754748582839966\n",
            "loss in epoch 95 iteration 122: 0.5470712184906006\n",
            "loss in epoch 95 iteration 123: 0.5589433312416077\n",
            "loss in epoch 95 iteration 124: 0.5626850128173828\n",
            "loss in epoch 95 iteration 125: 0.5745291709899902\n",
            "loss in epoch 95 iteration 126: 0.5482089519500732\n",
            "loss in epoch 95 iteration 127: 0.5697242021560669\n",
            "loss in epoch 95 iteration 128: 0.5489820241928101\n",
            "loss in epoch 95 iteration 129: 0.5956222414970398\n",
            "loss in epoch 95 iteration 130: 0.5703895092010498\n",
            "loss in epoch 95 iteration 131: 0.5706679821014404\n",
            "loss in epoch 95 iteration 132: 0.5728474855422974\n",
            "loss in epoch 95 iteration 133: 0.5475476980209351\n",
            "loss in epoch 95 iteration 134: 0.5556932687759399\n",
            "loss in epoch 95 iteration 135: 0.5857586860656738\n",
            "loss in epoch 95 iteration 136: 0.5551117658615112\n",
            "loss in epoch 95 iteration 137: 0.5410647392272949\n",
            "loss in epoch 95 iteration 138: 0.5629774928092957\n",
            "loss in epoch 95 iteration 139: 0.5878180265426636\n",
            "loss in epoch 95 iteration 140: 0.539525032043457\n",
            "loss in epoch 95 iteration 141: 0.5538262724876404\n",
            "loss in epoch 95 iteration 142: 0.573591947555542\n",
            "loss in epoch 95 iteration 143: 0.5740639567375183\n",
            "loss in epoch 95 iteration 144: 0.593278169631958\n",
            "loss in epoch 95 iteration 145: 0.5742879509925842\n",
            "loss in epoch 95 iteration 146: 0.5379627346992493\n",
            "loss in epoch 95 iteration 147: 0.5632520914077759\n",
            "loss in epoch 95 iteration 148: 0.552220344543457\n",
            "loss in epoch 95 iteration 149: 0.5505198240280151\n",
            "loss in epoch 95 iteration 150: 0.5521883368492126\n",
            "loss in epoch 95 iteration 151: 0.5265798568725586\n",
            "loss in epoch 95 iteration 152: 0.5449346303939819\n",
            "loss in epoch 95 iteration 153: 0.5501804351806641\n",
            "loss in epoch 95 iteration 154: 0.5382704138755798\n",
            "loss in epoch 95 iteration 155: 0.5441564321517944\n",
            "loss in epoch 95 iteration 156: 0.5280003547668457\n",
            "loss in epoch 95 iteration 157: 0.5521036386489868\n",
            "loss in epoch 95 iteration 158: 0.5546722412109375\n",
            "loss in epoch 95 iteration 159: 0.5638308525085449\n",
            "loss in epoch 95 iteration 160: 0.5442624688148499\n",
            "loss in epoch 95 iteration 161: 0.5402144193649292\n",
            "loss in epoch 95 iteration 162: 0.547394871711731\n",
            "loss in epoch 95 iteration 163: 0.5839446783065796\n",
            "loss in epoch 95 iteration 164: 0.5863385200500488\n",
            "loss in epoch 95 iteration 165: 0.5430288314819336\n",
            "loss in epoch 95 iteration 166: 0.5519589185714722\n",
            "loss in epoch 95 iteration 167: 0.5594853758811951\n",
            "loss in epoch 95 iteration 168: 0.5640141367912292\n",
            "loss in epoch 95 iteration 169: 0.5639606714248657\n",
            "loss in epoch 95 iteration 170: 0.5092959403991699\n",
            "loss in epoch 95 iteration 171: 0.5699594020843506\n",
            "loss in epoch 95 iteration 172: 0.5608100891113281\n",
            "loss in epoch 95 iteration 173: 0.5363100171089172\n",
            "loss in epoch 95 iteration 174: 0.5784815549850464\n",
            "loss in epoch 95 iteration 175: 0.5365753769874573\n",
            "loss in epoch 95 iteration 176: 0.5517153739929199\n",
            "loss in epoch 95 iteration 177: 0.5768805742263794\n",
            "loss in epoch 95 iteration 178: 0.5555238723754883\n",
            "loss in epoch 95 iteration 179: 0.5556236505508423\n",
            "loss in epoch 95 iteration 180: 0.589980959892273\n",
            "loss in epoch 95 iteration 181: 0.5531949996948242\n",
            "loss in epoch 95 iteration 182: 0.5511449575424194\n",
            "loss in epoch 95 iteration 183: 0.5515443086624146\n",
            "loss in epoch 95 iteration 184: 0.5601925849914551\n",
            "loss in epoch 95 iteration 185: 0.5733885765075684\n",
            "loss in epoch 95 iteration 186: 0.5522081255912781\n",
            "loss in epoch 95 iteration 187: 0.572688102722168\n",
            "loss in epoch 95 iteration 188: 0.5540319681167603\n",
            "loss in epoch 95 iteration 189: 0.5436471700668335\n",
            "loss in epoch 95 iteration 190: 0.5336543917655945\n",
            "loss in epoch 95 iteration 191: 0.5426321029663086\n",
            "loss in epoch 95 iteration 192: 0.5453572273254395\n",
            "loss in epoch 95 iteration 193: 0.5699396133422852\n",
            "loss in epoch 95 iteration 194: 0.5697115063667297\n",
            "loss in epoch 95 iteration 195: 0.5670698285102844\n",
            "loss in epoch 95 iteration 196: 0.5484187006950378\n",
            "loss in epoch 95 iteration 197: 0.5484364032745361\n",
            "loss in epoch 95 iteration 198: 0.5512428283691406\n",
            "loss in epoch 95 iteration 199: 0.5620201826095581\n",
            "loss in epoch 95 iteration 200: 0.5745430588722229\n",
            "loss in epoch 95 iteration 201: 0.5428481101989746\n",
            "loss in epoch 95 iteration 202: 0.5730034112930298\n",
            "loss in epoch 95 iteration 203: 0.552270770072937\n",
            "loss in epoch 95 iteration 204: 0.5458382964134216\n",
            "loss in epoch 95 iteration 205: 0.5304477214813232\n",
            "loss in epoch 95 iteration 206: 0.574230432510376\n",
            "loss in epoch 95 iteration 207: 0.5602089166641235\n",
            "loss in epoch 95 iteration 208: 0.556929349899292\n",
            "loss in epoch 95 iteration 209: 0.5618888139724731\n",
            "loss in epoch 95 iteration 210: 0.5397778749465942\n",
            "loss in epoch 95 iteration 211: 0.5484249591827393\n",
            "loss in epoch 95 iteration 212: 0.557034969329834\n",
            "loss in epoch 95 iteration 213: 0.5526416301727295\n",
            "loss in epoch 95 iteration 214: 0.5652952194213867\n",
            "loss in epoch 95 iteration 215: 0.5430446267127991\n",
            "loss in epoch 95 iteration 216: 0.552247941493988\n",
            "loss in epoch 95 iteration 217: 0.5407435894012451\n",
            "loss in epoch 95 iteration 218: 0.5609373450279236\n",
            "loss in epoch 95 iteration 219: 0.5462194681167603\n",
            "loss in epoch 95 iteration 220: 0.5715216398239136\n",
            "loss in epoch 95 iteration 221: 0.5647160410881042\n",
            "loss in epoch 95 iteration 222: 0.5687990188598633\n",
            "loss in epoch 95 iteration 223: 0.562553346157074\n",
            "loss in epoch 95 iteration 224: 0.5463119745254517\n",
            "loss in epoch 95 iteration 225: 0.5394368171691895\n",
            "loss in epoch 95 iteration 226: 0.5516905784606934\n",
            "loss in epoch 95 iteration 227: 0.5552883148193359\n",
            "loss in epoch 95 iteration 228: 0.5653300285339355\n",
            "loss in epoch 95 iteration 229: 0.5729552507400513\n",
            "loss in epoch 95 iteration 230: 0.5566320419311523\n",
            "loss in epoch 95 iteration 231: 0.5615676045417786\n",
            "loss in epoch 95 iteration 232: 0.5906232595443726\n",
            "loss in epoch 95 iteration 233: 0.5520009398460388\n",
            "loss in epoch 95 iteration 234: 0.5428568124771118\n",
            "loss in epoch 95 iteration 235: 0.5370528697967529\n",
            "loss in epoch 95 iteration 236: 0.5417577028274536\n",
            "loss in epoch 95 iteration 237: 0.5622511506080627\n",
            "loss in epoch 95 iteration 238: 0.5444781184196472\n",
            "loss in epoch 95 iteration 239: 0.5345573425292969\n",
            "loss in epoch 95 iteration 240: 0.534669041633606\n",
            "loss in epoch 95 iteration 241: 0.5544252395629883\n",
            "loss in epoch 95 iteration 242: 0.5469927787780762\n",
            "loss in epoch 96 iteration 0: 0.5495299100875854\n",
            "loss in epoch 96 iteration 1: 0.5647377967834473\n",
            "loss in epoch 96 iteration 2: 0.5462684631347656\n",
            "loss in epoch 96 iteration 3: 0.5749613046646118\n",
            "loss in epoch 96 iteration 4: 0.5518117547035217\n",
            "loss in epoch 96 iteration 5: 0.5896676778793335\n",
            "loss in epoch 96 iteration 6: 0.5840623378753662\n",
            "loss in epoch 96 iteration 7: 0.545318603515625\n",
            "loss in epoch 96 iteration 8: 0.5781397819519043\n",
            "loss in epoch 96 iteration 9: 0.559739351272583\n",
            "loss in epoch 96 iteration 10: 0.5748148560523987\n",
            "loss in epoch 96 iteration 11: 0.5792035460472107\n",
            "loss in epoch 96 iteration 12: 0.5468459129333496\n",
            "loss in epoch 96 iteration 13: 0.5574865341186523\n",
            "loss in epoch 96 iteration 14: 0.5167436003684998\n",
            "loss in epoch 96 iteration 15: 0.5535973310470581\n",
            "loss in epoch 96 iteration 16: 0.5968420505523682\n",
            "loss in epoch 96 iteration 17: 0.5846174955368042\n",
            "loss in epoch 96 iteration 18: 0.5579360723495483\n",
            "loss in epoch 96 iteration 19: 0.5485768914222717\n",
            "loss in epoch 96 iteration 20: 0.582984447479248\n",
            "loss in epoch 96 iteration 21: 0.5393418073654175\n",
            "loss in epoch 96 iteration 22: 0.5400847792625427\n",
            "loss in epoch 96 iteration 23: 0.561450719833374\n",
            "loss in epoch 96 iteration 24: 0.5649848580360413\n",
            "loss in epoch 96 iteration 25: 0.5573486089706421\n",
            "loss in epoch 96 iteration 26: 0.565556526184082\n",
            "loss in epoch 96 iteration 27: 0.5509483814239502\n",
            "loss in epoch 96 iteration 28: 0.5447438955307007\n",
            "loss in epoch 96 iteration 29: 0.5750768184661865\n",
            "loss in epoch 96 iteration 30: 0.5358773469924927\n",
            "loss in epoch 96 iteration 31: 0.5653653144836426\n",
            "loss in epoch 96 iteration 32: 0.5540447235107422\n",
            "loss in epoch 96 iteration 33: 0.5737318992614746\n",
            "loss in epoch 96 iteration 34: 0.5613462924957275\n",
            "loss in epoch 96 iteration 35: 0.5777376890182495\n",
            "loss in epoch 96 iteration 36: 0.5904973745346069\n",
            "loss in epoch 96 iteration 37: 0.5574625730514526\n",
            "loss in epoch 96 iteration 38: 0.579230785369873\n",
            "loss in epoch 96 iteration 39: 0.5563490986824036\n",
            "loss in epoch 96 iteration 40: 0.5706144571304321\n",
            "loss in epoch 96 iteration 41: 0.5778136253356934\n",
            "loss in epoch 96 iteration 42: 0.5475040674209595\n",
            "loss in epoch 96 iteration 43: 0.5629976987838745\n",
            "loss in epoch 96 iteration 44: 0.5611110329627991\n",
            "loss in epoch 96 iteration 45: 0.5416275262832642\n",
            "loss in epoch 96 iteration 46: 0.5714035034179688\n",
            "loss in epoch 96 iteration 47: 0.5492198467254639\n",
            "loss in epoch 96 iteration 48: 0.5641945600509644\n",
            "loss in epoch 96 iteration 49: 0.5501874685287476\n",
            "loss in epoch 96 iteration 50: 0.5728813409805298\n",
            "loss in epoch 96 iteration 51: 0.561198353767395\n",
            "loss in epoch 96 iteration 52: 0.580620288848877\n",
            "loss in epoch 96 iteration 53: 0.5918917655944824\n",
            "loss in epoch 96 iteration 54: 0.5556952953338623\n",
            "loss in epoch 96 iteration 55: 0.5595777034759521\n",
            "loss in epoch 96 iteration 56: 0.5344353914260864\n",
            "loss in epoch 96 iteration 57: 0.5464537143707275\n",
            "loss in epoch 96 iteration 58: 0.5489166975021362\n",
            "loss in epoch 96 iteration 59: 0.5683013200759888\n",
            "loss in epoch 96 iteration 60: 0.5673431158065796\n",
            "loss in epoch 96 iteration 61: 0.5765495300292969\n",
            "loss in epoch 96 iteration 62: 0.5427737236022949\n",
            "loss in epoch 96 iteration 63: 0.5397534370422363\n",
            "loss in epoch 96 iteration 64: 0.5414429903030396\n",
            "loss in epoch 96 iteration 65: 0.5799928903579712\n",
            "loss in epoch 96 iteration 66: 0.5756059885025024\n",
            "loss in epoch 96 iteration 67: 0.5274299383163452\n",
            "loss in epoch 96 iteration 68: 0.5344651937484741\n",
            "loss in epoch 96 iteration 69: 0.5874112248420715\n",
            "loss in epoch 96 iteration 70: 0.5911718010902405\n",
            "loss in epoch 96 iteration 71: 0.5889626741409302\n",
            "loss in epoch 96 iteration 72: 0.5527746677398682\n",
            "loss in epoch 96 iteration 73: 0.5493603944778442\n",
            "loss in epoch 96 iteration 74: 0.5667121410369873\n",
            "loss in epoch 96 iteration 75: 0.5419871807098389\n",
            "loss in epoch 96 iteration 76: 0.5718671083450317\n",
            "loss in epoch 96 iteration 77: 0.5437248945236206\n",
            "loss in epoch 96 iteration 78: 0.576625645160675\n",
            "loss in epoch 96 iteration 79: 0.5642659664154053\n",
            "loss in epoch 96 iteration 80: 0.5384027361869812\n",
            "loss in epoch 96 iteration 81: 0.5661241412162781\n",
            "loss in epoch 96 iteration 82: 0.5852649211883545\n",
            "loss in epoch 96 iteration 83: 0.5480058193206787\n",
            "loss in epoch 96 iteration 84: 0.533471941947937\n",
            "loss in epoch 96 iteration 85: 0.5395696759223938\n",
            "loss in epoch 96 iteration 86: 0.5433425903320312\n",
            "loss in epoch 96 iteration 87: 0.5404319763183594\n",
            "loss in epoch 96 iteration 88: 0.5404353141784668\n",
            "loss in epoch 96 iteration 89: 0.5558022260665894\n",
            "loss in epoch 96 iteration 90: 0.5591155290603638\n",
            "loss in epoch 96 iteration 91: 0.5744413137435913\n",
            "loss in epoch 96 iteration 92: 0.5449399948120117\n",
            "loss in epoch 96 iteration 93: 0.5750925540924072\n",
            "loss in epoch 96 iteration 94: 0.5767048597335815\n",
            "loss in epoch 96 iteration 95: 0.5539311170578003\n",
            "loss in epoch 96 iteration 96: 0.5517022609710693\n",
            "loss in epoch 96 iteration 97: 0.563836395740509\n",
            "loss in epoch 96 iteration 98: 0.5621644258499146\n",
            "loss in epoch 96 iteration 99: 0.5643383264541626\n",
            "loss in epoch 96 iteration 100: 0.5432592630386353\n",
            "loss in epoch 96 iteration 101: 0.5572268962860107\n",
            "loss in epoch 96 iteration 102: 0.5881479382514954\n",
            "loss in epoch 96 iteration 103: 0.5676434636116028\n",
            "loss in epoch 96 iteration 104: 0.5824761390686035\n",
            "loss in epoch 96 iteration 105: 0.5610510110855103\n",
            "loss in epoch 96 iteration 106: 0.5456902384757996\n",
            "loss in epoch 96 iteration 107: 0.5587664842605591\n",
            "loss in epoch 96 iteration 108: 0.55281662940979\n",
            "loss in epoch 96 iteration 109: 0.5473073720932007\n",
            "loss in epoch 96 iteration 110: 0.5640897750854492\n",
            "loss in epoch 96 iteration 111: 0.5683538913726807\n",
            "loss in epoch 96 iteration 112: 0.5462573766708374\n",
            "loss in epoch 96 iteration 113: 0.5641159415245056\n",
            "loss in epoch 96 iteration 114: 0.5687110424041748\n",
            "loss in epoch 96 iteration 115: 0.5755171775817871\n",
            "loss in epoch 96 iteration 116: 0.5543949604034424\n",
            "loss in epoch 96 iteration 117: 0.559621274471283\n",
            "loss in epoch 96 iteration 118: 0.5652735233306885\n",
            "loss in epoch 96 iteration 119: 0.5575906038284302\n",
            "loss in epoch 96 iteration 120: 0.5459507703781128\n",
            "loss in epoch 96 iteration 121: 0.5514777898788452\n",
            "loss in epoch 96 iteration 122: 0.5592350959777832\n",
            "loss in epoch 96 iteration 123: 0.562021791934967\n",
            "loss in epoch 96 iteration 124: 0.5541776418685913\n",
            "loss in epoch 96 iteration 125: 0.5475074052810669\n",
            "loss in epoch 96 iteration 126: 0.5657956600189209\n",
            "loss in epoch 96 iteration 127: 0.5379930138587952\n",
            "loss in epoch 96 iteration 128: 0.5622432231903076\n",
            "loss in epoch 96 iteration 129: 0.5557959079742432\n",
            "loss in epoch 96 iteration 130: 0.5384913682937622\n",
            "loss in epoch 96 iteration 131: 0.5823249220848083\n",
            "loss in epoch 96 iteration 132: 0.5304335355758667\n",
            "loss in epoch 96 iteration 133: 0.5391160249710083\n",
            "loss in epoch 96 iteration 134: 0.567520797252655\n",
            "loss in epoch 96 iteration 135: 0.533974289894104\n",
            "loss in epoch 96 iteration 136: 0.5501492023468018\n",
            "loss in epoch 96 iteration 137: 0.5379645824432373\n",
            "loss in epoch 96 iteration 138: 0.542120099067688\n",
            "loss in epoch 96 iteration 139: 0.5531048774719238\n",
            "loss in epoch 96 iteration 140: 0.5678001642227173\n",
            "loss in epoch 96 iteration 141: 0.552689790725708\n",
            "loss in epoch 96 iteration 142: 0.5720877051353455\n",
            "loss in epoch 96 iteration 143: 0.545974850654602\n",
            "loss in epoch 96 iteration 144: 0.5306126475334167\n",
            "loss in epoch 96 iteration 145: 0.5612128973007202\n",
            "loss in epoch 96 iteration 146: 0.5487903356552124\n",
            "loss in epoch 96 iteration 147: 0.5636163949966431\n",
            "loss in epoch 96 iteration 148: 0.5443628430366516\n",
            "loss in epoch 96 iteration 149: 0.5802811980247498\n",
            "loss in epoch 96 iteration 150: 0.5734204053878784\n",
            "loss in epoch 96 iteration 151: 0.571231484413147\n",
            "loss in epoch 96 iteration 152: 0.5437787175178528\n",
            "loss in epoch 96 iteration 153: 0.5390686392784119\n",
            "loss in epoch 96 iteration 154: 0.5456302165985107\n",
            "loss in epoch 96 iteration 155: 0.5451140403747559\n",
            "loss in epoch 96 iteration 156: 0.5840931534767151\n",
            "loss in epoch 96 iteration 157: 0.5988785028457642\n",
            "loss in epoch 96 iteration 158: 0.5537571310997009\n",
            "loss in epoch 96 iteration 159: 0.5790979266166687\n",
            "loss in epoch 96 iteration 160: 0.5562257766723633\n",
            "loss in epoch 96 iteration 161: 0.5673590898513794\n",
            "loss in epoch 96 iteration 162: 0.5469216704368591\n",
            "loss in epoch 96 iteration 163: 0.5522259473800659\n",
            "loss in epoch 96 iteration 164: 0.5497316718101501\n",
            "loss in epoch 96 iteration 165: 0.5613042116165161\n",
            "loss in epoch 96 iteration 166: 0.5692141652107239\n",
            "loss in epoch 96 iteration 167: 0.5529608726501465\n",
            "loss in epoch 96 iteration 168: 0.5571143627166748\n",
            "loss in epoch 96 iteration 169: 0.5510158538818359\n",
            "loss in epoch 96 iteration 170: 0.5333782434463501\n",
            "loss in epoch 96 iteration 171: 0.546437680721283\n",
            "loss in epoch 96 iteration 172: 0.5831277966499329\n",
            "loss in epoch 96 iteration 173: 0.5764697790145874\n",
            "loss in epoch 96 iteration 174: 0.5646224021911621\n",
            "loss in epoch 96 iteration 175: 0.54694664478302\n",
            "loss in epoch 96 iteration 176: 0.5604037642478943\n",
            "loss in epoch 96 iteration 177: 0.5831702947616577\n",
            "loss in epoch 96 iteration 178: 0.5580935478210449\n",
            "loss in epoch 96 iteration 179: 0.5607193112373352\n",
            "loss in epoch 96 iteration 180: 0.601706862449646\n",
            "loss in epoch 96 iteration 181: 0.5518492460250854\n",
            "loss in epoch 96 iteration 182: 0.5560312867164612\n",
            "loss in epoch 96 iteration 183: 0.5465534925460815\n",
            "loss in epoch 96 iteration 184: 0.531161904335022\n",
            "loss in epoch 96 iteration 185: 0.5764329433441162\n",
            "loss in epoch 96 iteration 186: 0.5623081922531128\n",
            "loss in epoch 96 iteration 187: 0.5772680044174194\n",
            "loss in epoch 96 iteration 188: 0.5501079559326172\n",
            "loss in epoch 96 iteration 189: 0.5637867450714111\n",
            "loss in epoch 96 iteration 190: 0.5708041191101074\n",
            "loss in epoch 96 iteration 191: 0.556907594203949\n",
            "loss in epoch 96 iteration 192: 0.5794273614883423\n",
            "loss in epoch 96 iteration 193: 0.5761386156082153\n",
            "loss in epoch 96 iteration 194: 0.5494287014007568\n",
            "loss in epoch 96 iteration 195: 0.5856158137321472\n",
            "loss in epoch 96 iteration 196: 0.5737001299858093\n",
            "loss in epoch 96 iteration 197: 0.5773323774337769\n",
            "loss in epoch 96 iteration 198: 0.6040893197059631\n",
            "loss in epoch 96 iteration 199: 0.5356037616729736\n",
            "loss in epoch 96 iteration 200: 0.5749683380126953\n",
            "loss in epoch 96 iteration 201: 0.5593032836914062\n",
            "loss in epoch 96 iteration 202: 0.5732802152633667\n",
            "loss in epoch 96 iteration 203: 0.5763815641403198\n",
            "loss in epoch 96 iteration 204: 0.5682075023651123\n",
            "loss in epoch 96 iteration 205: 0.5600313544273376\n",
            "loss in epoch 96 iteration 206: 0.5264716744422913\n",
            "loss in epoch 96 iteration 207: 0.5378233790397644\n",
            "loss in epoch 96 iteration 208: 0.5626125931739807\n",
            "loss in epoch 96 iteration 209: 0.5852695107460022\n",
            "loss in epoch 96 iteration 210: 0.5624750852584839\n",
            "loss in epoch 96 iteration 211: 0.5582947731018066\n",
            "loss in epoch 96 iteration 212: 0.5452804565429688\n",
            "loss in epoch 96 iteration 213: 0.5242214202880859\n",
            "loss in epoch 96 iteration 214: 0.5803714394569397\n",
            "loss in epoch 96 iteration 215: 0.5739715099334717\n",
            "loss in epoch 96 iteration 216: 0.5479384660720825\n",
            "loss in epoch 96 iteration 217: 0.5589940547943115\n",
            "loss in epoch 96 iteration 218: 0.5578430891036987\n",
            "loss in epoch 96 iteration 219: 0.5435638427734375\n",
            "loss in epoch 96 iteration 220: 0.5632957220077515\n",
            "loss in epoch 96 iteration 221: 0.5914163589477539\n",
            "loss in epoch 96 iteration 222: 0.5417532920837402\n",
            "loss in epoch 96 iteration 223: 0.5615177154541016\n",
            "loss in epoch 96 iteration 224: 0.5633863210678101\n",
            "loss in epoch 96 iteration 225: 0.553415834903717\n",
            "loss in epoch 96 iteration 226: 0.5705470442771912\n",
            "loss in epoch 96 iteration 227: 0.5616543292999268\n",
            "loss in epoch 96 iteration 228: 0.5445545315742493\n",
            "loss in epoch 96 iteration 229: 0.5235832333564758\n",
            "loss in epoch 96 iteration 230: 0.5299764275550842\n",
            "loss in epoch 96 iteration 231: 0.551957368850708\n",
            "loss in epoch 96 iteration 232: 0.5393966436386108\n",
            "loss in epoch 96 iteration 233: 0.5380998849868774\n",
            "loss in epoch 96 iteration 234: 0.5868927240371704\n",
            "loss in epoch 96 iteration 235: 0.5785276293754578\n",
            "loss in epoch 96 iteration 236: 0.5761122107505798\n",
            "loss in epoch 96 iteration 237: 0.533466637134552\n",
            "loss in epoch 96 iteration 238: 0.5510530471801758\n",
            "loss in epoch 96 iteration 239: 0.5480105876922607\n",
            "loss in epoch 96 iteration 240: 0.5791134834289551\n",
            "loss in epoch 96 iteration 241: 0.5514894723892212\n",
            "loss in epoch 96 iteration 242: 0.5547949075698853\n",
            "loss in epoch 97 iteration 0: 0.563881516456604\n",
            "loss in epoch 97 iteration 1: 0.5644128322601318\n",
            "loss in epoch 97 iteration 2: 0.5584830045700073\n",
            "loss in epoch 97 iteration 3: 0.5647412538528442\n",
            "loss in epoch 97 iteration 4: 0.5467073321342468\n",
            "loss in epoch 97 iteration 5: 0.5413281917572021\n",
            "loss in epoch 97 iteration 6: 0.5885342359542847\n",
            "loss in epoch 97 iteration 7: 0.5479891300201416\n",
            "loss in epoch 97 iteration 8: 0.5808759927749634\n",
            "loss in epoch 97 iteration 9: 0.5738840103149414\n",
            "loss in epoch 97 iteration 10: 0.5444021821022034\n",
            "loss in epoch 97 iteration 11: 0.5882264375686646\n",
            "loss in epoch 97 iteration 12: 0.5462817549705505\n",
            "loss in epoch 97 iteration 13: 0.5564191341400146\n",
            "loss in epoch 97 iteration 14: 0.5461908578872681\n",
            "loss in epoch 97 iteration 15: 0.5755100250244141\n",
            "loss in epoch 97 iteration 16: 0.5685849785804749\n",
            "loss in epoch 97 iteration 17: 0.5598516464233398\n",
            "loss in epoch 97 iteration 18: 0.5748469829559326\n",
            "loss in epoch 97 iteration 19: 0.5579897165298462\n",
            "loss in epoch 97 iteration 20: 0.5890518426895142\n",
            "loss in epoch 97 iteration 21: 0.5629498958587646\n",
            "loss in epoch 97 iteration 22: 0.5863096117973328\n",
            "loss in epoch 97 iteration 23: 0.5503503680229187\n",
            "loss in epoch 97 iteration 24: 0.5431689620018005\n",
            "loss in epoch 97 iteration 25: 0.5517318248748779\n",
            "loss in epoch 97 iteration 26: 0.5668900012969971\n",
            "loss in epoch 97 iteration 27: 0.5396848917007446\n",
            "loss in epoch 97 iteration 28: 0.5518778562545776\n",
            "loss in epoch 97 iteration 29: 0.5685844421386719\n",
            "loss in epoch 97 iteration 30: 0.5616782903671265\n",
            "loss in epoch 97 iteration 31: 0.5580431222915649\n",
            "loss in epoch 97 iteration 32: 0.572141170501709\n",
            "loss in epoch 97 iteration 33: 0.5431400537490845\n",
            "loss in epoch 97 iteration 34: 0.5865516662597656\n",
            "loss in epoch 97 iteration 35: 0.5469632148742676\n",
            "loss in epoch 97 iteration 36: 0.5366942882537842\n",
            "loss in epoch 97 iteration 37: 0.5597890615463257\n",
            "loss in epoch 97 iteration 38: 0.5827929973602295\n",
            "loss in epoch 97 iteration 39: 0.5555893778800964\n",
            "loss in epoch 97 iteration 40: 0.5781087875366211\n",
            "loss in epoch 97 iteration 41: 0.5605236291885376\n",
            "loss in epoch 97 iteration 42: 0.5373304486274719\n",
            "loss in epoch 97 iteration 43: 0.5614436864852905\n",
            "loss in epoch 97 iteration 44: 0.5591568946838379\n",
            "loss in epoch 97 iteration 45: 0.5374189615249634\n",
            "loss in epoch 97 iteration 46: 0.5839085578918457\n",
            "loss in epoch 97 iteration 47: 0.5646899938583374\n",
            "loss in epoch 97 iteration 48: 0.5870553255081177\n",
            "loss in epoch 97 iteration 49: 0.5384998321533203\n",
            "loss in epoch 97 iteration 50: 0.5575712323188782\n",
            "loss in epoch 97 iteration 51: 0.5782333612442017\n",
            "loss in epoch 97 iteration 52: 0.5733028650283813\n",
            "loss in epoch 97 iteration 53: 0.5563931465148926\n",
            "loss in epoch 97 iteration 54: 0.5604817867279053\n",
            "loss in epoch 97 iteration 55: 0.5745850205421448\n",
            "loss in epoch 97 iteration 56: 0.5721683502197266\n",
            "loss in epoch 97 iteration 57: 0.5645233392715454\n",
            "loss in epoch 97 iteration 58: 0.5481324195861816\n",
            "loss in epoch 97 iteration 59: 0.5676669478416443\n",
            "loss in epoch 97 iteration 60: 0.5522147417068481\n",
            "loss in epoch 97 iteration 61: 0.5373868942260742\n",
            "loss in epoch 97 iteration 62: 0.5382943749427795\n",
            "loss in epoch 97 iteration 63: 0.5403242707252502\n",
            "loss in epoch 97 iteration 64: 0.5470389127731323\n",
            "loss in epoch 97 iteration 65: 0.5510240197181702\n",
            "loss in epoch 97 iteration 66: 0.5489832162857056\n",
            "loss in epoch 97 iteration 67: 0.5725127458572388\n",
            "loss in epoch 97 iteration 68: 0.5490508079528809\n",
            "loss in epoch 97 iteration 69: 0.5784430503845215\n",
            "loss in epoch 97 iteration 70: 0.549310564994812\n",
            "loss in epoch 97 iteration 71: 0.5807062387466431\n",
            "loss in epoch 97 iteration 72: 0.5649644136428833\n",
            "loss in epoch 97 iteration 73: 0.5369623899459839\n",
            "loss in epoch 97 iteration 74: 0.5894190669059753\n",
            "loss in epoch 97 iteration 75: 0.5811598896980286\n",
            "loss in epoch 97 iteration 76: 0.5784144401550293\n",
            "loss in epoch 97 iteration 77: 0.5655596256256104\n",
            "loss in epoch 97 iteration 78: 0.5458452105522156\n",
            "loss in epoch 97 iteration 79: 0.5387189388275146\n",
            "loss in epoch 97 iteration 80: 0.5326948165893555\n",
            "loss in epoch 97 iteration 81: 0.5235732793807983\n",
            "loss in epoch 97 iteration 82: 0.5144025087356567\n",
            "loss in epoch 97 iteration 83: 0.5667387247085571\n",
            "loss in epoch 97 iteration 84: 0.5329223871231079\n",
            "loss in epoch 97 iteration 85: 0.5595564842224121\n",
            "loss in epoch 97 iteration 86: 0.5458632707595825\n",
            "loss in epoch 97 iteration 87: 0.5588557720184326\n",
            "loss in epoch 97 iteration 88: 0.5804476737976074\n",
            "loss in epoch 97 iteration 89: 0.5713695287704468\n",
            "loss in epoch 97 iteration 90: 0.5577304363250732\n",
            "loss in epoch 97 iteration 91: 0.5877453088760376\n",
            "loss in epoch 97 iteration 92: 0.5619203448295593\n",
            "loss in epoch 97 iteration 93: 0.5443574786186218\n",
            "loss in epoch 97 iteration 94: 0.5847302675247192\n",
            "loss in epoch 97 iteration 95: 0.5634961128234863\n",
            "loss in epoch 97 iteration 96: 0.5542865991592407\n",
            "loss in epoch 97 iteration 97: 0.5606125593185425\n",
            "loss in epoch 97 iteration 98: 0.5799176692962646\n",
            "loss in epoch 97 iteration 99: 0.5384780168533325\n",
            "loss in epoch 97 iteration 100: 0.5724823474884033\n",
            "loss in epoch 97 iteration 101: 0.5461042523384094\n",
            "loss in epoch 97 iteration 102: 0.5592871904373169\n",
            "loss in epoch 97 iteration 103: 0.5704253911972046\n",
            "loss in epoch 97 iteration 104: 0.5471758842468262\n",
            "loss in epoch 97 iteration 105: 0.5585234761238098\n",
            "loss in epoch 97 iteration 106: 0.5576558113098145\n",
            "loss in epoch 97 iteration 107: 0.5671553611755371\n",
            "loss in epoch 97 iteration 108: 0.5509291887283325\n",
            "loss in epoch 97 iteration 109: 0.5458506345748901\n",
            "loss in epoch 97 iteration 110: 0.5688782930374146\n",
            "loss in epoch 97 iteration 111: 0.5601066946983337\n",
            "loss in epoch 97 iteration 112: 0.58064204454422\n",
            "loss in epoch 97 iteration 113: 0.5515137314796448\n",
            "loss in epoch 97 iteration 114: 0.5749908685684204\n",
            "loss in epoch 97 iteration 115: 0.5665310025215149\n",
            "loss in epoch 97 iteration 116: 0.5679953694343567\n",
            "loss in epoch 97 iteration 117: 0.542873740196228\n",
            "loss in epoch 97 iteration 118: 0.5841193199157715\n",
            "loss in epoch 97 iteration 119: 0.585672914981842\n",
            "loss in epoch 97 iteration 120: 0.5409417152404785\n",
            "loss in epoch 97 iteration 121: 0.5587133169174194\n",
            "loss in epoch 97 iteration 122: 0.5595633387565613\n",
            "loss in epoch 97 iteration 123: 0.5744034051895142\n",
            "loss in epoch 97 iteration 124: 0.5539981126785278\n",
            "loss in epoch 97 iteration 125: 0.5741784572601318\n",
            "loss in epoch 97 iteration 126: 0.5585999488830566\n",
            "loss in epoch 97 iteration 127: 0.5464743375778198\n",
            "loss in epoch 97 iteration 128: 0.5681803226470947\n",
            "loss in epoch 97 iteration 129: 0.5700139403343201\n",
            "loss in epoch 97 iteration 130: 0.5764694809913635\n",
            "loss in epoch 97 iteration 131: 0.5830880403518677\n",
            "loss in epoch 97 iteration 132: 0.5469304323196411\n",
            "loss in epoch 97 iteration 133: 0.576151430606842\n",
            "loss in epoch 97 iteration 134: 0.5465579628944397\n",
            "loss in epoch 97 iteration 135: 0.5738823413848877\n",
            "loss in epoch 97 iteration 136: 0.5417070388793945\n",
            "loss in epoch 97 iteration 137: 0.5439364910125732\n",
            "loss in epoch 97 iteration 138: 0.5559425354003906\n",
            "loss in epoch 97 iteration 139: 0.5615824460983276\n",
            "loss in epoch 97 iteration 140: 0.5576462745666504\n",
            "loss in epoch 97 iteration 141: 0.5626964569091797\n",
            "loss in epoch 97 iteration 142: 0.563990592956543\n",
            "loss in epoch 97 iteration 143: 0.5716546773910522\n",
            "loss in epoch 97 iteration 144: 0.5846471786499023\n",
            "loss in epoch 97 iteration 145: 0.5389758348464966\n",
            "loss in epoch 97 iteration 146: 0.5808677673339844\n",
            "loss in epoch 97 iteration 147: 0.5727257132530212\n",
            "loss in epoch 97 iteration 148: 0.5398343801498413\n",
            "loss in epoch 97 iteration 149: 0.5753417015075684\n",
            "loss in epoch 97 iteration 150: 0.56806480884552\n",
            "loss in epoch 97 iteration 151: 0.5437663197517395\n",
            "loss in epoch 97 iteration 152: 0.5602861642837524\n",
            "loss in epoch 97 iteration 153: 0.5669820308685303\n",
            "loss in epoch 97 iteration 154: 0.553919792175293\n",
            "loss in epoch 97 iteration 155: 0.57228684425354\n",
            "loss in epoch 97 iteration 156: 0.5364824533462524\n",
            "loss in epoch 97 iteration 157: 0.5427533984184265\n",
            "loss in epoch 97 iteration 158: 0.5526026487350464\n",
            "loss in epoch 97 iteration 159: 0.5720869898796082\n",
            "loss in epoch 97 iteration 160: 0.5629115104675293\n",
            "loss in epoch 97 iteration 161: 0.5697901248931885\n",
            "loss in epoch 97 iteration 162: 0.5575569868087769\n",
            "loss in epoch 97 iteration 163: 0.5647145509719849\n",
            "loss in epoch 97 iteration 164: 0.5574288368225098\n",
            "loss in epoch 97 iteration 165: 0.5442379713058472\n",
            "loss in epoch 97 iteration 166: 0.5643835067749023\n",
            "loss in epoch 97 iteration 167: 0.5773835182189941\n",
            "loss in epoch 97 iteration 168: 0.5676671266555786\n",
            "loss in epoch 97 iteration 169: 0.5542721748352051\n",
            "loss in epoch 97 iteration 170: 0.5301828980445862\n",
            "loss in epoch 97 iteration 171: 0.5495539307594299\n",
            "loss in epoch 97 iteration 172: 0.5704613327980042\n",
            "loss in epoch 97 iteration 173: 0.5722253322601318\n",
            "loss in epoch 97 iteration 174: 0.5568569302558899\n",
            "loss in epoch 97 iteration 175: 0.5789031982421875\n",
            "loss in epoch 97 iteration 176: 0.5650225877761841\n",
            "loss in epoch 97 iteration 177: 0.5344145894050598\n",
            "loss in epoch 97 iteration 178: 0.5634636878967285\n",
            "loss in epoch 97 iteration 179: 0.5706434845924377\n",
            "loss in epoch 97 iteration 180: 0.5656701922416687\n",
            "loss in epoch 97 iteration 181: 0.5818814039230347\n",
            "loss in epoch 97 iteration 182: 0.5678374767303467\n",
            "loss in epoch 97 iteration 183: 0.5636799335479736\n",
            "loss in epoch 97 iteration 184: 0.5407564640045166\n",
            "loss in epoch 97 iteration 185: 0.5805679559707642\n",
            "loss in epoch 97 iteration 186: 0.5764705538749695\n",
            "loss in epoch 97 iteration 187: 0.5576554536819458\n",
            "loss in epoch 97 iteration 188: 0.5530108213424683\n",
            "loss in epoch 97 iteration 189: 0.5479997992515564\n",
            "loss in epoch 97 iteration 190: 0.5464783906936646\n",
            "loss in epoch 97 iteration 191: 0.5818547010421753\n",
            "loss in epoch 97 iteration 192: 0.5243621468544006\n",
            "loss in epoch 97 iteration 193: 0.5571199655532837\n",
            "loss in epoch 97 iteration 194: 0.5383365750312805\n",
            "loss in epoch 97 iteration 195: 0.5793989896774292\n",
            "loss in epoch 97 iteration 196: 0.5616574287414551\n",
            "loss in epoch 97 iteration 197: 0.559506893157959\n",
            "loss in epoch 97 iteration 198: 0.5633386969566345\n",
            "loss in epoch 97 iteration 199: 0.5600100755691528\n",
            "loss in epoch 97 iteration 200: 0.5762932300567627\n",
            "loss in epoch 97 iteration 201: 0.5653993487358093\n",
            "loss in epoch 97 iteration 202: 0.5558657050132751\n",
            "loss in epoch 97 iteration 203: 0.589093804359436\n",
            "loss in epoch 97 iteration 204: 0.5406890511512756\n",
            "loss in epoch 97 iteration 205: 0.5704982280731201\n",
            "loss in epoch 97 iteration 206: 0.537463366985321\n",
            "loss in epoch 97 iteration 207: 0.5632067918777466\n",
            "loss in epoch 97 iteration 208: 0.5528326034545898\n",
            "loss in epoch 97 iteration 209: 0.5776550769805908\n",
            "loss in epoch 97 iteration 210: 0.5609170794487\n",
            "loss in epoch 97 iteration 211: 0.5607210397720337\n",
            "loss in epoch 97 iteration 212: 0.5294845104217529\n",
            "loss in epoch 97 iteration 213: 0.548876166343689\n",
            "loss in epoch 97 iteration 214: 0.5440810322761536\n",
            "loss in epoch 97 iteration 215: 0.5709042549133301\n",
            "loss in epoch 97 iteration 216: 0.5762989521026611\n",
            "loss in epoch 97 iteration 217: 0.577202558517456\n",
            "loss in epoch 97 iteration 218: 0.5574631690979004\n",
            "loss in epoch 97 iteration 219: 0.5487080216407776\n",
            "loss in epoch 97 iteration 220: 0.5660514831542969\n",
            "loss in epoch 97 iteration 221: 0.5596635341644287\n",
            "loss in epoch 97 iteration 222: 0.5827465057373047\n",
            "loss in epoch 97 iteration 223: 0.566619873046875\n",
            "loss in epoch 97 iteration 224: 0.5908069014549255\n",
            "loss in epoch 97 iteration 225: 0.5955991744995117\n",
            "loss in epoch 97 iteration 226: 0.5818954706192017\n",
            "loss in epoch 97 iteration 227: 0.5574431419372559\n",
            "loss in epoch 97 iteration 228: 0.5557284951210022\n",
            "loss in epoch 97 iteration 229: 0.5443215370178223\n",
            "loss in epoch 97 iteration 230: 0.5586196184158325\n",
            "loss in epoch 97 iteration 231: 0.5942085981369019\n",
            "loss in epoch 97 iteration 232: 0.5349180698394775\n",
            "loss in epoch 97 iteration 233: 0.5749951601028442\n",
            "loss in epoch 97 iteration 234: 0.5690561532974243\n",
            "loss in epoch 97 iteration 235: 0.5618900060653687\n",
            "loss in epoch 97 iteration 236: 0.5542070865631104\n",
            "loss in epoch 97 iteration 237: 0.5913896560668945\n",
            "loss in epoch 97 iteration 238: 0.5294559001922607\n",
            "loss in epoch 97 iteration 239: 0.5499081611633301\n",
            "loss in epoch 97 iteration 240: 0.5205888152122498\n",
            "loss in epoch 97 iteration 241: 0.5530171394348145\n",
            "loss in epoch 97 iteration 242: 0.5577072501182556\n",
            "loss in epoch 98 iteration 0: 0.5661770701408386\n",
            "loss in epoch 98 iteration 1: 0.5640740394592285\n",
            "loss in epoch 98 iteration 2: 0.5634676218032837\n",
            "loss in epoch 98 iteration 3: 0.5813077688217163\n",
            "loss in epoch 98 iteration 4: 0.5581842064857483\n",
            "loss in epoch 98 iteration 5: 0.5600806474685669\n",
            "loss in epoch 98 iteration 6: 0.5445342063903809\n",
            "loss in epoch 98 iteration 7: 0.5497292280197144\n",
            "loss in epoch 98 iteration 8: 0.5612885355949402\n",
            "loss in epoch 98 iteration 9: 0.5554282069206238\n",
            "loss in epoch 98 iteration 10: 0.550335168838501\n",
            "loss in epoch 98 iteration 11: 0.5569311380386353\n",
            "loss in epoch 98 iteration 12: 0.5628777742385864\n",
            "loss in epoch 98 iteration 13: 0.5495541095733643\n",
            "loss in epoch 98 iteration 14: 0.5503395795822144\n",
            "loss in epoch 98 iteration 15: 0.5302841067314148\n",
            "loss in epoch 98 iteration 16: 0.5640838742256165\n",
            "loss in epoch 98 iteration 17: 0.5614640712738037\n",
            "loss in epoch 98 iteration 18: 0.5416203737258911\n",
            "loss in epoch 98 iteration 19: 0.5672156810760498\n",
            "loss in epoch 98 iteration 20: 0.5745648145675659\n",
            "loss in epoch 98 iteration 21: 0.527450680732727\n",
            "loss in epoch 98 iteration 22: 0.561118483543396\n",
            "loss in epoch 98 iteration 23: 0.5829819440841675\n",
            "loss in epoch 98 iteration 24: 0.5621201992034912\n",
            "loss in epoch 98 iteration 25: 0.551882803440094\n",
            "loss in epoch 98 iteration 26: 0.5610735416412354\n",
            "loss in epoch 98 iteration 27: 0.5498435497283936\n",
            "loss in epoch 98 iteration 28: 0.542884111404419\n",
            "loss in epoch 98 iteration 29: 0.5285561680793762\n",
            "loss in epoch 98 iteration 30: 0.5282456874847412\n",
            "loss in epoch 98 iteration 31: 0.5515023469924927\n",
            "loss in epoch 98 iteration 32: 0.5729395747184753\n",
            "loss in epoch 98 iteration 33: 0.5537905693054199\n",
            "loss in epoch 98 iteration 34: 0.5835161209106445\n",
            "loss in epoch 98 iteration 35: 0.5401952862739563\n",
            "loss in epoch 98 iteration 36: 0.5412538647651672\n",
            "loss in epoch 98 iteration 37: 0.5690551996231079\n",
            "loss in epoch 98 iteration 38: 0.570560872554779\n",
            "loss in epoch 98 iteration 39: 0.5280322432518005\n",
            "loss in epoch 98 iteration 40: 0.5432400703430176\n",
            "loss in epoch 98 iteration 41: 0.532185435295105\n",
            "loss in epoch 98 iteration 42: 0.5890498161315918\n",
            "loss in epoch 98 iteration 43: 0.5672307014465332\n",
            "loss in epoch 98 iteration 44: 0.5506411790847778\n",
            "loss in epoch 98 iteration 45: 0.5317109823226929\n",
            "loss in epoch 98 iteration 46: 0.5810585021972656\n",
            "loss in epoch 98 iteration 47: 0.5474501848220825\n",
            "loss in epoch 98 iteration 48: 0.5611182451248169\n",
            "loss in epoch 98 iteration 49: 0.5588294267654419\n",
            "loss in epoch 98 iteration 50: 0.5568798780441284\n",
            "loss in epoch 98 iteration 51: 0.5579161047935486\n",
            "loss in epoch 98 iteration 52: 0.5852324962615967\n",
            "loss in epoch 98 iteration 53: 0.5643675327301025\n",
            "loss in epoch 98 iteration 54: 0.5488828420639038\n",
            "loss in epoch 98 iteration 55: 0.5655612349510193\n",
            "loss in epoch 98 iteration 56: 0.5677142143249512\n",
            "loss in epoch 98 iteration 57: 0.5900784730911255\n",
            "loss in epoch 98 iteration 58: 0.5491048097610474\n",
            "loss in epoch 98 iteration 59: 0.5452350378036499\n",
            "loss in epoch 98 iteration 60: 0.5476534366607666\n",
            "loss in epoch 98 iteration 61: 0.551297664642334\n",
            "loss in epoch 98 iteration 62: 0.5747114419937134\n",
            "loss in epoch 98 iteration 63: 0.543331503868103\n",
            "loss in epoch 98 iteration 64: 0.5598360300064087\n",
            "loss in epoch 98 iteration 65: 0.5414925217628479\n",
            "loss in epoch 98 iteration 66: 0.5566244125366211\n",
            "loss in epoch 98 iteration 67: 0.5741426944732666\n",
            "loss in epoch 98 iteration 68: 0.5319361686706543\n",
            "loss in epoch 98 iteration 69: 0.5379345417022705\n",
            "loss in epoch 98 iteration 70: 0.5412545204162598\n",
            "loss in epoch 98 iteration 71: 0.5582343935966492\n",
            "loss in epoch 98 iteration 72: 0.538014829158783\n",
            "loss in epoch 98 iteration 73: 0.5457130670547485\n",
            "loss in epoch 98 iteration 74: 0.5400773286819458\n",
            "loss in epoch 98 iteration 75: 0.5795892477035522\n",
            "loss in epoch 98 iteration 76: 0.591285228729248\n",
            "loss in epoch 98 iteration 77: 0.5761755704879761\n",
            "loss in epoch 98 iteration 78: 0.5589419603347778\n",
            "loss in epoch 98 iteration 79: 0.5450791120529175\n",
            "loss in epoch 98 iteration 80: 0.5409108996391296\n",
            "loss in epoch 98 iteration 81: 0.5658389925956726\n",
            "loss in epoch 98 iteration 82: 0.5754401683807373\n",
            "loss in epoch 98 iteration 83: 0.5562604665756226\n",
            "loss in epoch 98 iteration 84: 0.5621110200881958\n",
            "loss in epoch 98 iteration 85: 0.5267353653907776\n",
            "loss in epoch 98 iteration 86: 0.5367027521133423\n",
            "loss in epoch 98 iteration 87: 0.5725038051605225\n",
            "loss in epoch 98 iteration 88: 0.5648564100265503\n",
            "loss in epoch 98 iteration 89: 0.5414323210716248\n",
            "loss in epoch 98 iteration 90: 0.5847160816192627\n",
            "loss in epoch 98 iteration 91: 0.5834636092185974\n",
            "loss in epoch 98 iteration 92: 0.5676606893539429\n",
            "loss in epoch 98 iteration 93: 0.5693578720092773\n",
            "loss in epoch 98 iteration 94: 0.5468662977218628\n",
            "loss in epoch 98 iteration 95: 0.555385410785675\n",
            "loss in epoch 98 iteration 96: 0.5200917720794678\n",
            "loss in epoch 98 iteration 97: 0.5883781909942627\n",
            "loss in epoch 98 iteration 98: 0.5506481528282166\n",
            "loss in epoch 98 iteration 99: 0.545850396156311\n",
            "loss in epoch 98 iteration 100: 0.5470789670944214\n",
            "loss in epoch 98 iteration 101: 0.5556480884552002\n",
            "loss in epoch 98 iteration 102: 0.5421210527420044\n",
            "loss in epoch 98 iteration 103: 0.5516296625137329\n",
            "loss in epoch 98 iteration 104: 0.5446677207946777\n",
            "loss in epoch 98 iteration 105: 0.5553274154663086\n",
            "loss in epoch 98 iteration 106: 0.5596755743026733\n",
            "loss in epoch 98 iteration 107: 0.5540140867233276\n",
            "loss in epoch 98 iteration 108: 0.5828948020935059\n",
            "loss in epoch 98 iteration 109: 0.5621234774589539\n",
            "loss in epoch 98 iteration 110: 0.5486871004104614\n",
            "loss in epoch 98 iteration 111: 0.5455076694488525\n",
            "loss in epoch 98 iteration 112: 0.5547865629196167\n",
            "loss in epoch 98 iteration 113: 0.5536922812461853\n",
            "loss in epoch 98 iteration 114: 0.5656479597091675\n",
            "loss in epoch 98 iteration 115: 0.56397545337677\n",
            "loss in epoch 98 iteration 116: 0.5612877011299133\n",
            "loss in epoch 98 iteration 117: 0.5418360233306885\n",
            "loss in epoch 98 iteration 118: 0.5554680824279785\n",
            "loss in epoch 98 iteration 119: 0.5431658625602722\n",
            "loss in epoch 98 iteration 120: 0.5840473771095276\n",
            "loss in epoch 98 iteration 121: 0.5678278207778931\n",
            "loss in epoch 98 iteration 122: 0.5556265115737915\n",
            "loss in epoch 98 iteration 123: 0.5429916381835938\n",
            "loss in epoch 98 iteration 124: 0.5555562376976013\n",
            "loss in epoch 98 iteration 125: 0.5799651145935059\n",
            "loss in epoch 98 iteration 126: 0.5644427537918091\n",
            "loss in epoch 98 iteration 127: 0.5513424873352051\n",
            "loss in epoch 98 iteration 128: 0.5495150685310364\n",
            "loss in epoch 98 iteration 129: 0.5627201199531555\n",
            "loss in epoch 98 iteration 130: 0.5531240701675415\n",
            "loss in epoch 98 iteration 131: 0.5886855721473694\n",
            "loss in epoch 98 iteration 132: 0.5609254837036133\n",
            "loss in epoch 98 iteration 133: 0.5611299276351929\n",
            "loss in epoch 98 iteration 134: 0.5390545129776001\n",
            "loss in epoch 98 iteration 135: 0.577284574508667\n",
            "loss in epoch 98 iteration 136: 0.5843138694763184\n",
            "loss in epoch 98 iteration 137: 0.5630866289138794\n",
            "loss in epoch 98 iteration 138: 0.5516036152839661\n",
            "loss in epoch 98 iteration 139: 0.5449406504631042\n",
            "loss in epoch 98 iteration 140: 0.5644354224205017\n",
            "loss in epoch 98 iteration 141: 0.5560383796691895\n",
            "loss in epoch 98 iteration 142: 0.5254286527633667\n",
            "loss in epoch 98 iteration 143: 0.5644947290420532\n",
            "loss in epoch 98 iteration 144: 0.5720575451850891\n",
            "loss in epoch 98 iteration 145: 0.5376455783843994\n",
            "loss in epoch 98 iteration 146: 0.5417637825012207\n",
            "loss in epoch 98 iteration 147: 0.5362570285797119\n",
            "loss in epoch 98 iteration 148: 0.5582554936408997\n",
            "loss in epoch 98 iteration 149: 0.5527417659759521\n",
            "loss in epoch 98 iteration 150: 0.5380238890647888\n",
            "loss in epoch 98 iteration 151: 0.5664985179901123\n",
            "loss in epoch 98 iteration 152: 0.5391693115234375\n",
            "loss in epoch 98 iteration 153: 0.5790234804153442\n",
            "loss in epoch 98 iteration 154: 0.5526080131530762\n",
            "loss in epoch 98 iteration 155: 0.5430552363395691\n",
            "loss in epoch 98 iteration 156: 0.5489791035652161\n",
            "loss in epoch 98 iteration 157: 0.5641299486160278\n",
            "loss in epoch 98 iteration 158: 0.5567883849143982\n",
            "loss in epoch 98 iteration 159: 0.570667028427124\n",
            "loss in epoch 98 iteration 160: 0.564850926399231\n",
            "loss in epoch 98 iteration 161: 0.562247097492218\n",
            "loss in epoch 98 iteration 162: 0.5637701749801636\n",
            "loss in epoch 98 iteration 163: 0.5700143575668335\n",
            "loss in epoch 98 iteration 164: 0.5545662641525269\n",
            "loss in epoch 98 iteration 165: 0.5823614597320557\n",
            "loss in epoch 98 iteration 166: 0.5675524473190308\n",
            "loss in epoch 98 iteration 167: 0.5905759334564209\n",
            "loss in epoch 98 iteration 168: 0.5722197890281677\n",
            "loss in epoch 98 iteration 169: 0.5486948490142822\n",
            "loss in epoch 98 iteration 170: 0.5688821077346802\n",
            "loss in epoch 98 iteration 171: 0.5603041648864746\n",
            "loss in epoch 98 iteration 172: 0.5295116305351257\n",
            "loss in epoch 98 iteration 173: 0.5858985781669617\n",
            "loss in epoch 98 iteration 174: 0.5437557697296143\n",
            "loss in epoch 98 iteration 175: 0.5530644655227661\n",
            "loss in epoch 98 iteration 176: 0.578682005405426\n",
            "loss in epoch 98 iteration 177: 0.5574811697006226\n",
            "loss in epoch 98 iteration 178: 0.5356822609901428\n",
            "loss in epoch 98 iteration 179: 0.5469048023223877\n",
            "loss in epoch 98 iteration 180: 0.5284109115600586\n",
            "loss in epoch 98 iteration 181: 0.5446768999099731\n",
            "loss in epoch 98 iteration 182: 0.5439517498016357\n",
            "loss in epoch 98 iteration 183: 0.5382969379425049\n",
            "loss in epoch 98 iteration 184: 0.5554916262626648\n",
            "loss in epoch 98 iteration 185: 0.5618389248847961\n",
            "loss in epoch 98 iteration 186: 0.5593502521514893\n",
            "loss in epoch 98 iteration 187: 0.588559627532959\n",
            "loss in epoch 98 iteration 188: 0.5611703991889954\n",
            "loss in epoch 98 iteration 189: 0.5649787187576294\n",
            "loss in epoch 98 iteration 190: 0.5547029972076416\n",
            "loss in epoch 98 iteration 191: 0.5713455677032471\n",
            "loss in epoch 98 iteration 192: 0.5611507892608643\n",
            "loss in epoch 98 iteration 193: 0.5770562887191772\n",
            "loss in epoch 98 iteration 194: 0.5507548451423645\n",
            "loss in epoch 98 iteration 195: 0.5619997382164001\n",
            "loss in epoch 98 iteration 196: 0.5541231632232666\n",
            "loss in epoch 98 iteration 197: 0.5699349045753479\n",
            "loss in epoch 98 iteration 198: 0.5703211426734924\n",
            "loss in epoch 98 iteration 199: 0.5746649503707886\n",
            "loss in epoch 98 iteration 200: 0.5376880168914795\n",
            "loss in epoch 98 iteration 201: 0.5817582011222839\n",
            "loss in epoch 98 iteration 202: 0.5519941449165344\n",
            "loss in epoch 98 iteration 203: 0.5627493262290955\n",
            "loss in epoch 98 iteration 204: 0.5453644394874573\n",
            "loss in epoch 98 iteration 205: 0.5581519603729248\n",
            "loss in epoch 98 iteration 206: 0.5364155769348145\n",
            "loss in epoch 98 iteration 207: 0.5511556267738342\n",
            "loss in epoch 98 iteration 208: 0.5175432562828064\n",
            "loss in epoch 98 iteration 209: 0.5684738159179688\n",
            "loss in epoch 98 iteration 210: 0.5680198669433594\n",
            "loss in epoch 98 iteration 211: 0.5456318855285645\n",
            "loss in epoch 98 iteration 212: 0.5322548747062683\n",
            "loss in epoch 98 iteration 213: 0.5445933938026428\n",
            "loss in epoch 98 iteration 214: 0.5751484632492065\n",
            "loss in epoch 98 iteration 215: 0.5353033542633057\n",
            "loss in epoch 98 iteration 216: 0.5717407464981079\n",
            "loss in epoch 98 iteration 217: 0.5745630264282227\n",
            "loss in epoch 98 iteration 218: 0.556305468082428\n",
            "loss in epoch 98 iteration 219: 0.5141028761863708\n",
            "loss in epoch 98 iteration 220: 0.5323572158813477\n",
            "loss in epoch 98 iteration 221: 0.5656052827835083\n",
            "loss in epoch 98 iteration 222: 0.5357030630111694\n",
            "loss in epoch 98 iteration 223: 0.5808403491973877\n",
            "loss in epoch 98 iteration 224: 0.5655020475387573\n",
            "loss in epoch 98 iteration 225: 0.5719500780105591\n",
            "loss in epoch 98 iteration 226: 0.5621256828308105\n",
            "loss in epoch 98 iteration 227: 0.5377951264381409\n",
            "loss in epoch 98 iteration 228: 0.5446062684059143\n",
            "loss in epoch 98 iteration 229: 0.586716890335083\n",
            "loss in epoch 98 iteration 230: 0.5752688646316528\n",
            "loss in epoch 98 iteration 231: 0.5787293910980225\n",
            "loss in epoch 98 iteration 232: 0.5620420575141907\n",
            "loss in epoch 98 iteration 233: 0.5562558174133301\n",
            "loss in epoch 98 iteration 234: 0.54482102394104\n",
            "loss in epoch 98 iteration 235: 0.5837033987045288\n",
            "loss in epoch 98 iteration 236: 0.5416788458824158\n",
            "loss in epoch 98 iteration 237: 0.5532430410385132\n",
            "loss in epoch 98 iteration 238: 0.5583337545394897\n",
            "loss in epoch 98 iteration 239: 0.5466218590736389\n",
            "loss in epoch 98 iteration 240: 0.5306499004364014\n",
            "loss in epoch 98 iteration 241: 0.541763424873352\n",
            "loss in epoch 98 iteration 242: 0.5562042593955994\n",
            "loss in epoch 99 iteration 0: 0.5458942651748657\n",
            "loss in epoch 99 iteration 1: 0.5469701886177063\n",
            "loss in epoch 99 iteration 2: 0.5520651936531067\n",
            "loss in epoch 99 iteration 3: 0.5409676432609558\n",
            "loss in epoch 99 iteration 4: 0.5245316624641418\n",
            "loss in epoch 99 iteration 5: 0.5692794322967529\n",
            "loss in epoch 99 iteration 6: 0.5598622560501099\n",
            "loss in epoch 99 iteration 7: 0.5668590068817139\n",
            "loss in epoch 99 iteration 8: 0.5430453419685364\n",
            "loss in epoch 99 iteration 9: 0.5778713226318359\n",
            "loss in epoch 99 iteration 10: 0.5697938799858093\n",
            "loss in epoch 99 iteration 11: 0.6089733839035034\n",
            "loss in epoch 99 iteration 12: 0.5646011233329773\n",
            "loss in epoch 99 iteration 13: 0.5736216306686401\n",
            "loss in epoch 99 iteration 14: 0.5794295072555542\n",
            "loss in epoch 99 iteration 15: 0.5769895315170288\n",
            "loss in epoch 99 iteration 16: 0.5740350484848022\n",
            "loss in epoch 99 iteration 17: 0.5565487146377563\n",
            "loss in epoch 99 iteration 18: 0.5535314083099365\n",
            "loss in epoch 99 iteration 19: 0.6096919775009155\n",
            "loss in epoch 99 iteration 20: 0.5659911632537842\n",
            "loss in epoch 99 iteration 21: 0.547748327255249\n",
            "loss in epoch 99 iteration 22: 0.569306492805481\n",
            "loss in epoch 99 iteration 23: 0.5742042660713196\n",
            "loss in epoch 99 iteration 24: 0.5550686120986938\n",
            "loss in epoch 99 iteration 25: 0.5409101843833923\n",
            "loss in epoch 99 iteration 26: 0.5586837530136108\n",
            "loss in epoch 99 iteration 27: 0.5634998083114624\n",
            "loss in epoch 99 iteration 28: 0.5746909379959106\n",
            "loss in epoch 99 iteration 29: 0.5652331113815308\n",
            "loss in epoch 99 iteration 30: 0.5756011009216309\n",
            "loss in epoch 99 iteration 31: 0.5622431039810181\n",
            "loss in epoch 99 iteration 32: 0.55162513256073\n",
            "loss in epoch 99 iteration 33: 0.5907741785049438\n",
            "loss in epoch 99 iteration 34: 0.5884366035461426\n",
            "loss in epoch 99 iteration 35: 0.5587839484214783\n",
            "loss in epoch 99 iteration 36: 0.5447577834129333\n",
            "loss in epoch 99 iteration 37: 0.547136664390564\n",
            "loss in epoch 99 iteration 38: 0.5384997129440308\n",
            "loss in epoch 99 iteration 39: 0.5424427390098572\n",
            "loss in epoch 99 iteration 40: 0.5538941025733948\n",
            "loss in epoch 99 iteration 41: 0.5665664672851562\n",
            "loss in epoch 99 iteration 42: 0.5481582880020142\n",
            "loss in epoch 99 iteration 43: 0.55995112657547\n",
            "loss in epoch 99 iteration 44: 0.5635170936584473\n",
            "loss in epoch 99 iteration 45: 0.5636062622070312\n",
            "loss in epoch 99 iteration 46: 0.5834518671035767\n",
            "loss in epoch 99 iteration 47: 0.558125376701355\n",
            "loss in epoch 99 iteration 48: 0.5620013475418091\n",
            "loss in epoch 99 iteration 49: 0.5674532055854797\n",
            "loss in epoch 99 iteration 50: 0.5560182332992554\n",
            "loss in epoch 99 iteration 51: 0.5739527940750122\n",
            "loss in epoch 99 iteration 52: 0.5471233129501343\n",
            "loss in epoch 99 iteration 53: 0.5706202983856201\n",
            "loss in epoch 99 iteration 54: 0.5631709098815918\n",
            "loss in epoch 99 iteration 55: 0.5504936575889587\n",
            "loss in epoch 99 iteration 56: 0.5646678805351257\n",
            "loss in epoch 99 iteration 57: 0.5321547985076904\n",
            "loss in epoch 99 iteration 58: 0.568527102470398\n",
            "loss in epoch 99 iteration 59: 0.5629944801330566\n",
            "loss in epoch 99 iteration 60: 0.5398328900337219\n",
            "loss in epoch 99 iteration 61: 0.5797473192214966\n",
            "loss in epoch 99 iteration 62: 0.5333696007728577\n",
            "loss in epoch 99 iteration 63: 0.5444850325584412\n",
            "loss in epoch 99 iteration 64: 0.571340799331665\n",
            "loss in epoch 99 iteration 65: 0.5772778987884521\n",
            "loss in epoch 99 iteration 66: 0.5532111525535583\n",
            "loss in epoch 99 iteration 67: 0.5326951146125793\n",
            "loss in epoch 99 iteration 68: 0.5698623657226562\n",
            "loss in epoch 99 iteration 69: 0.5678136348724365\n",
            "loss in epoch 99 iteration 70: 0.5655431151390076\n",
            "loss in epoch 99 iteration 71: 0.538894534111023\n",
            "loss in epoch 99 iteration 72: 0.5896352529525757\n",
            "loss in epoch 99 iteration 73: 0.5460442304611206\n",
            "loss in epoch 99 iteration 74: 0.5522473454475403\n",
            "loss in epoch 99 iteration 75: 0.5554542541503906\n",
            "loss in epoch 99 iteration 76: 0.5587062835693359\n",
            "loss in epoch 99 iteration 77: 0.5893250703811646\n",
            "loss in epoch 99 iteration 78: 0.5290353894233704\n",
            "loss in epoch 99 iteration 79: 0.5471224188804626\n",
            "loss in epoch 99 iteration 80: 0.5611271858215332\n",
            "loss in epoch 99 iteration 81: 0.5755215883255005\n",
            "loss in epoch 99 iteration 82: 0.5427765250205994\n",
            "loss in epoch 99 iteration 83: 0.5417655110359192\n",
            "loss in epoch 99 iteration 84: 0.5561690926551819\n",
            "loss in epoch 99 iteration 85: 0.5527214407920837\n",
            "loss in epoch 99 iteration 86: 0.5701854825019836\n",
            "loss in epoch 99 iteration 87: 0.5635672807693481\n",
            "loss in epoch 99 iteration 88: 0.5605080127716064\n",
            "loss in epoch 99 iteration 89: 0.5447629690170288\n",
            "loss in epoch 99 iteration 90: 0.5488438010215759\n",
            "loss in epoch 99 iteration 91: 0.5695599317550659\n",
            "loss in epoch 99 iteration 92: 0.5276899337768555\n",
            "loss in epoch 99 iteration 93: 0.5884606838226318\n",
            "loss in epoch 99 iteration 94: 0.5515105724334717\n",
            "loss in epoch 99 iteration 95: 0.5623955726623535\n",
            "loss in epoch 99 iteration 96: 0.5674464702606201\n",
            "loss in epoch 99 iteration 97: 0.5696622729301453\n",
            "loss in epoch 99 iteration 98: 0.5537150502204895\n",
            "loss in epoch 99 iteration 99: 0.5790524482727051\n",
            "loss in epoch 99 iteration 100: 0.5468151569366455\n",
            "loss in epoch 99 iteration 101: 0.5758475661277771\n",
            "loss in epoch 99 iteration 102: 0.5591766834259033\n",
            "loss in epoch 99 iteration 103: 0.5576266050338745\n",
            "loss in epoch 99 iteration 104: 0.5548375844955444\n",
            "loss in epoch 99 iteration 105: 0.560506284236908\n",
            "loss in epoch 99 iteration 106: 0.5695304870605469\n",
            "loss in epoch 99 iteration 107: 0.5640960931777954\n",
            "loss in epoch 99 iteration 108: 0.5658615827560425\n",
            "loss in epoch 99 iteration 109: 0.5620446801185608\n",
            "loss in epoch 99 iteration 110: 0.5655778646469116\n",
            "loss in epoch 99 iteration 111: 0.5350552797317505\n",
            "loss in epoch 99 iteration 112: 0.5493587255477905\n",
            "loss in epoch 99 iteration 113: 0.5783602595329285\n",
            "loss in epoch 99 iteration 114: 0.5595552325248718\n",
            "loss in epoch 99 iteration 115: 0.5764917731285095\n",
            "loss in epoch 99 iteration 116: 0.5662623643875122\n",
            "loss in epoch 99 iteration 117: 0.5740935802459717\n",
            "loss in epoch 99 iteration 118: 0.5585407018661499\n",
            "loss in epoch 99 iteration 119: 0.5483025312423706\n",
            "loss in epoch 99 iteration 120: 0.5466921925544739\n",
            "loss in epoch 99 iteration 121: 0.5783270597457886\n",
            "loss in epoch 99 iteration 122: 0.5440080165863037\n",
            "loss in epoch 99 iteration 123: 0.5631117224693298\n",
            "loss in epoch 99 iteration 124: 0.5399936437606812\n",
            "loss in epoch 99 iteration 125: 0.5729311108589172\n",
            "loss in epoch 99 iteration 126: 0.5699794292449951\n",
            "loss in epoch 99 iteration 127: 0.5463533401489258\n",
            "loss in epoch 99 iteration 128: 0.5650646686553955\n",
            "loss in epoch 99 iteration 129: 0.5714415311813354\n",
            "loss in epoch 99 iteration 130: 0.5790433883666992\n",
            "loss in epoch 99 iteration 131: 0.5396474599838257\n",
            "loss in epoch 99 iteration 132: 0.5505884885787964\n",
            "loss in epoch 99 iteration 133: 0.574262797832489\n",
            "loss in epoch 99 iteration 134: 0.5501089096069336\n",
            "loss in epoch 99 iteration 135: 0.5541137456893921\n",
            "loss in epoch 99 iteration 136: 0.5364071130752563\n",
            "loss in epoch 99 iteration 137: 0.5426793694496155\n",
            "loss in epoch 99 iteration 138: 0.5447593331336975\n",
            "loss in epoch 99 iteration 139: 0.5527642965316772\n",
            "loss in epoch 99 iteration 140: 0.5548559427261353\n",
            "loss in epoch 99 iteration 141: 0.5582672953605652\n",
            "loss in epoch 99 iteration 142: 0.5365387201309204\n",
            "loss in epoch 99 iteration 143: 0.558375358581543\n",
            "loss in epoch 99 iteration 144: 0.5560191869735718\n",
            "loss in epoch 99 iteration 145: 0.5650301575660706\n",
            "loss in epoch 99 iteration 146: 0.5693187117576599\n",
            "loss in epoch 99 iteration 147: 0.5430227518081665\n",
            "loss in epoch 99 iteration 148: 0.5682952404022217\n",
            "loss in epoch 99 iteration 149: 0.5637421011924744\n",
            "loss in epoch 99 iteration 150: 0.5632495880126953\n",
            "loss in epoch 99 iteration 151: 0.5471156239509583\n",
            "loss in epoch 99 iteration 152: 0.5530483722686768\n",
            "loss in epoch 99 iteration 153: 0.5681862831115723\n",
            "loss in epoch 99 iteration 154: 0.5532439351081848\n",
            "loss in epoch 99 iteration 155: 0.5700164437294006\n",
            "loss in epoch 99 iteration 156: 0.5680589079856873\n",
            "loss in epoch 99 iteration 157: 0.5943831205368042\n",
            "loss in epoch 99 iteration 158: 0.5636522769927979\n",
            "loss in epoch 99 iteration 159: 0.5690910220146179\n",
            "loss in epoch 99 iteration 160: 0.5688505172729492\n",
            "loss in epoch 99 iteration 161: 0.5505226254463196\n",
            "loss in epoch 99 iteration 162: 0.5569962859153748\n",
            "loss in epoch 99 iteration 163: 0.5541961789131165\n",
            "loss in epoch 99 iteration 164: 0.5534899234771729\n",
            "loss in epoch 99 iteration 165: 0.5821698904037476\n",
            "loss in epoch 99 iteration 166: 0.5526682138442993\n",
            "loss in epoch 99 iteration 167: 0.5432593822479248\n",
            "loss in epoch 99 iteration 168: 0.5758004188537598\n",
            "loss in epoch 99 iteration 169: 0.5622576475143433\n",
            "loss in epoch 99 iteration 170: 0.5690677762031555\n",
            "loss in epoch 99 iteration 171: 0.5487281680107117\n",
            "loss in epoch 99 iteration 172: 0.5705914497375488\n",
            "loss in epoch 99 iteration 173: 0.5502380132675171\n",
            "loss in epoch 99 iteration 174: 0.5337501764297485\n",
            "loss in epoch 99 iteration 175: 0.5304369330406189\n",
            "loss in epoch 99 iteration 176: 0.5612924098968506\n",
            "loss in epoch 99 iteration 177: 0.5713841915130615\n",
            "loss in epoch 99 iteration 178: 0.5833414793014526\n",
            "loss in epoch 99 iteration 179: 0.5608370900154114\n",
            "loss in epoch 99 iteration 180: 0.5614778995513916\n",
            "loss in epoch 99 iteration 181: 0.5522060394287109\n",
            "loss in epoch 99 iteration 182: 0.5506041049957275\n",
            "loss in epoch 99 iteration 183: 0.5411170721054077\n",
            "loss in epoch 99 iteration 184: 0.5850292444229126\n",
            "loss in epoch 99 iteration 185: 0.5483499765396118\n",
            "loss in epoch 99 iteration 186: 0.5751345157623291\n",
            "loss in epoch 99 iteration 187: 0.5681748390197754\n",
            "loss in epoch 99 iteration 188: 0.570832371711731\n",
            "loss in epoch 99 iteration 189: 0.5616096258163452\n",
            "loss in epoch 99 iteration 190: 0.5823533535003662\n",
            "loss in epoch 99 iteration 191: 0.5702540874481201\n",
            "loss in epoch 99 iteration 192: 0.5828015804290771\n",
            "loss in epoch 99 iteration 193: 0.5574637651443481\n",
            "loss in epoch 99 iteration 194: 0.5485161542892456\n",
            "loss in epoch 99 iteration 195: 0.5503717064857483\n",
            "loss in epoch 99 iteration 196: 0.5435841679573059\n",
            "loss in epoch 99 iteration 197: 0.5458980798721313\n",
            "loss in epoch 99 iteration 198: 0.5660727620124817\n",
            "loss in epoch 99 iteration 199: 0.5677317380905151\n",
            "loss in epoch 99 iteration 200: 0.5444362759590149\n",
            "loss in epoch 99 iteration 201: 0.5416617393493652\n",
            "loss in epoch 99 iteration 202: 0.5502185225486755\n",
            "loss in epoch 99 iteration 203: 0.5474929809570312\n",
            "loss in epoch 99 iteration 204: 0.5306220054626465\n",
            "loss in epoch 99 iteration 205: 0.5366544723510742\n",
            "loss in epoch 99 iteration 206: 0.5764243602752686\n",
            "loss in epoch 99 iteration 207: 0.570387601852417\n",
            "loss in epoch 99 iteration 208: 0.5546172857284546\n",
            "loss in epoch 99 iteration 209: 0.5601946115493774\n",
            "loss in epoch 99 iteration 210: 0.5663681030273438\n",
            "loss in epoch 99 iteration 211: 0.5634135603904724\n",
            "loss in epoch 99 iteration 212: 0.5533387660980225\n",
            "loss in epoch 99 iteration 213: 0.5579554438591003\n",
            "loss in epoch 99 iteration 214: 0.5481480360031128\n",
            "loss in epoch 99 iteration 215: 0.5396289229393005\n",
            "loss in epoch 99 iteration 216: 0.5352736711502075\n",
            "loss in epoch 99 iteration 217: 0.5457294583320618\n",
            "loss in epoch 99 iteration 218: 0.5267441272735596\n",
            "loss in epoch 99 iteration 219: 0.5571078062057495\n",
            "loss in epoch 99 iteration 220: 0.5616192817687988\n",
            "loss in epoch 99 iteration 221: 0.5366493463516235\n",
            "loss in epoch 99 iteration 222: 0.5447954535484314\n",
            "loss in epoch 99 iteration 223: 0.5493908524513245\n",
            "loss in epoch 99 iteration 224: 0.5534250736236572\n",
            "loss in epoch 99 iteration 225: 0.5638803243637085\n",
            "loss in epoch 99 iteration 226: 0.585996150970459\n",
            "loss in epoch 99 iteration 227: 0.5639646649360657\n",
            "loss in epoch 99 iteration 228: 0.5672785043716431\n",
            "loss in epoch 99 iteration 229: 0.5486866235733032\n",
            "loss in epoch 99 iteration 230: 0.5851063132286072\n",
            "loss in epoch 99 iteration 231: 0.5468122363090515\n",
            "loss in epoch 99 iteration 232: 0.559634268283844\n",
            "loss in epoch 99 iteration 233: 0.5554167032241821\n",
            "loss in epoch 99 iteration 234: 0.5530984401702881\n",
            "loss in epoch 99 iteration 235: 0.5666425824165344\n",
            "loss in epoch 99 iteration 236: 0.5466780662536621\n",
            "loss in epoch 99 iteration 237: 0.5581797957420349\n",
            "loss in epoch 99 iteration 238: 0.566676676273346\n",
            "loss in epoch 99 iteration 239: 0.5364603400230408\n",
            "loss in epoch 99 iteration 240: 0.5491151809692383\n",
            "loss in epoch 99 iteration 241: 0.5676811933517456\n",
            "loss in epoch 99 iteration 242: 0.5449392199516296\n",
            "loss in epoch 100 iteration 0: 0.5688598155975342\n",
            "loss in epoch 100 iteration 1: 0.5504668951034546\n",
            "loss in epoch 100 iteration 2: 0.5626131296157837\n",
            "loss in epoch 100 iteration 3: 0.5895919799804688\n",
            "loss in epoch 100 iteration 4: 0.5632708072662354\n",
            "loss in epoch 100 iteration 5: 0.5491857528686523\n",
            "loss in epoch 100 iteration 6: 0.5521472692489624\n",
            "loss in epoch 100 iteration 7: 0.5542941093444824\n",
            "loss in epoch 100 iteration 8: 0.5631304383277893\n",
            "loss in epoch 100 iteration 9: 0.5622032284736633\n",
            "loss in epoch 100 iteration 10: 0.5759154558181763\n",
            "loss in epoch 100 iteration 11: 0.5684520602226257\n",
            "loss in epoch 100 iteration 12: 0.5628424882888794\n",
            "loss in epoch 100 iteration 13: 0.5535870790481567\n",
            "loss in epoch 100 iteration 14: 0.5427546501159668\n",
            "loss in epoch 100 iteration 15: 0.5774291753768921\n",
            "loss in epoch 100 iteration 16: 0.542155385017395\n",
            "loss in epoch 100 iteration 17: 0.5722852945327759\n",
            "loss in epoch 100 iteration 18: 0.5260205268859863\n",
            "loss in epoch 100 iteration 19: 0.5205429196357727\n",
            "loss in epoch 100 iteration 20: 0.5514745712280273\n",
            "loss in epoch 100 iteration 21: 0.5511828660964966\n",
            "loss in epoch 100 iteration 22: 0.5759881138801575\n",
            "loss in epoch 100 iteration 23: 0.5677019357681274\n",
            "loss in epoch 100 iteration 24: 0.5668593049049377\n",
            "loss in epoch 100 iteration 25: 0.5521165132522583\n",
            "loss in epoch 100 iteration 26: 0.5633994340896606\n",
            "loss in epoch 100 iteration 27: 0.5503060221672058\n",
            "loss in epoch 100 iteration 28: 0.558974027633667\n",
            "loss in epoch 100 iteration 29: 0.5415684580802917\n",
            "loss in epoch 100 iteration 30: 0.5587203502655029\n",
            "loss in epoch 100 iteration 31: 0.5427135229110718\n",
            "loss in epoch 100 iteration 32: 0.5965437889099121\n",
            "loss in epoch 100 iteration 33: 0.5751103162765503\n",
            "loss in epoch 100 iteration 34: 0.551800012588501\n",
            "loss in epoch 100 iteration 35: 0.555233359336853\n",
            "loss in epoch 100 iteration 36: 0.5364812016487122\n",
            "loss in epoch 100 iteration 37: 0.559266984462738\n",
            "loss in epoch 100 iteration 38: 0.5563521981239319\n",
            "loss in epoch 100 iteration 39: 0.5655339360237122\n",
            "loss in epoch 100 iteration 40: 0.5270272493362427\n",
            "loss in epoch 100 iteration 41: 0.5555009245872498\n",
            "loss in epoch 100 iteration 42: 0.5862456560134888\n",
            "loss in epoch 100 iteration 43: 0.5630485415458679\n",
            "loss in epoch 100 iteration 44: 0.5617262125015259\n",
            "loss in epoch 100 iteration 45: 0.595024585723877\n",
            "loss in epoch 100 iteration 46: 0.572439432144165\n",
            "loss in epoch 100 iteration 47: 0.544990062713623\n",
            "loss in epoch 100 iteration 48: 0.5537443161010742\n",
            "loss in epoch 100 iteration 49: 0.5460543632507324\n",
            "loss in epoch 100 iteration 50: 0.5832902193069458\n",
            "loss in epoch 100 iteration 51: 0.5527162551879883\n",
            "loss in epoch 100 iteration 52: 0.5644542574882507\n",
            "loss in epoch 100 iteration 53: 0.5629316568374634\n",
            "loss in epoch 100 iteration 54: 0.5637747049331665\n",
            "loss in epoch 100 iteration 55: 0.5451959371566772\n",
            "loss in epoch 100 iteration 56: 0.5459504127502441\n",
            "loss in epoch 100 iteration 57: 0.5512175559997559\n",
            "loss in epoch 100 iteration 58: 0.5482223629951477\n",
            "loss in epoch 100 iteration 59: 0.5530816316604614\n",
            "loss in epoch 100 iteration 60: 0.5589002966880798\n",
            "loss in epoch 100 iteration 61: 0.5440993309020996\n",
            "loss in epoch 100 iteration 62: 0.5586833953857422\n",
            "loss in epoch 100 iteration 63: 0.5452337861061096\n",
            "loss in epoch 100 iteration 64: 0.5383781790733337\n",
            "loss in epoch 100 iteration 65: 0.5545961260795593\n",
            "loss in epoch 100 iteration 66: 0.5522670149803162\n",
            "loss in epoch 100 iteration 67: 0.5788041353225708\n",
            "loss in epoch 100 iteration 68: 0.5503438711166382\n",
            "loss in epoch 100 iteration 69: 0.537081241607666\n",
            "loss in epoch 100 iteration 70: 0.5617012977600098\n",
            "loss in epoch 100 iteration 71: 0.5396468639373779\n",
            "loss in epoch 100 iteration 72: 0.5671639442443848\n",
            "loss in epoch 100 iteration 73: 0.5558797121047974\n",
            "loss in epoch 100 iteration 74: 0.5406192541122437\n",
            "loss in epoch 100 iteration 75: 0.5714637637138367\n",
            "loss in epoch 100 iteration 76: 0.5301381945610046\n",
            "loss in epoch 100 iteration 77: 0.5638906955718994\n",
            "loss in epoch 100 iteration 78: 0.5439150333404541\n",
            "loss in epoch 100 iteration 79: 0.5685510039329529\n",
            "loss in epoch 100 iteration 80: 0.5241337418556213\n",
            "loss in epoch 100 iteration 81: 0.5948119163513184\n",
            "loss in epoch 100 iteration 82: 0.5559282898902893\n",
            "loss in epoch 100 iteration 83: 0.55522221326828\n",
            "loss in epoch 100 iteration 84: 0.5571880340576172\n",
            "loss in epoch 100 iteration 85: 0.59079909324646\n",
            "loss in epoch 100 iteration 86: 0.5573825836181641\n",
            "loss in epoch 100 iteration 87: 0.5643469095230103\n",
            "loss in epoch 100 iteration 88: 0.5614333152770996\n",
            "loss in epoch 100 iteration 89: 0.5332001447677612\n",
            "loss in epoch 100 iteration 90: 0.5459307432174683\n",
            "loss in epoch 100 iteration 91: 0.5516996383666992\n",
            "loss in epoch 100 iteration 92: 0.5567902326583862\n",
            "loss in epoch 100 iteration 93: 0.5571346282958984\n",
            "loss in epoch 100 iteration 94: 0.5561040043830872\n",
            "loss in epoch 100 iteration 95: 0.5935696363449097\n",
            "loss in epoch 100 iteration 96: 0.5761746168136597\n",
            "loss in epoch 100 iteration 97: 0.5669087171554565\n",
            "loss in epoch 100 iteration 98: 0.5527297258377075\n",
            "loss in epoch 100 iteration 99: 0.55897057056427\n",
            "loss in epoch 100 iteration 100: 0.5566014051437378\n",
            "loss in epoch 100 iteration 101: 0.5524389743804932\n",
            "loss in epoch 100 iteration 102: 0.5607239603996277\n",
            "loss in epoch 100 iteration 103: 0.5453734397888184\n",
            "loss in epoch 100 iteration 104: 0.5703467130661011\n",
            "loss in epoch 100 iteration 105: 0.5729135274887085\n",
            "loss in epoch 100 iteration 106: 0.5397011041641235\n",
            "loss in epoch 100 iteration 107: 0.5722025036811829\n",
            "loss in epoch 100 iteration 108: 0.5635566115379333\n",
            "loss in epoch 100 iteration 109: 0.5560304522514343\n",
            "loss in epoch 100 iteration 110: 0.5458027124404907\n",
            "loss in epoch 100 iteration 111: 0.5506452322006226\n",
            "loss in epoch 100 iteration 112: 0.577674925327301\n",
            "loss in epoch 100 iteration 113: 0.5697414875030518\n",
            "loss in epoch 100 iteration 114: 0.5475724935531616\n",
            "loss in epoch 100 iteration 115: 0.5484095215797424\n",
            "loss in epoch 100 iteration 116: 0.5646519660949707\n",
            "loss in epoch 100 iteration 117: 0.5675739049911499\n",
            "loss in epoch 100 iteration 118: 0.5579524040222168\n",
            "loss in epoch 100 iteration 119: 0.5465272665023804\n",
            "loss in epoch 100 iteration 120: 0.5651842355728149\n",
            "loss in epoch 100 iteration 121: 0.5553699731826782\n",
            "loss in epoch 100 iteration 122: 0.549458384513855\n",
            "loss in epoch 100 iteration 123: 0.569941520690918\n",
            "loss in epoch 100 iteration 124: 0.5584146976470947\n",
            "loss in epoch 100 iteration 125: 0.5638366937637329\n",
            "loss in epoch 100 iteration 126: 0.5822864174842834\n",
            "loss in epoch 100 iteration 127: 0.5443341732025146\n",
            "loss in epoch 100 iteration 128: 0.5815355181694031\n",
            "loss in epoch 100 iteration 129: 0.559714674949646\n",
            "loss in epoch 100 iteration 130: 0.575946569442749\n",
            "loss in epoch 100 iteration 131: 0.5521146059036255\n",
            "loss in epoch 100 iteration 132: 0.5598737001419067\n",
            "loss in epoch 100 iteration 133: 0.5628238916397095\n",
            "loss in epoch 100 iteration 134: 0.5618113279342651\n",
            "loss in epoch 100 iteration 135: 0.583213746547699\n",
            "loss in epoch 100 iteration 136: 0.5434718132019043\n",
            "loss in epoch 100 iteration 137: 0.5772859454154968\n",
            "loss in epoch 100 iteration 138: 0.5566406846046448\n",
            "loss in epoch 100 iteration 139: 0.5553216934204102\n",
            "loss in epoch 100 iteration 140: 0.5757296085357666\n",
            "loss in epoch 100 iteration 141: 0.5805851221084595\n",
            "loss in epoch 100 iteration 142: 0.5542121529579163\n",
            "loss in epoch 100 iteration 143: 0.5435577034950256\n",
            "loss in epoch 100 iteration 144: 0.5600696802139282\n",
            "loss in epoch 100 iteration 145: 0.5665274858474731\n",
            "loss in epoch 100 iteration 146: 0.5401484370231628\n",
            "loss in epoch 100 iteration 147: 0.5279630422592163\n",
            "loss in epoch 100 iteration 148: 0.5581068992614746\n",
            "loss in epoch 100 iteration 149: 0.5617139935493469\n",
            "loss in epoch 100 iteration 150: 0.5448799729347229\n",
            "loss in epoch 100 iteration 151: 0.5719359517097473\n",
            "loss in epoch 100 iteration 152: 0.5690662264823914\n",
            "loss in epoch 100 iteration 153: 0.5748488306999207\n",
            "loss in epoch 100 iteration 154: 0.5207377672195435\n",
            "loss in epoch 100 iteration 155: 0.5674690008163452\n",
            "loss in epoch 100 iteration 156: 0.5675069093704224\n",
            "loss in epoch 100 iteration 157: 0.5600128173828125\n",
            "loss in epoch 100 iteration 158: 0.5473874807357788\n",
            "loss in epoch 100 iteration 159: 0.561992883682251\n",
            "loss in epoch 100 iteration 160: 0.5600117444992065\n",
            "loss in epoch 100 iteration 161: 0.5500632524490356\n",
            "loss in epoch 100 iteration 162: 0.5567240118980408\n",
            "loss in epoch 100 iteration 163: 0.5553877353668213\n",
            "loss in epoch 100 iteration 164: 0.57687908411026\n",
            "loss in epoch 100 iteration 165: 0.5513937473297119\n",
            "loss in epoch 100 iteration 166: 0.5636196136474609\n",
            "loss in epoch 100 iteration 167: 0.5366388559341431\n",
            "loss in epoch 100 iteration 168: 0.5373954772949219\n",
            "loss in epoch 100 iteration 169: 0.5797686576843262\n",
            "loss in epoch 100 iteration 170: 0.5767722129821777\n",
            "loss in epoch 100 iteration 171: 0.5753679275512695\n",
            "loss in epoch 100 iteration 172: 0.5606968402862549\n",
            "loss in epoch 100 iteration 173: 0.5735015869140625\n",
            "loss in epoch 100 iteration 174: 0.5735456943511963\n",
            "loss in epoch 100 iteration 175: 0.5686075687408447\n",
            "loss in epoch 100 iteration 176: 0.5362213253974915\n",
            "loss in epoch 100 iteration 177: 0.5736925601959229\n",
            "loss in epoch 100 iteration 178: 0.5497045516967773\n",
            "loss in epoch 100 iteration 179: 0.5317153930664062\n",
            "loss in epoch 100 iteration 180: 0.5574876070022583\n",
            "loss in epoch 100 iteration 181: 0.542018711566925\n",
            "loss in epoch 100 iteration 182: 0.5628010034561157\n",
            "loss in epoch 100 iteration 183: 0.5693641901016235\n",
            "loss in epoch 100 iteration 184: 0.5314401388168335\n",
            "loss in epoch 100 iteration 185: 0.5580232739448547\n",
            "loss in epoch 100 iteration 186: 0.5431153774261475\n",
            "loss in epoch 100 iteration 187: 0.5579468011856079\n",
            "loss in epoch 100 iteration 188: 0.5557245016098022\n",
            "loss in epoch 100 iteration 189: 0.5557666420936584\n",
            "loss in epoch 100 iteration 190: 0.5415111184120178\n",
            "loss in epoch 100 iteration 191: 0.5783190727233887\n",
            "loss in epoch 100 iteration 192: 0.5540566444396973\n",
            "loss in epoch 100 iteration 193: 0.5677411556243896\n",
            "loss in epoch 100 iteration 194: 0.5726026892662048\n",
            "loss in epoch 100 iteration 195: 0.5480642914772034\n",
            "loss in epoch 100 iteration 196: 0.5541532039642334\n",
            "loss in epoch 100 iteration 197: 0.5494288802146912\n",
            "loss in epoch 100 iteration 198: 0.5626180768013\n",
            "loss in epoch 100 iteration 199: 0.5624666213989258\n",
            "loss in epoch 100 iteration 200: 0.5733624696731567\n",
            "loss in epoch 100 iteration 201: 0.5591459274291992\n",
            "loss in epoch 100 iteration 202: 0.5557265281677246\n",
            "loss in epoch 100 iteration 203: 0.5774160623550415\n",
            "loss in epoch 100 iteration 204: 0.5628268122673035\n",
            "loss in epoch 100 iteration 205: 0.5522841811180115\n",
            "loss in epoch 100 iteration 206: 0.561409592628479\n",
            "loss in epoch 100 iteration 207: 0.542665958404541\n",
            "loss in epoch 100 iteration 208: 0.5211861729621887\n",
            "loss in epoch 100 iteration 209: 0.5481621026992798\n",
            "loss in epoch 100 iteration 210: 0.5856044292449951\n",
            "loss in epoch 100 iteration 211: 0.5830020904541016\n",
            "loss in epoch 100 iteration 212: 0.5331990122795105\n",
            "loss in epoch 100 iteration 213: 0.5582963228225708\n",
            "loss in epoch 100 iteration 214: 0.5604465007781982\n",
            "loss in epoch 100 iteration 215: 0.5425841808319092\n",
            "loss in epoch 100 iteration 216: 0.5609089136123657\n",
            "loss in epoch 100 iteration 217: 0.566444993019104\n",
            "loss in epoch 100 iteration 218: 0.5761818885803223\n",
            "loss in epoch 100 iteration 219: 0.5755287408828735\n",
            "loss in epoch 100 iteration 220: 0.5501018762588501\n",
            "loss in epoch 100 iteration 221: 0.5625056624412537\n",
            "loss in epoch 100 iteration 222: 0.5597920417785645\n",
            "loss in epoch 100 iteration 223: 0.5491349697113037\n",
            "loss in epoch 100 iteration 224: 0.5308703184127808\n",
            "loss in epoch 100 iteration 225: 0.5386236906051636\n",
            "loss in epoch 100 iteration 226: 0.5516805052757263\n",
            "loss in epoch 100 iteration 227: 0.5896590948104858\n",
            "loss in epoch 100 iteration 228: 0.5610345602035522\n",
            "loss in epoch 100 iteration 229: 0.5486147999763489\n",
            "loss in epoch 100 iteration 230: 0.5498096346855164\n",
            "loss in epoch 100 iteration 231: 0.5456357002258301\n",
            "loss in epoch 100 iteration 232: 0.5628194212913513\n",
            "loss in epoch 100 iteration 233: 0.5523514151573181\n",
            "loss in epoch 100 iteration 234: 0.5771428346633911\n",
            "loss in epoch 100 iteration 235: 0.5639333128929138\n",
            "loss in epoch 100 iteration 236: 0.5381168723106384\n",
            "loss in epoch 100 iteration 237: 0.5611889362335205\n",
            "loss in epoch 100 iteration 238: 0.5571655035018921\n",
            "loss in epoch 100 iteration 239: 0.5632395148277283\n",
            "loss in epoch 100 iteration 240: 0.5706943273544312\n",
            "loss in epoch 100 iteration 241: 0.5803242921829224\n",
            "loss in epoch 100 iteration 242: 0.5336463451385498\n",
            "Evaluating........................................................................................................................................................................................................epoch:100, time: 626.973732(s), valid (NDCG@10: 0.5685, HR@10: 0.8217), test (NDCG@10: 0.5729, HR@10: 0.8247)\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --device=cuda --dataset=train --train_dir=default --inference_only=true --maxlen=50 --state_dict_path='/content/SASRec.pytorch/train_default/SASRec.epoch=100.lr=0.001.layer=2.head=1.hidden=50.maxlen=50.pth' "
      ],
      "metadata": {
        "id": "-kzmxHASUqgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0c94ab-4193-4c42-a68b-4c883b539b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average sequence length: 34.90\n",
            "100% 31137/31137 [01:41<00:00, 305.78it/s]\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_idx_map_inv = {item: idx for idx, item in item_idx_map.items()}\n",
        "\n",
        "sasrec_preds = json.load(open('sasrec_preds.json'))\n",
        "sasrec_preds = {user_idx_map_inv[int(user)]: [item_idx_map_inv[int(id)] for id in item] for user, item in sasrec_preds.items()}"
      ],
      "metadata": {
        "id": "cpDTWGIas8od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sasrec = pd.DataFrame({\n",
        "    'user_id': test['user_id'].unique()\n",
        "})\n",
        "\n",
        "sasrec['item_id'] = sasrec['user_id'].map(lambda x: sasrec_preds[x])\n",
        "sasrec = sasrec.explode('item_id')\n",
        "sasrec['item_id'] = sasrec['item_id'].astype(int)\n",
        "sasrec['rank'] = sasrec.groupby('user_id').cumcount() + 1 "
      ],
      "metadata": {
        "id": "G9V7gFnMwE30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sasrec_metrics = compute_metrics(test, sasrec, 10)\n",
        "sasrec_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNmXJsIIv-Lj",
        "outputId": "e84940c8-f337-4009-bf92-7d49e1e18292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Precision@1     0.000545\n",
              "Recall@1        0.000139\n",
              "Precision@2     0.000443\n",
              "Recall@2        0.000203\n",
              "Precision@3     0.000500\n",
              "Recall@3        0.000383\n",
              "Precision@4     0.000528\n",
              "Recall@4        0.000469\n",
              "Precision@5     0.000545\n",
              "Recall@5        0.000678\n",
              "Precision@6     0.000568\n",
              "Recall@6        0.000999\n",
              "Precision@7     0.000574\n",
              "Recall@7        0.001219\n",
              "Precision@8     0.000622\n",
              "Recall@8        0.001505\n",
              "Precision@9     0.000658\n",
              "Recall@9        0.001748\n",
              "Precision@10    0.000654\n",
              "Recall@10       0.001864\n",
              "MAP@10          0.000454\n",
              "MRR             0.001683\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    }
  ]
}