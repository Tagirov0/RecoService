{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 6\n",
        "4. Проэкспериментриуйте с различными моделями recbole и выберите лучшую. (4 балла)"
      ],
      "metadata": {
        "id": "CgSM18lFZMIb"
      },
      "id": "CgSM18lFZMIb"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install recbole ray >> None"
      ],
      "metadata": {
        "id": "3OMH-8kftUJP"
      },
      "id": "3OMH-8kftUJP",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6de2c8bc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:33:28.041759Z",
          "iopub.status.busy": "2022-11-27T16:33:28.041244Z",
          "iopub.status.idle": "2022-11-27T16:33:29.274165Z",
          "shell.execute_reply": "2022-11-27T16:33:29.272623Z"
        },
        "papermill": {
          "duration": 1.244043,
          "end_time": "2022-11-27T16:33:29.277270",
          "exception": false,
          "start_time": "2022-11-27T16:33:28.033227",
          "status": "completed"
        },
        "tags": [],
        "id": "6de2c8bc"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from collections import Counter\n",
        "from random import randint, random\n",
        "from scipy.sparse import coo_matrix, hstack\n",
        "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances, cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c54b3e92",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:33:29.290143Z",
          "iopub.status.busy": "2022-11-27T16:33:29.289663Z",
          "iopub.status.idle": "2022-11-27T16:33:29.294603Z",
          "shell.execute_reply": "2022-11-27T16:33:29.293618Z"
        },
        "papermill": {
          "duration": 0.013788,
          "end_time": "2022-11-27T16:33:29.297243",
          "exception": false,
          "start_time": "2022-11-27T16:33:29.283455",
          "status": "completed"
        },
        "tags": [],
        "id": "c54b3e92"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP0KTtyttAxk",
        "outputId": "1b1fe2c8-aced-475e-96b5-50bfd361c533"
      },
      "id": "dP0KTtyttAxk",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9052ce21",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:33:29.309390Z",
          "iopub.status.busy": "2022-11-27T16:33:29.308918Z",
          "iopub.status.idle": "2022-11-27T16:33:35.744619Z",
          "shell.execute_reply": "2022-11-27T16:33:35.743511Z"
        },
        "papermill": {
          "duration": 6.445298,
          "end_time": "2022-11-27T16:33:35.747539",
          "exception": false,
          "start_time": "2022-11-27T16:33:29.302241",
          "status": "completed"
        },
        "tags": [],
        "id": "9052ce21"
      },
      "outputs": [],
      "source": [
        "interactions_df = pd.read_csv('/content/drive/MyDrive/data/interactions_processed_kion.csv')\n",
        "users_df = pd.read_csv('/content/drive/MyDrive/data/users_processed_kion.csv')\n",
        "items_df = pd.read_csv('/content/drive/MyDrive/data/items_processed_kion.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0b371b15",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:33:35.759448Z",
          "iopub.status.busy": "2022-11-27T16:33:35.758615Z",
          "iopub.status.idle": "2022-11-27T16:33:36.674749Z",
          "shell.execute_reply": "2022-11-27T16:33:36.673314Z"
        },
        "papermill": {
          "duration": 0.925082,
          "end_time": "2022-11-27T16:33:36.677439",
          "exception": false,
          "start_time": "2022-11-27T16:33:35.752357",
          "status": "completed"
        },
        "tags": [],
        "id": "0b371b15"
      },
      "outputs": [],
      "source": [
        "interactions_df['t_dat'] = pd.to_datetime(interactions_df['last_watch_dt'], format=\"%Y-%m-%d\")\n",
        "interactions_df['timestamp'] = interactions_df.t_dat.values.astype(np.int64) // 10 ** 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7f075c88",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:33:36.688908Z",
          "iopub.status.busy": "2022-11-27T16:33:36.688507Z",
          "iopub.status.idle": "2022-11-27T16:33:36.963693Z",
          "shell.execute_reply": "2022-11-27T16:33:36.962323Z"
        },
        "papermill": {
          "duration": 0.284147,
          "end_time": "2022-11-27T16:33:36.966533",
          "exception": false,
          "start_time": "2022-11-27T16:33:36.682386",
          "status": "completed"
        },
        "tags": [],
        "id": "7f075c88"
      },
      "outputs": [],
      "source": [
        "df = interactions_df[['user_id', 'item_id', 'timestamp']].rename(\n",
        "    columns={'user_id': 'user_id:token', 'item_id': 'item_id:token', 'timestamp': 'timestamp:float'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aab347ea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:33:36.978797Z",
          "iopub.status.busy": "2022-11-27T16:33:36.977868Z",
          "iopub.status.idle": "2022-11-27T16:33:38.064289Z",
          "shell.execute_reply": "2022-11-27T16:33:38.062510Z"
        },
        "papermill": {
          "duration": 1.09547,
          "end_time": "2022-11-27T16:33:38.067180",
          "exception": false,
          "start_time": "2022-11-27T16:33:36.971710",
          "status": "completed"
        },
        "tags": [],
        "id": "aab347ea"
      },
      "outputs": [],
      "source": [
        "!mkdir recbox_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dff1fa1b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:33:38.079447Z",
          "iopub.status.busy": "2022-11-27T16:33:38.078986Z",
          "iopub.status.idle": "2022-11-27T16:33:45.904144Z",
          "shell.execute_reply": "2022-11-27T16:33:45.902874Z"
        },
        "papermill": {
          "duration": 7.834652,
          "end_time": "2022-11-27T16:33:45.906924",
          "exception": false,
          "start_time": "2022-11-27T16:33:38.072272",
          "status": "completed"
        },
        "tags": [],
        "id": "dff1fa1b"
      },
      "outputs": [],
      "source": [
        "df.to_csv('recbox_data/recbox_data.inter', index=False, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e126014d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:34:01.010002Z",
          "iopub.status.busy": "2022-11-27T16:34:01.009584Z",
          "iopub.status.idle": "2022-11-27T16:34:04.065652Z",
          "shell.execute_reply": "2022-11-27T16:34:04.064531Z"
        },
        "papermill": {
          "duration": 3.067001,
          "end_time": "2022-11-27T16:34:04.068318",
          "exception": false,
          "start_time": "2022-11-27T16:34:01.001317",
          "status": "completed"
        },
        "tags": [],
        "id": "e126014d"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from logging import getLogger\n",
        "from recbole.config import Config\n",
        "from recbole.data import create_dataset, data_preparation\n",
        "from recbole.model.sequential_recommender import GRU4Rec, Caser\n",
        "from recbole.trainer import Trainer\n",
        "from recbole.utils import init_seed, init_logger\n",
        "from recbole.quick_start import run_recbole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a4b97bdc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:34:04.084646Z",
          "iopub.status.busy": "2022-11-27T16:34:04.083930Z",
          "iopub.status.idle": "2022-11-27T16:34:04.217448Z",
          "shell.execute_reply": "2022-11-27T16:34:04.216060Z"
        },
        "papermill": {
          "duration": 0.145622,
          "end_time": "2022-11-27T16:34:04.220395",
          "exception": false,
          "start_time": "2022-11-27T16:34:04.074773",
          "status": "completed"
        },
        "tags": [],
        "id": "a4b97bdc"
      },
      "outputs": [],
      "source": [
        "parameter_dict = {\n",
        "    'data_path': '',\n",
        "    'USER_ID_FIELD': 'user_id',\n",
        "    'ITEM_ID_FIELD': 'item_id',\n",
        "    'TIME_FIELD': 'timestamp',\n",
        "    'device': 'GPU',\n",
        "    'user_inter_num_interval': \"[40,inf)\",\n",
        "    'item_inter_num_interval': \"[40,inf)\",\n",
        "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
        "    'neg_sampling': None,\n",
        "    'epochs': 10,\n",
        "    'eval_args': {\n",
        "        'split': {'RS': [9, 0, 1]},\n",
        "        'group_by': 'user',\n",
        "        'order': 'TO',\n",
        "        'mode': 'full'}\n",
        "}\n",
        "config = Config(model='MultiVAE', dataset='recbox_data', config_dict=parameter_dict)\n",
        "\n",
        "# init random seed\n",
        "init_seed(config['seed'], config['reproducibility'])\n",
        "\n",
        "# logger initialization\n",
        "init_logger(config)\n",
        "logger = getLogger()\n",
        "# Create handlers\n",
        "c_handler = logging.StreamHandler()\n",
        "c_handler.setLevel(logging.INFO)\n",
        "logger.addHandler(c_handler)\n",
        "\n",
        "# write config info into log\n",
        "# logger.info(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d6d18eea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:34:04.236251Z",
          "iopub.status.busy": "2022-11-27T16:34:04.235805Z",
          "iopub.status.idle": "2022-11-27T16:34:46.795905Z",
          "shell.execute_reply": "2022-11-27T16:34:46.794283Z"
        },
        "papermill": {
          "duration": 42.583583,
          "end_time": "2022-11-27T16:34:46.811041",
          "exception": false,
          "start_time": "2022-11-27T16:34:04.227458",
          "status": "completed"
        },
        "tags": [],
        "id": "d6d18eea"
      },
      "outputs": [],
      "source": [
        "dataset = create_dataset(config)\n",
        "logger.info(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "66706c2e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:34:46.827485Z",
          "iopub.status.busy": "2022-11-27T16:34:46.827025Z",
          "iopub.status.idle": "2022-11-27T16:34:49.051342Z",
          "shell.execute_reply": "2022-11-27T16:34:49.049929Z"
        },
        "papermill": {
          "duration": 2.241551,
          "end_time": "2022-11-27T16:34:49.059852",
          "exception": false,
          "start_time": "2022-11-27T16:34:46.818301",
          "status": "completed"
        },
        "tags": [],
        "id": "66706c2e"
      },
      "outputs": [],
      "source": [
        "# dataset splitting\n",
        "train_data, valid_data, test_data = data_preparation(config, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "606dedb1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:34:49.078524Z",
          "iopub.status.busy": "2022-11-27T16:34:49.078069Z",
          "iopub.status.idle": "2022-11-27T16:34:49.082700Z",
          "shell.execute_reply": "2022-11-27T16:34:49.081542Z"
        },
        "papermill": {
          "duration": 0.01694,
          "end_time": "2022-11-27T16:34:49.085164",
          "exception": false,
          "start_time": "2022-11-27T16:34:49.068224",
          "status": "completed"
        },
        "tags": [],
        "id": "606dedb1"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "потестим несколько моделей"
      ],
      "metadata": {
        "id": "Jyh44x4SanCB"
      },
      "id": "Jyh44x4SanCB"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model_list = ['ADMMSLIM'] \n",
        "\n",
        "for model_name in model_list:\n",
        "    print(f\"running {model_name}...\")\n",
        "    start = time.time()\n",
        "    result = run_recbole(model=model_name, dataset = 'recbox_data',config_dict = parameter_dict)\n",
        "    t = time.time() - start\n",
        "    print(f\"It took {t/60:.2f} mins\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgwo667rVF4g",
        "outputId": "c45bbaa4-e040-4da5-c96c-1d978fda7536"
      },
      "id": "Lgwo667rVF4g",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running ADMMSLIM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train     0: 100%|███████████████████████| 755/755 [00:22<00:00, 32.90it/s, GPU RAM: 0.00 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [07:47<00:00, 28.57it/s, GPU RAM: 0.00 G/14.76 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 11.15 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0982), ('mrr@10', 0.1872), ('ndcg@10', 0.0935), ('hit@10', 0.4019), ('precision@10', 0.0542)])}\n",
            "CPU times: user 10min 8s, sys: 3min 41s, total: 13min 50s\n",
            "Wall time: 11min 8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "02f721d5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-28T00:09:13.508805Z",
          "iopub.status.busy": "2022-11-28T00:09:13.508342Z",
          "iopub.status.idle": "2022-11-28T00:11:03.682512Z",
          "shell.execute_reply": "2022-11-28T00:11:03.681538Z"
        },
        "papermill": {
          "duration": 112.660326,
          "end_time": "2022-11-28T00:11:03.684802",
          "exception": false,
          "start_time": "2022-11-28T00:09:11.024476",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02f721d5",
        "outputId": "1b078634-9c9f-4eba-963a-0891af02559a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running BPR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train     0: 100%|███████████████████████| 378/378 [00:18<00:00, 20.14it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████| 378/378 [00:18<00:00, 20.25it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████| 378/378 [00:18<00:00, 20.14it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████| 378/378 [00:18<00:00, 20.91it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████| 378/378 [00:18<00:00, 20.13it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████| 378/378 [00:19<00:00, 19.70it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████| 378/378 [00:18<00:00, 20.03it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████| 378/378 [00:19<00:00, 19.47it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████| 378/378 [00:18<00:00, 20.37it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████| 378/378 [00:18<00:00, 20.00it/s, GPU RAM: 0.03 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [07:46<00:00, 28.61it/s, GPU RAM: 0.05 G/14.76 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 11.67 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0824), ('mrr@10', 0.1716), ('ndcg@10', 0.0819), ('hit@10', 0.3479), ('precision@10', 0.0457)])}\n",
            "CPU times: user 9min 22s, sys: 59.2 s, total: 10min 21s\n",
            "Wall time: 11min 40s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "model_list = ['BPR'] \n",
        "\n",
        "for model_name in model_list:\n",
        "    print(f\"running {model_name}...\")\n",
        "    start = time.time()\n",
        "    result = run_recbole(model=model_name, dataset = 'recbox_data',config_dict = parameter_dict)\n",
        "    t = time.time() - start\n",
        "    print(f\"It took {t/60:.2f} mins\")\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model_list = ['CDAE'] \n",
        "\n",
        "for model_name in model_list:\n",
        "    print(f\"running {model_name}...\")\n",
        "    start = time.time()\n",
        "    result = run_recbole(model=model_name, dataset = 'recbox_data',config_dict = parameter_dict)\n",
        "    t = time.time() - start\n",
        "    print(f\"It took {t/60:.2f} mins\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iw_bIBFY_ai",
        "outputId": "5fd068dc-c85c-4d5d-ebc7-0da468209846"
      },
      "id": "4iw_bIBFY_ai",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running CDAE...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.28it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00, 24.24it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00, 23.05it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 25.28it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00, 24.05it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00, 23.41it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00, 25.29it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00, 22.69it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00, 23.15it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00, 22.20it/s, GPU RAM: 0.37 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [04:04<00:00, 54.61it/s, GPU RAM: 0.37 G/14.76 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 5.06 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0634), ('mrr@10', 0.1428), ('ndcg@10', 0.0657), ('hit@10', 0.2724), ('precision@10', 0.0344)])}\n",
            "CPU times: user 4min 24s, sys: 16.4 s, total: 4min 40s\n",
            "Wall time: 5min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model_list = ['ConvNCF'] \n",
        "\n",
        "for model_name in model_list:\n",
        "    print(f\"running {model_name}...\")\n",
        "    start = time.time()\n",
        "    result = run_recbole(model=model_name, dataset = 'recbox_data',config_dict = parameter_dict)\n",
        "    t = time.time() - start\n",
        "    print(f\"It took {t/60:.2f} mins\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJuv4v6BeEmH",
        "outputId": "2917b3aa-382c-4e45-b8d7-3225d6b36dfd"
      },
      "id": "FJuv4v6BeEmH",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running ConvNCF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train     0: 100%|███████████████████████| 378/378 [00:53<00:00,  7.08it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████| 378/378 [00:51<00:00,  7.28it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████| 378/378 [00:53<00:00,  7.11it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████| 378/378 [00:52<00:00,  7.21it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████| 378/378 [00:53<00:00,  7.08it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████| 378/378 [00:51<00:00,  7.30it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████| 378/378 [00:52<00:00,  7.15it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████| 378/378 [00:52<00:00,  7.23it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████| 378/378 [00:55<00:00,  6.81it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████| 378/378 [00:53<00:00,  7.02it/s, GPU RAM: 0.50 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [10:17<00:00, 21.63it/s, GPU RAM: 0.70 G/14.76 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 19.92 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0618), ('mrr@10', 0.1353), ('ndcg@10', 0.063), ('hit@10', 0.2675), ('precision@10', 0.0334)])}\n",
            "CPU times: user 17min 6s, sys: 1min 24s, total: 18min 31s\n",
            "Wall time: 19min 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "модели с урока"
      ],
      "metadata": {
        "id": "w_Rt4tT-7jrT"
      },
      "id": "w_Rt4tT-7jrT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f5ae775",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-27T16:34:49.103661Z",
          "iopub.status.busy": "2022-11-27T16:34:49.103250Z",
          "iopub.status.idle": "2022-11-28T00:09:08.384762Z",
          "shell.execute_reply": "2022-11-28T00:09:08.383614Z"
        },
        "papermill": {
          "duration": 27259.293886,
          "end_time": "2022-11-28T00:09:08.387403",
          "exception": false,
          "start_time": "2022-11-27T16:34:49.093517",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5f5ae775",
        "outputId": "4c910f72-80aa-4879-d3ff-07eedc0e345c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running MultiVAE...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:02<00:00,  2.60it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00, 17.89it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00, 15.75it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 12.31it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00,  9.91it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00, 11.41it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00, 10.69it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00, 16.01it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00, 15.03it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00, 15.32it/s, GPU RAM: 0.36 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [04:49<00:00, 46.11it/s, GPU RAM: 0.36 G/14.76 G]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It took 6.13 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0834), ('mrr@10', 0.1671), ('ndcg@10', 0.0816), ('hit@10', 0.3466), ('precision@10', 0.0462)])}\n",
            "running MultiDAE...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:00<00:00, 18.84it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00, 18.16it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00, 16.50it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 17.37it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00, 17.18it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00, 16.57it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00, 16.93it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00, 18.03it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00, 14.85it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00, 14.55it/s, GPU RAM: 0.38 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [06:15<00:00, 35.60it/s, GPU RAM: 0.38 G/14.76 G]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It took 7.20 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0837), ('mrr@10', 0.1657), ('ndcg@10', 0.0814), ('hit@10', 0.3466), ('precision@10', 0.0463)])}\n",
            "running MacridVAE...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.28it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.39it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.48it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.48it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.46it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:02<00:00,  2.47it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:03<00:00,  2.29it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.43it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.43it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.43it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [09:03<00:00, 24.57it/s, GPU RAM: 0.93 G/14.76 G]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It took 10.28 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0827), ('mrr@10', 0.1548), ('ndcg@10', 0.0775), ('hit@10', 0.3469), ('precision@10', 0.0455)])}\n",
            "running NeuMF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train     0: 100%|███████████████████████| 755/755 [00:46<00:00, 16.36it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████| 755/755 [00:48<00:00, 15.73it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████| 755/755 [00:48<00:00, 15.65it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████| 755/755 [00:48<00:00, 15.57it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████| 755/755 [00:48<00:00, 15.68it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████| 755/755 [00:48<00:00, 15.67it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████| 755/755 [00:48<00:00, 15.61it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████| 755/755 [00:48<00:00, 15.57it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████| 755/755 [00:48<00:00, 15.69it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████| 755/755 [00:48<00:00, 15.72it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [07:21<00:00, 30.22it/s, GPU RAM: 0.93 G/14.76 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 16.23 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0687), ('mrr@10', 0.1187), ('ndcg@10', 0.0608), ('hit@10', 0.3019), ('precision@10', 0.038)])}\n",
            "running RecVAE...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  5.88it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.03it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.03it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.14it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.74it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.44it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.59it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.54it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.82it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.56it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.41it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.23it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.52it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.51it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.80it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.83it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.72it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.60it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.98it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.81it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.12it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.93it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.29it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.73it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.95it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.27it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.54it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.23it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.40it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.88it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.20it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.98it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.01it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.99it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.17it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.87it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.36it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.76it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.06it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:01<00:00,  5.75it/s, GPU RAM: 0.93 G/14.76 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [08:55<00:00, 24.94it/s, GPU RAM: 0.93 G/14.76 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 10.43 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0846), ('mrr@10', 0.1661), ('ndcg@10', 0.0818), ('hit@10', 0.3523), ('precision@10', 0.0469)])}\n",
            "running RepeatNet...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train     0: 100%|███████████████████████| 743/743 [16:18<00:00,  1.32s/it, GPU RAM: 4.00 G/14.76 G]\n",
            "Train     1: 100%|███████████████████████| 743/743 [16:16<00:00,  1.31s/it, GPU RAM: 4.00 G/14.76 G]\n",
            "Train     2:  94%|█████████████████████▋ | 701/743 [15:23<00:55,  1.32s/it, GPU RAM: 4.00 G/14.76 G]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/recbole/quick_start/quick_start.py\u001b[0m in \u001b[0;36mrun_recbole\u001b[0;34m(model, dataset, config_file_list, config_dict, saved)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     best_valid_score, best_valid_result = trainer.fit(\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"show_progress\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/recbole/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mtraining_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             train_loss = self._train_epoch(\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/recbole/trainer/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, train_data, epoch_idx, loss_func, show_progress)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 )\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msync_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "model_list = ['MultiVAE', 'MultiDAE', 'MacridVAE', \n",
        "              \"NeuMF\", \"RecVAE\", 'RepeatNet'] \n",
        "\n",
        "for model_name in model_list:\n",
        "    print(f\"running {model_name}...\")\n",
        "    start = time.time()\n",
        "    result = run_recbole(model=model_name, dataset = 'recbox_data',config_dict = parameter_dict)\n",
        "    t = time.time() - start\n",
        "    print(f\"It took {t/60:.2f} mins\")\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "лучшая модель - ADMMSLIM - Sparse Recommendations for Many Users"
      ],
      "metadata": {
        "id": "g1BKw5HslzND"
      },
      "id": "g1BKw5HslzND"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27491.154881,
      "end_time": "2022-11-28T00:11:27.624787",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-11-27T16:33:16.469906",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}